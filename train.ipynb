{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdeacc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Use multi-GPU setting ------\n",
      "if you stuck too long time with multi-GPU setting, try to set --workers 0\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
      "epoch : 0 [0/21279] Train loss: 8.01477,Valid loss: 7.96785, time : 43.055087089538574 lr : 1\n",
      "epoch : 0 [1/21279] Train loss: 7.90191,Valid loss: 7.95940, time : 10.63684606552124 lr : 1\n",
      "epoch : 0 [2/21279] Train loss: 7.76160,Valid loss: 7.92126, time : 10.193422079086304 lr : 1\n",
      "epoch : 0 [3/21279] Train loss: 7.57548,Valid loss: 7.62940, time : 10.5014328956604 lr : 1\n",
      "epoch : 0 [4/21279] Train loss: 7.32230,Valid loss: 7.44721, time : 10.221692562103271 lr : 1\n",
      "epoch : 0 [5/21279] Train loss: 7.04555,Valid loss: 6.98430, time : 10.762374639511108 lr : 1\n",
      "epoch : 0 [6/21279] Train loss: 6.85669,Valid loss: 6.81894, time : 10.311545372009277 lr : 1\n",
      "epoch : 0 [7/21279] Train loss: 6.76436,Valid loss: 6.71911, time : 10.600326299667358 lr : 1\n",
      "epoch : 0 [8/21279] Train loss: 6.68045,Valid loss: 6.63459, time : 10.21271014213562 lr : 1\n",
      "epoch : 0 [9/21279] Train loss: 6.61105,Valid loss: 6.55293, time : 13.480132579803467 lr : 1\n",
      "epoch : 0 [10/21279] Train loss: 6.54233,Valid loss: 6.49548, time : 10.963903665542603 lr : 1\n",
      "epoch : 0 [11/21279] Train loss: 6.50062,Valid loss: 6.37392, time : 10.653622388839722 lr : 1\n",
      "epoch : 0 [12/21279] Train loss: 6.38807,Valid loss: 6.29163, time : 10.627821683883667 lr : 1\n",
      "epoch : 0 [13/21279] Train loss: 6.32683,Valid loss: 6.22189, time : 11.06947135925293 lr : 1\n",
      "epoch : 0 [14/21279] Train loss: 6.24832,Valid loss: 6.15653, time : 10.768618822097778 lr : 1\n",
      "epoch : 0 [15/21279] Train loss: 6.19394,Valid loss: 6.10134, time : 10.813964128494263 lr : 1\n",
      "epoch : 0 [16/21279] Train loss: 6.12961,Valid loss: 6.04295, time : 11.175638914108276 lr : 1\n",
      "epoch : 0 [17/21279] Train loss: 6.09297,Valid loss: 5.99539, time : 11.38888168334961 lr : 1\n",
      "epoch : 0 [18/21279] Train loss: 6.02147,Valid loss: 5.94003, time : 11.198535680770874 lr : 1\n",
      "epoch : 0 [19/21279] Train loss: 5.97983,Valid loss: 5.91092, time : 10.629064083099365 lr : 1\n",
      "epoch : 0 [20/21279] Train loss: 5.93094,Valid loss: 5.86853, time : 11.049783945083618 lr : 1\n",
      "epoch : 0 [21/21279] Train loss: 5.89317,Valid loss: 5.86324, time : 13.841514348983765 lr : 1\n",
      "epoch : 0 [22/21279] Train loss: 5.87429,Valid loss: 5.81584, time : 10.554014444351196 lr : 1\n",
      "epoch : 0 [23/21279] Train loss: 5.85129,Valid loss: 5.80532, time : 10.686913013458252 lr : 1\n",
      "epoch : 0 [24/21279] Train loss: 5.80391,Valid loss: 5.75823, time : 10.952569484710693 lr : 1\n",
      "epoch : 0 [25/21279] Train loss: 5.76374,Valid loss: 5.74470, time : 11.005373001098633 lr : 1\n",
      "epoch : 0 [26/21279] Train loss: 5.73491,Valid loss: 5.71484, time : 10.571889162063599 lr : 1\n",
      "epoch : 0 [27/21279] Train loss: 5.70306,Valid loss: 5.70519, time : 11.132534503936768 lr : 1\n",
      "epoch : 0 [28/21279] Train loss: 5.67668,Valid loss: 5.68299, time : 11.278791666030884 lr : 1\n",
      "epoch : 0 [29/21279] Train loss: 5.64701,Valid loss: 5.67803, time : 11.37347149848938 lr : 1\n",
      "epoch : 0 [30/21279] Train loss: 5.63901,Valid loss: 5.65375, time : 11.725461721420288 lr : 1\n",
      "epoch : 0 [31/21279] Train loss: 5.65970,Valid loss: 5.65934, time : 11.293183326721191 lr : 1\n",
      "epoch : 0 [32/21279] Train loss: 5.62681,Valid loss: 5.63755, time : 11.790255784988403 lr : 1\n",
      "epoch : 0 [33/21279] Train loss: 5.60528,Valid loss: 5.64026, time : 10.727712869644165 lr : 1\n",
      "epoch : 0 [34/21279] Train loss: 5.59375,Valid loss: 5.62614, time : 11.04775357246399 lr : 1\n",
      "epoch : 0 [35/21279] Train loss: 5.58187,Valid loss: 5.62335, time : 11.187451601028442 lr : 1\n",
      "epoch : 0 [36/21279] Train loss: 5.59804,Valid loss: 5.60611, time : 10.771371364593506 lr : 1\n",
      "epoch : 0 [37/21279] Train loss: 5.57167,Valid loss: 5.60580, time : 13.01903772354126 lr : 1\n",
      "epoch : 0 [38/21279] Train loss: 5.54762,Valid loss: 5.59406, time : 11.230410814285278 lr : 1\n",
      "epoch : 0 [39/21279] Train loss: 5.53566,Valid loss: 5.58725, time : 10.84036636352539 lr : 1\n",
      "epoch : 0 [40/21279] Train loss: 5.53833,Valid loss: 5.58210, time : 11.267743110656738 lr : 1\n",
      "epoch : 0 [41/21279] Train loss: 5.52971,Valid loss: 5.57597, time : 10.683049440383911 lr : 1\n",
      "epoch : 0 [42/21279] Train loss: 5.53038,Valid loss: 5.57723, time : 11.189059257507324 lr : 1\n",
      "epoch : 0 [43/21279] Train loss: 5.50383,Valid loss: 5.56313, time : 11.107049942016602 lr : 1\n",
      "epoch : 0 [44/21279] Train loss: 5.52711,Valid loss: 5.56703, time : 10.768015623092651 lr : 1\n",
      "epoch : 0 [45/21279] Train loss: 5.50612,Valid loss: 5.55294, time : 11.073904514312744 lr : 1\n",
      "epoch : 0 [46/21279] Train loss: 5.50794,Valid loss: 5.55987, time : 10.82371735572815 lr : 1\n",
      "epoch : 0 [47/21279] Train loss: 5.47673,Valid loss: 5.53628, time : 11.350835800170898 lr : 1\n",
      "epoch : 0 [48/21279] Train loss: 5.47432,Valid loss: 5.54218, time : 10.768852949142456 lr : 1\n",
      "epoch : 0 [49/21279] Train loss: 5.47640,Valid loss: 5.52515, time : 15.789013385772705 lr : 1\n",
      "epoch : 0 [50/21279] Train loss: 5.48864,Valid loss: 5.54341, time : 11.28446912765503 lr : 1\n",
      "epoch : 0 [51/21279] Train loss: 5.47154,Valid loss: 5.54620, time : 10.769607305526733 lr : 1\n",
      "epoch : 0 [52/21279] Train loss: 5.49873,Valid loss: 5.53986, time : 11.653933048248291 lr : 1\n",
      "epoch : 0 [53/21279] Train loss: 5.48006,Valid loss: 5.51415, time : 10.534518003463745 lr : 1\n",
      "epoch : 0 [54/21279] Train loss: 5.45920,Valid loss: 5.51647, time : 11.176678895950317 lr : 1\n",
      "epoch : 0 [55/21279] Train loss: 5.44555,Valid loss: 5.50563, time : 11.817422151565552 lr : 1\n",
      "epoch : 0 [56/21279] Train loss: 5.43315,Valid loss: 5.51428, time : 11.439952611923218 lr : 1\n",
      "epoch : 0 [57/21279] Train loss: 5.42970,Valid loss: 5.50383, time : 11.938392877578735 lr : 1\n",
      "epoch : 0 [58/21279] Train loss: 5.45330,Valid loss: 5.50939, time : 10.956292867660522 lr : 1\n",
      "epoch : 0 [59/21279] Train loss: 5.44030,Valid loss: 5.49187, time : 11.358440160751343 lr : 1\n",
      "epoch : 0 [60/21279] Train loss: 5.45849,Valid loss: 5.49381, time : 11.453429460525513 lr : 1\n",
      "epoch : 0 [61/21279] Train loss: 5.43640,Valid loss: 5.47933, time : 11.505226612091064 lr : 1\n",
      "epoch : 0 [62/21279] Train loss: 5.41861,Valid loss: 5.52437, time : 11.53178334236145 lr : 1\n",
      "epoch : 0 [63/21279] Train loss: 5.44177,Valid loss: 5.52439, time : 11.587700128555298 lr : 1\n",
      "epoch : 0 [64/21279] Train loss: 5.45268,Valid loss: 5.51028, time : 11.804184198379517 lr : 1\n",
      "epoch : 0 [65/21279] Train loss: 5.43678,Valid loss: 5.47666, time : 14.311158895492554 lr : 1\n",
      "epoch : 0 [66/21279] Train loss: 5.41849,Valid loss: 5.47476, time : 11.626091718673706 lr : 1\n",
      "epoch : 0 [67/21279] Train loss: 5.40518,Valid loss: 5.46170, time : 11.435272693634033 lr : 1\n",
      "epoch : 0 [68/21279] Train loss: 5.38891,Valid loss: 5.49810, time : 11.169053077697754 lr : 1\n",
      "epoch : 0 [69/21279] Train loss: 5.41005,Valid loss: 5.50389, time : 11.684751272201538 lr : 1\n",
      "epoch : 0 [70/21279] Train loss: 5.45253,Valid loss: 5.49458, time : 12.029775142669678 lr : 1\n",
      "epoch : 0 [71/21279] Train loss: 5.41821,Valid loss: 5.46647, time : 12.007930040359497 lr : 1\n",
      "epoch : 0 [72/21279] Train loss: 5.40132,Valid loss: 5.46884, time : 11.967381715774536 lr : 1\n",
      "epoch : 0 [73/21279] Train loss: 5.39258,Valid loss: 5.45394, time : 11.448612213134766 lr : 1\n",
      "epoch : 0 [74/21279] Train loss: 5.37863,Valid loss: 5.45755, time : 12.249468326568604 lr : 1\n",
      "epoch : 0 [75/21279] Train loss: 5.37953,Valid loss: 5.44774, time : 11.868499517440796 lr : 1\n",
      "epoch : 0 [76/21279] Train loss: 5.38211,Valid loss: 5.45646, time : 11.595628023147583 lr : 1\n",
      "epoch : 0 [77/21279] Train loss: 5.39914,Valid loss: 5.45632, time : 11.979285955429077 lr : 1\n",
      "epoch : 0 [78/21279] Train loss: 5.39788,Valid loss: 5.47382, time : 13.888166189193726 lr : 1\n",
      "epoch : 0 [79/21279] Train loss: 5.39592,Valid loss: 5.44547, time : 11.959158897399902 lr : 1\n",
      "epoch : 0 [80/21279] Train loss: 5.37930,Valid loss: 5.44284, time : 11.26604700088501 lr : 1\n",
      "epoch : 0 [81/21279] Train loss: 5.39485,Valid loss: 5.42219, time : 12.041781902313232 lr : 1\n",
      "epoch : 0 [82/21279] Train loss: 5.38153,Valid loss: 5.45629, time : 11.574002027511597 lr : 1\n",
      "epoch : 0 [83/21279] Train loss: 5.39861,Valid loss: 5.47677, time : 11.078085660934448 lr : 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [84/21279] Train loss: 5.41221,Valid loss: 5.49292, time : 11.272991418838501 lr : 1\n",
      "epoch : 0 [85/21279] Train loss: 5.40791,Valid loss: 5.43533, time : 11.626311779022217 lr : 1\n",
      "epoch : 0 [86/21279] Train loss: 5.34941,Valid loss: 5.42027, time : 11.131417751312256 lr : 1\n",
      "epoch : 0 [87/21279] Train loss: 5.35101,Valid loss: 5.40940, time : 11.41591501235962 lr : 1\n",
      "epoch : 0 [88/21279] Train loss: 5.33876,Valid loss: 5.40374, time : 11.632770776748657 lr : 1\n",
      "epoch : 0 [89/21279] Train loss: 5.34406,Valid loss: 5.39797, time : 12.163928270339966 lr : 1\n",
      "epoch : 0 [90/21279] Train loss: 5.34067,Valid loss: 5.43872, time : 11.281046152114868 lr : 1\n",
      "epoch : 0 [91/21279] Train loss: 5.39648,Valid loss: 5.46886, time : 11.134479999542236 lr : 1\n",
      "epoch : 0 [92/21279] Train loss: 5.39831,Valid loss: 5.46828, time : 11.319393634796143 lr : 1\n",
      "epoch : 0 [93/21279] Train loss: 5.38359,Valid loss: 5.43556, time : 13.137430667877197 lr : 1\n",
      "epoch : 0 [94/21279] Train loss: 5.37351,Valid loss: 5.40691, time : 11.814749717712402 lr : 1\n",
      "epoch : 0 [95/21279] Train loss: 5.35069,Valid loss: 5.42517, time : 11.741566896438599 lr : 1\n",
      "epoch : 0 [96/21279] Train loss: 5.33860,Valid loss: 5.40262, time : 11.212947130203247 lr : 1\n",
      "epoch : 0 [97/21279] Train loss: 5.35849,Valid loss: 5.45256, time : 11.266962051391602 lr : 1\n",
      "epoch : 0 [98/21279] Train loss: 5.35690,Valid loss: 5.42460, time : 11.505337238311768 lr : 1\n",
      "epoch : 0 [99/21279] Train loss: 5.38416,Valid loss: 5.44316, time : 11.453402519226074 lr : 1\n",
      "epoch : 0 [100/21279] Train loss: 5.36151,Valid loss: 5.40020, time : 11.275737762451172 lr : 1\n",
      "epoch : 0 [101/21279] Train loss: 5.35332,Valid loss: 5.41146, time : 11.60727071762085 lr : 1\n",
      "epoch : 0 [102/21279] Train loss: 5.33418,Valid loss: 5.38594, time : 11.953143835067749 lr : 1\n",
      "epoch : 0 [103/21279] Train loss: 5.33117,Valid loss: 5.44112, time : 11.026046752929688 lr : 1\n",
      "epoch : 0 [104/21279] Train loss: 5.36165,Valid loss: 5.43920, time : 11.267732620239258 lr : 1\n",
      "epoch : 0 [105/21279] Train loss: 5.40361,Valid loss: 5.44215, time : 12.433201551437378 lr : 1\n",
      "epoch : 0 [106/21279] Train loss: 5.36429,Valid loss: 5.39075, time : 11.476086854934692 lr : 1\n",
      "epoch : 0 [107/21279] Train loss: 5.34012,Valid loss: 5.39489, time : 10.984962224960327 lr : 1\n",
      "epoch : 0 [108/21279] Train loss: 5.33250,Valid loss: 5.37710, time : 11.188261032104492 lr : 1\n",
      "epoch : 0 [109/21279] Train loss: 5.34859,Valid loss: 5.40003, time : 10.969206809997559 lr : 1\n",
      "epoch : 0 [110/21279] Train loss: 5.31615,Valid loss: 5.39825, time : 11.940385103225708 lr : 1\n",
      "epoch : 0 [111/21279] Train loss: 5.35410,Valid loss: 5.45531, time : 11.562174797058105 lr : 1\n",
      "epoch : 0 [112/21279] Train loss: 5.39090,Valid loss: 5.40477, time : 11.787965297698975 lr : 1\n",
      "epoch : 0 [113/21279] Train loss: 5.38668,Valid loss: 5.41237, time : 12.152633428573608 lr : 1\n",
      "epoch : 0 [114/21279] Train loss: 5.33470,Valid loss: 5.37521, time : 11.554844617843628 lr : 1\n",
      "epoch : 0 [115/21279] Train loss: 5.31746,Valid loss: 5.37903, time : 11.42163610458374 lr : 1\n",
      "epoch : 0 [116/21279] Train loss: 5.32322,Valid loss: 5.36907, time : 11.656008958816528 lr : 1\n",
      "epoch : 0 [117/21279] Train loss: 5.32763,Valid loss: 5.46223, time : 11.67063570022583 lr : 1\n",
      "epoch : 0 [118/21279] Train loss: 5.34420,Valid loss: 5.45475, time : 11.854933023452759 lr : 1\n",
      "epoch : 0 [119/21279] Train loss: 5.39698,Valid loss: 5.44642, time : 13.519354581832886 lr : 1\n",
      "epoch : 0 [120/21279] Train loss: 5.36906,Valid loss: 5.38875, time : 12.229228019714355 lr : 1\n",
      "epoch : 0 [121/21279] Train loss: 5.33559,Valid loss: 5.38039, time : 12.3858163356781 lr : 1\n",
      "epoch : 0 [122/21279] Train loss: 5.33666,Valid loss: 5.36879, time : 11.852832078933716 lr : 1\n",
      "epoch : 0 [123/21279] Train loss: 5.30358,Valid loss: 5.36891, time : 10.900947093963623 lr : 1\n",
      "epoch : 0 [124/21279] Train loss: 5.29982,Valid loss: 5.37065, time : 11.08472466468811 lr : 1\n",
      "epoch : 0 [125/21279] Train loss: 5.32947,Valid loss: 5.38985, time : 12.251230239868164 lr : 1\n",
      "epoch : 0 [126/21279] Train loss: 5.35268,Valid loss: 5.39689, time : 11.53671407699585 lr : 1\n",
      "epoch : 0 [127/21279] Train loss: 5.35950,Valid loss: 5.41507, time : 11.025002002716064 lr : 1\n",
      "epoch : 0 [128/21279] Train loss: 5.33233,Valid loss: 5.37963, time : 11.438477039337158 lr : 1\n",
      "epoch : 0 [129/21279] Train loss: 5.33542,Valid loss: 5.40184, time : 11.475641965866089 lr : 1\n",
      "epoch : 0 [130/21279] Train loss: 5.31677,Valid loss: 5.35645, time : 11.834407806396484 lr : 1\n",
      "epoch : 0 [131/21279] Train loss: 5.30976,Valid loss: 5.37493, time : 13.66870665550232 lr : 1\n",
      "epoch : 0 [132/21279] Train loss: 5.31973,Valid loss: 5.38563, time : 11.355222702026367 lr : 1\n",
      "epoch : 0 [133/21279] Train loss: 5.33185,Valid loss: 5.38050, time : 11.58971118927002 lr : 1\n",
      "epoch : 0 [134/21279] Train loss: 5.32402,Valid loss: 5.36390, time : 11.382641315460205 lr : 1\n",
      "epoch : 0 [135/21279] Train loss: 5.32342,Valid loss: 5.36825, time : 11.113606214523315 lr : 1\n",
      "epoch : 0 [136/21279] Train loss: 5.29199,Valid loss: 5.37213, time : 11.482554197311401 lr : 1\n",
      "epoch : 0 [137/21279] Train loss: 5.31845,Valid loss: 5.46460, time : 11.492589712142944 lr : 1\n",
      "epoch : 0 [138/21279] Train loss: 5.33859,Valid loss: 5.50219, time : 11.79604721069336 lr : 1\n",
      "epoch : 0 [139/21279] Train loss: 5.35764,Valid loss: 5.40681, time : 11.76108694076538 lr : 1\n",
      "epoch : 0 [140/21279] Train loss: 5.32997,Valid loss: 5.35201, time : 11.239502906799316 lr : 1\n",
      "epoch : 0 [141/21279] Train loss: 5.31263,Valid loss: 5.35337, time : 10.91124153137207 lr : 1\n",
      "epoch : 0 [142/21279] Train loss: 5.31316,Valid loss: 5.35141, time : 11.44866156578064 lr : 1\n",
      "epoch : 0 [143/21279] Train loss: 5.30628,Valid loss: 5.36092, time : 11.879422426223755 lr : 1\n",
      "epoch : 0 [144/21279] Train loss: 5.32890,Valid loss: 5.37135, time : 11.09315299987793 lr : 1\n",
      "epoch : 0 [145/21279] Train loss: 5.35619,Valid loss: 5.37291, time : 10.876575231552124 lr : 1\n",
      "epoch : 0 [146/21279] Train loss: 5.33293,Valid loss: 5.34419, time : 11.98007869720459 lr : 1\n",
      "epoch : 0 [147/21279] Train loss: 5.30022,Valid loss: 5.35368, time : 12.859410762786865 lr : 1\n",
      "epoch : 0 [148/21279] Train loss: 5.28894,Valid loss: 5.33223, time : 11.799180030822754 lr : 1\n",
      "epoch : 0 [149/21279] Train loss: 5.28647,Valid loss: 5.36341, time : 12.214793682098389 lr : 1\n",
      "epoch : 0 [150/21279] Train loss: 5.28917,Valid loss: 5.38305, time : 11.635626792907715 lr : 1\n",
      "epoch : 0 [151/21279] Train loss: 5.35124,Valid loss: 5.40245, time : 11.56697964668274 lr : 1\n",
      "epoch : 0 [152/21279] Train loss: 5.35829,Valid loss: 5.35949, time : 12.076005935668945 lr : 1\n",
      "epoch : 0 [153/21279] Train loss: 5.32470,Valid loss: 5.37284, time : 11.269959688186646 lr : 1\n",
      "epoch : 0 [154/21279] Train loss: 5.30868,Valid loss: 5.33673, time : 11.417890787124634 lr : 1\n",
      "epoch : 0 [155/21279] Train loss: 5.29389,Valid loss: 5.37223, time : 12.076416015625 lr : 1\n",
      "epoch : 0 [156/21279] Train loss: 5.29879,Valid loss: 5.37020, time : 12.016513347625732 lr : 1\n",
      "epoch : 0 [157/21279] Train loss: 5.33477,Valid loss: 5.40675, time : 11.837284088134766 lr : 1\n",
      "epoch : 0 [158/21279] Train loss: 5.32475,Valid loss: 5.35723, time : 11.95770525932312 lr : 1\n",
      "epoch : 0 [159/21279] Train loss: 5.32869,Valid loss: 5.35676, time : 14.573472738265991 lr : 1\n",
      "epoch : 0 [160/21279] Train loss: 5.30424,Valid loss: 5.33192, time : 11.483992338180542 lr : 1\n",
      "epoch : 0 [161/21279] Train loss: 5.29332,Valid loss: 5.34868, time : 11.058548212051392 lr : 1\n",
      "epoch : 0 [162/21279] Train loss: 5.28713,Valid loss: 5.32359, time : 11.795907735824585 lr : 1\n",
      "epoch : 0 [163/21279] Train loss: 5.27426,Valid loss: 5.43659, time : 11.801547765731812 lr : 1\n",
      "epoch : 0 [164/21279] Train loss: 5.33051,Valid loss: 5.44030, time : 11.140969276428223 lr : 1\n",
      "epoch : 0 [165/21279] Train loss: 5.39827,Valid loss: 5.37974, time : 11.504045009613037 lr : 1\n",
      "epoch : 0 [166/21279] Train loss: 5.32304,Valid loss: 5.33946, time : 11.878052234649658 lr : 1\n",
      "epoch : 0 [167/21279] Train loss: 5.28942,Valid loss: 5.32549, time : 11.329496622085571 lr : 1\n",
      "epoch : 0 [168/21279] Train loss: 5.28884,Valid loss: 5.32352, time : 11.880197763442993 lr : 1\n",
      "epoch : 0 [169/21279] Train loss: 5.26236,Valid loss: 5.32735, time : 11.297990322113037 lr : 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [170/21279] Train loss: 5.28152,Valid loss: 5.33538, time : 11.165393114089966 lr : 1\n",
      "epoch : 0 [171/21279] Train loss: 5.28371,Valid loss: 5.35307, time : 11.623157501220703 lr : 1\n",
      "epoch : 0 [172/21279] Train loss: 5.30113,Valid loss: 5.35610, time : 11.106384754180908 lr : 1\n",
      "epoch : 0 [173/21279] Train loss: 5.35670,Valid loss: 5.36009, time : 11.06220817565918 lr : 1\n",
      "epoch : 0 [174/21279] Train loss: 5.32081,Valid loss: 5.32951, time : 11.359291076660156 lr : 1\n",
      "epoch : 0 [175/21279] Train loss: 5.27810,Valid loss: 5.34589, time : 13.612498998641968 lr : 1\n",
      "epoch : 0 [176/21279] Train loss: 5.27699,Valid loss: 5.31777, time : 11.092890739440918 lr : 1\n",
      "epoch : 0 [177/21279] Train loss: 5.27325,Valid loss: 5.36933, time : 10.929848194122314 lr : 1\n",
      "epoch : 0 [178/21279] Train loss: 5.26845,Valid loss: 5.39074, time : 11.782737016677856 lr : 1\n",
      "epoch : 0 [179/21279] Train loss: 5.30323,Valid loss: 5.41977, time : 11.316992998123169 lr : 1\n",
      "epoch : 0 [180/21279] Train loss: 5.29604,Valid loss: 5.36916, time : 11.396858930587769 lr : 1\n",
      "epoch : 0 [181/21279] Train loss: 5.31087,Valid loss: 5.33580, time : 11.811972379684448 lr : 1\n",
      "epoch : 0 [182/21279] Train loss: 5.28321,Valid loss: 5.31586, time : 11.550957918167114 lr : 1\n",
      "epoch : 0 [183/21279] Train loss: 5.27268,Valid loss: 5.32073, time : 11.551287174224854 lr : 1\n",
      "epoch : 0 [184/21279] Train loss: 5.29357,Valid loss: 5.33875, time : 11.650590181350708 lr : 1\n",
      "epoch : 0 [185/21279] Train loss: 5.29076,Valid loss: 5.36345, time : 11.898527145385742 lr : 1\n",
      "epoch : 0 [186/21279] Train loss: 5.30866,Valid loss: 5.32866, time : 11.380461692810059 lr : 1\n",
      "epoch : 0 [187/21279] Train loss: 5.29487,Valid loss: 5.34558, time : 12.101368188858032 lr : 1\n",
      "epoch : 0 [188/21279] Train loss: 5.26328,Valid loss: 5.30988, time : 13.586382865905762 lr : 1\n",
      "epoch : 0 [189/21279] Train loss: 5.26313,Valid loss: 5.42128, time : 12.197416305541992 lr : 1\n",
      "epoch : 0 [190/21279] Train loss: 5.28657,Valid loss: 5.39251, time : 11.868329763412476 lr : 1\n",
      "epoch : 0 [191/21279] Train loss: 5.35075,Valid loss: 5.37175, time : 11.728104591369629 lr : 1\n",
      "epoch : 0 [192/21279] Train loss: 5.31527,Valid loss: 5.31328, time : 12.136050939559937 lr : 1\n",
      "epoch : 0 [193/21279] Train loss: 5.26915,Valid loss: 5.31349, time : 11.219848155975342 lr : 1\n",
      "epoch : 0 [194/21279] Train loss: 5.26003,Valid loss: 5.30829, time : 11.458728313446045 lr : 1\n",
      "epoch : 0 [195/21279] Train loss: 5.25612,Valid loss: 5.31337, time : 12.232390642166138 lr : 1\n",
      "epoch : 0 [196/21279] Train loss: 5.26160,Valid loss: 5.33624, time : 11.331915855407715 lr : 1\n",
      "epoch : 0 [197/21279] Train loss: 5.29551,Valid loss: 5.35768, time : 11.981334686279297 lr : 1\n",
      "epoch : 0 [198/21279] Train loss: 5.32772,Valid loss: 5.34657, time : 11.769131660461426 lr : 1\n",
      "epoch : 0 [199/21279] Train loss: 5.30448,Valid loss: 5.35841, time : 11.9029860496521 lr : 1\n",
      "epoch : 0 [200/21279] Train loss: 5.28267,Valid loss: 5.30486, time : 11.817837715148926 lr : 1\n",
      "epoch : 0 [201/21279] Train loss: 5.25735,Valid loss: 5.31129, time : 11.524958372116089 lr : 1\n",
      "epoch : 0 [202/21279] Train loss: 5.23397,Valid loss: 5.29596, time : 12.008506298065186 lr : 1\n",
      "epoch : 0 [203/21279] Train loss: 5.25400,Valid loss: 5.35067, time : 13.853322505950928 lr : 1\n",
      "epoch : 0 [204/21279] Train loss: 5.28238,Valid loss: 5.38418, time : 11.491297483444214 lr : 1\n",
      "epoch : 0 [205/21279] Train loss: 5.35872,Valid loss: 5.36225, time : 11.627723693847656 lr : 1\n",
      "epoch : 0 [206/21279] Train loss: 5.30073,Valid loss: 5.31519, time : 11.760804176330566 lr : 1\n",
      "epoch : 0 [207/21279] Train loss: 5.27060,Valid loss: 5.31975, time : 11.4637610912323 lr : 1\n",
      "epoch : 0 [208/21279] Train loss: 5.25675,Valid loss: 5.30979, time : 11.395877122879028 lr : 1\n",
      "epoch : 0 [209/21279] Train loss: 5.25856,Valid loss: 5.31663, time : 11.730956315994263 lr : 1\n",
      "epoch : 0 [210/21279] Train loss: 5.26164,Valid loss: 5.31510, time : 12.196374654769897 lr : 1\n",
      "epoch : 0 [211/21279] Train loss: 5.31233,Valid loss: 5.34032, time : 11.103362083435059 lr : 1\n",
      "epoch : 0 [212/21279] Train loss: 5.28835,Valid loss: 5.32091, time : 12.335651397705078 lr : 1\n",
      "epoch : 0 [213/21279] Train loss: 5.30554,Valid loss: 5.34180, time : 12.109625577926636 lr : 1\n",
      "epoch : 0 [214/21279] Train loss: 5.25955,Valid loss: 5.30469, time : 12.566092491149902 lr : 1\n",
      "epoch : 0 [215/21279] Train loss: 5.25896,Valid loss: 5.34642, time : 14.329610109329224 lr : 1\n",
      "epoch : 0 [216/21279] Train loss: 5.25792,Valid loss: 5.32070, time : 12.027398824691772 lr : 1\n",
      "epoch : 0 [217/21279] Train loss: 5.25540,Valid loss: 5.35597, time : 12.100178241729736 lr : 1\n",
      "epoch : 0 [218/21279] Train loss: 5.25448,Valid loss: 5.38938, time : 11.92907166481018 lr : 1\n",
      "epoch : 0 [219/21279] Train loss: 5.29891,Valid loss: 5.34934, time : 11.66586446762085 lr : 1\n",
      "epoch : 0 [220/21279] Train loss: 5.26712,Valid loss: 5.29997, time : 11.857492446899414 lr : 1\n",
      "epoch : 0 [221/21279] Train loss: 5.24908,Valid loss: 5.31156, time : 11.81889533996582 lr : 1\n",
      "epoch : 0 [222/21279] Train loss: 5.25349,Valid loss: 5.29756, time : 11.416688442230225 lr : 1\n",
      "epoch : 0 [223/21279] Train loss: 5.28170,Valid loss: 5.32958, time : 11.602861404418945 lr : 1\n",
      "epoch : 0 [224/21279] Train loss: 5.28795,Valid loss: 5.33833, time : 11.267123937606812 lr : 1\n",
      "epoch : 0 [225/21279] Train loss: 5.32499,Valid loss: 5.30700, time : 11.179280996322632 lr : 1\n",
      "epoch : 0 [226/21279] Train loss: 5.26361,Valid loss: 5.28791, time : 11.609659433364868 lr : 1\n",
      "epoch : 0 [227/21279] Train loss: 5.25036,Valid loss: 5.28541, time : 11.587512254714966 lr : 1\n",
      "epoch : 0 [228/21279] Train loss: 5.22926,Valid loss: 5.27732, time : 11.384361982345581 lr : 1\n",
      "epoch : 0 [229/21279] Train loss: 5.23927,Valid loss: 5.29167, time : 14.748223543167114 lr : 1\n",
      "epoch : 0 [230/21279] Train loss: 5.24149,Valid loss: 5.30395, time : 11.52862548828125 lr : 1\n",
      "epoch : 0 [231/21279] Train loss: 5.27577,Valid loss: 5.34449, time : 11.912279605865479 lr : 1\n",
      "epoch : 0 [232/21279] Train loss: 5.31004,Valid loss: 5.36815, time : 12.47048544883728 lr : 1\n",
      "epoch : 0 [233/21279] Train loss: 5.31918,Valid loss: 5.35466, time : 11.950621128082275 lr : 1\n",
      "epoch : 0 [234/21279] Train loss: 5.25639,Valid loss: 5.28978, time : 11.911160469055176 lr : 1\n",
      "epoch : 0 [235/21279] Train loss: 5.24919,Valid loss: 5.28890, time : 11.805295467376709 lr : 1\n",
      "epoch : 0 [236/21279] Train loss: 5.23186,Valid loss: 5.28227, time : 11.865992307662964 lr : 1\n",
      "epoch : 0 [237/21279] Train loss: 5.23243,Valid loss: 5.34523, time : 11.750067949295044 lr : 1\n",
      "epoch : 0 [238/21279] Train loss: 5.22602,Valid loss: 5.37453, time : 12.12150502204895 lr : 1\n",
      "epoch : 0 [239/21279] Train loss: 5.30600,Valid loss: 5.35731, time : 11.210055351257324 lr : 1\n",
      "epoch : 0 [240/21279] Train loss: 5.28076,Valid loss: 5.31524, time : 11.410068035125732 lr : 1\n",
      "epoch : 0 [241/21279] Train loss: 5.26883,Valid loss: 5.28413, time : 14.773707389831543 lr : 1\n",
      "epoch : 0 [242/21279] Train loss: 5.24596,Valid loss: 5.27161, time : 11.944579362869263 lr : 1\n",
      "epoch : 0 [243/21279] Train loss: 5.22899,Valid loss: 5.30276, time : 11.004411458969116 lr : 1\n",
      "epoch : 0 [244/21279] Train loss: 5.23834,Valid loss: 5.32825, time : 11.941521406173706 lr : 1\n",
      "epoch : 0 [245/21279] Train loss: 5.29026,Valid loss: 5.31324, time : 11.59393310546875 lr : 1\n",
      "epoch : 0 [246/21279] Train loss: 5.24886,Valid loss: 5.29227, time : 12.031566381454468 lr : 1\n",
      "epoch : 0 [247/21279] Train loss: 5.25100,Valid loss: 5.29028, time : 11.62196969985962 lr : 1\n",
      "epoch : 0 [248/21279] Train loss: 5.23046,Valid loss: 5.28747, time : 11.642313718795776 lr : 1\n",
      "epoch : 0 [249/21279] Train loss: 5.25315,Valid loss: 5.30150, time : 11.889705419540405 lr : 1\n",
      "epoch : 0 [250/21279] Train loss: 5.24471,Valid loss: 5.30111, time : 11.47409701347351 lr : 1\n",
      "epoch : 0 [251/21279] Train loss: 5.25729,Valid loss: 5.30273, time : 11.575609683990479 lr : 1\n",
      "epoch : 0 [252/21279] Train loss: 5.22837,Valid loss: 5.29312, time : 11.762329339981079 lr : 1\n",
      "epoch : 0 [253/21279] Train loss: 5.25127,Valid loss: 5.31473, time : 11.533639907836914 lr : 1\n",
      "epoch : 0 [254/21279] Train loss: 5.25594,Valid loss: 5.33291, time : 12.010834455490112 lr : 1\n",
      "epoch : 0 [255/21279] Train loss: 5.27420,Valid loss: 5.35471, time : 11.97821307182312 lr : 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [256/21279] Train loss: 5.23680,Valid loss: 5.34691, time : 11.953730344772339 lr : 1\n",
      "epoch : 0 [257/21279] Train loss: 5.23490,Valid loss: 5.34544, time : 14.809532880783081 lr : 1\n",
      "epoch : 0 [258/21279] Train loss: 5.23347,Valid loss: 5.29346, time : 11.987007856369019 lr : 1\n",
      "epoch : 0 [259/21279] Train loss: 5.24956,Valid loss: 5.29678, time : 11.74241328239441 lr : 1\n",
      "epoch : 0 [260/21279] Train loss: 5.26004,Valid loss: 5.29438, time : 11.420980215072632 lr : 1\n",
      "epoch : 0 [261/21279] Train loss: 5.27535,Valid loss: 5.27825, time : 11.69792890548706 lr : 1\n",
      "epoch : 0 [262/21279] Train loss: 5.23707,Valid loss: 5.26438, time : 12.20431113243103 lr : 1\n",
      "epoch : 0 [263/21279] Train loss: 5.22464,Valid loss: 5.29147, time : 11.829164743423462 lr : 1\n",
      "epoch : 0 [264/21279] Train loss: 5.23387,Valid loss: 5.31997, time : 12.200077772140503 lr : 1\n",
      "epoch : 0 [265/21279] Train loss: 5.29482,Valid loss: 5.31793, time : 10.906011819839478 lr : 1\n",
      "epoch : 0 [266/21279] Train loss: 5.25193,Valid loss: 5.26358, time : 11.922358274459839 lr : 1\n",
      "epoch : 0 [267/21279] Train loss: 5.21128,Valid loss: 5.26739, time : 11.651797533035278 lr : 1\n",
      "epoch : 0 [268/21279] Train loss: 5.19855,Valid loss: 5.27091, time : 11.722705125808716 lr : 1\n",
      "epoch : 0 [269/21279] Train loss: 5.24182,Valid loss: 5.31445, time : 14.800354719161987 lr : 1\n",
      "epoch : 0 [270/21279] Train loss: 5.25032,Valid loss: 5.36491, time : 12.487813949584961 lr : 1\n",
      "epoch : 0 [271/21279] Train loss: 5.29155,Valid loss: 5.31415, time : 12.160108804702759 lr : 1\n",
      "epoch : 0 [272/21279] Train loss: 5.22874,Valid loss: 5.25983, time : 11.785323858261108 lr : 1\n",
      "epoch : 0 [273/21279] Train loss: 5.22434,Valid loss: 5.28862, time : 12.242737770080566 lr : 1\n",
      "epoch : 0 [274/21279] Train loss: 5.20008,Valid loss: 5.26976, time : 11.338551759719849 lr : 1\n",
      "epoch : 0 [275/21279] Train loss: 5.23091,Valid loss: 5.32158, time : 10.964444160461426 lr : 1\n",
      "epoch : 0 [276/21279] Train loss: 5.24116,Valid loss: 5.31923, time : 11.400248527526855 lr : 1\n",
      "epoch : 0 [277/21279] Train loss: 5.28310,Valid loss: 5.34862, time : 11.61937141418457 lr : 1\n",
      "epoch : 0 [278/21279] Train loss: 5.24449,Valid loss: 5.27323, time : 11.420657396316528 lr : 1\n",
      "epoch : 0 [279/21279] Train loss: 5.21824,Valid loss: 5.30399, time : 11.587964296340942 lr : 1\n",
      "epoch : 0 [280/21279] Train loss: 5.20598,Valid loss: 5.28121, time : 11.47535514831543 lr : 1\n",
      "epoch : 0 [281/21279] Train loss: 5.24256,Valid loss: 5.29562, time : 11.653533220291138 lr : 1\n",
      "epoch : 0 [282/21279] Train loss: 5.22268,Valid loss: 5.30511, time : 11.275590419769287 lr : 1\n",
      "epoch : 0 [283/21279] Train loss: 5.25950,Valid loss: 5.29634, time : 11.875009298324585 lr : 1\n",
      "epoch : 0 [284/21279] Train loss: 5.21133,Valid loss: 5.26780, time : 11.5801362991333 lr : 1\n",
      "epoch : 0 [285/21279] Train loss: 5.21774,Valid loss: 5.27425, time : 13.682210206985474 lr : 1\n",
      "epoch : 0 [286/21279] Train loss: 5.20871,Valid loss: 5.28050, time : 11.90164303779602 lr : 1\n",
      "epoch : 0 [287/21279] Train loss: 5.23882,Valid loss: 5.29214, time : 11.723114252090454 lr : 1\n",
      "epoch : 0 [288/21279] Train loss: 5.22960,Valid loss: 5.27607, time : 11.987655639648438 lr : 1\n",
      "epoch : 0 [289/21279] Train loss: 5.25144,Valid loss: 5.28700, time : 11.238118886947632 lr : 1\n",
      "epoch : 0 [290/21279] Train loss: 5.21480,Valid loss: 5.25933, time : 11.517860651016235 lr : 1\n",
      "epoch : 0 [291/21279] Train loss: 5.20108,Valid loss: 5.27632, time : 11.950657606124878 lr : 1\n",
      "epoch : 0 [292/21279] Train loss: 5.21262,Valid loss: 5.30665, time : 11.29403018951416 lr : 1\n",
      "epoch : 0 [293/21279] Train loss: 5.22122,Valid loss: 5.34773, time : 11.751725912094116 lr : 1\n",
      "epoch : 0 [294/21279] Train loss: 5.23357,Valid loss: 5.39816, time : 12.005511045455933 lr : 1\n",
      "epoch : 0 [295/21279] Train loss: 5.28695,Valid loss: 5.28606, time : 11.409152507781982 lr : 1\n",
      "epoch : 0 [296/21279] Train loss: 5.22634,Valid loss: 5.27247, time : 11.09866976737976 lr : 1\n",
      "epoch : 0 [297/21279] Train loss: 5.21526,Valid loss: 5.25128, time : 10.926527738571167 lr : 1\n",
      "epoch : 0 [298/21279] Train loss: 5.19914,Valid loss: 5.28357, time : 13.207886934280396 lr : 1\n",
      "epoch : 0 [299/21279] Train loss: 5.22156,Valid loss: 5.27430, time : 12.071077108383179 lr : 1\n",
      "epoch : 0 [300/21279] Train loss: 5.21150,Valid loss: 5.29327, time : 12.04918384552002 lr : 1\n",
      "epoch : 0 [301/21279] Train loss: 5.24237,Valid loss: 5.29537, time : 11.783972024917603 lr : 1\n",
      "epoch : 0 [302/21279] Train loss: 5.22058,Valid loss: 5.25857, time : 11.971580505371094 lr : 1\n",
      "epoch : 0 [303/21279] Train loss: 5.24151,Valid loss: 5.27008, time : 11.810290098190308 lr : 1\n",
      "epoch : 0 [304/21279] Train loss: 5.23644,Valid loss: 5.25757, time : 11.001856327056885 lr : 1\n",
      "epoch : 0 [305/21279] Train loss: 5.23990,Valid loss: 5.33998, time : 11.577369928359985 lr : 1\n",
      "epoch : 0 [306/21279] Train loss: 5.21254,Valid loss: 5.24266, time : 11.694226264953613 lr : 1\n",
      "epoch : 0 [307/21279] Train loss: 5.19231,Valid loss: 5.33717, time : 11.456530094146729 lr : 1\n",
      "epoch : 0 [308/21279] Train loss: 5.19902,Valid loss: 5.27714, time : 12.306905508041382 lr : 1\n",
      "epoch : 0 [309/21279] Train loss: 5.22549,Valid loss: 5.36641, time : 12.903238773345947 lr : 1\n",
      "epoch : 0 [310/21279] Train loss: 5.21830,Valid loss: 5.28440, time : 12.317163944244385 lr : 1\n",
      "epoch : 0 [311/21279] Train loss: 5.20808,Valid loss: 5.31981, time : 12.382694244384766 lr : 1\n",
      "epoch : 0 [312/21279] Train loss: 5.19444,Valid loss: 5.25949, time : 12.059057235717773 lr : 1\n",
      "epoch : 0 [313/21279] Train loss: 5.19864,Valid loss: 5.27683, time : 13.92854118347168 lr : 1\n",
      "epoch : 0 [314/21279] Train loss: 5.20089,Valid loss: 5.27746, time : 11.28546929359436 lr : 1\n",
      "epoch : 0 [315/21279] Train loss: 5.22073,Valid loss: 5.26961, time : 11.528926134109497 lr : 1\n",
      "epoch : 0 [316/21279] Train loss: 5.20548,Valid loss: 5.25774, time : 11.58792495727539 lr : 1\n",
      "epoch : 0 [317/21279] Train loss: 5.19277,Valid loss: 5.27865, time : 11.490203142166138 lr : 1\n",
      "epoch : 0 [318/21279] Train loss: 5.20133,Valid loss: 5.30189, time : 12.045475959777832 lr : 1\n",
      "epoch : 0 [319/21279] Train loss: 5.27243,Valid loss: 5.38602, time : 12.480611562728882 lr : 1\n",
      "epoch : 0 [320/21279] Train loss: 5.28727,Valid loss: 5.33298, time : 11.79831862449646 lr : 1\n",
      "epoch : 0 [321/21279] Train loss: 5.26595,Valid loss: 5.34844, time : 11.734147787094116 lr : 1\n",
      "epoch : 0 [322/21279] Train loss: 5.20295,Valid loss: 5.23045, time : 12.501237392425537 lr : 1\n",
      "epoch : 0 [323/21279] Train loss: 5.17762,Valid loss: 5.27707, time : 12.253162860870361 lr : 1\n",
      "epoch : 0 [324/21279] Train loss: 5.18909,Valid loss: 5.22743, time : 11.736432075500488 lr : 1\n",
      "epoch : 0 [325/21279] Train loss: 5.20075,Valid loss: 5.29833, time : 14.206661462783813 lr : 1\n",
      "epoch : 0 [326/21279] Train loss: 5.18980,Valid loss: 5.26682, time : 12.022007465362549 lr : 1\n",
      "epoch : 0 [327/21279] Train loss: 5.19149,Valid loss: 5.28579, time : 11.473843812942505 lr : 1\n",
      "epoch : 0 [328/21279] Train loss: 5.16427,Valid loss: 5.27512, time : 11.81036376953125 lr : 1\n",
      "epoch : 0 [329/21279] Train loss: 5.20095,Valid loss: 5.31556, time : 10.8690185546875 lr : 1\n",
      "epoch : 0 [330/21279] Train loss: 5.18273,Valid loss: 5.32194, time : 11.294441223144531 lr : 1\n",
      "epoch : 0 [331/21279] Train loss: 5.24641,Valid loss: 5.33998, time : 11.910020112991333 lr : 1\n",
      "epoch : 0 [332/21279] Train loss: 5.26552,Valid loss: 5.34962, time : 11.755419254302979 lr : 1\n",
      "epoch : 0 [333/21279] Train loss: 5.26499,Valid loss: 5.29009, time : 11.745865106582642 lr : 1\n",
      "epoch : 0 [334/21279] Train loss: 5.20141,Valid loss: 5.23510, time : 11.325709342956543 lr : 1\n",
      "epoch : 0 [335/21279] Train loss: 5.17931,Valid loss: 5.22719, time : 11.67088794708252 lr : 1\n",
      "epoch : 0 [336/21279] Train loss: 5.17365,Valid loss: 5.22513, time : 11.265624761581421 lr : 1\n",
      "epoch : 0 [337/21279] Train loss: 5.16501,Valid loss: 5.24131, time : 11.615174770355225 lr : 1\n",
      "epoch : 0 [338/21279] Train loss: 5.20066,Valid loss: 5.28362, time : 12.013290405273438 lr : 1\n",
      "epoch : 0 [339/21279] Train loss: 5.25546,Valid loss: 5.29029, time : 13.718005657196045 lr : 1\n",
      "epoch : 0 [340/21279] Train loss: 5.24040,Valid loss: 5.25938, time : 11.751693725585938 lr : 1\n",
      "epoch : 0 [341/21279] Train loss: 5.22626,Valid loss: 5.33172, time : 11.71097707748413 lr : 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [342/21279] Train loss: 5.19425,Valid loss: 5.27383, time : 11.702513694763184 lr : 1\n",
      "epoch : 0 [343/21279] Train loss: 5.19970,Valid loss: 5.25378, time : 11.35193419456482 lr : 1\n",
      "epoch : 0 [344/21279] Train loss: 5.18005,Valid loss: 5.21135, time : 12.01891279220581 lr : 1\n",
      "epoch : 0 [345/21279] Train loss: 5.17978,Valid loss: 5.29264, time : 11.769244909286499 lr : 1\n",
      "epoch : 0 [346/21279] Train loss: 5.18000,Valid loss: 5.25759, time : 11.356447696685791 lr : 1\n",
      "epoch : 0 [347/21279] Train loss: 5.22911,Valid loss: 5.27330, time : 12.079937219619751 lr : 1\n",
      "epoch : 0 [348/21279] Train loss: 5.17796,Valid loss: 5.21624, time : 11.618089199066162 lr : 1\n",
      "epoch : 0 [349/21279] Train loss: 5.16843,Valid loss: 5.26767, time : 11.781020641326904 lr : 1\n",
      "epoch : 0 [350/21279] Train loss: 5.18131,Valid loss: 5.24291, time : 12.240309476852417 lr : 1\n",
      "epoch : 0 [351/21279] Train loss: 5.24084,Valid loss: 5.28639, time : 13.618338584899902 lr : 1\n",
      "epoch : 0 [352/21279] Train loss: 5.20673,Valid loss: 5.24371, time : 11.794689893722534 lr : 1\n",
      "epoch : 0 [353/21279] Train loss: 5.19180,Valid loss: 5.27297, time : 11.117115020751953 lr : 1\n",
      "epoch : 0 [354/21279] Train loss: 5.14928,Valid loss: 5.21348, time : 11.73414945602417 lr : 1\n",
      "epoch : 0 [355/21279] Train loss: 5.16475,Valid loss: 5.28561, time : 11.328065395355225 lr : 1\n",
      "epoch : 0 [356/21279] Train loss: 5.16395,Valid loss: 5.26112, time : 11.14325761795044 lr : 1\n",
      "epoch : 0 [357/21279] Train loss: 5.18761,Valid loss: 5.31978, time : 11.506280422210693 lr : 1\n",
      "epoch : 0 [358/21279] Train loss: 5.16837,Valid loss: 5.35873, time : 11.459213018417358 lr : 1\n",
      "epoch : 0 [359/21279] Train loss: 5.24914,Valid loss: 5.28102, time : 12.289143085479736 lr : 1\n",
      "epoch : 0 [360/21279] Train loss: 5.19068,Valid loss: 5.22867, time : 11.614936828613281 lr : 1\n",
      "epoch : 0 [361/21279] Train loss: 5.18367,Valid loss: 5.24315, time : 11.173425912857056 lr : 1\n",
      "epoch : 0 [362/21279] Train loss: 5.16220,Valid loss: 5.23908, time : 12.148579359054565 lr : 1\n",
      "epoch : 0 [363/21279] Train loss: 5.19714,Valid loss: 5.23224, time : 12.221495628356934 lr : 1\n",
      "epoch : 0 [364/21279] Train loss: 5.14045,Valid loss: 5.23313, time : 11.524275064468384 lr : 1\n",
      "epoch : 0 [365/21279] Train loss: 5.16743,Valid loss: 5.21838, time : 12.353378534317017 lr : 1\n",
      "epoch : 0 [366/21279] Train loss: 5.15620,Valid loss: 5.23833, time : 11.698696851730347 lr : 1\n",
      "epoch : 0 [367/21279] Train loss: 5.20760,Valid loss: 5.23811, time : 13.817153453826904 lr : 1\n",
      "epoch : 0 [368/21279] Train loss: 5.18955,Valid loss: 5.25153, time : 11.34747838973999 lr : 1\n",
      "epoch : 0 [369/21279] Train loss: 5.14889,Valid loss: 5.20386, time : 11.763962030410767 lr : 1\n",
      "epoch : 0 [370/21279] Train loss: 5.14582,Valid loss: 5.24421, time : 11.631202220916748 lr : 1\n",
      "epoch : 0 [371/21279] Train loss: 5.16331,Valid loss: 5.29977, time : 11.239492654800415 lr : 1\n",
      "epoch : 0 [372/21279] Train loss: 5.19800,Valid loss: 5.28165, time : 12.057334899902344 lr : 1\n",
      "epoch : 0 [373/21279] Train loss: 5.24281,Valid loss: 5.28913, time : 11.234554529190063 lr : 1\n",
      "epoch : 0 [374/21279] Train loss: 5.18018,Valid loss: 5.21822, time : 11.646997928619385 lr : 1\n",
      "epoch : 0 [375/21279] Train loss: 5.16232,Valid loss: 5.21596, time : 11.236021041870117 lr : 1\n",
      "epoch : 0 [376/21279] Train loss: 5.16761,Valid loss: 5.21433, time : 11.614428043365479 lr : 1\n",
      "epoch : 0 [377/21279] Train loss: 5.14375,Valid loss: 5.27156, time : 11.343394756317139 lr : 1\n",
      "epoch : 0 [378/21279] Train loss: 5.16400,Valid loss: 5.27254, time : 11.486699104309082 lr : 1\n",
      "epoch : 0 [379/21279] Train loss: 5.21526,Valid loss: 5.33965, time : 13.510199546813965 lr : 1\n",
      "epoch : 0 [380/21279] Train loss: 5.20153,Valid loss: 5.31249, time : 11.62024974822998 lr : 1\n",
      "epoch : 0 [381/21279] Train loss: 5.21965,Valid loss: 5.30822, time : 11.62053632736206 lr : 1\n",
      "epoch : 0 [382/21279] Train loss: 5.16341,Valid loss: 5.20601, time : 11.742935180664062 lr : 1\n",
      "epoch : 0 [383/21279] Train loss: 5.15789,Valid loss: 5.25490, time : 12.056201219558716 lr : 1\n",
      "epoch : 0 [384/21279] Train loss: 5.14837,Valid loss: 5.19996, time : 11.688487529754639 lr : 1\n",
      "epoch : 0 [385/21279] Train loss: 5.15880,Valid loss: 5.26754, time : 11.53860068321228 lr : 1\n",
      "epoch : 0 [386/21279] Train loss: 5.19604,Valid loss: 5.24657, time : 11.409378290176392 lr : 1\n",
      "epoch : 0 [387/21279] Train loss: 5.20653,Valid loss: 5.22587, time : 12.376484394073486 lr : 1\n",
      "epoch : 0 [388/21279] Train loss: 5.13907,Valid loss: 5.19948, time : 11.746496677398682 lr : 1\n",
      "epoch : 0 [389/21279] Train loss: 5.13945,Valid loss: 5.21119, time : 11.813257932662964 lr : 1\n",
      "epoch : 0 [390/21279] Train loss: 5.13848,Valid loss: 5.20811, time : 12.460396766662598 lr : 1\n",
      "epoch : 0 [391/21279] Train loss: 5.15246,Valid loss: 5.21576, time : 12.103394031524658 lr : 1\n",
      "epoch : 0 [392/21279] Train loss: 5.15376,Valid loss: 5.20882, time : 12.789535284042358 lr : 1\n",
      "epoch : 0 [393/21279] Train loss: 5.15958,Valid loss: 5.27212, time : 11.894116401672363 lr : 1\n",
      "epoch : 0 [394/21279] Train loss: 5.15150,Valid loss: 5.19394, time : 12.917814254760742 lr : 1\n",
      "epoch : 0 [395/21279] Train loss: 5.16867,Valid loss: 5.21221, time : 14.585896015167236 lr : 1\n",
      "epoch : 0 [396/21279] Train loss: 5.15052,Valid loss: 5.21746, time : 12.137595653533936 lr : 1\n",
      "epoch : 0 [397/21279] Train loss: 5.16685,Valid loss: 5.23268, time : 11.748939514160156 lr : 1\n",
      "epoch : 0 [398/21279] Train loss: 5.12666,Valid loss: 5.23769, time : 12.08474326133728 lr : 1\n",
      "epoch : 0 [399/21279] Train loss: 5.19208,Valid loss: 5.22781, time : 12.505884885787964 lr : 1\n",
      "epoch : 0 [400/21279] Train loss: 5.14798,Valid loss: 5.22738, time : 12.120012283325195 lr : 1\n",
      "epoch : 0 [401/21279] Train loss: 5.18462,Valid loss: 5.25816, time : 11.658865928649902 lr : 1\n",
      "epoch : 0 [402/21279] Train loss: 5.15106,Valid loss: 5.24031, time : 11.94988465309143 lr : 1\n",
      "epoch : 0 [403/21279] Train loss: 5.17863,Valid loss: 5.36105, time : 11.518046855926514 lr : 1\n",
      "epoch : 0 [404/21279] Train loss: 5.16357,Valid loss: 5.32356, time : 11.861358165740967 lr : 1\n",
      "epoch : 0 [405/21279] Train loss: 5.20280,Valid loss: 5.21975, time : 11.857386827468872 lr : 1\n",
      "epoch : 0 [406/21279] Train loss: 5.13899,Valid loss: 5.17741, time : 11.961541652679443 lr : 1\n",
      "epoch : 0 [407/21279] Train loss: 5.12710,Valid loss: 5.19989, time : 12.502003192901611 lr : 1\n",
      "epoch : 0 [408/21279] Train loss: 5.10002,Valid loss: 5.19132, time : 13.82387113571167 lr : 1\n",
      "epoch : 0 [409/21279] Train loss: 5.16359,Valid loss: 5.24745, time : 11.591214895248413 lr : 1\n",
      "epoch : 0 [410/21279] Train loss: 5.17388,Valid loss: 5.20992, time : 10.908637285232544 lr : 1\n",
      "epoch : 0 [411/21279] Train loss: 5.18451,Valid loss: 5.20555, time : 11.349644660949707 lr : 1\n",
      "epoch : 0 [412/21279] Train loss: 5.13930,Valid loss: 5.18098, time : 11.260617733001709 lr : 1\n",
      "epoch : 0 [413/21279] Train loss: 5.14121,Valid loss: 5.18787, time : 11.693455457687378 lr : 1\n",
      "epoch : 0 [414/21279] Train loss: 5.13096,Valid loss: 5.23513, time : 11.644547939300537 lr : 1\n",
      "epoch : 0 [415/21279] Train loss: 5.16923,Valid loss: 5.18022, time : 11.940606832504272 lr : 1\n",
      "epoch : 0 [416/21279] Train loss: 5.12136,Valid loss: 5.15807, time : 11.573823690414429 lr : 1\n",
      "epoch : 0 [417/21279] Train loss: 5.11950,Valid loss: 5.24769, time : 10.99350094795227 lr : 1\n",
      "epoch : 0 [418/21279] Train loss: 5.12939,Valid loss: 5.21976, time : 11.600632190704346 lr : 1\n",
      "epoch : 0 [419/21279] Train loss: 5.20967,Valid loss: 5.27221, time : 11.917933464050293 lr : 1\n",
      "epoch : 0 [420/21279] Train loss: 5.17822,Valid loss: 5.20646, time : 11.29684066772461 lr : 1\n",
      "epoch : 0 [421/21279] Train loss: 5.13366,Valid loss: 5.22951, time : 11.944446325302124 lr : 1\n",
      "epoch : 0 [422/21279] Train loss: 5.12236,Valid loss: 5.18173, time : 11.339457273483276 lr : 1\n",
      "epoch : 0 [423/21279] Train loss: 5.13479,Valid loss: 5.22217, time : 13.168999195098877 lr : 1\n",
      "epoch : 0 [424/21279] Train loss: 5.13166,Valid loss: 5.19617, time : 11.530441761016846 lr : 1\n",
      "epoch : 0 [425/21279] Train loss: 5.12498,Valid loss: 5.26722, time : 11.20842957496643 lr : 1\n",
      "epoch : 0 [426/21279] Train loss: 5.12757,Valid loss: 5.21993, time : 11.830154418945312 lr : 1\n",
      "epoch : 0 [427/21279] Train loss: 5.15880,Valid loss: 5.26640, time : 11.264769315719604 lr : 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [428/21279] Train loss: 5.11322,Valid loss: 5.23347, time : 11.591976642608643 lr : 1\n",
      "epoch : 0 [429/21279] Train loss: 5.17204,Valid loss: 5.26625, time : 11.33017635345459 lr : 1\n",
      "epoch : 0 [430/21279] Train loss: 5.11750,Valid loss: 5.17706, time : 11.976336479187012 lr : 1\n",
      "epoch : 0 [431/21279] Train loss: 5.13284,Valid loss: 5.21061, time : 12.367023229598999 lr : 1\n",
      "epoch : 0 [432/21279] Train loss: 5.10311,Valid loss: 5.14759, time : 11.352062463760376 lr : 1\n",
      "epoch : 0 [433/21279] Train loss: 5.14115,Valid loss: 5.21481, time : 11.484602689743042 lr : 1\n",
      "epoch : 0 [434/21279] Train loss: 5.10290,Valid loss: 5.19289, time : 11.47683835029602 lr : 1\n",
      "epoch : 0 [435/21279] Train loss: 5.16404,Valid loss: 5.22747, time : 12.90763545036316 lr : 1\n",
      "epoch : 0 [436/21279] Train loss: 5.12536,Valid loss: 5.19577, time : 11.468342542648315 lr : 1\n",
      "epoch : 0 [437/21279] Train loss: 5.10974,Valid loss: 5.24114, time : 11.501582145690918 lr : 1\n",
      "epoch : 0 [438/21279] Train loss: 5.09294,Valid loss: 5.15492, time : 11.582740783691406 lr : 1\n",
      "epoch : 0 [439/21279] Train loss: 5.12313,Valid loss: 5.24694, time : 11.864616870880127 lr : 1\n",
      "epoch : 0 [440/21279] Train loss: 5.13551,Valid loss: 5.24601, time : 11.821878433227539 lr : 1\n",
      "epoch : 0 [441/21279] Train loss: 5.15383,Valid loss: 5.25180, time : 11.68944001197815 lr : 1\n",
      "epoch : 0 [442/21279] Train loss: 5.11690,Valid loss: 5.17318, time : 11.465022802352905 lr : 1\n",
      "epoch : 0 [443/21279] Train loss: 5.10932,Valid loss: 5.20933, time : 11.806021690368652 lr : 1\n",
      "epoch : 0 [444/21279] Train loss: 5.09688,Valid loss: 5.21631, time : 12.190046787261963 lr : 1\n",
      "epoch : 0 [445/21279] Train loss: 5.12043,Valid loss: 5.21948, time : 11.850043058395386 lr : 1\n",
      "epoch : 0 [446/21279] Train loss: 5.14751,Valid loss: 5.20315, time : 12.664334774017334 lr : 1\n",
      "epoch : 0 [447/21279] Train loss: 5.12157,Valid loss: 5.19308, time : 12.237330198287964 lr : 1\n",
      "epoch : 0 [448/21279] Train loss: 5.09289,Valid loss: 5.25610, time : 12.3633713722229 lr : 1\n",
      "epoch : 0 [449/21279] Train loss: 5.11362,Valid loss: 5.23876, time : 12.951632976531982 lr : 1\n",
      "epoch : 0 [450/21279] Train loss: 5.19025,Valid loss: 5.27029, time : 11.326854228973389 lr : 1\n",
      "epoch : 0 [451/21279] Train loss: 5.15022,Valid loss: 5.22271, time : 12.078611850738525 lr : 1\n",
      "epoch : 0 [452/21279] Train loss: 5.12171,Valid loss: 5.15425, time : 11.289108276367188 lr : 1\n",
      "epoch : 0 [453/21279] Train loss: 5.08390,Valid loss: 5.20758, time : 11.85779356956482 lr : 1\n",
      "epoch : 0 [454/21279] Train loss: 5.08792,Valid loss: 5.17212, time : 11.309478282928467 lr : 1\n",
      "epoch : 0 [455/21279] Train loss: 5.10992,Valid loss: 5.23903, time : 11.662363529205322 lr : 1\n",
      "epoch : 0 [456/21279] Train loss: 5.13305,Valid loss: 5.24771, time : 11.503725051879883 lr : 1\n",
      "epoch : 0 [457/21279] Train loss: 5.17898,Valid loss: 5.21342, time : 11.17495322227478 lr : 1\n",
      "epoch : 0 [458/21279] Train loss: 5.11525,Valid loss: 5.15749, time : 11.642394065856934 lr : 1\n",
      "epoch : 0 [459/21279] Train loss: 5.08239,Valid loss: 5.13512, time : 12.570576190948486 lr : 1\n",
      "epoch : 0 [460/21279] Train loss: 5.08916,Valid loss: 5.16017, time : 11.637859344482422 lr : 1\n",
      "epoch : 0 [461/21279] Train loss: 5.09470,Valid loss: 5.14562, time : 13.606188535690308 lr : 1\n",
      "epoch : 0 [462/21279] Train loss: 5.07078,Valid loss: 5.20038, time : 12.237342119216919 lr : 1\n",
      "epoch : 0 [463/21279] Train loss: 5.16017,Valid loss: 5.16480, time : 12.112830638885498 lr : 1\n",
      "epoch : 0 [464/21279] Train loss: 5.10585,Valid loss: 5.19707, time : 11.58267879486084 lr : 1\n",
      "epoch : 0 [465/21279] Train loss: 5.11049,Valid loss: 5.26501, time : 12.182363986968994 lr : 1\n",
      "epoch : 0 [466/21279] Train loss: 5.11787,Valid loss: 5.18439, time : 12.526707887649536 lr : 1\n",
      "epoch : 0 [467/21279] Train loss: 5.11735,Valid loss: 5.18489, time : 11.60307002067566 lr : 1\n",
      "epoch : 0 [468/21279] Train loss: 5.07952,Valid loss: 5.10938, time : 12.160578727722168 lr : 1\n",
      "epoch : 0 [469/21279] Train loss: 5.07345,Valid loss: 5.23703, time : 11.915113687515259 lr : 1\n",
      "epoch : 0 [470/21279] Train loss: 5.07741,Valid loss: 5.22300, time : 12.033906936645508 lr : 1\n",
      "epoch : 0 [471/21279] Train loss: 5.16927,Valid loss: 5.23663, time : 12.190590381622314 lr : 1\n",
      "epoch : 0 [472/21279] Train loss: 5.07589,Valid loss: 5.12079, time : 12.34444522857666 lr : 1\n",
      "epoch : 0 [473/21279] Train loss: 5.08314,Valid loss: 5.18073, time : 12.546178579330444 lr : 1\n",
      "epoch : 0 [474/21279] Train loss: 5.06410,Valid loss: 5.16303, time : 11.77926254272461 lr : 1\n",
      "epoch : 0 [475/21279] Train loss: 5.14783,Valid loss: 5.21007, time : 12.590497970581055 lr : 1\n",
      "epoch : 0 [476/21279] Train loss: 5.11970,Valid loss: 5.16023, time : 12.247723579406738 lr : 1\n",
      "epoch : 0 [477/21279] Train loss: 5.07200,Valid loss: 5.14017, time : 13.482399225234985 lr : 1\n",
      "epoch : 0 [478/21279] Train loss: 5.05416,Valid loss: 5.12905, time : 11.755195140838623 lr : 1\n",
      "epoch : 0 [479/21279] Train loss: 5.06808,Valid loss: 5.20070, time : 11.875008583068848 lr : 1\n",
      "epoch : 0 [480/21279] Train loss: 5.07108,Valid loss: 5.19102, time : 11.588603496551514 lr : 1\n",
      "epoch : 0 [481/21279] Train loss: 5.11381,Valid loss: 5.22323, time : 11.82210087776184 lr : 1\n",
      "epoch : 0 [482/21279] Train loss: 5.08281,Valid loss: 5.15603, time : 11.565547227859497 lr : 1\n",
      "epoch : 0 [483/21279] Train loss: 5.12689,Valid loss: 5.22312, time : 11.879906415939331 lr : 1\n",
      "epoch : 0 [484/21279] Train loss: 5.10680,Valid loss: 5.19766, time : 11.931058406829834 lr : 1\n",
      "epoch : 0 [485/21279] Train loss: 5.14573,Valid loss: 5.17874, time : 11.986056566238403 lr : 1\n",
      "epoch : 0 [486/21279] Train loss: 5.05627,Valid loss: 5.08571, time : 12.354248523712158 lr : 1\n",
      "epoch : 0 [487/21279] Train loss: 5.04154,Valid loss: 5.15982, time : 11.879724740982056 lr : 1\n",
      "epoch : 0 [488/21279] Train loss: 5.05707,Valid loss: 5.15880, time : 12.214468717575073 lr : 1\n",
      "epoch : 0 [489/21279] Train loss: 5.11081,Valid loss: 5.15876, time : 13.314488887786865 lr : 1\n",
      "epoch : 0 [490/21279] Train loss: 5.05248,Valid loss: 5.14000, time : 11.683284044265747 lr : 1\n",
      "epoch : 0 [491/21279] Train loss: 5.05227,Valid loss: 5.17336, time : 12.385073900222778 lr : 1\n",
      "epoch : 0 [492/21279] Train loss: 5.04208,Valid loss: 5.14593, time : 11.882890462875366 lr : 1\n",
      "epoch : 0 [493/21279] Train loss: 5.06282,Valid loss: 5.14456, time : 12.100862264633179 lr : 1\n",
      "epoch : 0 [494/21279] Train loss: 5.04492,Valid loss: 5.12292, time : 12.265192985534668 lr : 1\n",
      "epoch : 0 [495/21279] Train loss: 5.07435,Valid loss: 5.22616, time : 11.85477900505066 lr : 1\n",
      "epoch : 0 [496/21279] Train loss: 5.05445,Valid loss: 5.15366, time : 11.580925941467285 lr : 1\n",
      "epoch : 0 [497/21279] Train loss: 5.09542,Valid loss: 5.21466, time : 11.648640394210815 lr : 1\n",
      "epoch : 0 [498/21279] Train loss: 5.04422,Valid loss: 5.12025, time : 11.15136170387268 lr : 1\n",
      "epoch : 0 [499/21279] Train loss: 5.07220,Valid loss: 5.14416, time : 11.240276098251343 lr : 0.99\n",
      "epoch : 0 [500/21279] Train loss: 5.06603,Valid loss: 5.15584, time : 11.50314974784851 lr : 0.99\n",
      "epoch : 0 [501/21279] Train loss: 5.08901,Valid loss: 5.09183, time : 11.33873701095581 lr : 0.99\n",
      "epoch : 0 [502/21279] Train loss: 5.02843,Valid loss: 5.09716, time : 11.287499904632568 lr : 0.99\n",
      "epoch : 0 [503/21279] Train loss: 4.98918,Valid loss: 5.12755, time : 11.394246339797974 lr : 0.99\n",
      "epoch : 0 [504/21279] Train loss: 5.03885,Valid loss: 5.31169, time : 11.261260986328125 lr : 0.99\n",
      "epoch : 0 [505/21279] Train loss: 5.15738,Valid loss: 5.27027, time : 12.918279647827148 lr : 0.99\n",
      "epoch : 0 [506/21279] Train loss: 5.21225,Valid loss: 5.18244, time : 11.427776098251343 lr : 0.99\n",
      "epoch : 0 [507/21279] Train loss: 5.14815,Valid loss: 5.13630, time : 11.146283388137817 lr : 0.99\n",
      "epoch : 0 [508/21279] Train loss: 5.08871,Valid loss: 5.09799, time : 12.053483486175537 lr : 0.99\n",
      "epoch : 0 [509/21279] Train loss: 5.03243,Valid loss: 5.08527, time : 11.380164384841919 lr : 0.99\n",
      "epoch : 0 [510/21279] Train loss: 4.99110,Valid loss: 5.09389, time : 11.37894892692566 lr : 0.99\n",
      "epoch : 0 [511/21279] Train loss: 5.00122,Valid loss: 5.10272, time : 11.936103820800781 lr : 0.99\n",
      "epoch : 0 [512/21279] Train loss: 5.04020,Valid loss: 5.11118, time : 11.230027198791504 lr : 0.99\n",
      "epoch : 0 [513/21279] Train loss: 5.06207,Valid loss: 5.10124, time : 11.15544843673706 lr : 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [514/21279] Train loss: 5.07555,Valid loss: 5.07585, time : 11.43490982055664 lr : 0.99\n",
      "epoch : 0 [515/21279] Train loss: 5.02315,Valid loss: 5.16638, time : 11.729246854782104 lr : 0.99\n",
      "epoch : 0 [516/21279] Train loss: 5.05295,Valid loss: 5.15610, time : 11.11424994468689 lr : 0.99\n",
      "epoch : 0 [517/21279] Train loss: 5.03698,Valid loss: 5.19962, time : 11.893129587173462 lr : 0.99\n",
      "epoch : 0 [518/21279] Train loss: 5.09268,Valid loss: 5.10049, time : 12.879006385803223 lr : 0.99\n",
      "epoch : 0 [519/21279] Train loss: 5.00213,Valid loss: 5.09368, time : 11.312658071517944 lr : 0.99\n",
      "epoch : 0 [520/21279] Train loss: 4.99637,Valid loss: 5.18923, time : 11.645411014556885 lr : 0.99\n",
      "epoch : 0 [521/21279] Train loss: 4.99414,Valid loss: 5.09800, time : 10.901386499404907 lr : 0.99\n",
      "epoch : 0 [522/21279] Train loss: 5.01575,Valid loss: 5.34819, time : 11.511387586593628 lr : 0.99\n",
      "epoch : 0 [523/21279] Train loss: 5.01855,Valid loss: 5.53032, time : 11.749949216842651 lr : 0.99\n",
      "epoch : 0 [524/21279] Train loss: 5.07026,Valid loss: 5.41936, time : 11.409926891326904 lr : 0.99\n",
      "epoch : 0 [525/21279] Train loss: 5.06604,Valid loss: 5.23186, time : 11.698120355606079 lr : 0.99\n",
      "epoch : 0 [526/21279] Train loss: 5.05287,Valid loss: 5.25672, time : 11.815969467163086 lr : 0.99\n",
      "epoch : 0 [527/21279] Train loss: 5.06981,Valid loss: 5.17033, time : 11.423299551010132 lr : 0.99\n",
      "epoch : 0 [528/21279] Train loss: 5.08976,Valid loss: 5.17822, time : 11.155216217041016 lr : 0.99\n",
      "epoch : 0 [529/21279] Train loss: 5.02952,Valid loss: 5.10429, time : 11.302711725234985 lr : 0.99\n",
      "epoch : 0 [530/21279] Train loss: 5.06133,Valid loss: 5.12772, time : 11.492515802383423 lr : 0.99\n",
      "epoch : 0 [531/21279] Train loss: 5.01719,Valid loss: 5.07456, time : 11.122750759124756 lr : 0.99\n",
      "epoch : 0 [532/21279] Train loss: 5.00209,Valid loss: 5.13396, time : 11.130847692489624 lr : 0.99\n",
      "epoch : 0 [533/21279] Train loss: 5.03555,Valid loss: 5.13391, time : 12.573107242584229 lr : 0.99\n",
      "epoch : 0 [534/21279] Train loss: 5.02287,Valid loss: 5.15197, time : 11.446467161178589 lr : 0.99\n",
      "epoch : 0 [535/21279] Train loss: 4.98817,Valid loss: 5.08013, time : 11.375478506088257 lr : 0.99\n",
      "epoch : 0 [536/21279] Train loss: 4.97691,Valid loss: 5.05174, time : 11.58197546005249 lr : 0.99\n",
      "epoch : 0 [537/21279] Train loss: 4.96301,Valid loss: 5.11932, time : 11.874741554260254 lr : 0.99\n",
      "epoch : 0 [538/21279] Train loss: 4.98650,Valid loss: 5.24774, time : 11.315253496170044 lr : 0.99\n",
      "epoch : 0 [539/21279] Train loss: 5.04834,Valid loss: 5.23194, time : 11.467966079711914 lr : 0.99\n",
      "epoch : 0 [540/21279] Train loss: 5.16778,Valid loss: 5.13393, time : 11.659642696380615 lr : 0.99\n",
      "epoch : 0 [541/21279] Train loss: 5.06437,Valid loss: 5.12061, time : 11.159709453582764 lr : 0.99\n",
      "epoch : 0 [542/21279] Train loss: 5.00054,Valid loss: 5.02254, time : 11.536559581756592 lr : 0.99\n",
      "epoch : 0 [543/21279] Train loss: 4.96450,Valid loss: 5.05688, time : 11.786421060562134 lr : 0.99\n",
      "epoch : 0 [544/21279] Train loss: 4.95595,Valid loss: 5.06557, time : 11.971861839294434 lr : 0.99\n",
      "epoch : 0 [545/21279] Train loss: 4.96139,Valid loss: 5.12003, time : 13.01344609260559 lr : 0.99\n",
      "epoch : 0 [546/21279] Train loss: 4.99140,Valid loss: 5.14163, time : 11.731989622116089 lr : 0.99\n",
      "epoch : 0 [547/21279] Train loss: 5.05611,Valid loss: 5.16695, time : 11.48366665840149 lr : 0.99\n",
      "epoch : 0 [548/21279] Train loss: 5.07326,Valid loss: 5.07909, time : 11.531878232955933 lr : 0.99\n",
      "epoch : 0 [549/21279] Train loss: 5.07683,Valid loss: 5.10891, time : 11.5901460647583 lr : 0.99\n",
      "epoch : 0 [550/21279] Train loss: 5.02306,Valid loss: 5.06129, time : 11.925158500671387 lr : 0.99\n",
      "epoch : 0 [551/21279] Train loss: 4.95930,Valid loss: 5.03406, time : 11.182785987854004 lr : 0.99\n",
      "epoch : 0 [552/21279] Train loss: 4.94002,Valid loss: 5.02725, time : 11.429497718811035 lr : 0.99\n",
      "epoch : 0 [553/21279] Train loss: 4.97125,Valid loss: 5.03845, time : 11.368722677230835 lr : 0.99\n",
      "epoch : 0 [554/21279] Train loss: 4.96611,Valid loss: 5.07989, time : 11.736413478851318 lr : 0.99\n",
      "epoch : 0 [555/21279] Train loss: 4.99904,Valid loss: 5.05149, time : 11.827404737472534 lr : 0.99\n",
      "epoch : 0 [556/21279] Train loss: 4.95548,Valid loss: 5.06328, time : 11.65423846244812 lr : 0.99\n",
      "epoch : 0 [557/21279] Train loss: 4.97170,Valid loss: 5.06087, time : 11.23839259147644 lr : 0.99\n",
      "epoch : 0 [558/21279] Train loss: 4.93926,Valid loss: 5.05353, time : 12.217053651809692 lr : 0.99\n",
      "epoch : 0 [559/21279] Train loss: 4.93179,Valid loss: 4.99987, time : 14.262688636779785 lr : 0.99\n",
      "epoch : 0 [560/21279] Train loss: 4.93764,Valid loss: 5.05196, time : 11.479026079177856 lr : 0.99\n",
      "epoch : 0 [561/21279] Train loss: 4.97189,Valid loss: 5.06785, time : 11.316577911376953 lr : 0.99\n",
      "epoch : 0 [562/21279] Train loss: 4.96953,Valid loss: 5.10450, time : 11.799113035202026 lr : 0.99\n",
      "epoch : 0 [563/21279] Train loss: 5.03873,Valid loss: 5.19725, time : 11.227672338485718 lr : 0.99\n",
      "epoch : 0 [564/21279] Train loss: 5.03475,Valid loss: 5.20423, time : 11.39076828956604 lr : 0.99\n",
      "epoch : 0 [565/21279] Train loss: 5.07926,Valid loss: 5.10016, time : 11.06217074394226 lr : 0.99\n",
      "epoch : 0 [566/21279] Train loss: 4.96886,Valid loss: 5.04127, time : 11.31278109550476 lr : 0.99\n",
      "epoch : 0 [567/21279] Train loss: 4.94485,Valid loss: 5.04418, time : 11.28470492362976 lr : 0.99\n",
      "epoch : 0 [568/21279] Train loss: 4.95376,Valid loss: 4.97816, time : 12.186381578445435 lr : 0.99\n",
      "epoch : 0 [569/21279] Train loss: 4.91097,Valid loss: 5.05100, time : 12.223610162734985 lr : 0.99\n",
      "epoch : 0 [570/21279] Train loss: 4.94878,Valid loss: 5.07629, time : 11.413738250732422 lr : 0.99\n",
      "epoch : 0 [571/21279] Train loss: 4.93381,Valid loss: 5.17457, time : 13.256752490997314 lr : 0.99\n",
      "epoch : 0 [572/21279] Train loss: 5.04052,Valid loss: 5.31381, time : 11.595651865005493 lr : 0.99\n",
      "epoch : 0 [573/21279] Train loss: 5.05499,Valid loss: 5.15739, time : 12.04532527923584 lr : 0.99\n",
      "epoch : 0 [574/21279] Train loss: 5.00089,Valid loss: 5.02166, time : 12.039128541946411 lr : 0.99\n",
      "epoch : 0 [575/21279] Train loss: 4.95821,Valid loss: 5.03718, time : 12.06540846824646 lr : 0.99\n",
      "epoch : 0 [576/21279] Train loss: 4.94233,Valid loss: 5.01309, time : 11.590930938720703 lr : 0.99\n",
      "epoch : 0 [577/21279] Train loss: 4.91846,Valid loss: 5.10113, time : 11.182050466537476 lr : 0.99\n",
      "epoch : 0 [578/21279] Train loss: 4.92243,Valid loss: 5.06749, time : 11.45698595046997 lr : 0.99\n",
      "epoch : 0 [579/21279] Train loss: 4.96536,Valid loss: 5.04573, time : 11.547247886657715 lr : 0.99\n",
      "epoch : 0 [580/21279] Train loss: 4.89631,Valid loss: 5.01411, time : 11.238849639892578 lr : 0.99\n",
      "epoch : 0 [581/21279] Train loss: 4.93551,Valid loss: 5.07376, time : 11.60050368309021 lr : 0.99\n",
      "epoch : 0 [582/21279] Train loss: 4.96770,Valid loss: 5.20316, time : 11.3144690990448 lr : 0.99\n",
      "epoch : 0 [583/21279] Train loss: 5.12095,Valid loss: 5.14227, time : 12.263683080673218 lr : 0.99\n",
      "epoch : 0 [584/21279] Train loss: 5.05033,Valid loss: 5.02537, time : 12.476498365402222 lr : 0.99\n",
      "epoch : 0 [585/21279] Train loss: 4.93810,Valid loss: 5.00827, time : 11.376840353012085 lr : 0.99\n",
      "epoch : 0 [586/21279] Train loss: 4.87174,Valid loss: 4.98433, time : 11.644931554794312 lr : 0.99\n",
      "epoch : 0 [587/21279] Train loss: 4.89522,Valid loss: 5.05617, time : 14.109066486358643 lr : 0.99\n",
      "epoch : 0 [588/21279] Train loss: 4.92062,Valid loss: 5.07844, time : 11.408222198486328 lr : 0.99\n",
      "epoch : 0 [589/21279] Train loss: 4.92469,Valid loss: 5.32160, time : 12.49355411529541 lr : 0.99\n",
      "epoch : 0 [590/21279] Train loss: 4.97151,Valid loss: 5.12705, time : 11.743050575256348 lr : 0.99\n",
      "epoch : 0 [591/21279] Train loss: 4.90531,Valid loss: 5.13675, time : 11.292160987854004 lr : 0.99\n",
      "epoch : 0 [592/21279] Train loss: 4.90722,Valid loss: 5.16289, time : 11.362831354141235 lr : 0.99\n",
      "epoch : 0 [593/21279] Train loss: 4.96846,Valid loss: 5.19380, time : 11.296674013137817 lr : 0.99\n",
      "epoch : 0 [594/21279] Train loss: 4.93872,Valid loss: 5.20359, time : 11.8067045211792 lr : 0.99\n",
      "epoch : 0 [595/21279] Train loss: 5.03824,Valid loss: 5.05262, time : 11.465324640274048 lr : 0.99\n",
      "epoch : 0 [596/21279] Train loss: 4.92420,Valid loss: 5.04055, time : 11.085063457489014 lr : 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [597/21279] Train loss: 4.90127,Valid loss: 5.02112, time : 11.477890968322754 lr : 0.99\n",
      "epoch : 0 [598/21279] Train loss: 4.85821,Valid loss: 4.97374, time : 11.706592798233032 lr : 0.99\n",
      "epoch : 0 [599/21279] Train loss: 4.87447,Valid loss: 5.08272, time : 13.371514797210693 lr : 0.99\n",
      "epoch : 0 [600/21279] Train loss: 4.89617,Valid loss: 5.04748, time : 11.541189908981323 lr : 0.99\n",
      "epoch : 0 [601/21279] Train loss: 4.97519,Valid loss: 5.00829, time : 12.695217847824097 lr : 0.99\n",
      "epoch : 0 [602/21279] Train loss: 4.89574,Valid loss: 4.93689, time : 11.205849170684814 lr : 0.99\n",
      "epoch : 0 [603/21279] Train loss: 4.88657,Valid loss: 5.02213, time : 11.40613842010498 lr : 0.99\n",
      "epoch : 0 [604/21279] Train loss: 4.88344,Valid loss: 5.03858, time : 11.02358341217041 lr : 0.99\n",
      "epoch : 0 [605/21279] Train loss: 4.92624,Valid loss: 5.00324, time : 11.716572523117065 lr : 0.99\n",
      "epoch : 0 [606/21279] Train loss: 4.92211,Valid loss: 5.04312, time : 11.395732402801514 lr : 0.99\n",
      "epoch : 0 [607/21279] Train loss: 4.93489,Valid loss: 4.99248, time : 11.909040451049805 lr : 0.99\n",
      "epoch : 0 [608/21279] Train loss: 4.85859,Valid loss: 5.01047, time : 11.551041603088379 lr : 0.99\n",
      "epoch : 0 [609/21279] Train loss: 4.87995,Valid loss: 5.06454, time : 11.446658611297607 lr : 0.99\n",
      "epoch : 0 [610/21279] Train loss: 4.87492,Valid loss: 5.08304, time : 11.425027132034302 lr : 0.99\n",
      "epoch : 0 [611/21279] Train loss: 4.89892,Valid loss: 5.15475, time : 11.896241664886475 lr : 0.99\n",
      "epoch : 0 [612/21279] Train loss: 4.87065,Valid loss: 5.01141, time : 11.644463300704956 lr : 0.99\n",
      "epoch : 0 [613/21279] Train loss: 4.84979,Valid loss: 5.10113, time : 11.765353679656982 lr : 0.99\n",
      "epoch : 0 [614/21279] Train loss: 4.88157,Valid loss: 5.12559, time : 11.488847494125366 lr : 0.99\n",
      "epoch : 0 [615/21279] Train loss: 4.96382,Valid loss: 4.99196, time : 13.6928231716156 lr : 0.99\n",
      "epoch : 0 [616/21279] Train loss: 4.87912,Valid loss: 4.96189, time : 11.548475742340088 lr : 0.99\n",
      "epoch : 0 [617/21279] Train loss: 4.85213,Valid loss: 4.99852, time : 11.085915803909302 lr : 0.99\n",
      "epoch : 0 [618/21279] Train loss: 4.84859,Valid loss: 5.01159, time : 11.752840518951416 lr : 0.99\n",
      "epoch : 0 [619/21279] Train loss: 4.85026,Valid loss: 5.00057, time : 11.463953256607056 lr : 0.99\n",
      "epoch : 0 [620/21279] Train loss: 4.88184,Valid loss: 5.11958, time : 11.980705738067627 lr : 0.99\n",
      "epoch : 0 [621/21279] Train loss: 4.96420,Valid loss: 5.06370, time : 11.912846326828003 lr : 0.99\n",
      "epoch : 0 [622/21279] Train loss: 4.85744,Valid loss: 4.94731, time : 12.110425472259521 lr : 0.99\n",
      "epoch : 0 [623/21279] Train loss: 4.85124,Valid loss: 4.97781, time : 11.965478420257568 lr : 0.99\n",
      "epoch : 0 [624/21279] Train loss: 4.85382,Valid loss: 4.94395, time : 11.465442419052124 lr : 0.99\n",
      "epoch : 0 [625/21279] Train loss: 4.87710,Valid loss: 4.94337, time : 12.612357378005981 lr : 0.99\n",
      "epoch : 0 [626/21279] Train loss: 4.82940,Valid loss: 4.95724, time : 12.017949104309082 lr : 0.99\n",
      "epoch : 0 [627/21279] Train loss: 4.88244,Valid loss: 4.99440, time : 11.665708065032959 lr : 0.99\n",
      "epoch : 0 [628/21279] Train loss: 4.86326,Valid loss: 5.01677, time : 13.472818851470947 lr : 0.99\n",
      "epoch : 0 [629/21279] Train loss: 4.88440,Valid loss: 4.96032, time : 11.334015130996704 lr : 0.99\n",
      "epoch : 0 [630/21279] Train loss: 4.83361,Valid loss: 4.94241, time : 12.151400089263916 lr : 0.99\n",
      "epoch : 0 [631/21279] Train loss: 4.85518,Valid loss: 4.96748, time : 11.620455026626587 lr : 0.99\n",
      "epoch : 0 [632/21279] Train loss: 4.85324,Valid loss: 4.98688, time : 11.618598937988281 lr : 0.99\n",
      "epoch : 0 [633/21279] Train loss: 4.95870,Valid loss: 5.14957, time : 12.28122615814209 lr : 0.99\n",
      "epoch : 0 [634/21279] Train loss: 4.97149,Valid loss: 5.02637, time : 11.045932292938232 lr : 0.99\n",
      "epoch : 0 [635/21279] Train loss: 4.86833,Valid loss: 5.00564, time : 11.85458779335022 lr : 0.99\n",
      "epoch : 0 [636/21279] Train loss: 4.87883,Valid loss: 4.99921, time : 10.953064680099487 lr : 0.99\n",
      "epoch : 0 [637/21279] Train loss: 4.81780,Valid loss: 4.94412, time : 11.525210857391357 lr : 0.99\n",
      "epoch : 0 [638/21279] Train loss: 4.84516,Valid loss: 5.09792, time : 11.856182098388672 lr : 0.99\n",
      "epoch : 0 [639/21279] Train loss: 4.84025,Valid loss: 5.00891, time : 12.02673053741455 lr : 0.99\n",
      "epoch : 0 [640/21279] Train loss: 4.88925,Valid loss: 4.99325, time : 11.608895540237427 lr : 0.99\n",
      "epoch : 0 [641/21279] Train loss: 4.83293,Valid loss: 4.97118, time : 11.610591173171997 lr : 0.99\n",
      "epoch : 0 [642/21279] Train loss: 4.85071,Valid loss: 5.01027, time : 11.55585241317749 lr : 0.99\n",
      "epoch : 0 [643/21279] Train loss: 4.85525,Valid loss: 5.06183, time : 12.9748694896698 lr : 0.99\n",
      "epoch : 0 [644/21279] Train loss: 4.87509,Valid loss: 5.00750, time : 11.668848037719727 lr : 0.99\n",
      "epoch : 0 [645/21279] Train loss: 4.82237,Valid loss: 4.93212, time : 12.407735824584961 lr : 0.99\n",
      "epoch : 0 [646/21279] Train loss: 4.84409,Valid loss: 4.91013, time : 11.420727252960205 lr : 0.99\n",
      "epoch : 0 [647/21279] Train loss: 4.77807,Valid loss: 4.90524, time : 11.793683528900146 lr : 0.99\n",
      "epoch : 0 [648/21279] Train loss: 4.78851,Valid loss: 4.98522, time : 12.516459226608276 lr : 0.99\n",
      "epoch : 0 [649/21279] Train loss: 4.81533,Valid loss: 5.07689, time : 12.01161241531372 lr : 0.99\n",
      "epoch : 0 [650/21279] Train loss: 4.93234,Valid loss: 4.95294, time : 12.226920366287231 lr : 0.99\n",
      "epoch : 0 [651/21279] Train loss: 4.86297,Valid loss: 4.92416, time : 12.26611328125 lr : 0.99\n",
      "epoch : 0 [652/21279] Train loss: 4.81377,Valid loss: 4.94253, time : 11.842548847198486 lr : 0.99\n",
      "epoch : 0 [653/21279] Train loss: 4.80224,Valid loss: 4.99259, time : 12.19976019859314 lr : 0.99\n",
      "epoch : 0 [654/21279] Train loss: 4.81467,Valid loss: 5.11488, time : 11.842346906661987 lr : 0.99\n",
      "epoch : 0 [655/21279] Train loss: 4.87590,Valid loss: 5.04912, time : 13.545645475387573 lr : 0.99\n",
      "epoch : 0 [656/21279] Train loss: 4.88648,Valid loss: 5.06401, time : 11.055323123931885 lr : 0.99\n",
      "epoch : 0 [657/21279] Train loss: 4.82826,Valid loss: 4.94362, time : 11.3868088722229 lr : 0.99\n",
      "epoch : 0 [658/21279] Train loss: 4.78843,Valid loss: 4.92586, time : 11.812207221984863 lr : 0.99\n",
      "epoch : 0 [659/21279] Train loss: 4.79772,Valid loss: 4.92393, time : 11.51995849609375 lr : 0.99\n",
      "epoch : 0 [660/21279] Train loss: 4.77604,Valid loss: 4.98371, time : 11.81940770149231 lr : 0.99\n",
      "epoch : 0 [661/21279] Train loss: 4.82920,Valid loss: 4.92448, time : 11.669634580612183 lr : 0.99\n",
      "epoch : 0 [662/21279] Train loss: 4.75864,Valid loss: 5.00097, time : 11.99649453163147 lr : 0.99\n",
      "epoch : 0 [663/21279] Train loss: 4.78984,Valid loss: 4.98755, time : 11.591433763504028 lr : 0.99\n",
      "epoch : 0 [664/21279] Train loss: 4.85097,Valid loss: 5.06700, time : 12.638649940490723 lr : 0.99\n",
      "epoch : 0 [665/21279] Train loss: 4.83605,Valid loss: 4.97846, time : 11.66014289855957 lr : 0.99\n",
      "epoch : 0 [666/21279] Train loss: 4.81255,Valid loss: 5.02649, time : 11.367387771606445 lr : 0.99\n",
      "epoch : 0 [667/21279] Train loss: 4.79241,Valid loss: 4.97008, time : 11.91671347618103 lr : 0.99\n",
      "epoch : 0 [668/21279] Train loss: 4.77864,Valid loss: 4.95989, time : 11.54710054397583 lr : 0.99\n",
      "epoch : 0 [669/21279] Train loss: 4.79771,Valid loss: 5.07617, time : 19.09786105155945 lr : 0.99\n",
      "epoch : 0 [670/21279] Train loss: 4.91547,Valid loss: 4.97061, time : 11.234501600265503 lr : 0.99\n",
      "epoch : 0 [671/21279] Train loss: 4.78845,Valid loss: 4.88860, time : 12.041261911392212 lr : 0.99\n",
      "epoch : 0 [672/21279] Train loss: 4.77321,Valid loss: 4.94821, time : 12.276734352111816 lr : 0.99\n",
      "epoch : 0 [673/21279] Train loss: 4.75708,Valid loss: 4.90208, time : 12.101750135421753 lr : 0.99\n",
      "epoch : 0 [674/21279] Train loss: 4.81820,Valid loss: 4.89219, time : 12.450238704681396 lr : 0.99\n",
      "epoch : 0 [675/21279] Train loss: 4.75621,Valid loss: 4.87592, time : 12.153184413909912 lr : 0.99\n",
      "epoch : 0 [676/21279] Train loss: 4.76829,Valid loss: 4.92448, time : 11.398029088973999 lr : 0.99\n",
      "epoch : 0 [677/21279] Train loss: 4.79665,Valid loss: 4.96028, time : 11.55619192123413 lr : 0.99\n",
      "epoch : 0 [678/21279] Train loss: 4.85155,Valid loss: 4.95405, time : 12.383007526397705 lr : 0.99\n",
      "epoch : 0 [679/21279] Train loss: 4.78417,Valid loss: 4.89951, time : 12.204881191253662 lr : 0.99\n",
      "epoch : 0 [680/21279] Train loss: 4.77000,Valid loss: 4.92390, time : 12.174318552017212 lr : 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [681/21279] Train loss: 4.76395,Valid loss: 4.89089, time : 13.364815473556519 lr : 0.99\n",
      "epoch : 0 [682/21279] Train loss: 4.72915,Valid loss: 4.92231, time : 11.838987350463867 lr : 0.99\n",
      "epoch : 0 [683/21279] Train loss: 4.72796,Valid loss: 4.90003, time : 12.177138328552246 lr : 0.99\n",
      "epoch : 0 [684/21279] Train loss: 4.76672,Valid loss: 4.98018, time : 12.371362686157227 lr : 0.99\n",
      "epoch : 0 [685/21279] Train loss: 4.75261,Valid loss: 5.03607, time : 12.422059535980225 lr : 0.99\n",
      "epoch : 0 [686/21279] Train loss: 4.80216,Valid loss: 4.99377, time : 11.944973945617676 lr : 0.99\n",
      "epoch : 0 [687/21279] Train loss: 4.76695,Valid loss: 5.00526, time : 12.215057373046875 lr : 0.99\n",
      "epoch : 0 [688/21279] Train loss: 4.74145,Valid loss: 4.97978, time : 12.045120477676392 lr : 0.99\n",
      "epoch : 0 [689/21279] Train loss: 4.74605,Valid loss: 5.10533, time : 12.57434630393982 lr : 0.99\n",
      "epoch : 0 [690/21279] Train loss: 4.78919,Valid loss: 5.05186, time : 12.539033889770508 lr : 0.99\n",
      "epoch : 0 [691/21279] Train loss: 4.82454,Valid loss: 5.16170, time : 11.80246376991272 lr : 0.99\n",
      "epoch : 0 [692/21279] Train loss: 4.88413,Valid loss: 4.95763, time : 11.96354341506958 lr : 0.99\n",
      "epoch : 0 [693/21279] Train loss: 4.73153,Valid loss: 4.86072, time : 11.462780475616455 lr : 0.99\n",
      "epoch : 0 [694/21279] Train loss: 4.73527,Valid loss: 4.83667, time : 11.840413331985474 lr : 0.99\n",
      "epoch : 0 [695/21279] Train loss: 4.70811,Valid loss: 4.88080, time : 12.294341564178467 lr : 0.99\n",
      "epoch : 0 [696/21279] Train loss: 4.71568,Valid loss: 4.82411, time : 11.91391897201538 lr : 0.99\n",
      "epoch : 0 [697/21279] Train loss: 4.71231,Valid loss: 4.94865, time : 17.562041759490967 lr : 0.99\n",
      "epoch : 0 [698/21279] Train loss: 4.82769,Valid loss: 4.86857, time : 11.617080211639404 lr : 0.99\n",
      "epoch : 0 [699/21279] Train loss: 4.77796,Valid loss: 5.03451, time : 11.72971510887146 lr : 0.99\n",
      "epoch : 0 [700/21279] Train loss: 4.82673,Valid loss: 5.03433, time : 12.134580135345459 lr : 0.99\n",
      "epoch : 0 [701/21279] Train loss: 4.75270,Valid loss: 4.92876, time : 12.283160924911499 lr : 0.99\n",
      "epoch : 0 [702/21279] Train loss: 4.72669,Valid loss: 4.91962, time : 12.265112400054932 lr : 0.99\n",
      "epoch : 0 [703/21279] Train loss: 4.70459,Valid loss: 4.87808, time : 12.344263076782227 lr : 0.99\n",
      "epoch : 0 [704/21279] Train loss: 4.77319,Valid loss: 4.96146, time : 12.733335971832275 lr : 0.99\n",
      "epoch : 0 [705/21279] Train loss: 4.80824,Valid loss: 5.03251, time : 11.733800172805786 lr : 0.99\n",
      "epoch : 0 [706/21279] Train loss: 4.89444,Valid loss: 5.09461, time : 11.256149768829346 lr : 0.99\n",
      "epoch : 0 [707/21279] Train loss: 4.82751,Valid loss: 5.15115, time : 11.572723865509033 lr : 0.99\n",
      "epoch : 0 [708/21279] Train loss: 4.77216,Valid loss: 5.02002, time : 11.277454376220703 lr : 0.99\n",
      "epoch : 0 [709/21279] Train loss: 4.76575,Valid loss: 4.98627, time : 13.794105052947998 lr : 0.99\n",
      "epoch : 0 [710/21279] Train loss: 4.80486,Valid loss: 4.90205, time : 12.00585126876831 lr : 0.99\n",
      "epoch : 0 [711/21279] Train loss: 4.71815,Valid loss: 4.84555, time : 11.80568790435791 lr : 0.99\n",
      "epoch : 0 [712/21279] Train loss: 4.70369,Valid loss: 4.85816, time : 12.448303699493408 lr : 0.99\n",
      "epoch : 0 [713/21279] Train loss: 4.69457,Valid loss: 4.85610, time : 11.631001472473145 lr : 0.99\n",
      "epoch : 0 [714/21279] Train loss: 4.73479,Valid loss: 4.93247, time : 12.501657724380493 lr : 0.99\n",
      "epoch : 0 [715/21279] Train loss: 4.71671,Valid loss: 4.89961, time : 12.29145097732544 lr : 0.99\n",
      "epoch : 0 [716/21279] Train loss: 4.73623,Valid loss: 4.89509, time : 12.209136009216309 lr : 0.99\n",
      "epoch : 0 [717/21279] Train loss: 4.72466,Valid loss: 4.93302, time : 12.249931573867798 lr : 0.99\n",
      "epoch : 0 [718/21279] Train loss: 4.75148,Valid loss: 4.81366, time : 11.910942554473877 lr : 0.99\n",
      "epoch : 0 [719/21279] Train loss: 4.68649,Valid loss: 4.85235, time : 12.222001552581787 lr : 0.99\n",
      "epoch : 0 [720/21279] Train loss: 4.69355,Valid loss: 4.88059, time : 11.725684404373169 lr : 0.99\n",
      "epoch : 0 [721/21279] Train loss: 4.70929,Valid loss: 4.91331, time : 12.332033634185791 lr : 0.99\n",
      "epoch : 0 [722/21279] Train loss: 4.72494,Valid loss: 4.88625, time : 12.285603284835815 lr : 0.99\n",
      "epoch : 0 [723/21279] Train loss: 4.71099,Valid loss: 4.87899, time : 11.620120763778687 lr : 0.99\n",
      "epoch : 0 [724/21279] Train loss: 4.69285,Valid loss: 4.94047, time : 11.52848482131958 lr : 0.99\n",
      "epoch : 0 [725/21279] Train loss: 4.70907,Valid loss: 4.86258, time : 13.574547529220581 lr : 0.99\n",
      "epoch : 0 [726/21279] Train loss: 4.70831,Valid loss: 5.01645, time : 11.594805240631104 lr : 0.99\n",
      "epoch : 0 [727/21279] Train loss: 4.72823,Valid loss: 4.85618, time : 12.141031265258789 lr : 0.99\n",
      "epoch : 0 [728/21279] Train loss: 4.68101,Valid loss: 4.91283, time : 12.212352991104126 lr : 0.99\n",
      "epoch : 0 [729/21279] Train loss: 4.68329,Valid loss: 4.90421, time : 11.971492052078247 lr : 0.99\n",
      "epoch : 0 [730/21279] Train loss: 4.68683,Valid loss: 5.00314, time : 11.850396394729614 lr : 0.99\n",
      "epoch : 0 [731/21279] Train loss: 4.74344,Valid loss: 4.97532, time : 12.571572542190552 lr : 0.99\n",
      "epoch : 0 [732/21279] Train loss: 4.77497,Valid loss: 4.87357, time : 12.329643726348877 lr : 0.99\n",
      "epoch : 0 [733/21279] Train loss: 4.73460,Valid loss: 4.86052, time : 12.067190885543823 lr : 0.99\n",
      "epoch : 0 [734/21279] Train loss: 4.68977,Valid loss: 4.88393, time : 12.094092845916748 lr : 0.99\n",
      "epoch : 0 [735/21279] Train loss: 4.70954,Valid loss: 4.82815, time : 12.49501347541809 lr : 0.99\n",
      "epoch : 0 [736/21279] Train loss: 4.65146,Valid loss: 4.85271, time : 12.104633808135986 lr : 0.99\n",
      "epoch : 0 [737/21279] Train loss: 4.64120,Valid loss: 4.80235, time : 14.925515413284302 lr : 0.99\n",
      "epoch : 0 [738/21279] Train loss: 4.66846,Valid loss: 4.91974, time : 11.4115469455719 lr : 0.99\n",
      "epoch : 0 [739/21279] Train loss: 4.72633,Valid loss: 5.18511, time : 11.75383996963501 lr : 0.99\n",
      "epoch : 0 [740/21279] Train loss: 4.88813,Valid loss: 4.87402, time : 11.780829191207886 lr : 0.99\n",
      "epoch : 0 [741/21279] Train loss: 4.73120,Valid loss: 4.88520, time : 12.34749460220337 lr : 0.99\n",
      "epoch : 0 [742/21279] Train loss: 4.66888,Valid loss: 4.86021, time : 12.144572973251343 lr : 0.99\n",
      "epoch : 0 [743/21279] Train loss: 4.68955,Valid loss: 4.82952, time : 12.035542249679565 lr : 0.99\n",
      "epoch : 0 [744/21279] Train loss: 4.68633,Valid loss: 4.83286, time : 12.2438325881958 lr : 0.99\n",
      "epoch : 0 [745/21279] Train loss: 4.64666,Valid loss: 4.86705, time : 11.803802490234375 lr : 0.99\n",
      "epoch : 0 [746/21279] Train loss: 4.71479,Valid loss: 4.82700, time : 11.991323471069336 lr : 0.99\n",
      "epoch : 0 [747/21279] Train loss: 4.66900,Valid loss: 4.89011, time : 12.204034328460693 lr : 0.99\n",
      "epoch : 0 [748/21279] Train loss: 4.71592,Valid loss: 4.82458, time : 11.845201969146729 lr : 0.99\n",
      "epoch : 0 [749/21279] Train loss: 4.65702,Valid loss: 4.87562, time : 13.682947397232056 lr : 0.99\n",
      "epoch : 0 [750/21279] Train loss: 4.69369,Valid loss: 4.85443, time : 11.3662109375 lr : 0.99\n",
      "epoch : 0 [751/21279] Train loss: 4.70689,Valid loss: 4.86176, time : 11.863182544708252 lr : 0.99\n",
      "epoch : 0 [752/21279] Train loss: 4.67130,Valid loss: 4.81967, time : 11.369528532028198 lr : 0.99\n",
      "epoch : 0 [753/21279] Train loss: 4.62974,Valid loss: 4.82965, time : 11.93157410621643 lr : 0.99\n",
      "epoch : 0 [754/21279] Train loss: 4.62458,Valid loss: 4.96073, time : 11.87497329711914 lr : 0.99\n",
      "epoch : 0 [755/21279] Train loss: 4.64065,Valid loss: 5.05958, time : 11.303467750549316 lr : 0.99\n",
      "epoch : 0 [756/21279] Train loss: 4.77283,Valid loss: 5.05467, time : 11.45335602760315 lr : 0.99\n",
      "epoch : 0 [757/21279] Train loss: 4.70825,Valid loss: 4.99894, time : 11.196098327636719 lr : 0.99\n",
      "epoch : 0 [758/21279] Train loss: 4.71117,Valid loss: 4.88620, time : 11.940390825271606 lr : 0.99\n",
      "epoch : 0 [759/21279] Train loss: 4.67877,Valid loss: 4.79986, time : 12.302936792373657 lr : 0.99\n",
      "epoch : 0 [760/21279] Train loss: 4.63365,Valid loss: 4.80639, time : 12.547696113586426 lr : 0.99\n",
      "epoch : 0 [761/21279] Train loss: 4.63350,Valid loss: 4.80962, time : 12.007564544677734 lr : 0.99\n",
      "epoch : 0 [762/21279] Train loss: 4.61465,Valid loss: 4.90208, time : 12.015055656433105 lr : 0.99\n",
      "epoch : 0 [763/21279] Train loss: 4.64633,Valid loss: 4.86150, time : 12.210180044174194 lr : 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [764/21279] Train loss: 4.66535,Valid loss: 4.95279, time : 12.148228406906128 lr : 0.99\n",
      "epoch : 0 [765/21279] Train loss: 4.67170,Valid loss: 4.89385, time : 15.0916907787323 lr : 0.99\n",
      "epoch : 0 [766/21279] Train loss: 4.66745,Valid loss: 4.91932, time : 12.13465929031372 lr : 0.99\n",
      "epoch : 0 [767/21279] Train loss: 4.66964,Valid loss: 4.88335, time : 12.14516282081604 lr : 0.99\n",
      "epoch : 0 [768/21279] Train loss: 4.66958,Valid loss: 4.83008, time : 11.661271572113037 lr : 0.99\n",
      "epoch : 0 [769/21279] Train loss: 4.61121,Valid loss: 4.85644, time : 11.53825330734253 lr : 0.99\n",
      "epoch : 0 [770/21279] Train loss: 4.61954,Valid loss: 4.83066, time : 11.700281620025635 lr : 0.99\n",
      "epoch : 0 [771/21279] Train loss: 4.63412,Valid loss: 4.89565, time : 11.78589391708374 lr : 0.99\n",
      "epoch : 0 [772/21279] Train loss: 4.63214,Valid loss: 4.95313, time : 11.704999685287476 lr : 0.99\n",
      "epoch : 0 [773/21279] Train loss: 4.71529,Valid loss: 4.79951, time : 12.16714859008789 lr : 0.99\n",
      "epoch : 0 [774/21279] Train loss: 4.63899,Valid loss: 4.96979, time : 11.848274946212769 lr : 0.99\n",
      "epoch : 0 [775/21279] Train loss: 4.68712,Valid loss: 4.86869, time : 11.919249773025513 lr : 0.99\n",
      "epoch : 0 [776/21279] Train loss: 4.64667,Valid loss: 4.88461, time : 11.788224697113037 lr : 0.99\n",
      "epoch : 0 [777/21279] Train loss: 4.64560,Valid loss: 4.92913, time : 11.987514972686768 lr : 0.99\n",
      "epoch : 0 [778/21279] Train loss: 4.58741,Valid loss: 4.91625, time : 14.096276044845581 lr : 0.99\n",
      "epoch : 0 [779/21279] Train loss: 4.60775,Valid loss: 4.85547, time : 12.46504545211792 lr : 0.99\n",
      "epoch : 0 [780/21279] Train loss: 4.61420,Valid loss: 4.88979, time : 12.23119831085205 lr : 0.99\n",
      "epoch : 0 [781/21279] Train loss: 4.65420,Valid loss: 4.83926, time : 12.120042562484741 lr : 0.99\n",
      "epoch : 0 [782/21279] Train loss: 4.61856,Valid loss: 4.90530, time : 11.909542798995972 lr : 0.99\n",
      "epoch : 0 [783/21279] Train loss: 4.62833,Valid loss: 4.91746, time : 12.137001514434814 lr : 0.99\n",
      "epoch : 0 [784/21279] Train loss: 4.62200,Valid loss: 4.93081, time : 11.598583221435547 lr : 0.99\n",
      "epoch : 0 [785/21279] Train loss: 4.74506,Valid loss: 4.88894, time : 11.987920045852661 lr : 0.99\n",
      "epoch : 0 [786/21279] Train loss: 4.65054,Valid loss: 4.90343, time : 11.958023309707642 lr : 0.99\n",
      "epoch : 0 [787/21279] Train loss: 4.65261,Valid loss: 4.86599, time : 11.724167823791504 lr : 0.99\n",
      "epoch : 0 [788/21279] Train loss: 4.64080,Valid loss: 4.87033, time : 11.745965242385864 lr : 0.99\n",
      "epoch : 0 [789/21279] Train loss: 4.59245,Valid loss: 4.89860, time : 11.68936824798584 lr : 0.99\n",
      "epoch : 0 [790/21279] Train loss: 4.58232,Valid loss: 4.81016, time : 12.213288068771362 lr : 0.99\n",
      "epoch : 0 [791/21279] Train loss: 4.61194,Valid loss: 5.05344, time : 11.451816320419312 lr : 0.99\n",
      "epoch : 0 [792/21279] Train loss: 4.61073,Valid loss: 4.90896, time : 12.298510074615479 lr : 0.99\n",
      "epoch : 0 [793/21279] Train loss: 4.62936,Valid loss: 4.95003, time : 13.52586841583252 lr : 0.99\n",
      "epoch : 0 [794/21279] Train loss: 4.60351,Valid loss: 4.81126, time : 11.671367168426514 lr : 0.99\n",
      "epoch : 0 [795/21279] Train loss: 4.61945,Valid loss: 4.82866, time : 12.10123610496521 lr : 0.99\n",
      "epoch : 0 [796/21279] Train loss: 4.62367,Valid loss: 4.97531, time : 12.54025387763977 lr : 0.99\n",
      "epoch : 0 [797/21279] Train loss: 4.71306,Valid loss: 4.79468, time : 11.756251573562622 lr : 0.99\n",
      "epoch : 0 [798/21279] Train loss: 4.62885,Valid loss: 4.93340, time : 12.134478330612183 lr : 0.99\n",
      "epoch : 0 [799/21279] Train loss: 4.59344,Valid loss: 4.77322, time : 12.184950590133667 lr : 0.99\n",
      "epoch : 0 [800/21279] Train loss: 4.61558,Valid loss: 4.85497, time : 12.19745922088623 lr : 0.99\n",
      "epoch : 0 [801/21279] Train loss: 4.66318,Valid loss: 4.87250, time : 11.700019121170044 lr : 0.99\n",
      "epoch : 0 [802/21279] Train loss: 4.59777,Valid loss: 4.79501, time : 11.793971538543701 lr : 0.99\n",
      "epoch : 0 [803/21279] Train loss: 4.60708,Valid loss: 4.84489, time : 11.997956991195679 lr : 0.99\n",
      "epoch : 0 [804/21279] Train loss: 4.60460,Valid loss: 4.77946, time : 12.025747299194336 lr : 0.99\n",
      "epoch : 0 [805/21279] Train loss: 4.60585,Valid loss: 4.90064, time : 14.397959470748901 lr : 0.99\n",
      "epoch : 0 [806/21279] Train loss: 4.58377,Valid loss: 4.88292, time : 12.283916711807251 lr : 0.99\n",
      "epoch : 0 [807/21279] Train loss: 4.64768,Valid loss: 4.84076, time : 12.59694242477417 lr : 0.99\n",
      "epoch : 0 [808/21279] Train loss: 4.53475,Valid loss: 4.77074, time : 12.73065733909607 lr : 0.99\n",
      "epoch : 0 [809/21279] Train loss: 4.56527,Valid loss: 4.81639, time : 11.75541877746582 lr : 0.99\n",
      "epoch : 0 [810/21279] Train loss: 4.55051,Valid loss: 4.94409, time : 12.371575593948364 lr : 0.99\n",
      "epoch : 0 [811/21279] Train loss: 4.65706,Valid loss: 4.86403, time : 11.864442348480225 lr : 0.99\n",
      "epoch : 0 [812/21279] Train loss: 4.67872,Valid loss: 4.93277, time : 12.22422480583191 lr : 0.99\n",
      "epoch : 0 [813/21279] Train loss: 4.63754,Valid loss: 4.76588, time : 12.113294839859009 lr : 0.99\n",
      "epoch : 0 [814/21279] Train loss: 4.57062,Valid loss: 4.70107, time : 12.618974685668945 lr : 0.99\n",
      "epoch : 0 [815/21279] Train loss: 4.56390,Valid loss: 4.78056, time : 12.195850133895874 lr : 0.99\n",
      "epoch : 0 [816/21279] Train loss: 4.55984,Valid loss: 4.73694, time : 12.064683675765991 lr : 0.99\n",
      "epoch : 0 [817/21279] Train loss: 4.54384,Valid loss: 4.83243, time : 12.44157862663269 lr : 0.99\n",
      "epoch : 0 [818/21279] Train loss: 4.59324,Valid loss: 4.75457, time : 12.089882135391235 lr : 0.99\n",
      "epoch : 0 [819/21279] Train loss: 4.56199,Valid loss: 4.82979, time : 16.92269468307495 lr : 0.99\n",
      "epoch : 0 [820/21279] Train loss: 4.59312,Valid loss: 4.88079, time : 11.997691869735718 lr : 0.99\n",
      "epoch : 0 [821/21279] Train loss: 4.53769,Valid loss: 4.89224, time : 12.366904258728027 lr : 0.99\n",
      "epoch : 0 [822/21279] Train loss: 4.58476,Valid loss: 4.84052, time : 11.810275077819824 lr : 0.99\n",
      "epoch : 0 [823/21279] Train loss: 4.56369,Valid loss: 4.80474, time : 11.962247133255005 lr : 0.99\n",
      "epoch : 0 [824/21279] Train loss: 4.55052,Valid loss: 4.89064, time : 11.849022150039673 lr : 0.99\n",
      "epoch : 0 [825/21279] Train loss: 4.60303,Valid loss: 5.06418, time : 12.13693904876709 lr : 0.99\n",
      "epoch : 0 [826/21279] Train loss: 4.62744,Valid loss: 4.87228, time : 11.990398645401001 lr : 0.99\n",
      "epoch : 0 [827/21279] Train loss: 4.60705,Valid loss: 4.83814, time : 12.399263143539429 lr : 0.99\n",
      "epoch : 0 [828/21279] Train loss: 4.55885,Valid loss: 4.79464, time : 12.277181625366211 lr : 0.99\n",
      "epoch : 0 [829/21279] Train loss: 4.57262,Valid loss: 4.84098, time : 12.549768924713135 lr : 0.99\n",
      "epoch : 0 [830/21279] Train loss: 4.61405,Valid loss: 4.81623, time : 12.931090593338013 lr : 0.99\n",
      "epoch : 0 [831/21279] Train loss: 4.57663,Valid loss: 4.89990, time : 13.848783493041992 lr : 0.99\n",
      "epoch : 0 [832/21279] Train loss: 4.68090,Valid loss: 4.96559, time : 12.391972303390503 lr : 0.99\n",
      "epoch : 0 [833/21279] Train loss: 4.64713,Valid loss: 4.88418, time : 11.916240930557251 lr : 0.99\n",
      "epoch : 0 [834/21279] Train loss: 4.59406,Valid loss: 4.76677, time : 11.577881813049316 lr : 0.99\n",
      "epoch : 0 [835/21279] Train loss: 4.52830,Valid loss: 4.73688, time : 12.12307596206665 lr : 0.99\n",
      "epoch : 0 [836/21279] Train loss: 4.50926,Valid loss: 4.76513, time : 12.499521970748901 lr : 0.99\n",
      "epoch : 0 [837/21279] Train loss: 4.52661,Valid loss: 4.70897, time : 12.372438192367554 lr : 0.99\n",
      "epoch : 0 [838/21279] Train loss: 4.52241,Valid loss: 4.72950, time : 12.34644865989685 lr : 0.99\n",
      "epoch : 0 [839/21279] Train loss: 4.51469,Valid loss: 4.78674, time : 12.520631551742554 lr : 0.99\n",
      "epoch : 0 [840/21279] Train loss: 4.56311,Valid loss: 4.85426, time : 12.801111459732056 lr : 0.99\n",
      "epoch : 0 [841/21279] Train loss: 4.52787,Valid loss: 4.92231, time : 12.560836791992188 lr : 0.99\n",
      "epoch : 0 [842/21279] Train loss: 4.60973,Valid loss: 4.86103, time : 12.708996772766113 lr : 0.99\n",
      "epoch : 0 [843/21279] Train loss: 4.57224,Valid loss: 4.85615, time : 12.305614471435547 lr : 0.99\n",
      "epoch : 0 [844/21279] Train loss: 4.56517,Valid loss: 4.74754, time : 12.297017097473145 lr : 0.99\n",
      "epoch : 0 [845/21279] Train loss: 4.52211,Valid loss: 4.69735, time : 12.455679416656494 lr : 0.99\n",
      "epoch : 0 [846/21279] Train loss: 4.51809,Valid loss: 4.70396, time : 12.638379335403442 lr : 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [847/21279] Train loss: 4.48605,Valid loss: 4.79699, time : 14.825771570205688 lr : 0.99\n",
      "epoch : 0 [848/21279] Train loss: 4.51176,Valid loss: 4.74874, time : 12.116151094436646 lr : 0.99\n",
      "epoch : 0 [849/21279] Train loss: 4.53311,Valid loss: 4.86619, time : 12.264716386795044 lr : 0.99\n",
      "epoch : 0 [850/21279] Train loss: 4.56540,Valid loss: 4.81469, time : 11.798486948013306 lr : 0.99\n",
      "epoch : 0 [851/21279] Train loss: 4.54449,Valid loss: 4.83404, time : 11.370555877685547 lr : 0.99\n",
      "epoch : 0 [852/21279] Train loss: 4.54550,Valid loss: 4.92144, time : 11.743183851242065 lr : 0.99\n",
      "epoch : 0 [853/21279] Train loss: 4.59577,Valid loss: 4.75182, time : 11.392359018325806 lr : 0.99\n",
      "epoch : 0 [854/21279] Train loss: 4.55297,Valid loss: 4.78440, time : 11.805839776992798 lr : 0.99\n",
      "epoch : 0 [855/21279] Train loss: 4.50317,Valid loss: 4.69580, time : 12.088062763214111 lr : 0.99\n",
      "epoch : 0 [856/21279] Train loss: 4.50418,Valid loss: 4.74251, time : 11.67400860786438 lr : 0.99\n",
      "epoch : 0 [857/21279] Train loss: 4.46592,Valid loss: 4.76948, time : 12.034579038619995 lr : 0.99\n",
      "epoch : 0 [858/21279] Train loss: 4.51287,Valid loss: 4.78250, time : 11.459020614624023 lr : 0.99\n",
      "epoch : 0 [859/21279] Train loss: 4.52412,Valid loss: 4.85232, time : 14.626460075378418 lr : 0.99\n",
      "epoch : 0 [860/21279] Train loss: 4.56233,Valid loss: 4.76232, time : 11.213714122772217 lr : 0.99\n",
      "epoch : 0 [861/21279] Train loss: 4.48843,Valid loss: 4.82260, time : 11.963680744171143 lr : 0.99\n",
      "epoch : 0 [862/21279] Train loss: 4.53577,Valid loss: 4.74881, time : 11.945760726928711 lr : 0.99\n",
      "epoch : 0 [863/21279] Train loss: 4.55218,Valid loss: 5.06395, time : 12.42764163017273 lr : 0.99\n",
      "epoch : 0 [864/21279] Train loss: 4.74523,Valid loss: 4.84561, time : 12.380677223205566 lr : 0.99\n",
      "epoch : 0 [865/21279] Train loss: 4.57002,Valid loss: 4.74086, time : 11.620521545410156 lr : 0.99\n",
      "epoch : 0 [866/21279] Train loss: 4.52265,Valid loss: 4.71737, time : 11.804432392120361 lr : 0.99\n",
      "epoch : 0 [867/21279] Train loss: 4.48479,Valid loss: 4.80722, time : 11.873898267745972 lr : 0.99\n",
      "epoch : 0 [868/21279] Train loss: 4.47158,Valid loss: 4.73635, time : 11.784863233566284 lr : 0.99\n",
      "epoch : 0 [869/21279] Train loss: 4.46960,Valid loss: 4.79523, time : 12.187206029891968 lr : 0.99\n",
      "epoch : 0 [870/21279] Train loss: 4.50788,Valid loss: 4.67842, time : 11.46297001838684 lr : 0.99\n",
      "epoch : 0 [871/21279] Train loss: 4.43464,Valid loss: 4.73862, time : 11.737876176834106 lr : 0.99\n",
      "epoch : 0 [872/21279] Train loss: 4.44509,Valid loss: 4.69178, time : 11.56871485710144 lr : 0.99\n",
      "epoch : 0 [873/21279] Train loss: 4.45701,Valid loss: 5.01402, time : 11.490430355072021 lr : 0.99\n",
      "epoch : 0 [874/21279] Train loss: 4.53243,Valid loss: 4.82450, time : 11.180182933807373 lr : 0.99\n",
      "epoch : 0 [875/21279] Train loss: 4.47622,Valid loss: 5.04994, time : 13.837278604507446 lr : 0.99\n",
      "epoch : 0 [876/21279] Train loss: 4.58042,Valid loss: 4.91371, time : 11.19331693649292 lr : 0.99\n",
      "epoch : 0 [877/21279] Train loss: 4.58459,Valid loss: 5.16315, time : 12.136316061019897 lr : 0.99\n",
      "epoch : 0 [878/21279] Train loss: 4.61784,Valid loss: 5.08411, time : 11.398006916046143 lr : 0.99\n",
      "epoch : 0 [879/21279] Train loss: 4.63556,Valid loss: 5.02194, time : 11.781622648239136 lr : 0.99\n",
      "epoch : 0 [880/21279] Train loss: 4.60613,Valid loss: 4.98699, time : 10.931854724884033 lr : 0.99\n",
      "epoch : 0 [881/21279] Train loss: 4.60385,Valid loss: 5.04245, time : 11.39275074005127 lr : 0.99\n",
      "epoch : 0 [882/21279] Train loss: 4.55023,Valid loss: 5.16101, time : 11.162061929702759 lr : 0.99\n",
      "epoch : 0 [883/21279] Train loss: 4.56593,Valid loss: 5.64517, time : 11.532244682312012 lr : 0.99\n",
      "epoch : 0 [884/21279] Train loss: 4.62596,Valid loss: 4.89537, time : 11.10231328010559 lr : 0.99\n",
      "epoch : 0 [885/21279] Train loss: 4.56791,Valid loss: 5.29278, time : 11.62829303741455 lr : 0.99\n",
      "epoch : 0 [886/21279] Train loss: 4.58820,Valid loss: 4.93806, time : 11.832592010498047 lr : 0.99\n",
      "epoch : 0 [887/21279] Train loss: 4.50108,Valid loss: 5.00603, time : 11.362890481948853 lr : 0.99\n",
      "epoch : 0 [888/21279] Train loss: 4.45802,Valid loss: 4.83693, time : 16.079893350601196 lr : 0.99\n",
      "epoch : 0 [889/21279] Train loss: 4.48557,Valid loss: 4.78148, time : 11.798684120178223 lr : 0.99\n",
      "epoch : 0 [890/21279] Train loss: 4.47104,Valid loss: 4.79670, time : 11.75847840309143 lr : 0.99\n",
      "epoch : 0 [891/21279] Train loss: 4.41778,Valid loss: 4.65955, time : 11.638136386871338 lr : 0.99\n",
      "epoch : 0 [892/21279] Train loss: 4.42404,Valid loss: 4.65069, time : 12.062778949737549 lr : 0.99\n",
      "epoch : 0 [893/21279] Train loss: 4.40785,Valid loss: 4.65510, time : 12.040125608444214 lr : 0.99\n",
      "epoch : 0 [894/21279] Train loss: 4.39675,Valid loss: 4.79665, time : 11.830027341842651 lr : 0.99\n",
      "epoch : 0 [895/21279] Train loss: 4.47540,Valid loss: 4.96077, time : 12.306503295898438 lr : 0.99\n",
      "epoch : 0 [896/21279] Train loss: 4.57059,Valid loss: 5.02142, time : 12.006842136383057 lr : 0.99\n",
      "epoch : 0 [897/21279] Train loss: 4.66811,Valid loss: 4.72122, time : 11.848801136016846 lr : 0.99\n",
      "epoch : 0 [898/21279] Train loss: 4.47466,Valid loss: 4.78242, time : 11.826870203018188 lr : 0.99\n",
      "epoch : 0 [899/21279] Train loss: 4.44166,Valid loss: 4.70948, time : 12.466864824295044 lr : 0.99\n",
      "epoch : 0 [900/21279] Train loss: 4.49916,Valid loss: 4.84420, time : 11.908057451248169 lr : 0.99\n",
      "epoch : 0 [901/21279] Train loss: 4.55789,Valid loss: 4.87951, time : 12.3252534866333 lr : 0.99\n",
      "epoch : 0 [902/21279] Train loss: 4.46204,Valid loss: 4.68806, time : 11.824056386947632 lr : 0.99\n",
      "epoch : 0 [903/21279] Train loss: 4.42986,Valid loss: 4.71253, time : 13.814565658569336 lr : 0.99\n",
      "epoch : 0 [904/21279] Train loss: 4.39805,Valid loss: 4.74330, time : 11.895829916000366 lr : 0.99\n",
      "epoch : 0 [905/21279] Train loss: 4.44105,Valid loss: 4.68820, time : 11.89911413192749 lr : 0.99\n",
      "epoch : 0 [906/21279] Train loss: 4.41793,Valid loss: 4.76767, time : 11.899381875991821 lr : 0.99\n",
      "epoch : 0 [907/21279] Train loss: 4.47077,Valid loss: 4.68638, time : 12.369113445281982 lr : 0.99\n",
      "epoch : 0 [908/21279] Train loss: 4.43767,Valid loss: 4.74242, time : 12.542829513549805 lr : 0.99\n",
      "epoch : 0 [909/21279] Train loss: 4.43067,Valid loss: 4.73496, time : 12.272859811782837 lr : 0.99\n",
      "epoch : 0 [910/21279] Train loss: 4.39775,Valid loss: 4.68125, time : 11.991232872009277 lr : 0.99\n",
      "epoch : 0 [911/21279] Train loss: 4.43338,Valid loss: 4.77917, time : 12.167121171951294 lr : 0.99\n",
      "epoch : 0 [912/21279] Train loss: 4.41565,Valid loss: 4.66064, time : 11.477370977401733 lr : 0.99\n",
      "epoch : 0 [913/21279] Train loss: 4.44327,Valid loss: 4.70870, time : 12.30100417137146 lr : 0.99\n",
      "epoch : 0 [914/21279] Train loss: 4.42567,Valid loss: 4.70472, time : 11.552613735198975 lr : 0.99\n",
      "epoch : 0 [915/21279] Train loss: 4.49543,Valid loss: 4.84958, time : 13.735886096954346 lr : 0.99\n",
      "epoch : 0 [916/21279] Train loss: 4.51215,Valid loss: 4.94501, time : 11.899543046951294 lr : 0.99\n",
      "epoch : 0 [917/21279] Train loss: 4.49557,Valid loss: 4.81719, time : 12.196959495544434 lr : 0.99\n",
      "epoch : 0 [918/21279] Train loss: 4.41407,Valid loss: 4.71994, time : 12.942791938781738 lr : 0.99\n",
      "epoch : 0 [919/21279] Train loss: 4.38618,Valid loss: 4.63611, time : 12.814234256744385 lr : 0.99\n",
      "epoch : 0 [920/21279] Train loss: 4.37743,Valid loss: 4.81488, time : 12.644470691680908 lr : 0.99\n",
      "epoch : 0 [921/21279] Train loss: 4.40469,Valid loss: 4.65935, time : 12.554946660995483 lr : 0.99\n",
      "epoch : 0 [922/21279] Train loss: 4.45480,Valid loss: 5.01944, time : 11.955682039260864 lr : 0.99\n",
      "epoch : 0 [923/21279] Train loss: 4.58186,Valid loss: 4.67899, time : 12.86485481262207 lr : 0.99\n",
      "epoch : 0 [924/21279] Train loss: 4.46777,Valid loss: 4.88873, time : 12.399932861328125 lr : 0.99\n",
      "epoch : 0 [925/21279] Train loss: 4.48826,Valid loss: 4.64633, time : 12.660581111907959 lr : 0.99\n",
      "epoch : 0 [926/21279] Train loss: 4.41238,Valid loss: 4.69192, time : 12.472249507904053 lr : 0.99\n",
      "epoch : 0 [927/21279] Train loss: 4.38469,Valid loss: 4.60180, time : 12.758558511734009 lr : 0.99\n",
      "epoch : 0 [928/21279] Train loss: 4.38879,Valid loss: 4.79127, time : 12.765122890472412 lr : 0.99\n",
      "epoch : 0 [929/21279] Train loss: 4.36599,Valid loss: 4.72229, time : 13.59383249282837 lr : 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [930/21279] Train loss: 4.37952,Valid loss: 4.76866, time : 12.301211595535278 lr : 0.99\n",
      "epoch : 0 [931/21279] Train loss: 4.45861,Valid loss: 4.74076, time : 12.349539756774902 lr : 0.99\n",
      "epoch : 0 [932/21279] Train loss: 4.36922,Valid loss: 4.61306, time : 12.458149671554565 lr : 0.99\n",
      "epoch : 0 [933/21279] Train loss: 4.37621,Valid loss: 4.67542, time : 12.403028726577759 lr : 0.99\n",
      "epoch : 0 [934/21279] Train loss: 4.39496,Valid loss: 4.72812, time : 12.492802381515503 lr : 0.99\n",
      "epoch : 0 [935/21279] Train loss: 4.45538,Valid loss: 4.67772, time : 12.581629753112793 lr : 0.99\n",
      "epoch : 0 [936/21279] Train loss: 4.37401,Valid loss: 4.64517, time : 11.836921215057373 lr : 0.99\n",
      "epoch : 0 [937/21279] Train loss: 4.36083,Valid loss: 4.62670, time : 11.885070562362671 lr : 0.99\n",
      "epoch : 0 [938/21279] Train loss: 4.33637,Valid loss: 4.68059, time : 11.8229660987854 lr : 0.99\n",
      "epoch : 0 [939/21279] Train loss: 4.34716,Valid loss: 4.72593, time : 12.516276836395264 lr : 0.99\n",
      "epoch : 0 [940/21279] Train loss: 4.38358,Valid loss: 4.87901, time : 11.67476773262024 lr : 0.99\n",
      "epoch : 0 [941/21279] Train loss: 4.46561,Valid loss: 4.85743, time : 14.364031791687012 lr : 0.99\n",
      "epoch : 0 [942/21279] Train loss: 4.53184,Valid loss: 4.77949, time : 11.785438776016235 lr : 0.99\n",
      "epoch : 0 [943/21279] Train loss: 4.48351,Valid loss: 4.92363, time : 12.512045621871948 lr : 0.99\n",
      "epoch : 0 [944/21279] Train loss: 4.48615,Valid loss: 4.74716, time : 11.63462233543396 lr : 0.99\n",
      "epoch : 0 [945/21279] Train loss: 4.42459,Valid loss: 4.82454, time : 12.341637372970581 lr : 0.99\n",
      "epoch : 0 [946/21279] Train loss: 4.42973,Valid loss: 4.59706, time : 12.355705976486206 lr : 0.99\n",
      "epoch : 0 [947/21279] Train loss: 4.35668,Valid loss: 4.95151, time : 12.178580045700073 lr : 0.99\n",
      "epoch : 0 [948/21279] Train loss: 4.48513,Valid loss: 4.71104, time : 12.219544172286987 lr : 0.99\n",
      "epoch : 0 [949/21279] Train loss: 4.40945,Valid loss: 4.92382, time : 11.710689783096313 lr : 0.99\n",
      "epoch : 0 [950/21279] Train loss: 4.42403,Valid loss: 4.55024, time : 11.961999416351318 lr : 0.99\n",
      "epoch : 0 [951/21279] Train loss: 4.40339,Valid loss: 4.88120, time : 11.998562812805176 lr : 0.99\n",
      "epoch : 0 [952/21279] Train loss: 4.43145,Valid loss: 4.60508, time : 12.028629779815674 lr : 0.99\n",
      "epoch : 0 [953/21279] Train loss: 4.33394,Valid loss: 4.70014, time : 12.09928560256958 lr : 0.99\n",
      "epoch : 0 [954/21279] Train loss: 4.31776,Valid loss: 4.67438, time : 11.854586362838745 lr : 0.99\n",
      "epoch : 0 [955/21279] Train loss: 4.34138,Valid loss: 4.75104, time : 12.445638656616211 lr : 0.99\n",
      "epoch : 0 [956/21279] Train loss: 4.31292,Valid loss: 4.67839, time : 12.47792387008667 lr : 0.99\n",
      "epoch : 0 [957/21279] Train loss: 4.33064,Valid loss: 4.72894, time : 15.088884353637695 lr : 0.99\n",
      "epoch : 0 [958/21279] Train loss: 4.35536,Valid loss: 4.58055, time : 12.383944272994995 lr : 0.99\n",
      "epoch : 0 [959/21279] Train loss: 4.33011,Valid loss: 4.62683, time : 12.52506971359253 lr : 0.99\n",
      "epoch : 0 [960/21279] Train loss: 4.33216,Valid loss: 4.60253, time : 12.279454469680786 lr : 0.99\n",
      "epoch : 0 [961/21279] Train loss: 4.29736,Valid loss: 4.64884, time : 12.653055429458618 lr : 0.99\n",
      "epoch : 0 [962/21279] Train loss: 4.34955,Valid loss: 4.61266, time : 11.944461822509766 lr : 0.99\n",
      "epoch : 0 [963/21279] Train loss: 4.33421,Valid loss: 4.60877, time : 12.061781644821167 lr : 0.99\n",
      "epoch : 0 [964/21279] Train loss: 4.33679,Valid loss: 4.82955, time : 12.182495355606079 lr : 0.99\n",
      "epoch : 0 [965/21279] Train loss: 4.36614,Valid loss: 4.61219, time : 12.235826253890991 lr : 0.99\n",
      "epoch : 0 [966/21279] Train loss: 4.33185,Valid loss: 4.82012, time : 12.530815362930298 lr : 0.99\n",
      "epoch : 0 [967/21279] Train loss: 4.39189,Valid loss: 4.69528, time : 12.41101336479187 lr : 0.99\n",
      "epoch : 0 [968/21279] Train loss: 4.40885,Valid loss: 4.96114, time : 12.46617078781128 lr : 0.99\n",
      "epoch : 0 [969/21279] Train loss: 4.48935,Valid loss: 4.61838, time : 22.528953075408936 lr : 0.99\n",
      "epoch : 0 [970/21279] Train loss: 4.32895,Valid loss: 4.78444, time : 12.677834749221802 lr : 0.99\n",
      "epoch : 0 [971/21279] Train loss: 4.35808,Valid loss: 4.60752, time : 11.913573741912842 lr : 0.99\n",
      "epoch : 0 [972/21279] Train loss: 4.35104,Valid loss: 4.97565, time : 12.039745330810547 lr : 0.99\n",
      "epoch : 0 [973/21279] Train loss: 4.38632,Valid loss: 4.75024, time : 12.45621109008789 lr : 0.99\n",
      "epoch : 0 [974/21279] Train loss: 4.36431,Valid loss: 4.76971, time : 12.138392448425293 lr : 0.99\n",
      "epoch : 0 [975/21279] Train loss: 4.36881,Valid loss: 4.82273, time : 12.393351316452026 lr : 0.99\n",
      "epoch : 0 [976/21279] Train loss: 4.29695,Valid loss: 4.69398, time : 11.86088752746582 lr : 0.99\n",
      "epoch : 0 [977/21279] Train loss: 4.33743,Valid loss: 4.66300, time : 12.174526691436768 lr : 0.99\n",
      "epoch : 0 [978/21279] Train loss: 4.31113,Valid loss: 4.88744, time : 12.703466892242432 lr : 0.99\n",
      "epoch : 0 [979/21279] Train loss: 4.36403,Valid loss: 4.73121, time : 11.837161302566528 lr : 0.99\n",
      "epoch : 0 [980/21279] Train loss: 4.32693,Valid loss: 4.74571, time : 12.07730746269226 lr : 0.99\n",
      "epoch : 0 [981/21279] Train loss: 4.37592,Valid loss: 4.68822, time : 11.458102464675903 lr : 0.99\n",
      "epoch : 0 [982/21279] Train loss: 4.33398,Valid loss: 4.73741, time : 12.067610263824463 lr : 0.99\n",
      "epoch : 0 [983/21279] Train loss: 4.39041,Valid loss: 4.52931, time : 12.14072585105896 lr : 0.99\n",
      "epoch : 0 [984/21279] Train loss: 4.32197,Valid loss: 4.73210, time : 11.968896389007568 lr : 0.99\n",
      "epoch : 0 [985/21279] Train loss: 4.34419,Valid loss: 4.67592, time : 14.275673389434814 lr : 0.99\n",
      "epoch : 0 [986/21279] Train loss: 4.36483,Valid loss: 4.87725, time : 11.924912452697754 lr : 0.99\n",
      "epoch : 0 [987/21279] Train loss: 4.46310,Valid loss: 4.74994, time : 12.036211252212524 lr : 0.99\n",
      "epoch : 0 [988/21279] Train loss: 4.44458,Valid loss: 4.76563, time : 11.844857215881348 lr : 0.99\n",
      "epoch : 0 [989/21279] Train loss: 4.40192,Valid loss: 4.72741, time : 12.128936529159546 lr : 0.99\n",
      "epoch : 0 [990/21279] Train loss: 4.33388,Valid loss: 4.64960, time : 11.97417950630188 lr : 0.99\n",
      "epoch : 0 [991/21279] Train loss: 4.28630,Valid loss: 4.73753, time : 12.172738790512085 lr : 0.99\n",
      "epoch : 0 [992/21279] Train loss: 4.30958,Valid loss: 4.57936, time : 12.341378211975098 lr : 0.99\n",
      "epoch : 0 [993/21279] Train loss: 4.27235,Valid loss: 4.68834, time : 12.041906118392944 lr : 0.99\n",
      "epoch : 0 [994/21279] Train loss: 4.24598,Valid loss: 4.47124, time : 11.854633808135986 lr : 0.99\n",
      "epoch : 0 [995/21279] Train loss: 4.23469,Valid loss: 4.70788, time : 11.866610765457153 lr : 0.99\n",
      "epoch : 0 [996/21279] Train loss: 4.24155,Valid loss: 4.58732, time : 12.168824195861816 lr : 0.99\n",
      "epoch : 0 [997/21279] Train loss: 4.24192,Valid loss: 4.78862, time : 12.094123840332031 lr : 0.99\n",
      "epoch : 0 [998/21279] Train loss: 4.28429,Valid loss: 4.61164, time : 14.851678848266602 lr : 0.99\n",
      "epoch : 0 [999/21279] Train loss: 4.30248,Valid loss: 4.74656, time : 12.514533042907715 lr : 0.9801\n",
      "epoch : 0 [1000/21279] Train loss: 4.34276,Valid loss: 4.67059, time : 12.500263214111328 lr : 0.9801\n",
      "epoch : 0 [1001/21279] Train loss: 4.31849,Valid loss: 4.95423, time : 11.480052947998047 lr : 0.9801\n",
      "epoch : 0 [1002/21279] Train loss: 4.33839,Valid loss: 4.57637, time : 11.857372760772705 lr : 0.9801\n",
      "epoch : 0 [1003/21279] Train loss: 4.35617,Valid loss: 4.79725, time : 12.053105592727661 lr : 0.9801\n",
      "epoch : 0 [1004/21279] Train loss: 4.36190,Valid loss: 4.50951, time : 11.865160465240479 lr : 0.9801\n",
      "epoch : 0 [1005/21279] Train loss: 4.29228,Valid loss: 4.57433, time : 12.021605014801025 lr : 0.9801\n",
      "epoch : 0 [1006/21279] Train loss: 4.26919,Valid loss: 4.46094, time : 12.402257442474365 lr : 0.9801\n",
      "epoch : 0 [1007/21279] Train loss: 4.25464,Valid loss: 4.54477, time : 12.851183891296387 lr : 0.9801\n",
      "epoch : 0 [1008/21279] Train loss: 4.23130,Valid loss: 4.47177, time : 11.98517370223999 lr : 0.9801\n",
      "epoch : 0 [1009/21279] Train loss: 4.24613,Valid loss: 4.60397, time : 13.061215877532959 lr : 0.9801\n",
      "epoch : 0 [1010/21279] Train loss: 4.30547,Valid loss: 4.81483, time : 14.384992837905884 lr : 0.9801\n",
      "epoch : 0 [1011/21279] Train loss: 4.28782,Valid loss: 4.52673, time : 11.887145042419434 lr : 0.9801\n",
      "epoch : 0 [1012/21279] Train loss: 4.25115,Valid loss: 4.57196, time : 12.593375444412231 lr : 0.9801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [1013/21279] Train loss: 4.20017,Valid loss: 4.53295, time : 12.752357721328735 lr : 0.9801\n",
      "epoch : 0 [1014/21279] Train loss: 4.18680,Valid loss: 4.42982, time : 12.576718807220459 lr : 0.9801\n",
      "epoch : 0 [1015/21279] Train loss: 4.18361,Valid loss: 4.60114, time : 12.155163764953613 lr : 0.9801\n",
      "epoch : 0 [1016/21279] Train loss: 4.20166,Valid loss: 4.58365, time : 12.003170251846313 lr : 0.9801\n",
      "epoch : 0 [1017/21279] Train loss: 4.24715,Valid loss: 4.83136, time : 12.553152322769165 lr : 0.9801\n",
      "epoch : 0 [1018/21279] Train loss: 4.43388,Valid loss: 4.65443, time : 12.345698118209839 lr : 0.9801\n",
      "epoch : 0 [1019/21279] Train loss: 4.30320,Valid loss: 4.70717, time : 12.049137592315674 lr : 0.9801\n",
      "epoch : 0 [1020/21279] Train loss: 4.32904,Valid loss: 4.55457, time : 12.334321975708008 lr : 0.9801\n",
      "epoch : 0 [1021/21279] Train loss: 4.24966,Valid loss: 4.79372, time : 12.025235652923584 lr : 0.9801\n",
      "epoch : 0 [1022/21279] Train loss: 4.31353,Valid loss: 4.69875, time : 12.476579666137695 lr : 0.9801\n",
      "epoch : 0 [1023/21279] Train loss: 4.34119,Valid loss: 4.86878, time : 12.846697092056274 lr : 0.9801\n",
      "epoch : 0 [1024/21279] Train loss: 4.38563,Valid loss: 4.61560, time : 12.478460311889648 lr : 0.9801\n",
      "epoch : 0 [1025/21279] Train loss: 4.31898,Valid loss: 5.13012, time : 12.182263612747192 lr : 0.9801\n",
      "epoch : 0 [1026/21279] Train loss: 4.45451,Valid loss: 4.60369, time : 13.229955196380615 lr : 0.9801\n",
      "epoch : 0 [1027/21279] Train loss: 4.28724,Valid loss: 4.70692, time : 12.19317626953125 lr : 0.9801\n",
      "epoch : 0 [1028/21279] Train loss: 4.27175,Valid loss: 4.59539, time : 12.330847263336182 lr : 0.9801\n",
      "epoch : 0 [1029/21279] Train loss: 4.27311,Valid loss: 4.69190, time : 12.192266941070557 lr : 0.9801\n",
      "epoch : 0 [1030/21279] Train loss: 4.31122,Valid loss: 4.56158, time : 12.094183921813965 lr : 0.9801\n",
      "epoch : 0 [1031/21279] Train loss: 4.24551,Valid loss: 4.52367, time : 12.834205627441406 lr : 0.9801\n",
      "epoch : 0 [1032/21279] Train loss: 4.19125,Valid loss: 4.45976, time : 12.467546463012695 lr : 0.9801\n",
      "epoch : 0 [1033/21279] Train loss: 4.16140,Valid loss: 4.44729, time : 11.88997483253479 lr : 0.9801\n",
      "epoch : 0 [1034/21279] Train loss: 4.15915,Valid loss: 4.55917, time : 12.4704430103302 lr : 0.9801\n",
      "epoch : 0 [1035/21279] Train loss: 4.19348,Valid loss: 4.47655, time : 12.328959226608276 lr : 0.9801\n",
      "epoch : 0 [1036/21279] Train loss: 4.22422,Valid loss: 4.87779, time : 12.707441568374634 lr : 0.9801\n",
      "epoch : 0 [1037/21279] Train loss: 4.29009,Valid loss: 4.46251, time : 11.465617418289185 lr : 0.9801\n",
      "epoch : 0 [1038/21279] Train loss: 4.21700,Valid loss: 4.90767, time : 13.85132646560669 lr : 0.9801\n",
      "epoch : 0 [1039/21279] Train loss: 4.28059,Valid loss: 4.52803, time : 11.936651468276978 lr : 0.9801\n",
      "epoch : 0 [1040/21279] Train loss: 4.18038,Valid loss: 4.76635, time : 11.663173198699951 lr : 0.9801\n",
      "epoch : 0 [1041/21279] Train loss: 4.27424,Valid loss: 4.55016, time : 11.962229013442993 lr : 0.9801\n",
      "epoch : 0 [1042/21279] Train loss: 4.18975,Valid loss: 4.71929, time : 11.911298751831055 lr : 0.9801\n",
      "epoch : 0 [1043/21279] Train loss: 4.27012,Valid loss: 4.48173, time : 11.644116401672363 lr : 0.9801\n",
      "epoch : 0 [1044/21279] Train loss: 4.24739,Valid loss: 4.70259, time : 12.359689950942993 lr : 0.9801\n",
      "epoch : 0 [1045/21279] Train loss: 4.44437,Valid loss: 4.73987, time : 12.298170328140259 lr : 0.9801\n",
      "epoch : 0 [1046/21279] Train loss: 4.32395,Valid loss: 4.74558, time : 12.124971389770508 lr : 0.9801\n",
      "epoch : 0 [1047/21279] Train loss: 4.28806,Valid loss: 4.75978, time : 12.735389947891235 lr : 0.9801\n",
      "epoch : 0 [1048/21279] Train loss: 4.22879,Valid loss: 4.67631, time : 11.285455465316772 lr : 0.9801\n",
      "epoch : 0 [1049/21279] Train loss: 4.25425,Valid loss: 4.65239, time : 12.668084859848022 lr : 0.9801\n",
      "epoch : 0 [1050/21279] Train loss: 4.15847,Valid loss: 4.37754, time : 11.917782545089722 lr : 0.9801\n",
      "epoch : 0 [1051/21279] Train loss: 4.14167,Valid loss: 4.50539, time : 12.640672445297241 lr : 0.9801\n",
      "epoch : 0 [1052/21279] Train loss: 4.14429,Valid loss: 4.58549, time : 13.092987298965454 lr : 0.9801\n",
      "epoch : 0 [1053/21279] Train loss: 4.18938,Valid loss: 4.60463, time : 13.267418622970581 lr : 0.9801\n",
      "epoch : 0 [1054/21279] Train loss: 4.21245,Valid loss: 4.46671, time : 14.503057956695557 lr : 0.9801\n",
      "epoch : 0 [1055/21279] Train loss: 4.20880,Valid loss: 4.50633, time : 12.999439477920532 lr : 0.9801\n",
      "epoch : 0 [1056/21279] Train loss: 4.15911,Valid loss: 4.40153, time : 12.627241849899292 lr : 0.9801\n",
      "epoch : 0 [1057/21279] Train loss: 4.13760,Valid loss: 4.46790, time : 12.088407516479492 lr : 0.9801\n",
      "epoch : 0 [1058/21279] Train loss: 4.13389,Valid loss: 4.69812, time : 11.907813787460327 lr : 0.9801\n",
      "epoch : 0 [1059/21279] Train loss: 4.20759,Valid loss: 4.42751, time : 12.61441445350647 lr : 0.9801\n",
      "epoch : 0 [1060/21279] Train loss: 4.18941,Valid loss: 4.83202, time : 12.370943546295166 lr : 0.9801\n",
      "epoch : 0 [1061/21279] Train loss: 4.20808,Valid loss: 4.47640, time : 11.95117735862732 lr : 0.9801\n",
      "epoch : 0 [1062/21279] Train loss: 4.19030,Valid loss: 4.87090, time : 11.84778094291687 lr : 0.9801\n",
      "epoch : 0 [1063/21279] Train loss: 4.27282,Valid loss: 4.45731, time : 12.134337425231934 lr : 0.9801\n",
      "epoch : 0 [1064/21279] Train loss: 4.21241,Valid loss: 4.70169, time : 11.556559324264526 lr : 0.9801\n",
      "epoch : 0 [1065/21279] Train loss: 4.28208,Valid loss: 4.42627, time : 11.673810958862305 lr : 0.9801\n",
      "epoch : 0 [1066/21279] Train loss: 4.15682,Valid loss: 4.40862, time : 12.071560382843018 lr : 0.9801\n",
      "epoch : 0 [1067/21279] Train loss: 4.12080,Valid loss: 4.38940, time : 13.89342451095581 lr : 0.9801\n",
      "epoch : 0 [1068/21279] Train loss: 4.11600,Valid loss: 4.38987, time : 11.634675979614258 lr : 0.9801\n",
      "epoch : 0 [1069/21279] Train loss: 4.13459,Valid loss: 4.33287, time : 11.474636316299438 lr : 0.9801\n",
      "epoch : 0 [1070/21279] Train loss: 4.09785,Valid loss: 4.51684, time : 11.37293028831482 lr : 0.9801\n",
      "epoch : 0 [1071/21279] Train loss: 4.11368,Valid loss: 4.32755, time : 11.670710325241089 lr : 0.9801\n",
      "epoch : 0 [1072/21279] Train loss: 4.12614,Valid loss: 4.43086, time : 11.654341220855713 lr : 0.9801\n",
      "epoch : 0 [1073/21279] Train loss: 4.15556,Valid loss: 4.53719, time : 12.578556776046753 lr : 0.9801\n",
      "epoch : 0 [1074/21279] Train loss: 4.08920,Valid loss: 4.45988, time : 12.536606550216675 lr : 0.9801\n",
      "epoch : 0 [1075/21279] Train loss: 4.10218,Valid loss: 4.43716, time : 11.875591516494751 lr : 0.9801\n",
      "epoch : 0 [1076/21279] Train loss: 4.11106,Valid loss: 4.41492, time : 11.963180780410767 lr : 0.9801\n",
      "epoch : 0 [1077/21279] Train loss: 4.14100,Valid loss: 4.46193, time : 12.444833755493164 lr : 0.9801\n",
      "epoch : 0 [1078/21279] Train loss: 4.18213,Valid loss: 4.60836, time : 11.593201637268066 lr : 0.9801\n",
      "epoch : 0 [1079/21279] Train loss: 4.16487,Valid loss: 4.38953, time : 11.417667627334595 lr : 0.9801\n",
      "epoch : 0 [1080/21279] Train loss: 4.14036,Valid loss: 4.47974, time : 12.059951066970825 lr : 0.9801\n",
      "epoch : 0 [1081/21279] Train loss: 4.08181,Valid loss: 4.37829, time : 11.593379020690918 lr : 0.9801\n",
      "epoch : 0 [1082/21279] Train loss: 4.07604,Valid loss: 4.48782, time : 14.639532566070557 lr : 0.9801\n",
      "epoch : 0 [1083/21279] Train loss: 4.05554,Valid loss: 4.54366, time : 12.203224420547485 lr : 0.9801\n",
      "epoch : 0 [1084/21279] Train loss: 4.13877,Valid loss: 4.60690, time : 12.808926343917847 lr : 0.9801\n",
      "epoch : 0 [1085/21279] Train loss: 4.23532,Valid loss: 5.25671, time : 12.242538452148438 lr : 0.9801\n",
      "epoch : 0 [1086/21279] Train loss: 4.68964,Valid loss: 4.94700, time : 12.975761413574219 lr : 0.9801\n",
      "epoch : 0 [1087/21279] Train loss: 4.40122,Valid loss: 5.37220, time : 12.470124959945679 lr : 0.9801\n",
      "epoch : 0 [1088/21279] Train loss: 4.43752,Valid loss: 4.61733, time : 12.164174318313599 lr : 0.9801\n",
      "epoch : 0 [1089/21279] Train loss: 4.22756,Valid loss: 5.05653, time : 11.604585409164429 lr : 0.9801\n",
      "epoch : 0 [1090/21279] Train loss: 4.28330,Valid loss: 5.14709, time : 11.819375991821289 lr : 0.9801\n",
      "epoch : 0 [1091/21279] Train loss: 4.44437,Valid loss: 5.84721, time : 12.141785144805908 lr : 0.9801\n",
      "epoch : 0 [1092/21279] Train loss: 4.25918,Valid loss: 4.83589, time : 12.159008026123047 lr : 0.9801\n",
      "epoch : 0 [1093/21279] Train loss: 4.18748,Valid loss: 4.68145, time : 11.493332862854004 lr : 0.9801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [1094/21279] Train loss: 4.14991,Valid loss: 4.64955, time : 14.925849437713623 lr : 0.9801\n",
      "epoch : 0 [1095/21279] Train loss: 4.14725,Valid loss: 4.39892, time : 12.555384635925293 lr : 0.9801\n",
      "epoch : 0 [1096/21279] Train loss: 4.09396,Valid loss: 4.60786, time : 12.393287420272827 lr : 0.9801\n",
      "epoch : 0 [1097/21279] Train loss: 4.10718,Valid loss: 4.44913, time : 11.588823795318604 lr : 0.9801\n",
      "epoch : 0 [1098/21279] Train loss: 4.15120,Valid loss: 4.66338, time : 12.403114318847656 lr : 0.9801\n",
      "epoch : 0 [1099/21279] Train loss: 4.15626,Valid loss: 4.36918, time : 12.570399045944214 lr : 0.9801\n",
      "epoch : 0 [1100/21279] Train loss: 4.05871,Valid loss: 4.21812, time : 12.272849321365356 lr : 0.9801\n",
      "epoch : 0 [1101/21279] Train loss: 4.03052,Valid loss: 4.57328, time : 12.476317167282104 lr : 0.9801\n",
      "epoch : 0 [1102/21279] Train loss: 4.08744,Valid loss: 4.55236, time : 12.034842729568481 lr : 0.9801\n",
      "epoch : 0 [1103/21279] Train loss: 4.20607,Valid loss: 4.37129, time : 12.217006921768188 lr : 0.9801\n",
      "epoch : 0 [1104/21279] Train loss: 4.08623,Valid loss: 4.33115, time : 11.962604761123657 lr : 0.9801\n",
      "epoch : 0 [1105/21279] Train loss: 4.05881,Valid loss: 4.40249, time : 12.410748481750488 lr : 0.9801\n",
      "epoch : 0 [1106/21279] Train loss: 4.02574,Valid loss: 4.45588, time : 12.786585092544556 lr : 0.9801\n",
      "epoch : 0 [1107/21279] Train loss: 4.03945,Valid loss: 4.51886, time : 12.278035163879395 lr : 0.9801\n",
      "epoch : 0 [1108/21279] Train loss: 4.06075,Valid loss: 4.53634, time : 15.588823080062866 lr : 0.9801\n",
      "epoch : 0 [1109/21279] Train loss: 4.10400,Valid loss: 4.45365, time : 12.24244999885559 lr : 0.9801\n",
      "epoch : 0 [1110/21279] Train loss: 4.05859,Valid loss: 4.55446, time : 11.509893894195557 lr : 0.9801\n",
      "epoch : 0 [1111/21279] Train loss: 4.09068,Valid loss: 4.39201, time : 12.360203266143799 lr : 0.9801\n",
      "epoch : 0 [1112/21279] Train loss: 4.10577,Valid loss: 4.52783, time : 11.546988725662231 lr : 0.9801\n",
      "epoch : 0 [1113/21279] Train loss: 4.12613,Valid loss: 4.29323, time : 12.738669633865356 lr : 0.9801\n",
      "epoch : 0 [1114/21279] Train loss: 4.01538,Valid loss: 4.63444, time : 11.777338981628418 lr : 0.9801\n",
      "epoch : 0 [1115/21279] Train loss: 4.13712,Valid loss: 4.78556, time : 12.403722047805786 lr : 0.9801\n",
      "epoch : 0 [1116/21279] Train loss: 4.12737,Valid loss: 4.51058, time : 11.51456069946289 lr : 0.9801\n",
      "epoch : 0 [1117/21279] Train loss: 4.13010,Valid loss: 4.34435, time : 12.08065414428711 lr : 0.9801\n",
      "epoch : 0 [1118/21279] Train loss: 4.04657,Valid loss: 4.42021, time : 11.93660831451416 lr : 0.9801\n",
      "epoch : 0 [1119/21279] Train loss: 4.06380,Valid loss: 4.26080, time : 12.540329933166504 lr : 0.9801\n",
      "epoch : 0 [1120/21279] Train loss: 4.00246,Valid loss: 4.22970, time : 13.935823440551758 lr : 0.9801\n",
      "epoch : 0 [1121/21279] Train loss: 3.96791,Valid loss: 4.23770, time : 12.136481285095215 lr : 0.9801\n",
      "epoch : 0 [1122/21279] Train loss: 3.95662,Valid loss: 4.50431, time : 12.134453058242798 lr : 0.9801\n",
      "epoch : 0 [1123/21279] Train loss: 4.05473,Valid loss: 4.54692, time : 11.970713138580322 lr : 0.9801\n",
      "epoch : 0 [1124/21279] Train loss: 4.04439,Valid loss: 4.43984, time : 12.056194543838501 lr : 0.9801\n",
      "epoch : 0 [1125/21279] Train loss: 4.03620,Valid loss: 4.37708, time : 11.929764747619629 lr : 0.9801\n",
      "epoch : 0 [1126/21279] Train loss: 4.01658,Valid loss: 4.66759, time : 11.755772113800049 lr : 0.9801\n",
      "epoch : 0 [1127/21279] Train loss: 4.09209,Valid loss: 4.34136, time : 12.640257120132446 lr : 0.9801\n",
      "epoch : 0 [1128/21279] Train loss: 4.00337,Valid loss: 4.30028, time : 11.832207202911377 lr : 0.9801\n",
      "epoch : 0 [1129/21279] Train loss: 3.99693,Valid loss: 4.31351, time : 11.552194833755493 lr : 0.9801\n",
      "epoch : 0 [1130/21279] Train loss: 3.93037,Valid loss: 4.14479, time : 11.622956037521362 lr : 0.9801\n",
      "epoch : 0 [1131/21279] Train loss: 3.93984,Valid loss: 4.27691, time : 12.175045013427734 lr : 0.9801\n",
      "epoch : 0 [1132/21279] Train loss: 3.90917,Valid loss: 4.26267, time : 11.842278957366943 lr : 0.9801\n",
      "epoch : 0 [1133/21279] Train loss: 3.97721,Valid loss: 4.25628, time : 12.416704654693604 lr : 0.9801\n",
      "epoch : 0 [1134/21279] Train loss: 3.92664,Valid loss: 4.40371, time : 11.631947755813599 lr : 0.9801\n",
      "epoch : 0 [1135/21279] Train loss: 3.95226,Valid loss: 4.44494, time : 11.866669178009033 lr : 0.9801\n",
      "epoch : 0 [1136/21279] Train loss: 4.00572,Valid loss: 4.58666, time : 13.760353088378906 lr : 0.9801\n",
      "epoch : 0 [1137/21279] Train loss: 4.11050,Valid loss: 4.55282, time : 12.911465644836426 lr : 0.9801\n",
      "epoch : 0 [1138/21279] Train loss: 4.25622,Valid loss: 4.57384, time : 12.539326667785645 lr : 0.9801\n",
      "epoch : 0 [1139/21279] Train loss: 4.23753,Valid loss: 4.63328, time : 11.907187223434448 lr : 0.9801\n",
      "epoch : 0 [1140/21279] Train loss: 4.20577,Valid loss: 4.80424, time : 12.141929864883423 lr : 0.9801\n",
      "epoch : 0 [1141/21279] Train loss: 4.15108,Valid loss: 4.65134, time : 12.391536474227905 lr : 0.9801\n",
      "epoch : 0 [1142/21279] Train loss: 4.04435,Valid loss: 4.32316, time : 12.13302731513977 lr : 0.9801\n",
      "epoch : 0 [1143/21279] Train loss: 4.07230,Valid loss: 4.46220, time : 12.556804895401001 lr : 0.9801\n",
      "epoch : 0 [1144/21279] Train loss: 4.02271,Valid loss: 4.46719, time : 12.053639888763428 lr : 0.9801\n",
      "epoch : 0 [1145/21279] Train loss: 4.04712,Valid loss: 4.34821, time : 12.654994010925293 lr : 0.9801\n",
      "epoch : 0 [1146/21279] Train loss: 3.94044,Valid loss: 4.38188, time : 12.595763921737671 lr : 0.9801\n",
      "epoch : 0 [1147/21279] Train loss: 3.95597,Valid loss: 4.12982, time : 12.384002447128296 lr : 0.9801\n",
      "epoch : 0 [1148/21279] Train loss: 3.92732,Valid loss: 4.52248, time : 14.438478231430054 lr : 0.9801\n",
      "epoch : 0 [1149/21279] Train loss: 4.02405,Valid loss: 4.35043, time : 12.363207340240479 lr : 0.9801\n",
      "epoch : 0 [1150/21279] Train loss: 4.04211,Valid loss: 4.71898, time : 12.285502910614014 lr : 0.9801\n",
      "epoch : 0 [1151/21279] Train loss: 4.06891,Valid loss: 4.20466, time : 12.538227558135986 lr : 0.9801\n",
      "epoch : 0 [1152/21279] Train loss: 3.92925,Valid loss: 4.23270, time : 12.413882732391357 lr : 0.9801\n",
      "epoch : 0 [1153/21279] Train loss: 3.89737,Valid loss: 4.24023, time : 11.830342292785645 lr : 0.9801\n",
      "epoch : 0 [1154/21279] Train loss: 3.90118,Valid loss: 4.19746, time : 11.974751710891724 lr : 0.9801\n",
      "epoch : 0 [1155/21279] Train loss: 3.89551,Valid loss: 4.26371, time : 11.873830318450928 lr : 0.9801\n",
      "epoch : 0 [1156/21279] Train loss: 3.89800,Valid loss: 4.20147, time : 11.852257251739502 lr : 0.9801\n",
      "epoch : 0 [1157/21279] Train loss: 3.89666,Valid loss: 4.32009, time : 11.587895154953003 lr : 0.9801\n",
      "epoch : 0 [1158/21279] Train loss: 3.92918,Valid loss: 4.35487, time : 12.182169914245605 lr : 0.9801\n",
      "epoch : 0 [1159/21279] Train loss: 3.99125,Valid loss: 4.33201, time : 11.823906898498535 lr : 0.9801\n",
      "epoch : 0 [1160/21279] Train loss: 3.93009,Valid loss: 4.23489, time : 12.185260534286499 lr : 0.9801\n",
      "epoch : 0 [1161/21279] Train loss: 3.92866,Valid loss: 4.36795, time : 11.767197132110596 lr : 0.9801\n",
      "epoch : 0 [1162/21279] Train loss: 3.92227,Valid loss: 4.14015, time : 12.334577798843384 lr : 0.9801\n",
      "epoch : 0 [1163/21279] Train loss: 3.93731,Valid loss: 4.39043, time : 12.23352313041687 lr : 0.9801\n",
      "epoch : 0 [1164/21279] Train loss: 3.98394,Valid loss: 4.37295, time : 14.281543016433716 lr : 0.9801\n",
      "epoch : 0 [1165/21279] Train loss: 3.94968,Valid loss: 4.35369, time : 12.046419858932495 lr : 0.9801\n",
      "epoch : 0 [1166/21279] Train loss: 3.95002,Valid loss: 4.38178, time : 12.208903789520264 lr : 0.9801\n",
      "epoch : 0 [1167/21279] Train loss: 3.85873,Valid loss: 4.35380, time : 12.39072585105896 lr : 0.9801\n",
      "epoch : 0 [1168/21279] Train loss: 3.90627,Valid loss: 4.36760, time : 11.066817045211792 lr : 0.9801\n",
      "epoch : 0 [1169/21279] Train loss: 3.89653,Valid loss: 4.66704, time : 11.996803760528564 lr : 0.9801\n",
      "epoch : 0 [1170/21279] Train loss: 3.99737,Valid loss: 4.32245, time : 12.446534395217896 lr : 0.9801\n",
      "epoch : 0 [1171/21279] Train loss: 4.00473,Valid loss: 5.03883, time : 11.57456350326538 lr : 0.9801\n",
      "epoch : 0 [1172/21279] Train loss: 4.13336,Valid loss: 4.49378, time : 12.267910718917847 lr : 0.9801\n",
      "epoch : 0 [1173/21279] Train loss: 4.08285,Valid loss: 5.28032, time : 12.44967269897461 lr : 0.9801\n",
      "epoch : 0 [1174/21279] Train loss: 4.19395,Valid loss: 4.55397, time : 12.368466138839722 lr : 0.9801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [1175/21279] Train loss: 4.07538,Valid loss: 4.95509, time : 12.82300329208374 lr : 0.9801\n",
      "epoch : 0 [1176/21279] Train loss: 4.02922,Valid loss: 4.52468, time : 12.460582256317139 lr : 0.9801\n",
      "epoch : 0 [1177/21279] Train loss: 3.98009,Valid loss: 4.44999, time : 13.908876180648804 lr : 0.9801\n",
      "epoch : 0 [1178/21279] Train loss: 3.90821,Valid loss: 4.20476, time : 12.043365001678467 lr : 0.9801\n",
      "epoch : 0 [1179/21279] Train loss: 3.85936,Valid loss: 4.15587, time : 12.615407943725586 lr : 0.9801\n",
      "epoch : 0 [1180/21279] Train loss: 3.84092,Valid loss: 4.12375, time : 12.498673915863037 lr : 0.9801\n",
      "epoch : 0 [1181/21279] Train loss: 3.79951,Valid loss: 4.23350, time : 12.282057523727417 lr : 0.9801\n",
      "epoch : 0 [1182/21279] Train loss: 3.83258,Valid loss: 4.29029, time : 12.467796564102173 lr : 0.9801\n",
      "epoch : 0 [1183/21279] Train loss: 3.87342,Valid loss: 4.38464, time : 12.578464031219482 lr : 0.9801\n",
      "epoch : 0 [1184/21279] Train loss: 3.87940,Valid loss: 4.40553, time : 12.649717807769775 lr : 0.9801\n",
      "epoch : 0 [1185/21279] Train loss: 3.84765,Valid loss: 4.23624, time : 11.61497163772583 lr : 0.9801\n",
      "epoch : 0 [1186/21279] Train loss: 3.81255,Valid loss: 4.25103, time : 11.929991722106934 lr : 0.9801\n",
      "epoch : 0 [1187/21279] Train loss: 3.81330,Valid loss: 4.22526, time : 12.397703170776367 lr : 0.9801\n",
      "epoch : 0 [1188/21279] Train loss: 3.84923,Valid loss: 4.34776, time : 12.78807258605957 lr : 0.9801\n",
      "epoch : 0 [1189/21279] Train loss: 3.86861,Valid loss: 4.40241, time : 12.837380647659302 lr : 0.9801\n",
      "epoch : 0 [1190/21279] Train loss: 3.91007,Valid loss: 4.33248, time : 12.644508123397827 lr : 0.9801\n",
      "epoch : 0 [1191/21279] Train loss: 3.87138,Valid loss: 4.25634, time : 12.44681978225708 lr : 0.9801\n",
      "epoch : 0 [1192/21279] Train loss: 3.88760,Valid loss: 4.26436, time : 14.645237684249878 lr : 0.9801\n",
      "epoch : 0 [1193/21279] Train loss: 3.88201,Valid loss: 4.76840, time : 12.064267635345459 lr : 0.9801\n",
      "epoch : 0 [1194/21279] Train loss: 4.05250,Valid loss: 4.17154, time : 12.39037036895752 lr : 0.9801\n",
      "epoch : 0 [1195/21279] Train loss: 3.89604,Valid loss: 4.47925, time : 12.050937175750732 lr : 0.9801\n",
      "epoch : 0 [1196/21279] Train loss: 3.93509,Valid loss: 4.23243, time : 12.758912801742554 lr : 0.9801\n",
      "epoch : 0 [1197/21279] Train loss: 3.86717,Valid loss: 4.40131, time : 12.897155046463013 lr : 0.9801\n",
      "epoch : 0 [1198/21279] Train loss: 3.95519,Valid loss: 4.24868, time : 11.79867935180664 lr : 0.9801\n",
      "epoch : 0 [1199/21279] Train loss: 3.82807,Valid loss: 4.16275, time : 12.21507477760315 lr : 0.9801\n",
      "epoch : 0 [1200/21279] Train loss: 3.87132,Valid loss: 4.11494, time : 12.13159728050232 lr : 0.9801\n",
      "epoch : 0 [1201/21279] Train loss: 3.80992,Valid loss: 4.11855, time : 12.667754650115967 lr : 0.9801\n",
      "epoch : 0 [1202/21279] Train loss: 3.82585,Valid loss: 4.12540, time : 12.303286790847778 lr : 0.9801\n",
      "epoch : 0 [1203/21279] Train loss: 3.79059,Valid loss: 4.14271, time : 11.672839164733887 lr : 0.9801\n",
      "epoch : 0 [1204/21279] Train loss: 3.80646,Valid loss: 4.26883, time : 13.934818506240845 lr : 0.9801\n",
      "epoch : 0 [1205/21279] Train loss: 3.82794,Valid loss: 4.26097, time : 12.257103443145752 lr : 0.9801\n",
      "epoch : 0 [1206/21279] Train loss: 3.85594,Valid loss: 4.25471, time : 12.103046894073486 lr : 0.9801\n",
      "epoch : 0 [1207/21279] Train loss: 3.85176,Valid loss: 4.65519, time : 12.496304988861084 lr : 0.9801\n",
      "epoch : 0 [1208/21279] Train loss: 3.99885,Valid loss: 4.55559, time : 12.34079623222351 lr : 0.9801\n",
      "epoch : 0 [1209/21279] Train loss: 3.87499,Valid loss: 4.52166, time : 11.99058985710144 lr : 0.9801\n",
      "epoch : 0 [1210/21279] Train loss: 3.99809,Valid loss: 4.24813, time : 12.663356304168701 lr : 0.9801\n",
      "epoch : 0 [1211/21279] Train loss: 3.87931,Valid loss: 4.32173, time : 13.016921043395996 lr : 0.9801\n",
      "epoch : 0 [1212/21279] Train loss: 3.86866,Valid loss: 4.34099, time : 12.170270442962646 lr : 0.9801\n",
      "epoch : 0 [1213/21279] Train loss: 3.90748,Valid loss: 4.70396, time : 12.730201959609985 lr : 0.9801\n",
      "epoch : 0 [1214/21279] Train loss: 4.05517,Valid loss: 4.11908, time : 12.591170072555542 lr : 0.9801\n",
      "epoch : 0 [1215/21279] Train loss: 3.78497,Valid loss: 4.04798, time : 12.887978792190552 lr : 0.9801\n",
      "epoch : 0 [1216/21279] Train loss: 3.75549,Valid loss: 4.24401, time : 12.727729797363281 lr : 0.9801\n",
      "epoch : 0 [1217/21279] Train loss: 3.74345,Valid loss: 4.19635, time : 12.517866373062134 lr : 0.9801\n",
      "epoch : 0 [1218/21279] Train loss: 3.75890,Valid loss: 4.45154, time : 14.434346199035645 lr : 0.9801\n",
      "epoch : 0 [1219/21279] Train loss: 3.81099,Valid loss: 4.16972, time : 12.714056253433228 lr : 0.9801\n",
      "epoch : 0 [1220/21279] Train loss: 3.79594,Valid loss: 4.33518, time : 12.654623985290527 lr : 0.9801\n",
      "epoch : 0 [1221/21279] Train loss: 3.84604,Valid loss: 4.24345, time : 12.738640308380127 lr : 0.9801\n",
      "epoch : 0 [1222/21279] Train loss: 3.86300,Valid loss: 4.83016, time : 13.05900239944458 lr : 0.9801\n",
      "epoch : 0 [1223/21279] Train loss: 3.99944,Valid loss: 4.07794, time : 12.55875849723816 lr : 0.9801\n",
      "epoch : 0 [1224/21279] Train loss: 3.83451,Valid loss: 4.59086, time : 12.751197576522827 lr : 0.9801\n",
      "epoch : 0 [1225/21279] Train loss: 3.87180,Valid loss: 4.23009, time : 12.433589935302734 lr : 0.9801\n",
      "epoch : 0 [1226/21279] Train loss: 3.78201,Valid loss: 4.18326, time : 12.64842176437378 lr : 0.9801\n",
      "epoch : 0 [1227/21279] Train loss: 3.76881,Valid loss: 4.03339, time : 12.558511018753052 lr : 0.9801\n",
      "epoch : 0 [1228/21279] Train loss: 3.72598,Valid loss: 4.05271, time : 12.360159873962402 lr : 0.9801\n",
      "epoch : 0 [1229/21279] Train loss: 3.72640,Valid loss: 4.09784, time : 12.63591742515564 lr : 0.9801\n",
      "epoch : 0 [1230/21279] Train loss: 3.71639,Valid loss: 4.49898, time : 14.713696718215942 lr : 0.9801\n",
      "epoch : 0 [1231/21279] Train loss: 3.72546,Valid loss: 4.06287, time : 12.399092197418213 lr : 0.9801\n",
      "epoch : 0 [1232/21279] Train loss: 3.71268,Valid loss: 4.54637, time : 11.816956281661987 lr : 0.9801\n",
      "epoch : 0 [1233/21279] Train loss: 3.71925,Valid loss: 4.07666, time : 12.988703966140747 lr : 0.9801\n",
      "epoch : 0 [1234/21279] Train loss: 3.75100,Valid loss: 4.47384, time : 12.825756072998047 lr : 0.9801\n",
      "epoch : 0 [1235/21279] Train loss: 3.81022,Valid loss: 4.25629, time : 11.785642623901367 lr : 0.9801\n",
      "epoch : 0 [1236/21279] Train loss: 3.80633,Valid loss: 4.35050, time : 12.310204267501831 lr : 0.9801\n",
      "epoch : 0 [1237/21279] Train loss: 3.92689,Valid loss: 4.19224, time : 12.023943662643433 lr : 0.9801\n",
      "epoch : 0 [1238/21279] Train loss: 3.78898,Valid loss: 4.22401, time : 12.515164613723755 lr : 0.9801\n",
      "epoch : 0 [1239/21279] Train loss: 3.75364,Valid loss: 4.06226, time : 12.708751916885376 lr : 0.9801\n",
      "epoch : 0 [1240/21279] Train loss: 3.68041,Valid loss: 3.94641, time : 12.25322413444519 lr : 0.9801\n",
      "epoch : 0 [1241/21279] Train loss: 3.66565,Valid loss: 3.92233, time : 12.985851287841797 lr : 0.9801\n",
      "epoch : 0 [1242/21279] Train loss: 3.62540,Valid loss: 3.88609, time : 12.996184825897217 lr : 0.9801\n",
      "epoch : 0 [1243/21279] Train loss: 3.63153,Valid loss: 4.06437, time : 12.892340898513794 lr : 0.9801\n",
      "epoch : 0 [1244/21279] Train loss: 3.65714,Valid loss: 4.10146, time : 12.973039388656616 lr : 0.9801\n",
      "epoch : 0 [1245/21279] Train loss: 3.72856,Valid loss: 4.28780, time : 13.035661697387695 lr : 0.9801\n",
      "epoch : 0 [1246/21279] Train loss: 3.84409,Valid loss: 4.43183, time : 14.551243543624878 lr : 0.9801\n",
      "epoch : 0 [1247/21279] Train loss: 3.89911,Valid loss: 4.70890, time : 12.645019292831421 lr : 0.9801\n",
      "epoch : 0 [1248/21279] Train loss: 4.04718,Valid loss: 4.44408, time : 12.840280294418335 lr : 0.9801\n",
      "epoch : 0 [1249/21279] Train loss: 3.80165,Valid loss: 4.60524, time : 12.335621356964111 lr : 0.9801\n",
      "epoch : 0 [1250/21279] Train loss: 3.79930,Valid loss: 4.50790, time : 12.441247701644897 lr : 0.9801\n",
      "epoch : 0 [1251/21279] Train loss: 3.81784,Valid loss: 4.90263, time : 12.525942087173462 lr : 0.9801\n",
      "epoch : 0 [1252/21279] Train loss: 3.86914,Valid loss: 3.94475, time : 11.676888465881348 lr : 0.9801\n",
      "epoch : 0 [1253/21279] Train loss: 3.64894,Valid loss: 3.89441, time : 12.293845415115356 lr : 0.9801\n",
      "epoch : 0 [1254/21279] Train loss: 3.65225,Valid loss: 4.11901, time : 12.738770246505737 lr : 0.9801\n",
      "epoch : 0 [1255/21279] Train loss: 3.67198,Valid loss: 3.99704, time : 12.086668968200684 lr : 0.9801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [1256/21279] Train loss: 3.70820,Valid loss: 4.01986, time : 12.60851263999939 lr : 0.9801\n",
      "epoch : 0 [1257/21279] Train loss: 3.64665,Valid loss: 3.93333, time : 13.032427549362183 lr : 0.9801\n",
      "epoch : 0 [1258/21279] Train loss: 3.62463,Valid loss: 3.94344, time : 14.628081321716309 lr : 0.9801\n",
      "epoch : 0 [1259/21279] Train loss: 3.61097,Valid loss: 3.93756, time : 12.62645673751831 lr : 0.9801\n",
      "epoch : 0 [1260/21279] Train loss: 3.64998,Valid loss: 4.08627, time : 12.612124681472778 lr : 0.9801\n",
      "epoch : 0 [1261/21279] Train loss: 3.61993,Valid loss: 3.93935, time : 12.896236419677734 lr : 0.9801\n",
      "epoch : 0 [1262/21279] Train loss: 3.64113,Valid loss: 4.28620, time : 12.69379448890686 lr : 0.9801\n",
      "epoch : 0 [1263/21279] Train loss: 3.63566,Valid loss: 4.26213, time : 12.798458576202393 lr : 0.9801\n",
      "epoch : 0 [1264/21279] Train loss: 3.74840,Valid loss: 4.44477, time : 12.345874547958374 lr : 0.9801\n",
      "epoch : 0 [1265/21279] Train loss: 3.85944,Valid loss: 3.99501, time : 13.025241374969482 lr : 0.9801\n",
      "epoch : 0 [1266/21279] Train loss: 3.78335,Valid loss: 4.33022, time : 13.052709579467773 lr : 0.9801\n",
      "epoch : 0 [1267/21279] Train loss: 3.81736,Valid loss: 4.18287, time : 12.357434749603271 lr : 0.9801\n",
      "epoch : 0 [1268/21279] Train loss: 3.70813,Valid loss: 4.30701, time : 12.736276149749756 lr : 0.9801\n",
      "epoch : 0 [1269/21279] Train loss: 3.76382,Valid loss: 4.40565, time : 12.8876633644104 lr : 0.9801\n",
      "epoch : 0 [1270/21279] Train loss: 3.76451,Valid loss: 4.37922, time : 12.461227178573608 lr : 0.9801\n",
      "epoch : 0 [1271/21279] Train loss: 3.88228,Valid loss: 5.76461, time : 12.942224025726318 lr : 0.9801\n",
      "epoch : 0 [1272/21279] Train loss: 3.96084,Valid loss: 5.37191, time : 12.378893375396729 lr : 0.9801\n",
      "epoch : 0 [1273/21279] Train loss: 4.05216,Valid loss: 4.37726, time : 12.867704391479492 lr : 0.9801\n",
      "epoch : 0 [1274/21279] Train loss: 3.81701,Valid loss: 4.49843, time : 15.343004703521729 lr : 0.9801\n",
      "epoch : 0 [1275/21279] Train loss: 3.86823,Valid loss: 4.25892, time : 12.864569187164307 lr : 0.9801\n",
      "epoch : 0 [1276/21279] Train loss: 3.79758,Valid loss: 4.26782, time : 12.96778678894043 lr : 0.9801\n",
      "epoch : 0 [1277/21279] Train loss: 3.71085,Valid loss: 3.98103, time : 12.631709575653076 lr : 0.9801\n",
      "epoch : 0 [1278/21279] Train loss: 3.60536,Valid loss: 3.94572, time : 12.52228307723999 lr : 0.9801\n",
      "epoch : 0 [1279/21279] Train loss: 3.59828,Valid loss: 3.86527, time : 12.408509254455566 lr : 0.9801\n",
      "epoch : 0 [1280/21279] Train loss: 3.55338,Valid loss: 3.93024, time : 12.396983861923218 lr : 0.9801\n",
      "epoch : 0 [1281/21279] Train loss: 3.51810,Valid loss: 3.87035, time : 12.420361757278442 lr : 0.9801\n",
      "epoch : 0 [1282/21279] Train loss: 3.52555,Valid loss: 3.92663, time : 12.281661033630371 lr : 0.9801\n",
      "epoch : 0 [1283/21279] Train loss: 3.54157,Valid loss: 4.15635, time : 12.502544641494751 lr : 0.9801\n",
      "epoch : 0 [1284/21279] Train loss: 3.58715,Valid loss: 3.98998, time : 12.363461971282959 lr : 0.9801\n",
      "epoch : 0 [1285/21279] Train loss: 3.61396,Valid loss: 4.35085, time : 12.432294607162476 lr : 0.9801\n",
      "epoch : 0 [1286/21279] Train loss: 3.74819,Valid loss: 4.71136, time : 12.474510908126831 lr : 0.9801\n",
      "epoch : 0 [1287/21279] Train loss: 3.84538,Valid loss: 4.99641, time : 14.796111822128296 lr : 0.9801\n",
      "epoch : 0 [1288/21279] Train loss: 4.09420,Valid loss: 4.54485, time : 13.095276355743408 lr : 0.9801\n",
      "epoch : 0 [1289/21279] Train loss: 3.85764,Valid loss: 4.72707, time : 12.753940343856812 lr : 0.9801\n",
      "epoch : 0 [1290/21279] Train loss: 4.10773,Valid loss: 5.03763, time : 12.71976637840271 lr : 0.9801\n",
      "epoch : 0 [1291/21279] Train loss: 3.88038,Valid loss: 4.50139, time : 12.973934888839722 lr : 0.9801\n",
      "epoch : 0 [1292/21279] Train loss: 3.77958,Valid loss: 4.22629, time : 12.745423555374146 lr : 0.9801\n",
      "epoch : 0 [1293/21279] Train loss: 3.59975,Valid loss: 4.21798, time : 13.062399864196777 lr : 0.9801\n",
      "epoch : 0 [1294/21279] Train loss: 3.56220,Valid loss: 4.45222, time : 12.130562782287598 lr : 0.9801\n",
      "epoch : 0 [1295/21279] Train loss: 3.51150,Valid loss: 3.96542, time : 12.141222953796387 lr : 0.9801\n",
      "epoch : 0 [1296/21279] Train loss: 3.51973,Valid loss: 3.98616, time : 11.68329906463623 lr : 0.9801\n",
      "epoch : 0 [1297/21279] Train loss: 3.53617,Valid loss: 4.01235, time : 12.377700805664062 lr : 0.9801\n",
      "epoch : 0 [1298/21279] Train loss: 3.53470,Valid loss: 3.83641, time : 13.274166345596313 lr : 0.9801\n",
      "epoch : 0 [1299/21279] Train loss: 3.48722,Valid loss: 3.90066, time : 12.734879732131958 lr : 0.9801\n",
      "epoch : 0 [1300/21279] Train loss: 3.51321,Valid loss: 4.08144, time : 12.769133567810059 lr : 0.9801\n",
      "epoch : 0 [1301/21279] Train loss: 3.54245,Valid loss: 4.32392, time : 12.596842288970947 lr : 0.9801\n",
      "epoch : 0 [1302/21279] Train loss: 3.68695,Valid loss: 4.06088, time : 15.545215129852295 lr : 0.9801\n",
      "epoch : 0 [1303/21279] Train loss: 3.56540,Valid loss: 3.89517, time : 11.970068216323853 lr : 0.9801\n",
      "epoch : 0 [1304/21279] Train loss: 3.53376,Valid loss: 3.91019, time : 11.918106317520142 lr : 0.9801\n",
      "epoch : 0 [1305/21279] Train loss: 3.48544,Valid loss: 3.91713, time : 13.127784013748169 lr : 0.9801\n",
      "epoch : 0 [1306/21279] Train loss: 3.47085,Valid loss: 3.90560, time : 12.311521530151367 lr : 0.9801\n",
      "epoch : 0 [1307/21279] Train loss: 3.46717,Valid loss: 4.13268, time : 12.654212951660156 lr : 0.9801\n",
      "epoch : 0 [1308/21279] Train loss: 3.58399,Valid loss: 3.99721, time : 12.1561439037323 lr : 0.9801\n",
      "epoch : 0 [1309/21279] Train loss: 3.54089,Valid loss: 4.05675, time : 12.634501695632935 lr : 0.9801\n",
      "epoch : 0 [1310/21279] Train loss: 3.62602,Valid loss: 3.87230, time : 13.274272680282593 lr : 0.9801\n",
      "epoch : 0 [1311/21279] Train loss: 3.56006,Valid loss: 3.93221, time : 12.49693250656128 lr : 0.9801\n",
      "epoch : 0 [1312/21279] Train loss: 3.55754,Valid loss: 3.84235, time : 12.789724111557007 lr : 0.9801\n",
      "epoch : 0 [1313/21279] Train loss: 3.45984,Valid loss: 3.79863, time : 12.477033376693726 lr : 0.9801\n",
      "epoch : 0 [1314/21279] Train loss: 3.48558,Valid loss: 3.89572, time : 14.538255214691162 lr : 0.9801\n",
      "epoch : 0 [1315/21279] Train loss: 3.46068,Valid loss: 3.90357, time : 12.694668531417847 lr : 0.9801\n",
      "epoch : 0 [1316/21279] Train loss: 3.51387,Valid loss: 4.07474, time : 12.745387315750122 lr : 0.9801\n",
      "epoch : 0 [1317/21279] Train loss: 3.45725,Valid loss: 3.75748, time : 12.450449466705322 lr : 0.9801\n",
      "epoch : 0 [1318/21279] Train loss: 3.49138,Valid loss: 3.82495, time : 12.29530119895935 lr : 0.9801\n",
      "epoch : 0 [1319/21279] Train loss: 3.45982,Valid loss: 3.77114, time : 11.605515241622925 lr : 0.9801\n",
      "epoch : 0 [1320/21279] Train loss: 3.46208,Valid loss: 3.92840, time : 11.75126576423645 lr : 0.9801\n",
      "epoch : 0 [1321/21279] Train loss: 3.51306,Valid loss: 3.97147, time : 11.929117202758789 lr : 0.9801\n",
      "epoch : 0 [1322/21279] Train loss: 3.64496,Valid loss: 3.98257, time : 11.644814729690552 lr : 0.9801\n",
      "epoch : 0 [1323/21279] Train loss: 3.68793,Valid loss: 4.87331, time : 12.068970203399658 lr : 0.9801\n",
      "epoch : 0 [1324/21279] Train loss: 3.89059,Valid loss: 4.03608, time : 11.829064846038818 lr : 0.9801\n",
      "epoch : 0 [1325/21279] Train loss: 3.54720,Valid loss: 4.22985, time : 11.845698118209839 lr : 0.9801\n",
      "epoch : 0 [1326/21279] Train loss: 3.45385,Valid loss: 4.07664, time : 12.04378604888916 lr : 0.9801\n",
      "epoch : 0 [1327/21279] Train loss: 3.47931,Valid loss: 4.09529, time : 11.774391174316406 lr : 0.9801\n",
      "epoch : 0 [1328/21279] Train loss: 3.47133,Valid loss: 3.94889, time : 16.262123584747314 lr : 0.9801\n",
      "epoch : 0 [1329/21279] Train loss: 3.41215,Valid loss: 3.80208, time : 11.955345392227173 lr : 0.9801\n",
      "epoch : 0 [1330/21279] Train loss: 3.39438,Valid loss: 3.82759, time : 12.29519510269165 lr : 0.9801\n",
      "epoch : 0 [1331/21279] Train loss: 3.40175,Valid loss: 3.76856, time : 11.816149711608887 lr : 0.9801\n",
      "epoch : 0 [1332/21279] Train loss: 3.35416,Valid loss: 3.76744, time : 12.36803913116455 lr : 0.9801\n",
      "epoch : 0 [1333/21279] Train loss: 3.38522,Valid loss: 3.79239, time : 12.275990724563599 lr : 0.9801\n",
      "epoch : 0 [1334/21279] Train loss: 3.43562,Valid loss: 3.99961, time : 11.947463750839233 lr : 0.9801\n",
      "epoch : 0 [1335/21279] Train loss: 3.44182,Valid loss: 3.84825, time : 11.93414044380188 lr : 0.9801\n",
      "epoch : 0 [1336/21279] Train loss: 3.48724,Valid loss: 3.84012, time : 11.385077238082886 lr : 0.9801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [1337/21279] Train loss: 3.45682,Valid loss: 3.94995, time : 12.261680603027344 lr : 0.9801\n",
      "epoch : 0 [1338/21279] Train loss: 3.51501,Valid loss: 3.98116, time : 11.8374662399292 lr : 0.9801\n",
      "epoch : 0 [1339/21279] Train loss: 3.54026,Valid loss: 4.17807, time : 11.472371101379395 lr : 0.9801\n",
      "epoch : 0 [1340/21279] Train loss: 3.69295,Valid loss: 3.85387, time : 13.863228559494019 lr : 0.9801\n",
      "epoch : 0 [1341/21279] Train loss: 3.46196,Valid loss: 3.98392, time : 11.797799587249756 lr : 0.9801\n",
      "epoch : 0 [1342/21279] Train loss: 3.48098,Valid loss: 3.83292, time : 12.442875385284424 lr : 0.9801\n",
      "epoch : 0 [1343/21279] Train loss: 3.49105,Valid loss: 4.08576, time : 11.716596364974976 lr : 0.9801\n",
      "epoch : 0 [1344/21279] Train loss: 3.53653,Valid loss: 3.91688, time : 11.987570762634277 lr : 0.9801\n",
      "epoch : 0 [1345/21279] Train loss: 3.41783,Valid loss: 4.07006, time : 11.649301052093506 lr : 0.9801\n",
      "epoch : 0 [1346/21279] Train loss: 3.42253,Valid loss: 4.08300, time : 11.754367351531982 lr : 0.9801\n",
      "epoch : 0 [1347/21279] Train loss: 3.38602,Valid loss: 3.83908, time : 12.026806592941284 lr : 0.9801\n",
      "epoch : 0 [1348/21279] Train loss: 3.39301,Valid loss: 3.74700, time : 12.182595252990723 lr : 0.9801\n",
      "epoch : 0 [1349/21279] Train loss: 3.33104,Valid loss: 3.79028, time : 12.226365804672241 lr : 0.9801\n",
      "epoch : 0 [1350/21279] Train loss: 3.31673,Valid loss: 3.77150, time : 11.786758422851562 lr : 0.9801\n",
      "epoch : 0 [1351/21279] Train loss: 3.36143,Valid loss: 4.26351, time : 11.378916501998901 lr : 0.9801\n",
      "epoch : 0 [1352/21279] Train loss: 3.46831,Valid loss: 3.80976, time : 11.855992317199707 lr : 0.9801\n",
      "epoch : 0 [1353/21279] Train loss: 3.44642,Valid loss: 4.01337, time : 11.652301788330078 lr : 0.9801\n",
      "epoch : 0 [1354/21279] Train loss: 3.46194,Valid loss: 3.79981, time : 11.860870361328125 lr : 0.9801\n",
      "epoch : 0 [1355/21279] Train loss: 3.44023,Valid loss: 4.04838, time : 12.360690116882324 lr : 0.9801\n",
      "epoch : 0 [1356/21279] Train loss: 3.45840,Valid loss: 3.87447, time : 21.66049575805664 lr : 0.9801\n",
      "epoch : 0 [1357/21279] Train loss: 3.39511,Valid loss: 4.24892, time : 11.867721796035767 lr : 0.9801\n",
      "epoch : 0 [1358/21279] Train loss: 3.43551,Valid loss: 3.86805, time : 11.876532077789307 lr : 0.9801\n",
      "epoch : 0 [1359/21279] Train loss: 3.46077,Valid loss: 4.39502, time : 12.32043194770813 lr : 0.9801\n",
      "epoch : 0 [1360/21279] Train loss: 3.53504,Valid loss: 3.89041, time : 11.68635630607605 lr : 0.9801\n",
      "epoch : 0 [1361/21279] Train loss: 3.47572,Valid loss: 3.99379, time : 11.748452425003052 lr : 0.9801\n",
      "epoch : 0 [1362/21279] Train loss: 3.50010,Valid loss: 3.82350, time : 11.90561819076538 lr : 0.9801\n",
      "epoch : 0 [1363/21279] Train loss: 3.48812,Valid loss: 4.26456, time : 11.871633529663086 lr : 0.9801\n",
      "epoch : 0 [1364/21279] Train loss: 3.70445,Valid loss: 4.11972, time : 12.135140657424927 lr : 0.9801\n",
      "epoch : 0 [1365/21279] Train loss: 3.56051,Valid loss: 4.11682, time : 11.953707456588745 lr : 0.9801\n",
      "epoch : 0 [1366/21279] Train loss: 3.49797,Valid loss: 3.90419, time : 12.239639282226562 lr : 0.9801\n",
      "epoch : 0 [1367/21279] Train loss: 3.32881,Valid loss: 3.96285, time : 12.208908557891846 lr : 0.9801\n",
      "epoch : 0 [1368/21279] Train loss: 3.34318,Valid loss: 3.76884, time : 14.354423761367798 lr : 0.9801\n",
      "epoch : 0 [1369/21279] Train loss: 3.33406,Valid loss: 3.87319, time : 12.84996509552002 lr : 0.9801\n",
      "epoch : 0 [1370/21279] Train loss: 3.33494,Valid loss: 3.88926, time : 11.91070556640625 lr : 0.9801\n",
      "epoch : 0 [1371/21279] Train loss: 3.30681,Valid loss: 3.81001, time : 12.697417259216309 lr : 0.9801\n",
      "epoch : 0 [1372/21279] Train loss: 3.32252,Valid loss: 3.67782, time : 12.642069816589355 lr : 0.9801\n",
      "epoch : 0 [1373/21279] Train loss: 3.34997,Valid loss: 3.66815, time : 12.874762535095215 lr : 0.9801\n",
      "epoch : 0 [1374/21279] Train loss: 3.31845,Valid loss: 3.68731, time : 12.433399438858032 lr : 0.9801\n",
      "epoch : 0 [1375/21279] Train loss: 3.36259,Valid loss: 3.81594, time : 12.975297451019287 lr : 0.9801\n",
      "epoch : 0 [1376/21279] Train loss: 3.34031,Valid loss: 4.28916, time : 13.030428171157837 lr : 0.9801\n",
      "epoch : 0 [1377/21279] Train loss: 3.50727,Valid loss: 4.02405, time : 12.971471071243286 lr : 0.9801\n",
      "epoch : 0 [1378/21279] Train loss: 3.48420,Valid loss: 4.45333, time : 12.116828441619873 lr : 0.9801\n",
      "epoch : 0 [1379/21279] Train loss: 3.79952,Valid loss: 4.03763, time : 12.239490032196045 lr : 0.9801\n",
      "epoch : 0 [1380/21279] Train loss: 3.47517,Valid loss: 4.62497, time : 12.615021228790283 lr : 0.9801\n",
      "epoch : 0 [1381/21279] Train loss: 3.53028,Valid loss: 3.85403, time : 12.483309030532837 lr : 0.9801\n",
      "epoch : 0 [1382/21279] Train loss: 3.47915,Valid loss: 4.03892, time : 12.421942949295044 lr : 0.9801\n",
      "epoch : 0 [1383/21279] Train loss: 3.49052,Valid loss: 4.15512, time : 12.110154390335083 lr : 0.9801\n",
      "epoch : 0 [1384/21279] Train loss: 3.40613,Valid loss: 4.18110, time : 13.941877365112305 lr : 0.9801\n",
      "epoch : 0 [1385/21279] Train loss: 3.38739,Valid loss: 3.60687, time : 12.68933629989624 lr : 0.9801\n",
      "epoch : 0 [1386/21279] Train loss: 3.28156,Valid loss: 3.75618, time : 12.584084510803223 lr : 0.9801\n",
      "epoch : 0 [1387/21279] Train loss: 3.29767,Valid loss: 3.62126, time : 12.315730333328247 lr : 0.9801\n",
      "epoch : 0 [1388/21279] Train loss: 3.26324,Valid loss: 3.89611, time : 12.431904315948486 lr : 0.9801\n",
      "epoch : 0 [1389/21279] Train loss: 3.27659,Valid loss: 3.73806, time : 12.766142845153809 lr : 0.9801\n",
      "epoch : 0 [1390/21279] Train loss: 3.25031,Valid loss: 3.71020, time : 12.591999530792236 lr : 0.9801\n",
      "epoch : 0 [1391/21279] Train loss: 3.24799,Valid loss: 3.78082, time : 12.591672420501709 lr : 0.9801\n",
      "epoch : 0 [1392/21279] Train loss: 3.24158,Valid loss: 3.60780, time : 11.985020637512207 lr : 0.9801\n",
      "epoch : 0 [1393/21279] Train loss: 3.22550,Valid loss: 3.65589, time : 12.4364755153656 lr : 0.9801\n",
      "epoch : 0 [1394/21279] Train loss: 3.22100,Valid loss: 3.70158, time : 12.28304409980774 lr : 0.9801\n",
      "epoch : 0 [1395/21279] Train loss: 3.22955,Valid loss: 3.76550, time : 12.513023853302002 lr : 0.9801\n",
      "epoch : 0 [1396/21279] Train loss: 3.22921,Valid loss: 3.95526, time : 12.710881233215332 lr : 0.9801\n",
      "epoch : 0 [1397/21279] Train loss: 3.38776,Valid loss: 3.95760, time : 14.363962411880493 lr : 0.9801\n",
      "epoch : 0 [1398/21279] Train loss: 3.41029,Valid loss: 3.98846, time : 11.862202882766724 lr : 0.9801\n",
      "epoch : 0 [1399/21279] Train loss: 3.46270,Valid loss: 3.98791, time : 12.392035245895386 lr : 0.9801\n",
      "epoch : 0 [1400/21279] Train loss: 3.32576,Valid loss: 3.78412, time : 11.785690307617188 lr : 0.9801\n",
      "epoch : 0 [1401/21279] Train loss: 3.33142,Valid loss: 3.67858, time : 12.065944910049438 lr : 0.9801\n",
      "epoch : 0 [1402/21279] Train loss: 3.37722,Valid loss: 4.54850, time : 12.263771295547485 lr : 0.9801\n",
      "epoch : 0 [1403/21279] Train loss: 3.46431,Valid loss: 4.16455, time : 12.511680126190186 lr : 0.9801\n",
      "epoch : 0 [1404/21279] Train loss: 3.35205,Valid loss: 4.12833, time : 12.88781189918518 lr : 0.9801\n",
      "epoch : 0 [1405/21279] Train loss: 3.27157,Valid loss: 3.61010, time : 12.524543046951294 lr : 0.9801\n",
      "epoch : 0 [1406/21279] Train loss: 3.18452,Valid loss: 3.70644, time : 12.986730575561523 lr : 0.9801\n",
      "epoch : 0 [1407/21279] Train loss: 3.16843,Valid loss: 3.52315, time : 12.54008436203003 lr : 0.9801\n",
      "epoch : 0 [1408/21279] Train loss: 3.15915,Valid loss: 3.83341, time : 12.435262441635132 lr : 0.9801\n",
      "epoch : 0 [1409/21279] Train loss: 3.16044,Valid loss: 3.79541, time : 12.618390083312988 lr : 0.9801\n",
      "epoch : 0 [1410/21279] Train loss: 3.16184,Valid loss: 3.70679, time : 12.574789762496948 lr : 0.9801\n",
      "epoch : 0 [1411/21279] Train loss: 3.19643,Valid loss: 3.72344, time : 12.363623142242432 lr : 0.9801\n",
      "epoch : 0 [1412/21279] Train loss: 3.15926,Valid loss: 3.78134, time : 14.373430490493774 lr : 0.9801\n",
      "epoch : 0 [1413/21279] Train loss: 3.23810,Valid loss: 4.19535, time : 11.780324935913086 lr : 0.9801\n",
      "epoch : 0 [1414/21279] Train loss: 3.28459,Valid loss: 4.15298, time : 12.222447633743286 lr : 0.9801\n",
      "epoch : 0 [1415/21279] Train loss: 3.39644,Valid loss: 4.22980, time : 11.770663261413574 lr : 0.9801\n",
      "epoch : 0 [1416/21279] Train loss: 3.31631,Valid loss: 3.78208, time : 12.404509782791138 lr : 0.9801\n",
      "epoch : 0 [1417/21279] Train loss: 3.34126,Valid loss: 3.85706, time : 11.763689041137695 lr : 0.9801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [1418/21279] Train loss: 3.31261,Valid loss: 4.02894, time : 12.231131553649902 lr : 0.9801\n",
      "epoch : 0 [1419/21279] Train loss: 3.49420,Valid loss: 3.86497, time : 11.838268995285034 lr : 0.9801\n",
      "epoch : 0 [1420/21279] Train loss: 3.24169,Valid loss: 3.76659, time : 11.989887475967407 lr : 0.9801\n",
      "epoch : 0 [1421/21279] Train loss: 3.22349,Valid loss: 3.56756, time : 12.219864130020142 lr : 0.9801\n",
      "epoch : 0 [1422/21279] Train loss: 3.17076,Valid loss: 3.69608, time : 12.097031831741333 lr : 0.9801\n",
      "epoch : 0 [1423/21279] Train loss: 3.18776,Valid loss: 3.52428, time : 12.225686311721802 lr : 0.9801\n",
      "epoch : 0 [1424/21279] Train loss: 3.19177,Valid loss: 3.48285, time : 14.030378818511963 lr : 0.9801\n",
      "epoch : 0 [1425/21279] Train loss: 3.13071,Valid loss: 3.39529, time : 11.734416723251343 lr : 0.9801\n",
      "epoch : 0 [1426/21279] Train loss: 3.09261,Valid loss: 3.48342, time : 12.130078077316284 lr : 0.9801\n",
      "epoch : 0 [1427/21279] Train loss: 3.07899,Valid loss: 3.41676, time : 12.133591175079346 lr : 0.9801\n",
      "epoch : 0 [1428/21279] Train loss: 3.09019,Valid loss: 3.67010, time : 12.44530963897705 lr : 0.9801\n",
      "epoch : 0 [1429/21279] Train loss: 3.09844,Valid loss: 3.55647, time : 11.661978960037231 lr : 0.9801\n",
      "epoch : 0 [1430/21279] Train loss: 3.09900,Valid loss: 3.69404, time : 11.976045846939087 lr : 0.9801\n",
      "epoch : 0 [1431/21279] Train loss: 3.08139,Valid loss: 3.45926, time : 12.098052740097046 lr : 0.9801\n",
      "epoch : 0 [1432/21279] Train loss: 3.10045,Valid loss: 3.61678, time : 12.552653789520264 lr : 0.9801\n",
      "epoch : 0 [1433/21279] Train loss: 3.14402,Valid loss: 3.98727, time : 12.259320259094238 lr : 0.9801\n",
      "epoch : 0 [1434/21279] Train loss: 3.27959,Valid loss: 4.30182, time : 12.44389009475708 lr : 0.9801\n",
      "epoch : 0 [1435/21279] Train loss: 3.74882,Valid loss: 4.60594, time : 12.431882381439209 lr : 0.9801\n",
      "epoch : 0 [1436/21279] Train loss: 3.59436,Valid loss: 4.31349, time : 12.014100551605225 lr : 0.9801\n",
      "epoch : 0 [1437/21279] Train loss: 3.81498,Valid loss: 4.23617, time : 11.985446214675903 lr : 0.9801\n",
      "epoch : 0 [1438/21279] Train loss: 3.41659,Valid loss: 3.62074, time : 14.198102474212646 lr : 0.9801\n",
      "epoch : 0 [1439/21279] Train loss: 3.24208,Valid loss: 3.50381, time : 12.299317359924316 lr : 0.9801\n",
      "epoch : 0 [1440/21279] Train loss: 3.14310,Valid loss: 3.53848, time : 11.652990818023682 lr : 0.9801\n",
      "epoch : 0 [1441/21279] Train loss: 3.11240,Valid loss: 3.40929, time : 12.233548164367676 lr : 0.9801\n",
      "epoch : 0 [1442/21279] Train loss: 3.05222,Valid loss: 3.48334, time : 11.900672674179077 lr : 0.9801\n",
      "epoch : 0 [1443/21279] Train loss: 3.05904,Valid loss: 3.55323, time : 12.425428628921509 lr : 0.9801\n",
      "epoch : 0 [1444/21279] Train loss: 3.04431,Valid loss: 3.49264, time : 11.872101783752441 lr : 0.9801\n",
      "epoch : 0 [1445/21279] Train loss: 3.06458,Valid loss: 3.47642, time : 12.507279872894287 lr : 0.9801\n",
      "epoch : 0 [1446/21279] Train loss: 3.08535,Valid loss: 3.72870, time : 11.872214078903198 lr : 0.9801\n",
      "epoch : 0 [1447/21279] Train loss: 3.13300,Valid loss: 4.11724, time : 12.340919733047485 lr : 0.9801\n",
      "epoch : 0 [1448/21279] Train loss: 3.13602,Valid loss: 3.83490, time : 12.068429708480835 lr : 0.9801\n",
      "epoch : 0 [1449/21279] Train loss: 3.16745,Valid loss: 3.64222, time : 12.393710851669312 lr : 0.9801\n",
      "epoch : 0 [1450/21279] Train loss: 3.08558,Valid loss: 3.38229, time : 15.204339265823364 lr : 0.9801\n",
      "epoch : 0 [1451/21279] Train loss: 3.09626,Valid loss: 3.39731, time : 12.092113733291626 lr : 0.9801\n",
      "epoch : 0 [1452/21279] Train loss: 3.04664,Valid loss: 3.66953, time : 11.863998889923096 lr : 0.9801\n",
      "epoch : 0 [1453/21279] Train loss: 3.06068,Valid loss: 3.66951, time : 12.352402687072754 lr : 0.9801\n",
      "epoch : 0 [1454/21279] Train loss: 3.02617,Valid loss: 3.62488, time : 11.722203254699707 lr : 0.9801\n",
      "epoch : 0 [1455/21279] Train loss: 3.06423,Valid loss: 3.64566, time : 11.953399419784546 lr : 0.9801\n",
      "epoch : 0 [1456/21279] Train loss: 3.01369,Valid loss: 3.65260, time : 12.031623363494873 lr : 0.9801\n",
      "epoch : 0 [1457/21279] Train loss: 3.10120,Valid loss: 3.72598, time : 12.402640104293823 lr : 0.9801\n",
      "epoch : 0 [1458/21279] Train loss: 3.09691,Valid loss: 4.13545, time : 12.29974627494812 lr : 0.9801\n",
      "epoch : 0 [1459/21279] Train loss: 3.24165,Valid loss: 3.63349, time : 12.393284320831299 lr : 0.9801\n",
      "epoch : 0 [1460/21279] Train loss: 3.31434,Valid loss: 4.02460, time : 12.661722183227539 lr : 0.9801\n",
      "epoch : 0 [1461/21279] Train loss: 3.36343,Valid loss: 3.99578, time : 12.506052494049072 lr : 0.9801\n",
      "epoch : 0 [1462/21279] Train loss: 3.19704,Valid loss: 4.09572, time : 12.4816255569458 lr : 0.9801\n",
      "epoch : 0 [1463/21279] Train loss: 3.12495,Valid loss: 3.36931, time : 12.611453771591187 lr : 0.9801\n",
      "epoch : 0 [1464/21279] Train loss: 3.02449,Valid loss: 3.39139, time : 11.779472351074219 lr : 0.9801\n",
      "epoch : 0 [1465/21279] Train loss: 2.98692,Valid loss: 3.50210, time : 12.2646644115448 lr : 0.9801\n",
      "epoch : 0 [1466/21279] Train loss: 3.04921,Valid loss: 3.58509, time : 14.880779266357422 lr : 0.9801\n",
      "epoch : 0 [1467/21279] Train loss: 3.03716,Valid loss: 3.51909, time : 12.056938409805298 lr : 0.9801\n",
      "epoch : 0 [1468/21279] Train loss: 3.08302,Valid loss: 3.43098, time : 12.00379991531372 lr : 0.9801\n",
      "epoch : 0 [1469/21279] Train loss: 3.00878,Valid loss: 3.44816, time : 12.585535764694214 lr : 0.9801\n",
      "epoch : 0 [1470/21279] Train loss: 3.02052,Valid loss: 3.31286, time : 12.114095449447632 lr : 0.9801\n",
      "epoch : 0 [1471/21279] Train loss: 2.96942,Valid loss: 3.31615, time : 11.962183952331543 lr : 0.9801\n",
      "epoch : 0 [1472/21279] Train loss: 2.96605,Valid loss: 3.38949, time : 11.932937622070312 lr : 0.9801\n",
      "epoch : 0 [1473/21279] Train loss: 3.01181,Valid loss: 3.71381, time : 12.259356260299683 lr : 0.9801\n",
      "epoch : 0 [1474/21279] Train loss: 3.03612,Valid loss: 3.57044, time : 12.370203971862793 lr : 0.9801\n",
      "epoch : 0 [1475/21279] Train loss: 3.03374,Valid loss: 3.56736, time : 12.161558628082275 lr : 0.9801\n",
      "epoch : 0 [1476/21279] Train loss: 3.05094,Valid loss: 3.53256, time : 12.31006932258606 lr : 0.9801\n",
      "epoch : 0 [1477/21279] Train loss: 3.04951,Valid loss: 3.35846, time : 11.774492740631104 lr : 0.9801\n",
      "epoch : 0 [1478/21279] Train loss: 3.04263,Valid loss: 3.62705, time : 18.09849238395691 lr : 0.9801\n",
      "epoch : 0 [1479/21279] Train loss: 3.07671,Valid loss: 3.65887, time : 11.853193521499634 lr : 0.9801\n",
      "epoch : 0 [1480/21279] Train loss: 3.08701,Valid loss: 4.24387, time : 12.19118857383728 lr : 0.9801\n",
      "epoch : 0 [1481/21279] Train loss: 3.16033,Valid loss: 3.70025, time : 12.088727474212646 lr : 0.9801\n",
      "epoch : 0 [1482/21279] Train loss: 3.17189,Valid loss: 4.85785, time : 12.259620189666748 lr : 0.9801\n",
      "epoch : 0 [1483/21279] Train loss: 3.42971,Valid loss: 4.85780, time : 12.149897575378418 lr : 0.9801\n",
      "epoch : 0 [1484/21279] Train loss: 3.03136,Valid loss: 4.40215, time : 12.676008939743042 lr : 0.9801\n",
      "epoch : 0 [1485/21279] Train loss: 3.13751,Valid loss: 3.21872, time : 12.810022830963135 lr : 0.9801\n",
      "epoch : 0 [1486/21279] Train loss: 2.87156,Valid loss: 3.14808, time : 12.48824954032898 lr : 0.9801\n",
      "epoch : 0 [1487/21279] Train loss: 2.85331,Valid loss: 3.11327, time : 12.104726791381836 lr : 0.9801\n",
      "epoch : 0 [1488/21279] Train loss: 2.87049,Valid loss: 3.21701, time : 11.73918342590332 lr : 0.9801\n",
      "epoch : 0 [1489/21279] Train loss: 2.83191,Valid loss: 3.33204, time : 11.78356385231018 lr : 0.9801\n",
      "epoch : 0 [1490/21279] Train loss: 2.90353,Valid loss: 3.61748, time : 12.679969310760498 lr : 0.9801\n",
      "epoch : 0 [1491/21279] Train loss: 2.99084,Valid loss: 3.89257, time : 12.009235382080078 lr : 0.9801\n",
      "epoch : 0 [1492/21279] Train loss: 3.07548,Valid loss: 3.78044, time : 12.233021020889282 lr : 0.9801\n",
      "epoch : 0 [1493/21279] Train loss: 3.08701,Valid loss: 3.63181, time : 12.404260396957397 lr : 0.9801\n",
      "epoch : 0 [1494/21279] Train loss: 3.15080,Valid loss: 3.78925, time : 15.677157640457153 lr : 0.9801\n",
      "epoch : 0 [1495/21279] Train loss: 3.24495,Valid loss: 4.16672, time : 12.262525081634521 lr : 0.9801\n",
      "epoch : 0 [1496/21279] Train loss: 3.48018,Valid loss: 3.79253, time : 12.126757383346558 lr : 0.9801\n",
      "epoch : 0 [1497/21279] Train loss: 3.19543,Valid loss: 4.04559, time : 12.473565578460693 lr : 0.9801\n",
      "epoch : 0 [1498/21279] Train loss: 3.21667,Valid loss: 3.69670, time : 12.470125913619995 lr : 0.9801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [1499/21279] Train loss: 3.21080,Valid loss: 4.89626, time : 12.395850419998169 lr : 0.9702989999999999\n",
      "epoch : 0 [1500/21279] Train loss: 3.37350,Valid loss: 3.69204, time : 12.352985620498657 lr : 0.9702989999999999\n",
      "epoch : 0 [1501/21279] Train loss: 3.06176,Valid loss: 3.51403, time : 12.509890079498291 lr : 0.9702989999999999\n",
      "epoch : 0 [1502/21279] Train loss: 2.97944,Valid loss: 3.37265, time : 12.232416152954102 lr : 0.9702989999999999\n",
      "epoch : 0 [1503/21279] Train loss: 2.91213,Valid loss: 3.19336, time : 12.617674589157104 lr : 0.9702989999999999\n",
      "epoch : 0 [1504/21279] Train loss: 2.91532,Valid loss: 3.39419, time : 12.904682159423828 lr : 0.9702989999999999\n",
      "epoch : 0 [1505/21279] Train loss: 2.91325,Valid loss: 3.23332, time : 12.851622819900513 lr : 0.9702989999999999\n",
      "epoch : 0 [1506/21279] Train loss: 2.90464,Valid loss: 3.33870, time : 13.04464602470398 lr : 0.9702989999999999\n",
      "epoch : 0 [1507/21279] Train loss: 2.92001,Valid loss: 3.28997, time : 14.741681814193726 lr : 0.9702989999999999\n",
      "epoch : 0 [1508/21279] Train loss: 2.88168,Valid loss: 3.41829, time : 12.61618185043335 lr : 0.9702989999999999\n",
      "epoch : 0 [1509/21279] Train loss: 2.88690,Valid loss: 3.68719, time : 12.804656982421875 lr : 0.9702989999999999\n",
      "epoch : 0 [1510/21279] Train loss: 2.94353,Valid loss: 3.83275, time : 12.569643020629883 lr : 0.9702989999999999\n",
      "epoch : 0 [1511/21279] Train loss: 2.94136,Valid loss: 4.41229, time : 11.994025945663452 lr : 0.9702989999999999\n",
      "epoch : 0 [1512/21279] Train loss: 3.07147,Valid loss: 3.99017, time : 12.579023361206055 lr : 0.9702989999999999\n",
      "epoch : 0 [1513/21279] Train loss: 3.18143,Valid loss: 3.65274, time : 12.455643892288208 lr : 0.9702989999999999\n",
      "epoch : 0 [1514/21279] Train loss: 3.04293,Valid loss: 3.81949, time : 12.702270269393921 lr : 0.9702989999999999\n",
      "epoch : 0 [1515/21279] Train loss: 3.20957,Valid loss: 3.52683, time : 13.041043043136597 lr : 0.9702989999999999\n",
      "epoch : 0 [1516/21279] Train loss: 3.05195,Valid loss: 3.61543, time : 13.112486839294434 lr : 0.9702989999999999\n",
      "epoch : 0 [1517/21279] Train loss: 3.05919,Valid loss: 3.53243, time : 13.085984230041504 lr : 0.9702989999999999\n",
      "epoch : 0 [1518/21279] Train loss: 2.92320,Valid loss: 3.28820, time : 13.120845556259155 lr : 0.9702989999999999\n",
      "epoch : 0 [1519/21279] Train loss: 2.90258,Valid loss: 3.35612, time : 12.89953088760376 lr : 0.9702989999999999\n",
      "epoch : 0 [1520/21279] Train loss: 2.86116,Valid loss: 3.27558, time : 12.077221632003784 lr : 0.9702989999999999\n",
      "epoch : 0 [1521/21279] Train loss: 2.81922,Valid loss: 3.13913, time : 12.02177095413208 lr : 0.9702989999999999\n",
      "epoch : 0 [1522/21279] Train loss: 2.82308,Valid loss: 3.19582, time : 14.378817081451416 lr : 0.9702989999999999\n",
      "epoch : 0 [1523/21279] Train loss: 2.79214,Valid loss: 3.18995, time : 12.57237195968628 lr : 0.9702989999999999\n",
      "epoch : 0 [1524/21279] Train loss: 2.83661,Valid loss: 3.35332, time : 13.093453168869019 lr : 0.9702989999999999\n",
      "epoch : 0 [1525/21279] Train loss: 2.82364,Valid loss: 3.38642, time : 12.159586191177368 lr : 0.9702989999999999\n",
      "epoch : 0 [1526/21279] Train loss: 2.81979,Valid loss: 3.26874, time : 12.302046537399292 lr : 0.9702989999999999\n",
      "epoch : 0 [1527/21279] Train loss: 2.84622,Valid loss: 3.48614, time : 12.595163583755493 lr : 0.9702989999999999\n",
      "epoch : 0 [1528/21279] Train loss: 2.86997,Valid loss: 3.33442, time : 12.34587836265564 lr : 0.9702989999999999\n",
      "epoch : 0 [1529/21279] Train loss: 2.84748,Valid loss: 3.20319, time : 12.728567361831665 lr : 0.9702989999999999\n",
      "epoch : 0 [1530/21279] Train loss: 2.88168,Valid loss: 3.36021, time : 12.596153497695923 lr : 0.9702989999999999\n",
      "epoch : 0 [1531/21279] Train loss: 2.81492,Valid loss: 3.29456, time : 12.643747568130493 lr : 0.9702989999999999\n",
      "epoch : 0 [1532/21279] Train loss: 2.77804,Valid loss: 3.21710, time : 12.626916408538818 lr : 0.9702989999999999\n",
      "epoch : 0 [1533/21279] Train loss: 2.77896,Valid loss: 3.30040, time : 12.889594793319702 lr : 0.9702989999999999\n",
      "epoch : 0 [1534/21279] Train loss: 2.81444,Valid loss: 3.36097, time : 13.828588485717773 lr : 0.9702989999999999\n",
      "epoch : 0 [1535/21279] Train loss: 2.83975,Valid loss: 3.19368, time : 12.528199195861816 lr : 0.9702989999999999\n",
      "epoch : 0 [1536/21279] Train loss: 2.84779,Valid loss: 3.48253, time : 12.633768558502197 lr : 0.9702989999999999\n",
      "epoch : 0 [1537/21279] Train loss: 2.86746,Valid loss: 3.31964, time : 12.229535341262817 lr : 0.9702989999999999\n",
      "epoch : 0 [1538/21279] Train loss: 2.86354,Valid loss: 3.64796, time : 12.673377990722656 lr : 0.9702989999999999\n",
      "epoch : 0 [1539/21279] Train loss: 2.92263,Valid loss: 3.41792, time : 12.484196901321411 lr : 0.9702989999999999\n",
      "epoch : 0 [1540/21279] Train loss: 2.92812,Valid loss: 3.58844, time : 12.703116178512573 lr : 0.9702989999999999\n",
      "epoch : 0 [1541/21279] Train loss: 3.19252,Valid loss: 3.65729, time : 12.66253137588501 lr : 0.9702989999999999\n",
      "epoch : 0 [1542/21279] Train loss: 3.16015,Valid loss: 4.11725, time : 12.580503463745117 lr : 0.9702989999999999\n",
      "epoch : 0 [1543/21279] Train loss: 3.37482,Valid loss: 3.59039, time : 12.45457410812378 lr : 0.9702989999999999\n",
      "epoch : 0 [1544/21279] Train loss: 3.08389,Valid loss: 3.75272, time : 11.766648054122925 lr : 0.9702989999999999\n",
      "epoch : 0 [1545/21279] Train loss: 3.07266,Valid loss: 3.53892, time : 11.51518177986145 lr : 0.9702989999999999\n",
      "epoch : 0 [1546/21279] Train loss: 2.84655,Valid loss: 3.32403, time : 11.954699993133545 lr : 0.9702989999999999\n",
      "epoch : 0 [1547/21279] Train loss: 2.76615,Valid loss: 3.26956, time : 11.874342918395996 lr : 0.9702989999999999\n",
      "epoch : 0 [1548/21279] Train loss: 2.74504,Valid loss: 3.39821, time : 14.312681674957275 lr : 0.9702989999999999\n",
      "epoch : 0 [1549/21279] Train loss: 2.77944,Valid loss: 3.21319, time : 12.287859439849854 lr : 0.9702989999999999\n",
      "epoch : 0 [1550/21279] Train loss: 2.75352,Valid loss: 3.18930, time : 12.570695638656616 lr : 0.9702989999999999\n",
      "epoch : 0 [1551/21279] Train loss: 2.76144,Valid loss: 3.12486, time : 12.724989652633667 lr : 0.9702989999999999\n",
      "epoch : 0 [1552/21279] Train loss: 2.74213,Valid loss: 3.34168, time : 12.256437063217163 lr : 0.9702989999999999\n",
      "epoch : 0 [1553/21279] Train loss: 2.82108,Valid loss: 3.55617, time : 12.388745784759521 lr : 0.9702989999999999\n",
      "epoch : 0 [1554/21279] Train loss: 2.86268,Valid loss: 4.14058, time : 12.664684534072876 lr : 0.9702989999999999\n",
      "epoch : 0 [1555/21279] Train loss: 3.15918,Valid loss: 3.98551, time : 12.893938541412354 lr : 0.9702989999999999\n",
      "epoch : 0 [1556/21279] Train loss: 3.25152,Valid loss: 4.23640, time : 12.588830471038818 lr : 0.9702989999999999\n",
      "epoch : 0 [1557/21279] Train loss: 3.13649,Valid loss: 3.23388, time : 13.072132349014282 lr : 0.9702989999999999\n",
      "epoch : 0 [1558/21279] Train loss: 2.83289,Valid loss: 3.30553, time : 12.547446966171265 lr : 0.9702989999999999\n",
      "epoch : 0 [1559/21279] Train loss: 2.76174,Valid loss: 3.17116, time : 12.512971878051758 lr : 0.9702989999999999\n",
      "epoch : 0 [1560/21279] Train loss: 2.75313,Valid loss: 3.23064, time : 15.827422618865967 lr : 0.9702989999999999\n",
      "epoch : 0 [1561/21279] Train loss: 2.69840,Valid loss: 3.09753, time : 12.907250165939331 lr : 0.9702989999999999\n",
      "epoch : 0 [1562/21279] Train loss: 2.74512,Valid loss: 3.22272, time : 12.595290899276733 lr : 0.9702989999999999\n",
      "epoch : 0 [1563/21279] Train loss: 2.70541,Valid loss: 3.14235, time : 12.034982204437256 lr : 0.9702989999999999\n",
      "epoch : 0 [1564/21279] Train loss: 2.71091,Valid loss: 3.30068, time : 12.524924516677856 lr : 0.9702989999999999\n",
      "epoch : 0 [1565/21279] Train loss: 2.71492,Valid loss: 3.18708, time : 12.475645542144775 lr : 0.9702989999999999\n",
      "epoch : 0 [1566/21279] Train loss: 2.73146,Valid loss: 3.34566, time : 12.627382516860962 lr : 0.9702989999999999\n",
      "epoch : 0 [1567/21279] Train loss: 2.70257,Valid loss: 3.52418, time : 12.42355489730835 lr : 0.9702989999999999\n",
      "epoch : 0 [1568/21279] Train loss: 2.73940,Valid loss: 3.78911, time : 12.67684292793274 lr : 0.9702989999999999\n",
      "epoch : 0 [1569/21279] Train loss: 2.79288,Valid loss: 3.93403, time : 12.229138851165771 lr : 0.9702989999999999\n",
      "epoch : 0 [1570/21279] Train loss: 2.90465,Valid loss: 4.23714, time : 12.296812772750854 lr : 0.9702989999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [1571/21279] Train loss: 2.83777,Valid loss: 3.74481, time : 12.56140398979187 lr : 0.9702989999999999\n",
      "epoch : 0 [1572/21279] Train loss: 2.99013,Valid loss: 3.14669, time : 12.793037176132202 lr : 0.9702989999999999\n",
      "epoch : 0 [1573/21279] Train loss: 2.84518,Valid loss: 3.31975, time : 13.04988169670105 lr : 0.9702989999999999\n",
      "epoch : 0 [1574/21279] Train loss: 2.79162,Valid loss: 3.21466, time : 12.938713788986206 lr : 0.9702989999999999\n",
      "epoch : 0 [1575/21279] Train loss: 2.70566,Valid loss: 3.30445, time : 12.618752479553223 lr : 0.9702989999999999\n",
      "epoch : 0 [1576/21279] Train loss: 2.72364,Valid loss: 3.21305, time : 20.19285297393799 lr : 0.9702989999999999\n",
      "epoch : 0 [1577/21279] Train loss: 2.72572,Valid loss: 3.30945, time : 12.310718536376953 lr : 0.9702989999999999\n",
      "epoch : 0 [1578/21279] Train loss: 2.70164,Valid loss: 3.07654, time : 12.52318549156189 lr : 0.9702989999999999\n",
      "epoch : 0 [1579/21279] Train loss: 2.68680,Valid loss: 3.28044, time : 12.592390060424805 lr : 0.9702989999999999\n",
      "epoch : 0 [1580/21279] Train loss: 2.70711,Valid loss: 3.13779, time : 12.786821842193604 lr : 0.9702989999999999\n",
      "epoch : 0 [1581/21279] Train loss: 2.67932,Valid loss: 3.10593, time : 12.621519327163696 lr : 0.9702989999999999\n",
      "epoch : 0 [1582/21279] Train loss: 2.67289,Valid loss: 3.20184, time : 12.539576768875122 lr : 0.9702989999999999\n",
      "epoch : 0 [1583/21279] Train loss: 2.71188,Valid loss: 3.15374, time : 12.423660278320312 lr : 0.9702989999999999\n",
      "epoch : 0 [1584/21279] Train loss: 2.75466,Valid loss: 4.20352, time : 12.374812364578247 lr : 0.9702989999999999\n",
      "epoch : 0 [1585/21279] Train loss: 2.79842,Valid loss: 3.41962, time : 11.802969694137573 lr : 0.9702989999999999\n",
      "epoch : 0 [1586/21279] Train loss: 2.78195,Valid loss: 3.19576, time : 12.240540504455566 lr : 0.9702989999999999\n",
      "epoch : 0 [1587/21279] Train loss: 2.75247,Valid loss: 3.16286, time : 12.2500581741333 lr : 0.9702989999999999\n",
      "epoch : 0 [1588/21279] Train loss: 2.66413,Valid loss: 3.40410, time : 14.606021881103516 lr : 0.9702989999999999\n",
      "epoch : 0 [1589/21279] Train loss: 2.65360,Valid loss: 3.27070, time : 12.32822322845459 lr : 0.9702989999999999\n",
      "epoch : 0 [1590/21279] Train loss: 2.66475,Valid loss: 3.16949, time : 12.911905527114868 lr : 0.9702989999999999\n",
      "epoch : 0 [1591/21279] Train loss: 2.66434,Valid loss: 3.17441, time : 11.740474700927734 lr : 0.9702989999999999\n",
      "epoch : 0 [1592/21279] Train loss: 2.66846,Valid loss: 3.28173, time : 12.205323696136475 lr : 0.9702989999999999\n",
      "epoch : 0 [1593/21279] Train loss: 2.68343,Valid loss: 3.04599, time : 12.411024570465088 lr : 0.9702989999999999\n",
      "epoch : 0 [1594/21279] Train loss: 2.71125,Valid loss: 3.16126, time : 12.648212671279907 lr : 0.9702989999999999\n",
      "epoch : 0 [1595/21279] Train loss: 2.64774,Valid loss: 3.25516, time : 11.745887041091919 lr : 0.9702989999999999\n",
      "epoch : 0 [1596/21279] Train loss: 2.68509,Valid loss: 3.21663, time : 12.050176620483398 lr : 0.9702989999999999\n",
      "epoch : 0 [1597/21279] Train loss: 2.68510,Valid loss: 3.34478, time : 11.693726778030396 lr : 0.9702989999999999\n",
      "epoch : 0 [1598/21279] Train loss: 2.72852,Valid loss: 3.27599, time : 12.496139526367188 lr : 0.9702989999999999\n",
      "epoch : 0 [1599/21279] Train loss: 2.69621,Valid loss: 3.85047, time : 12.897010803222656 lr : 0.9702989999999999\n",
      "epoch : 0 [1600/21279] Train loss: 2.78351,Valid loss: 3.43013, time : 12.335597515106201 lr : 0.9702989999999999\n",
      "epoch : 0 [1601/21279] Train loss: 2.78936,Valid loss: 4.18623, time : 12.76382327079773 lr : 0.9702989999999999\n",
      "epoch : 0 [1602/21279] Train loss: 3.30786,Valid loss: 3.95659, time : 12.972450494766235 lr : 0.9702989999999999\n",
      "epoch : 0 [1603/21279] Train loss: 3.04415,Valid loss: 4.56134, time : 12.736292600631714 lr : 0.9702989999999999\n",
      "epoch : 0 [1604/21279] Train loss: 3.33477,Valid loss: 5.01041, time : 15.104953527450562 lr : 0.9702989999999999\n",
      "epoch : 0 [1605/21279] Train loss: 2.88651,Valid loss: 3.86402, time : 13.20689606666565 lr : 0.9702989999999999\n",
      "epoch : 0 [1606/21279] Train loss: 2.82693,Valid loss: 3.44395, time : 12.974002599716187 lr : 0.9702989999999999\n",
      "epoch : 0 [1607/21279] Train loss: 2.69226,Valid loss: 3.16658, time : 12.4545738697052 lr : 0.9702989999999999\n",
      "epoch : 0 [1608/21279] Train loss: 2.66994,Valid loss: 3.09115, time : 12.006996631622314 lr : 0.9702989999999999\n",
      "epoch : 0 [1609/21279] Train loss: 2.63658,Valid loss: 3.16193, time : 12.01159381866455 lr : 0.9702989999999999\n",
      "epoch : 0 [1610/21279] Train loss: 2.63613,Valid loss: 3.07038, time : 12.029994249343872 lr : 0.9702989999999999\n",
      "epoch : 0 [1611/21279] Train loss: 2.63736,Valid loss: 3.22562, time : 12.191056966781616 lr : 0.9702989999999999\n",
      "epoch : 0 [1612/21279] Train loss: 2.63307,Valid loss: 3.02429, time : 12.293550968170166 lr : 0.9702989999999999\n",
      "epoch : 0 [1613/21279] Train loss: 2.60308,Valid loss: 3.10005, time : 12.15311074256897 lr : 0.9702989999999999\n",
      "epoch : 0 [1614/21279] Train loss: 2.63655,Valid loss: 3.01529, time : 12.043142318725586 lr : 0.9702989999999999\n",
      "epoch : 0 [1615/21279] Train loss: 2.58577,Valid loss: 2.91035, time : 12.279464960098267 lr : 0.9702989999999999\n",
      "epoch : 0 [1616/21279] Train loss: 2.59136,Valid loss: 3.01561, time : 12.64720892906189 lr : 0.9702989999999999\n",
      "epoch : 0 [1617/21279] Train loss: 2.55216,Valid loss: 3.01106, time : 15.228119134902954 lr : 0.9702989999999999\n",
      "epoch : 0 [1618/21279] Train loss: 2.56677,Valid loss: 3.05874, time : 12.922747611999512 lr : 0.9702989999999999\n",
      "epoch : 0 [1619/21279] Train loss: 2.57367,Valid loss: 3.05110, time : 12.299980640411377 lr : 0.9702989999999999\n",
      "epoch : 0 [1620/21279] Train loss: 2.59596,Valid loss: 3.23972, time : 12.477699995040894 lr : 0.9702989999999999\n",
      "epoch : 0 [1621/21279] Train loss: 2.61551,Valid loss: 3.11856, time : 12.361003637313843 lr : 0.9702989999999999\n",
      "epoch : 0 [1622/21279] Train loss: 2.58098,Valid loss: 3.47981, time : 12.050240278244019 lr : 0.9702989999999999\n",
      "epoch : 0 [1623/21279] Train loss: 2.64886,Valid loss: 3.26737, time : 12.222153902053833 lr : 0.9702989999999999\n",
      "epoch : 0 [1624/21279] Train loss: 2.55873,Valid loss: 3.03139, time : 12.598008394241333 lr : 0.9702989999999999\n",
      "epoch : 0 [1625/21279] Train loss: 2.57782,Valid loss: 3.08280, time : 12.078783988952637 lr : 0.9702989999999999\n",
      "epoch : 0 [1626/21279] Train loss: 2.57429,Valid loss: 3.10628, time : 12.312807083129883 lr : 0.9702989999999999\n",
      "epoch : 0 [1627/21279] Train loss: 2.59197,Valid loss: 3.07841, time : 12.419418811798096 lr : 0.9702989999999999\n",
      "epoch : 0 [1628/21279] Train loss: 2.55693,Valid loss: 3.07525, time : 12.466521978378296 lr : 0.9702989999999999\n",
      "epoch : 0 [1629/21279] Train loss: 2.56532,Valid loss: 3.01163, time : 12.69094467163086 lr : 0.9702989999999999\n",
      "epoch : 0 [1630/21279] Train loss: 2.54973,Valid loss: 2.97809, time : 12.248805284500122 lr : 0.9702989999999999\n",
      "epoch : 0 [1631/21279] Train loss: 2.55742,Valid loss: 3.31212, time : 12.55801248550415 lr : 0.9702989999999999\n",
      "epoch : 0 [1632/21279] Train loss: 2.59815,Valid loss: 3.44560, time : 14.198047399520874 lr : 0.9702989999999999\n",
      "epoch : 0 [1633/21279] Train loss: 2.62696,Valid loss: 3.52089, time : 12.57254147529602 lr : 0.9702989999999999\n",
      "epoch : 0 [1634/21279] Train loss: 2.73223,Valid loss: 3.62951, time : 12.617884874343872 lr : 0.9702989999999999\n",
      "epoch : 0 [1635/21279] Train loss: 2.64266,Valid loss: 3.75447, time : 12.457946062088013 lr : 0.9702989999999999\n",
      "epoch : 0 [1636/21279] Train loss: 2.72543,Valid loss: 5.91595, time : 12.425170660018921 lr : 0.9702989999999999\n",
      "epoch : 0 [1637/21279] Train loss: 3.07171,Valid loss: 5.01080, time : 12.048225164413452 lr : 0.9702989999999999\n",
      "epoch : 0 [1638/21279] Train loss: 3.10252,Valid loss: 5.48893, time : 12.15597653388977 lr : 0.9702989999999999\n",
      "epoch : 0 [1639/21279] Train loss: 2.78520,Valid loss: 3.96636, time : 12.307873010635376 lr : 0.9702989999999999\n",
      "epoch : 0 [1640/21279] Train loss: 3.02334,Valid loss: 3.64826, time : 11.873499155044556 lr : 0.9702989999999999\n",
      "epoch : 0 [1641/21279] Train loss: 2.66735,Valid loss: 3.13507, time : 12.0763680934906 lr : 0.9702989999999999\n",
      "epoch : 0 [1642/21279] Train loss: 2.54286,Valid loss: 3.06592, time : 11.905770301818848 lr : 0.9702989999999999\n",
      "epoch : 0 [1643/21279] Train loss: 2.56371,Valid loss: 3.28315, time : 12.261159658432007 lr : 0.9702989999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [1644/21279] Train loss: 2.69780,Valid loss: 3.16299, time : 14.85951852798462 lr : 0.9702989999999999\n",
      "epoch : 0 [1645/21279] Train loss: 2.63407,Valid loss: 3.11042, time : 12.447931289672852 lr : 0.9702989999999999\n",
      "epoch : 0 [1646/21279] Train loss: 2.50722,Valid loss: 2.80638, time : 12.498783826828003 lr : 0.9702989999999999\n",
      "epoch : 0 [1647/21279] Train loss: 2.47490,Valid loss: 2.93815, time : 12.490886449813843 lr : 0.9702989999999999\n",
      "epoch : 0 [1648/21279] Train loss: 2.52447,Valid loss: 2.86041, time : 12.670697689056396 lr : 0.9702989999999999\n",
      "epoch : 0 [1649/21279] Train loss: 2.53323,Valid loss: 2.98663, time : 12.463221788406372 lr : 0.9702989999999999\n",
      "epoch : 0 [1650/21279] Train loss: 2.55881,Valid loss: 2.97110, time : 12.604193449020386 lr : 0.9702989999999999\n",
      "epoch : 0 [1651/21279] Train loss: 2.52544,Valid loss: 2.89959, time : 12.658018112182617 lr : 0.9702989999999999\n",
      "epoch : 0 [1652/21279] Train loss: 2.54811,Valid loss: 3.05189, time : 12.571591854095459 lr : 0.9702989999999999\n",
      "epoch : 0 [1653/21279] Train loss: 2.55634,Valid loss: 2.92405, time : 12.752064228057861 lr : 0.9702989999999999\n",
      "epoch : 0 [1654/21279] Train loss: 2.59140,Valid loss: 3.16659, time : 12.113570928573608 lr : 0.9702989999999999\n",
      "epoch : 0 [1655/21279] Train loss: 2.53114,Valid loss: 2.98244, time : 12.475566864013672 lr : 0.9702989999999999\n",
      "epoch : 0 [1656/21279] Train loss: 2.51103,Valid loss: 3.28869, time : 12.467173099517822 lr : 0.9702989999999999\n",
      "epoch : 0 [1657/21279] Train loss: 2.52415,Valid loss: 3.15724, time : 12.7043936252594 lr : 0.9702989999999999\n",
      "epoch : 0 [1658/21279] Train loss: 2.48745,Valid loss: 3.41555, time : 16.203954219818115 lr : 0.9702989999999999\n",
      "epoch : 0 [1659/21279] Train loss: 2.52374,Valid loss: 3.53507, time : 13.434560298919678 lr : 0.9702989999999999\n",
      "epoch : 0 [1660/21279] Train loss: 2.67440,Valid loss: 4.20843, time : 12.305875062942505 lr : 0.9702989999999999\n",
      "epoch : 0 [1661/21279] Train loss: 2.70597,Valid loss: 3.65737, time : 11.853793144226074 lr : 0.9702989999999999\n",
      "epoch : 0 [1662/21279] Train loss: 3.18527,Valid loss: 4.14976, time : 12.408772706985474 lr : 0.9702989999999999\n",
      "epoch : 0 [1663/21279] Train loss: 2.97411,Valid loss: 3.66976, time : 11.915754318237305 lr : 0.9702989999999999\n",
      "epoch : 0 [1664/21279] Train loss: 2.90765,Valid loss: 4.49284, time : 12.53383731842041 lr : 0.9702989999999999\n",
      "epoch : 0 [1665/21279] Train loss: 3.50229,Valid loss: 3.09215, time : 12.071691513061523 lr : 0.9702989999999999\n",
      "epoch : 0 [1666/21279] Train loss: 2.65941,Valid loss: 3.62649, time : 12.401812076568604 lr : 0.9702989999999999\n",
      "epoch : 0 [1667/21279] Train loss: 2.72063,Valid loss: 3.93986, time : 12.057852983474731 lr : 0.9702989999999999\n",
      "epoch : 0 [1668/21279] Train loss: 3.13526,Valid loss: 7.53336, time : 12.619950294494629 lr : 0.9702989999999999\n",
      "epoch : 0 [1669/21279] Train loss: 2.82537,Valid loss: 3.59139, time : 12.491929769515991 lr : 0.9702989999999999\n",
      "epoch : 0 [1670/21279] Train loss: 2.69692,Valid loss: 3.42364, time : 16.72568416595459 lr : 0.9702989999999999\n",
      "epoch : 0 [1671/21279] Train loss: 2.62867,Valid loss: 3.35618, time : 12.086069822311401 lr : 0.9702989999999999\n",
      "epoch : 0 [1672/21279] Train loss: 2.55867,Valid loss: 3.07529, time : 12.430277585983276 lr : 0.9702989999999999\n",
      "epoch : 0 [1673/21279] Train loss: 2.47938,Valid loss: 2.98613, time : 12.345536470413208 lr : 0.9702989999999999\n",
      "epoch : 0 [1674/21279] Train loss: 2.45778,Valid loss: 2.85094, time : 12.789555311203003 lr : 0.9702989999999999\n",
      "epoch : 0 [1675/21279] Train loss: 2.45760,Valid loss: 2.98434, time : 12.139900922775269 lr : 0.9702989999999999\n",
      "epoch : 0 [1676/21279] Train loss: 2.43396,Valid loss: 2.80639, time : 12.31160020828247 lr : 0.9702989999999999\n",
      "epoch : 0 [1677/21279] Train loss: 2.43648,Valid loss: 2.93504, time : 12.212057113647461 lr : 0.9702989999999999\n",
      "epoch : 0 [1678/21279] Train loss: 2.45712,Valid loss: 3.29280, time : 12.39572024345398 lr : 0.9702989999999999\n",
      "epoch : 0 [1679/21279] Train loss: 2.44041,Valid loss: 2.81144, time : 12.198368072509766 lr : 0.9702989999999999\n",
      "epoch : 0 [1680/21279] Train loss: 2.47006,Valid loss: 3.21233, time : 12.278651237487793 lr : 0.9702989999999999\n",
      "epoch : 0 [1681/21279] Train loss: 2.44864,Valid loss: 2.94306, time : 12.37459135055542 lr : 0.9702989999999999\n",
      "epoch : 0 [1682/21279] Train loss: 2.47684,Valid loss: 3.00601, time : 12.36154580116272 lr : 0.9702989999999999\n",
      "epoch : 0 [1683/21279] Train loss: 2.43017,Valid loss: 3.14858, time : 12.465847492218018 lr : 0.9702989999999999\n",
      "epoch : 0 [1684/21279] Train loss: 2.47457,Valid loss: 2.97137, time : 12.433335542678833 lr : 0.9702989999999999\n",
      "epoch : 0 [1685/21279] Train loss: 2.47384,Valid loss: 3.13012, time : 12.55284857749939 lr : 0.9702989999999999\n",
      "epoch : 0 [1686/21279] Train loss: 2.47640,Valid loss: 3.06798, time : 14.85723614692688 lr : 0.9702989999999999\n",
      "epoch : 0 [1687/21279] Train loss: 2.50428,Valid loss: 3.00327, time : 12.602301836013794 lr : 0.9702989999999999\n",
      "epoch : 0 [1688/21279] Train loss: 2.44752,Valid loss: 2.95528, time : 12.947785377502441 lr : 0.9702989999999999\n",
      "epoch : 0 [1689/21279] Train loss: 2.45606,Valid loss: 2.96560, time : 12.580694437026978 lr : 0.9702989999999999\n",
      "epoch : 0 [1690/21279] Train loss: 2.36845,Valid loss: 2.93547, time : 12.929752111434937 lr : 0.9702989999999999\n",
      "epoch : 0 [1691/21279] Train loss: 2.38116,Valid loss: 3.05463, time : 12.559127569198608 lr : 0.9702989999999999\n",
      "epoch : 0 [1692/21279] Train loss: 2.45093,Valid loss: 3.04295, time : 12.587488412857056 lr : 0.9702989999999999\n",
      "epoch : 0 [1693/21279] Train loss: 2.43662,Valid loss: 3.46406, time : 12.841261863708496 lr : 0.9702989999999999\n",
      "epoch : 0 [1694/21279] Train loss: 2.57463,Valid loss: 3.85781, time : 12.804783821105957 lr : 0.9702989999999999\n",
      "epoch : 0 [1695/21279] Train loss: 2.59043,Valid loss: 3.65777, time : 12.884747982025146 lr : 0.9702989999999999\n",
      "epoch : 0 [1696/21279] Train loss: 3.03814,Valid loss: 3.78184, time : 12.212871074676514 lr : 0.9702989999999999\n",
      "epoch : 0 [1697/21279] Train loss: 2.83777,Valid loss: 3.75938, time : 12.19965934753418 lr : 0.9702989999999999\n",
      "epoch : 0 [1698/21279] Train loss: 2.80469,Valid loss: 3.20679, time : 14.701138019561768 lr : 0.9702989999999999\n",
      "epoch : 0 [1699/21279] Train loss: 2.44597,Valid loss: 2.91157, time : 12.23116946220398 lr : 0.9702989999999999\n",
      "epoch : 0 [1700/21279] Train loss: 2.37936,Valid loss: 2.81267, time : 12.594027519226074 lr : 0.9702989999999999\n",
      "epoch : 0 [1701/21279] Train loss: 2.36279,Valid loss: 2.76676, time : 12.986169576644897 lr : 0.9702989999999999\n",
      "epoch : 0 [1702/21279] Train loss: 2.33864,Valid loss: 2.90013, time : 12.490797758102417 lr : 0.9702989999999999\n",
      "epoch : 0 [1703/21279] Train loss: 2.35212,Valid loss: 2.82630, time : 12.423807144165039 lr : 0.9702989999999999\n",
      "epoch : 0 [1704/21279] Train loss: 2.35784,Valid loss: 2.91823, time : 13.01559066772461 lr : 0.9702989999999999\n",
      "epoch : 0 [1705/21279] Train loss: 2.39613,Valid loss: 2.81131, time : 13.234549045562744 lr : 0.9702989999999999\n",
      "epoch : 0 [1706/21279] Train loss: 2.33292,Valid loss: 2.85878, time : 13.151682615280151 lr : 0.9702989999999999\n",
      "epoch : 0 [1707/21279] Train loss: 2.36118,Valid loss: 2.73018, time : 12.799429655075073 lr : 0.9702989999999999\n",
      "epoch : 0 [1708/21279] Train loss: 2.35164,Valid loss: 2.85497, time : 12.838950872421265 lr : 0.9702989999999999\n",
      "epoch : 0 [1709/21279] Train loss: 2.36854,Valid loss: 2.88689, time : 12.731979846954346 lr : 0.9702989999999999\n",
      "epoch : 0 [1710/21279] Train loss: 2.35035,Valid loss: 2.91474, time : 12.874405860900879 lr : 0.9702989999999999\n",
      "epoch : 0 [1711/21279] Train loss: 2.35278,Valid loss: 3.03639, time : 12.33130955696106 lr : 0.9702989999999999\n",
      "epoch : 0 [1712/21279] Train loss: 2.35730,Valid loss: 3.65218, time : 12.841081380844116 lr : 0.9702989999999999\n",
      "epoch : 0 [1713/21279] Train loss: 2.40728,Valid loss: 3.62521, time : 12.644157409667969 lr : 0.9702989999999999\n",
      "epoch : 0 [1714/21279] Train loss: 2.52850,Valid loss: 4.58863, time : 14.293476343154907 lr : 0.9702989999999999\n",
      "epoch : 0 [1715/21279] Train loss: 2.54828,Valid loss: 2.96865, time : 12.629832983016968 lr : 0.9702989999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [1716/21279] Train loss: 2.39643,Valid loss: 2.61118, time : 12.908348083496094 lr : 0.9702989999999999\n",
      "epoch : 0 [1717/21279] Train loss: 2.28626,Valid loss: 2.68190, time : 13.167324542999268 lr : 0.9702989999999999\n",
      "epoch : 0 [1718/21279] Train loss: 2.25052,Valid loss: 2.66957, time : 12.671744346618652 lr : 0.9702989999999999\n",
      "epoch : 0 [1719/21279] Train loss: 2.25264,Valid loss: 2.61274, time : 13.027038097381592 lr : 0.9702989999999999\n",
      "epoch : 0 [1720/21279] Train loss: 2.26367,Valid loss: 2.55642, time : 12.451454401016235 lr : 0.9702989999999999\n",
      "epoch : 0 [1721/21279] Train loss: 2.23763,Valid loss: 2.75655, time : 12.946502923965454 lr : 0.9702989999999999\n",
      "epoch : 0 [1722/21279] Train loss: 2.31919,Valid loss: 2.80365, time : 12.731686115264893 lr : 0.9702989999999999\n",
      "epoch : 0 [1723/21279] Train loss: 2.34370,Valid loss: 2.82562, time : 12.703648090362549 lr : 0.9702989999999999\n",
      "epoch : 0 [1724/21279] Train loss: 2.37636,Valid loss: 2.96073, time : 12.889241933822632 lr : 0.9702989999999999\n",
      "epoch : 0 [1725/21279] Train loss: 2.39414,Valid loss: 2.89500, time : 12.741790533065796 lr : 0.9702989999999999\n",
      "epoch : 0 [1726/21279] Train loss: 2.36363,Valid loss: 2.81435, time : 12.17006516456604 lr : 0.9702989999999999\n",
      "epoch : 0 [1727/21279] Train loss: 2.36850,Valid loss: 2.93705, time : 14.08558702468872 lr : 0.9702989999999999\n",
      "epoch : 0 [1728/21279] Train loss: 2.36268,Valid loss: 2.62507, time : 12.191632747650146 lr : 0.9702989999999999\n",
      "epoch : 0 [1729/21279] Train loss: 2.31094,Valid loss: 2.85375, time : 12.41738510131836 lr : 0.9702989999999999\n",
      "epoch : 0 [1730/21279] Train loss: 2.32071,Valid loss: 2.87020, time : 12.375513315200806 lr : 0.9702989999999999\n",
      "epoch : 0 [1731/21279] Train loss: 2.28376,Valid loss: 2.76659, time : 12.732484102249146 lr : 0.9702989999999999\n",
      "epoch : 0 [1732/21279] Train loss: 2.29769,Valid loss: 2.74720, time : 12.509739637374878 lr : 0.9702989999999999\n",
      "epoch : 0 [1733/21279] Train loss: 2.30857,Valid loss: 2.80812, time : 12.456832885742188 lr : 0.9702989999999999\n",
      "epoch : 0 [1734/21279] Train loss: 2.31556,Valid loss: 2.92849, time : 12.216148138046265 lr : 0.9702989999999999\n",
      "epoch : 0 [1735/21279] Train loss: 2.35609,Valid loss: 3.18826, time : 11.726360559463501 lr : 0.9702989999999999\n",
      "epoch : 0 [1736/21279] Train loss: 2.53693,Valid loss: 3.80554, time : 12.110827922821045 lr : 0.9702989999999999\n",
      "epoch : 0 [1737/21279] Train loss: 2.93589,Valid loss: 3.14308, time : 12.255393743515015 lr : 0.9702989999999999\n",
      "epoch : 0 [1738/21279] Train loss: 2.52379,Valid loss: 3.32509, time : 12.608520984649658 lr : 0.9702989999999999\n",
      "epoch : 0 [1739/21279] Train loss: 2.57874,Valid loss: 3.13335, time : 12.888540267944336 lr : 0.9702989999999999\n",
      "epoch : 0 [1740/21279] Train loss: 2.43830,Valid loss: 3.48015, time : 12.88908576965332 lr : 0.9702989999999999\n",
      "epoch : 0 [1741/21279] Train loss: 2.52445,Valid loss: 3.18201, time : 13.161909341812134 lr : 0.9702989999999999\n",
      "epoch : 0 [1742/21279] Train loss: 2.43201,Valid loss: 3.30328, time : 14.933539628982544 lr : 0.9702989999999999\n",
      "epoch : 0 [1743/21279] Train loss: 2.46867,Valid loss: 3.14609, time : 13.098755598068237 lr : 0.9702989999999999\n",
      "epoch : 0 [1744/21279] Train loss: 2.42230,Valid loss: 3.21528, time : 12.878111839294434 lr : 0.9702989999999999\n",
      "epoch : 0 [1745/21279] Train loss: 2.38360,Valid loss: 3.21251, time : 12.704323768615723 lr : 0.9702989999999999\n",
      "epoch : 0 [1746/21279] Train loss: 2.33603,Valid loss: 2.85417, time : 12.341760873794556 lr : 0.9702989999999999\n",
      "epoch : 0 [1747/21279] Train loss: 2.35743,Valid loss: 2.79942, time : 12.545695543289185 lr : 0.9702989999999999\n",
      "epoch : 0 [1748/21279] Train loss: 2.28394,Valid loss: 2.76959, time : 12.904397964477539 lr : 0.9702989999999999\n",
      "epoch : 0 [1749/21279] Train loss: 2.27714,Valid loss: 2.65179, time : 13.14000129699707 lr : 0.9702989999999999\n",
      "epoch : 0 [1750/21279] Train loss: 2.23772,Valid loss: 2.83930, time : 12.614600419998169 lr : 0.9702989999999999\n",
      "epoch : 0 [1751/21279] Train loss: 2.25317,Valid loss: 2.56020, time : 12.745481729507446 lr : 0.9702989999999999\n",
      "epoch : 0 [1752/21279] Train loss: 2.22552,Valid loss: 2.81708, time : 12.298024415969849 lr : 0.9702989999999999\n",
      "epoch : 0 [1753/21279] Train loss: 2.23433,Valid loss: 2.71145, time : 12.865602254867554 lr : 0.9702989999999999\n",
      "epoch : 0 [1754/21279] Train loss: 2.23690,Valid loss: 2.96054, time : 15.674236297607422 lr : 0.9702989999999999\n",
      "epoch : 0 [1755/21279] Train loss: 2.24798,Valid loss: 2.75547, time : 12.3961820602417 lr : 0.9702989999999999\n",
      "epoch : 0 [1756/21279] Train loss: 2.24733,Valid loss: 2.75582, time : 12.212734937667847 lr : 0.9702989999999999\n",
      "epoch : 0 [1757/21279] Train loss: 2.23582,Valid loss: 2.76248, time : 12.445916175842285 lr : 0.9702989999999999\n",
      "epoch : 0 [1758/21279] Train loss: 2.26763,Valid loss: 2.79871, time : 12.59408450126648 lr : 0.9702989999999999\n",
      "epoch : 0 [1759/21279] Train loss: 2.28677,Valid loss: 3.01266, time : 12.43275785446167 lr : 0.9702989999999999\n",
      "epoch : 0 [1760/21279] Train loss: 2.29294,Valid loss: 2.79687, time : 12.455986261367798 lr : 0.9702989999999999\n",
      "epoch : 0 [1761/21279] Train loss: 2.33834,Valid loss: 3.33567, time : 12.835326671600342 lr : 0.9702989999999999\n",
      "epoch : 0 [1762/21279] Train loss: 2.25167,Valid loss: 2.73436, time : 12.71788215637207 lr : 0.9702989999999999\n",
      "epoch : 0 [1763/21279] Train loss: 2.23524,Valid loss: 3.17135, time : 12.880887031555176 lr : 0.9702989999999999\n",
      "epoch : 0 [1764/21279] Train loss: 2.32207,Valid loss: 3.10984, time : 12.732992887496948 lr : 0.9702989999999999\n",
      "epoch : 0 [1765/21279] Train loss: 2.14095,Valid loss: 2.79652, time : 12.334903001785278 lr : 0.9702989999999999\n",
      "epoch : 0 [1766/21279] Train loss: 2.15756,Valid loss: 2.74425, time : 12.952276229858398 lr : 0.9702989999999999\n",
      "epoch : 0 [1767/21279] Train loss: 2.12914,Valid loss: 3.06911, time : 12.849304437637329 lr : 0.9702989999999999\n",
      "epoch : 0 [1768/21279] Train loss: 2.15256,Valid loss: 3.16618, time : 15.18458080291748 lr : 0.9702989999999999\n",
      "epoch : 0 [1769/21279] Train loss: 2.27351,Valid loss: 3.37626, time : 12.977873802185059 lr : 0.9702989999999999\n",
      "epoch : 0 [1770/21279] Train loss: 2.25001,Valid loss: 3.12723, time : 12.021199226379395 lr : 0.9702989999999999\n",
      "epoch : 0 [1771/21279] Train loss: 2.43614,Valid loss: 4.43054, time : 12.412108898162842 lr : 0.9702989999999999\n",
      "epoch : 0 [1772/21279] Train loss: 2.78276,Valid loss: 3.32257, time : 12.699740171432495 lr : 0.9702989999999999\n",
      "epoch : 0 [1773/21279] Train loss: 2.72965,Valid loss: 3.31547, time : 12.476986646652222 lr : 0.9702989999999999\n",
      "epoch : 0 [1774/21279] Train loss: 2.60714,Valid loss: 3.11613, time : 12.34926438331604 lr : 0.9702989999999999\n",
      "epoch : 0 [1775/21279] Train loss: 2.46183,Valid loss: 2.83033, time : 12.218864440917969 lr : 0.9702989999999999\n",
      "epoch : 0 [1776/21279] Train loss: 2.32265,Valid loss: 2.82491, time : 12.157313108444214 lr : 0.9702989999999999\n",
      "epoch : 0 [1777/21279] Train loss: 2.23349,Valid loss: 2.81588, time : 12.615620136260986 lr : 0.9702989999999999\n",
      "epoch : 0 [1778/21279] Train loss: 2.21783,Valid loss: 2.83885, time : 12.637892007827759 lr : 0.9702989999999999\n",
      "epoch : 0 [1779/21279] Train loss: 2.23071,Valid loss: 2.66922, time : 11.98195481300354 lr : 0.9702989999999999\n",
      "epoch : 0 [1780/21279] Train loss: 2.18962,Valid loss: 2.89358, time : 14.050688028335571 lr : 0.9702989999999999\n",
      "epoch : 0 [1781/21279] Train loss: 2.21748,Valid loss: 2.71206, time : 12.427503108978271 lr : 0.9702989999999999\n",
      "epoch : 0 [1782/21279] Train loss: 2.23508,Valid loss: 2.90387, time : 11.809277534484863 lr : 0.9702989999999999\n",
      "epoch : 0 [1783/21279] Train loss: 2.27227,Valid loss: 2.56921, time : 11.943854808807373 lr : 0.9702989999999999\n",
      "epoch : 0 [1784/21279] Train loss: 2.24828,Valid loss: 2.71157, time : 12.002873420715332 lr : 0.9702989999999999\n",
      "epoch : 0 [1785/21279] Train loss: 2.19072,Valid loss: 2.45233, time : 12.106694459915161 lr : 0.9702989999999999\n",
      "epoch : 0 [1786/21279] Train loss: 2.19085,Valid loss: 2.72731, time : 12.147426843643188 lr : 0.9702989999999999\n",
      "epoch : 0 [1787/21279] Train loss: 2.15807,Valid loss: 2.75400, time : 12.547695636749268 lr : 0.9702989999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [1788/21279] Train loss: 2.16011,Valid loss: 2.72081, time : 12.146829605102539 lr : 0.9702989999999999\n",
      "epoch : 0 [1789/21279] Train loss: 2.21572,Valid loss: 3.01003, time : 12.496015310287476 lr : 0.9702989999999999\n",
      "epoch : 0 [1790/21279] Train loss: 2.17877,Valid loss: 2.61786, time : 12.10011339187622 lr : 0.9702989999999999\n",
      "epoch : 0 [1791/21279] Train loss: 2.14771,Valid loss: 2.58887, time : 11.950153827667236 lr : 0.9702989999999999\n",
      "epoch : 0 [1792/21279] Train loss: 2.15740,Valid loss: 2.64470, time : 12.035864114761353 lr : 0.9702989999999999\n",
      "epoch : 0 [1793/21279] Train loss: 2.14703,Valid loss: 2.63343, time : 12.242386102676392 lr : 0.9702989999999999\n",
      "epoch : 0 [1794/21279] Train loss: 2.15378,Valid loss: 2.78129, time : 12.352553606033325 lr : 0.9702989999999999\n",
      "epoch : 0 [1795/21279] Train loss: 2.15235,Valid loss: 2.77107, time : 12.470820426940918 lr : 0.9702989999999999\n",
      "epoch : 0 [1796/21279] Train loss: 2.21751,Valid loss: 3.32570, time : 18.255366563796997 lr : 0.9702989999999999\n",
      "epoch : 0 [1797/21279] Train loss: 2.38253,Valid loss: 3.42974, time : 12.78304147720337 lr : 0.9702989999999999\n",
      "epoch : 0 [1798/21279] Train loss: 2.44608,Valid loss: 3.40092, time : 12.28105354309082 lr : 0.9702989999999999\n",
      "epoch : 0 [1799/21279] Train loss: 2.62318,Valid loss: 2.99584, time : 11.82973337173462 lr : 0.9702989999999999\n",
      "epoch : 0 [1800/21279] Train loss: 2.45890,Valid loss: 3.04919, time : 12.590011835098267 lr : 0.9702989999999999\n",
      "epoch : 0 [1801/21279] Train loss: 2.22097,Valid loss: 2.66836, time : 12.173891067504883 lr : 0.9702989999999999\n",
      "epoch : 0 [1802/21279] Train loss: 2.13039,Valid loss: 2.53551, time : 12.625639200210571 lr : 0.9702989999999999\n",
      "epoch : 0 [1803/21279] Train loss: 2.08656,Valid loss: 2.54791, time : 12.61966609954834 lr : 0.9702989999999999\n",
      "epoch : 0 [1804/21279] Train loss: 2.07533,Valid loss: 2.51820, time : 12.725826263427734 lr : 0.9702989999999999\n",
      "epoch : 0 [1805/21279] Train loss: 2.04857,Valid loss: 2.55166, time : 12.560346126556396 lr : 0.9702989999999999\n",
      "epoch : 0 [1806/21279] Train loss: 2.09619,Valid loss: 2.69148, time : 12.781634330749512 lr : 0.9702989999999999\n",
      "epoch : 0 [1807/21279] Train loss: 2.10228,Valid loss: 2.65158, time : 12.45043396949768 lr : 0.9702989999999999\n",
      "epoch : 0 [1808/21279] Train loss: 2.13789,Valid loss: 2.78975, time : 15.398964643478394 lr : 0.9702989999999999\n",
      "epoch : 0 [1809/21279] Train loss: 2.16955,Valid loss: 2.89088, time : 12.813389539718628 lr : 0.9702989999999999\n",
      "epoch : 0 [1810/21279] Train loss: 2.23009,Valid loss: 2.85138, time : 12.883278131484985 lr : 0.9702989999999999\n",
      "epoch : 0 [1811/21279] Train loss: 2.22678,Valid loss: 2.74355, time : 12.119859218597412 lr : 0.9702989999999999\n",
      "epoch : 0 [1812/21279] Train loss: 2.21243,Valid loss: 2.71904, time : 12.709770202636719 lr : 0.9702989999999999\n",
      "epoch : 0 [1813/21279] Train loss: 2.16389,Valid loss: 2.58031, time : 12.066579580307007 lr : 0.9702989999999999\n",
      "epoch : 0 [1814/21279] Train loss: 2.17274,Valid loss: 2.75450, time : 11.731945753097534 lr : 0.9702989999999999\n",
      "epoch : 0 [1815/21279] Train loss: 2.16598,Valid loss: 2.61697, time : 12.029809713363647 lr : 0.9702989999999999\n",
      "epoch : 0 [1816/21279] Train loss: 2.13543,Valid loss: 2.72369, time : 12.63421630859375 lr : 0.9702989999999999\n",
      "epoch : 0 [1817/21279] Train loss: 2.09165,Valid loss: 2.62164, time : 12.126758098602295 lr : 0.9702989999999999\n",
      "epoch : 0 [1818/21279] Train loss: 2.09861,Valid loss: 2.68583, time : 12.186551094055176 lr : 0.9702989999999999\n",
      "epoch : 0 [1819/21279] Train loss: 2.11615,Valid loss: 2.61736, time : 12.101512670516968 lr : 0.9702989999999999\n",
      "epoch : 0 [1820/21279] Train loss: 2.10512,Valid loss: 2.58644, time : 12.517367362976074 lr : 0.9702989999999999\n",
      "epoch : 0 [1821/21279] Train loss: 2.09497,Valid loss: 2.69171, time : 12.232200145721436 lr : 0.9702989999999999\n",
      "epoch : 0 [1822/21279] Train loss: 2.11119,Valid loss: 2.51558, time : 12.724296808242798 lr : 0.9702989999999999\n",
      "epoch : 0 [1823/21279] Train loss: 2.11172,Valid loss: 2.73685, time : 12.159592866897583 lr : 0.9702989999999999\n",
      "epoch : 0 [1824/21279] Train loss: 2.12346,Valid loss: 2.66447, time : 16.210333347320557 lr : 0.9702989999999999\n",
      "epoch : 0 [1825/21279] Train loss: 2.15868,Valid loss: 2.86552, time : 12.299697160720825 lr : 0.9702989999999999\n",
      "epoch : 0 [1826/21279] Train loss: 2.12929,Valid loss: 2.80850, time : 12.33662462234497 lr : 0.9702989999999999\n",
      "epoch : 0 [1827/21279] Train loss: 2.15278,Valid loss: 3.06401, time : 12.627249956130981 lr : 0.9702989999999999\n",
      "epoch : 0 [1828/21279] Train loss: 2.16867,Valid loss: 3.01798, time : 12.899781227111816 lr : 0.9702989999999999\n",
      "epoch : 0 [1829/21279] Train loss: 2.17032,Valid loss: 3.73000, time : 12.5933358669281 lr : 0.9702989999999999\n",
      "epoch : 0 [1830/21279] Train loss: 2.24606,Valid loss: 3.17637, time : 12.279607057571411 lr : 0.9702989999999999\n",
      "epoch : 0 [1831/21279] Train loss: 2.45497,Valid loss: 4.10804, time : 12.342482566833496 lr : 0.9702989999999999\n",
      "epoch : 0 [1832/21279] Train loss: 2.47394,Valid loss: 3.03780, time : 12.343655824661255 lr : 0.9702989999999999\n",
      "epoch : 0 [1833/21279] Train loss: 2.43041,Valid loss: 3.42358, time : 12.662084579467773 lr : 0.9702989999999999\n",
      "epoch : 0 [1834/21279] Train loss: 2.36029,Valid loss: 4.50566, time : 12.508469581604004 lr : 0.9702989999999999\n",
      "epoch : 0 [1835/21279] Train loss: 2.52667,Valid loss: 2.94173, time : 12.630533218383789 lr : 0.9702989999999999\n",
      "epoch : 0 [1836/21279] Train loss: 2.12739,Valid loss: 2.63461, time : 12.498069286346436 lr : 0.9702989999999999\n",
      "epoch : 0 [1837/21279] Train loss: 2.07669,Valid loss: 2.69520, time : 14.454948663711548 lr : 0.9702989999999999\n",
      "epoch : 0 [1838/21279] Train loss: 2.06159,Valid loss: 2.78028, time : 12.834619522094727 lr : 0.9702989999999999\n",
      "epoch : 0 [1839/21279] Train loss: 2.17605,Valid loss: 3.05702, time : 12.620096683502197 lr : 0.9702989999999999\n",
      "epoch : 0 [1840/21279] Train loss: 2.15665,Valid loss: 3.03067, time : 12.750296831130981 lr : 0.9702989999999999\n",
      "epoch : 0 [1841/21279] Train loss: 2.09573,Valid loss: 2.50924, time : 12.411783933639526 lr : 0.9702989999999999\n",
      "epoch : 0 [1842/21279] Train loss: 2.01013,Valid loss: 2.59217, time : 13.069613933563232 lr : 0.9702989999999999\n",
      "epoch : 0 [1843/21279] Train loss: 1.99020,Valid loss: 2.75875, time : 12.13017988204956 lr : 0.9702989999999999\n",
      "epoch : 0 [1844/21279] Train loss: 1.98686,Valid loss: 2.59771, time : 12.076087474822998 lr : 0.9702989999999999\n",
      "epoch : 0 [1845/21279] Train loss: 2.00742,Valid loss: 2.58090, time : 12.377051591873169 lr : 0.9702989999999999\n",
      "epoch : 0 [1846/21279] Train loss: 2.03039,Valid loss: 2.63370, time : 12.269203186035156 lr : 0.9702989999999999\n",
      "epoch : 0 [1847/21279] Train loss: 2.00250,Valid loss: 2.61544, time : 12.31681227684021 lr : 0.9702989999999999\n",
      "epoch : 0 [1848/21279] Train loss: 2.03157,Valid loss: 2.58782, time : 12.290218114852905 lr : 0.9702989999999999\n",
      "epoch : 0 [1849/21279] Train loss: 1.98848,Valid loss: 2.62301, time : 12.483688592910767 lr : 0.9702989999999999\n",
      "epoch : 0 [1850/21279] Train loss: 2.04160,Valid loss: 2.58186, time : 12.45191478729248 lr : 0.9702989999999999\n",
      "epoch : 0 [1851/21279] Train loss: 2.01721,Valid loss: 2.65798, time : 12.602105379104614 lr : 0.9702989999999999\n",
      "epoch : 0 [1852/21279] Train loss: 2.07030,Valid loss: 2.54484, time : 14.49658489227295 lr : 0.9702989999999999\n",
      "epoch : 0 [1853/21279] Train loss: 2.01384,Valid loss: 2.66402, time : 12.278164386749268 lr : 0.9702989999999999\n",
      "epoch : 0 [1854/21279] Train loss: 2.04901,Valid loss: 2.50275, time : 12.512412071228027 lr : 0.9702989999999999\n",
      "epoch : 0 [1855/21279] Train loss: 2.05988,Valid loss: 2.52397, time : 12.05812406539917 lr : 0.9702989999999999\n",
      "epoch : 0 [1856/21279] Train loss: 2.02817,Valid loss: 2.50109, time : 12.651070356369019 lr : 0.9702989999999999\n",
      "epoch : 0 [1857/21279] Train loss: 2.01339,Valid loss: 2.53707, time : 12.886832475662231 lr : 0.9702989999999999\n",
      "epoch : 0 [1858/21279] Train loss: 2.00331,Valid loss: 2.50509, time : 12.51524567604065 lr : 0.9702989999999999\n",
      "epoch : 0 [1859/21279] Train loss: 1.97983,Valid loss: 2.54464, time : 12.86261248588562 lr : 0.9702989999999999\n",
      "epoch : 0 [1860/21279] Train loss: 1.98975,Valid loss: 2.53811, time : 12.58499550819397 lr : 0.9702989999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [1861/21279] Train loss: 2.00551,Valid loss: 2.57861, time : 12.112256050109863 lr : 0.9702989999999999\n",
      "epoch : 0 [1862/21279] Train loss: 1.97808,Valid loss: 2.60533, time : 12.238425731658936 lr : 0.9702989999999999\n",
      "epoch : 0 [1863/21279] Train loss: 1.98505,Valid loss: 2.61417, time : 12.211870908737183 lr : 0.9702989999999999\n",
      "epoch : 0 [1864/21279] Train loss: 1.97466,Valid loss: 2.49281, time : 14.306227207183838 lr : 0.9702989999999999\n",
      "epoch : 0 [1865/21279] Train loss: 2.02311,Valid loss: 2.60688, time : 12.729799270629883 lr : 0.9702989999999999\n",
      "epoch : 0 [1866/21279] Train loss: 2.03491,Valid loss: 4.00958, time : 12.584155559539795 lr : 0.9702989999999999\n",
      "epoch : 0 [1867/21279] Train loss: 2.33011,Valid loss: 2.92266, time : 12.662853956222534 lr : 0.9702989999999999\n",
      "epoch : 0 [1868/21279] Train loss: 2.40198,Valid loss: 2.91692, time : 12.58060908317566 lr : 0.9702989999999999\n",
      "epoch : 0 [1869/21279] Train loss: 2.06080,Valid loss: 3.13784, time : 12.65628457069397 lr : 0.9702989999999999\n",
      "epoch : 0 [1870/21279] Train loss: 2.04327,Valid loss: 2.58221, time : 12.370356321334839 lr : 0.9702989999999999\n",
      "epoch : 0 [1871/21279] Train loss: 1.98818,Valid loss: 3.06970, time : 12.038020610809326 lr : 0.9702989999999999\n",
      "epoch : 0 [1872/21279] Train loss: 1.97757,Valid loss: 2.49444, time : 12.158772706985474 lr : 0.9702989999999999\n",
      "epoch : 0 [1873/21279] Train loss: 1.95097,Valid loss: 2.50362, time : 12.26374340057373 lr : 0.9702989999999999\n",
      "epoch : 0 [1874/21279] Train loss: 1.93372,Valid loss: 2.67276, time : 12.2727952003479 lr : 0.9702989999999999\n",
      "epoch : 0 [1875/21279] Train loss: 1.96564,Valid loss: 2.47018, time : 12.116310358047485 lr : 0.9702989999999999\n",
      "epoch : 0 [1876/21279] Train loss: 1.96495,Valid loss: 2.57603, time : 12.42430329322815 lr : 0.9702989999999999\n",
      "epoch : 0 [1877/21279] Train loss: 1.99219,Valid loss: 2.42781, time : 12.167632818222046 lr : 0.9702989999999999\n",
      "epoch : 0 [1878/21279] Train loss: 1.99201,Valid loss: 2.64731, time : 14.329593420028687 lr : 0.9702989999999999\n",
      "epoch : 0 [1879/21279] Train loss: 1.99666,Valid loss: 2.48370, time : 12.004499912261963 lr : 0.9702989999999999\n",
      "epoch : 0 [1880/21279] Train loss: 2.04552,Valid loss: 3.01821, time : 12.269824981689453 lr : 0.9702989999999999\n",
      "epoch : 0 [1881/21279] Train loss: 2.03572,Valid loss: 2.66818, time : 12.266427040100098 lr : 0.9702989999999999\n",
      "epoch : 0 [1882/21279] Train loss: 2.04690,Valid loss: 2.96474, time : 12.207696914672852 lr : 0.9702989999999999\n",
      "epoch : 0 [1883/21279] Train loss: 2.17629,Valid loss: 3.37136, time : 12.43066930770874 lr : 0.9702989999999999\n",
      "epoch : 0 [1884/21279] Train loss: 2.14693,Valid loss: 2.65569, time : 12.728663682937622 lr : 0.9702989999999999\n",
      "epoch : 0 [1885/21279] Train loss: 2.36351,Valid loss: 3.37306, time : 12.418313980102539 lr : 0.9702989999999999\n",
      "epoch : 0 [1886/21279] Train loss: 2.06970,Valid loss: 2.50349, time : 12.273412704467773 lr : 0.9702989999999999\n",
      "epoch : 0 [1887/21279] Train loss: 2.08291,Valid loss: 2.69633, time : 12.519180059432983 lr : 0.9702989999999999\n",
      "epoch : 0 [1888/21279] Train loss: 1.96820,Valid loss: 2.52673, time : 11.985816955566406 lr : 0.9702989999999999\n",
      "epoch : 0 [1889/21279] Train loss: 1.95262,Valid loss: 2.52776, time : 12.670939445495605 lr : 0.9702989999999999\n",
      "epoch : 0 [1890/21279] Train loss: 1.96675,Valid loss: 2.44322, time : 13.91145372390747 lr : 0.9702989999999999\n",
      "epoch : 0 [1891/21279] Train loss: 1.97457,Valid loss: 2.49631, time : 12.520737409591675 lr : 0.9702989999999999\n",
      "epoch : 0 [1892/21279] Train loss: 1.96300,Valid loss: 2.45545, time : 12.28568720817566 lr : 0.9702989999999999\n",
      "epoch : 0 [1893/21279] Train loss: 1.93155,Valid loss: 2.45070, time : 12.753116846084595 lr : 0.9702989999999999\n",
      "epoch : 0 [1894/21279] Train loss: 1.91824,Valid loss: 2.27140, time : 12.50747537612915 lr : 0.9702989999999999\n",
      "epoch : 0 [1895/21279] Train loss: 1.91522,Valid loss: 2.35583, time : 12.397241592407227 lr : 0.9702989999999999\n",
      "epoch : 0 [1896/21279] Train loss: 1.90110,Valid loss: 2.37992, time : 12.551457166671753 lr : 0.9702989999999999\n",
      "epoch : 0 [1897/21279] Train loss: 1.91074,Valid loss: 2.22622, time : 13.050604581832886 lr : 0.9702989999999999\n",
      "epoch : 0 [1898/21279] Train loss: 1.91748,Valid loss: 2.40489, time : 13.056684970855713 lr : 0.9702989999999999\n",
      "epoch : 0 [1899/21279] Train loss: 1.91517,Valid loss: 2.14147, time : 12.702999830245972 lr : 0.9702989999999999\n",
      "epoch : 0 [1900/21279] Train loss: 1.87844,Valid loss: 2.25535, time : 12.955548763275146 lr : 0.9702989999999999\n",
      "epoch : 0 [1901/21279] Train loss: 2.04262,Valid loss: 6.04293, time : 12.758180618286133 lr : 0.9702989999999999\n",
      "epoch : 0 [1902/21279] Train loss: 2.61190,Valid loss: 3.50617, time : 12.251829862594604 lr : 0.9702989999999999\n",
      "epoch : 0 [1903/21279] Train loss: 1.98037,Valid loss: 2.89543, time : 12.287903547286987 lr : 0.9702989999999999\n",
      "epoch : 0 [1904/21279] Train loss: 2.09445,Valid loss: 3.25572, time : 12.229154348373413 lr : 0.9702989999999999\n",
      "epoch : 0 [1905/21279] Train loss: 1.98741,Valid loss: 3.06785, time : 12.304642915725708 lr : 0.9702989999999999\n",
      "epoch : 0 [1906/21279] Train loss: 1.87080,Valid loss: 2.43588, time : 15.151662111282349 lr : 0.9702989999999999\n",
      "epoch : 0 [1907/21279] Train loss: 1.86433,Valid loss: 2.35463, time : 12.3739652633667 lr : 0.9702989999999999\n",
      "epoch : 0 [1908/21279] Train loss: 1.83574,Valid loss: 2.24115, time : 13.038547992706299 lr : 0.9702989999999999\n",
      "epoch : 0 [1909/21279] Train loss: 1.86055,Valid loss: 2.23580, time : 11.868942022323608 lr : 0.9702989999999999\n",
      "epoch : 0 [1910/21279] Train loss: 1.82566,Valid loss: 2.18908, time : 12.199047565460205 lr : 0.9702989999999999\n",
      "epoch : 0 [1911/21279] Train loss: 1.85671,Valid loss: 2.35048, time : 11.80743408203125 lr : 0.9702989999999999\n",
      "epoch : 0 [1912/21279] Train loss: 1.88644,Valid loss: 2.32897, time : 12.074026584625244 lr : 0.9702989999999999\n",
      "epoch : 0 [1913/21279] Train loss: 1.92860,Valid loss: 2.45228, time : 11.962220191955566 lr : 0.9702989999999999\n",
      "epoch : 0 [1914/21279] Train loss: 1.95636,Valid loss: 2.79138, time : 12.268964529037476 lr : 0.9702989999999999\n",
      "epoch : 0 [1915/21279] Train loss: 2.10053,Valid loss: 3.60425, time : 11.76950478553772 lr : 0.9702989999999999\n",
      "epoch : 0 [1916/21279] Train loss: 2.43617,Valid loss: 2.70787, time : 12.108657121658325 lr : 0.9702989999999999\n",
      "epoch : 0 [1917/21279] Train loss: 2.18222,Valid loss: 2.88183, time : 11.967662572860718 lr : 0.9702989999999999\n",
      "epoch : 0 [1918/21279] Train loss: 2.26114,Valid loss: 2.60478, time : 14.368965148925781 lr : 0.9702989999999999\n",
      "epoch : 0 [1919/21279] Train loss: 2.05358,Valid loss: 2.51971, time : 12.559612512588501 lr : 0.9702989999999999\n",
      "epoch : 0 [1920/21279] Train loss: 1.91673,Valid loss: 2.41009, time : 12.589855194091797 lr : 0.9702989999999999\n",
      "epoch : 0 [1921/21279] Train loss: 1.91370,Valid loss: 2.35050, time : 12.382726669311523 lr : 0.9702989999999999\n",
      "epoch : 0 [1922/21279] Train loss: 1.87416,Valid loss: 2.48097, time : 12.280537366867065 lr : 0.9702989999999999\n",
      "epoch : 0 [1923/21279] Train loss: 1.89042,Valid loss: 2.33444, time : 12.462749242782593 lr : 0.9702989999999999\n",
      "epoch : 0 [1924/21279] Train loss: 1.89104,Valid loss: 2.40590, time : 12.780792713165283 lr : 0.9702989999999999\n",
      "epoch : 0 [1925/21279] Train loss: 1.89739,Valid loss: 2.35608, time : 12.500913143157959 lr : 0.9702989999999999\n",
      "epoch : 0 [1926/21279] Train loss: 1.86417,Valid loss: 2.94351, time : 12.560627460479736 lr : 0.9702989999999999\n",
      "epoch : 0 [1927/21279] Train loss: 2.28224,Valid loss: 6.81427, time : 11.846973180770874 lr : 0.9702989999999999\n",
      "epoch : 0 [1928/21279] Train loss: 3.01152,Valid loss: 2.85678, time : 12.392233848571777 lr : 0.9702989999999999\n",
      "epoch : 0 [1929/21279] Train loss: 1.94104,Valid loss: 2.52289, time : 12.447276592254639 lr : 0.9702989999999999\n",
      "epoch : 0 [1930/21279] Train loss: 1.91297,Valid loss: 2.44251, time : 12.629440069198608 lr : 0.9702989999999999\n",
      "epoch : 0 [1931/21279] Train loss: 1.93389,Valid loss: 2.53712, time : 12.898438215255737 lr : 0.9702989999999999\n",
      "epoch : 0 [1932/21279] Train loss: 1.95326,Valid loss: 3.58161, time : 12.780774116516113 lr : 0.9702989999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [1933/21279] Train loss: 1.93214,Valid loss: 3.84265, time : 13.105113506317139 lr : 0.9702989999999999\n",
      "epoch : 0 [1934/21279] Train loss: 1.88216,Valid loss: 3.24275, time : 14.471104860305786 lr : 0.9702989999999999\n",
      "epoch : 0 [1935/21279] Train loss: 1.86723,Valid loss: 2.31087, time : 12.977384328842163 lr : 0.9702989999999999\n",
      "epoch : 0 [1936/21279] Train loss: 1.85113,Valid loss: 2.40141, time : 12.87059998512268 lr : 0.9702989999999999\n",
      "epoch : 0 [1937/21279] Train loss: 1.84744,Valid loss: 2.23017, time : 12.593381881713867 lr : 0.9702989999999999\n",
      "epoch : 0 [1938/21279] Train loss: 1.83888,Valid loss: 2.49041, time : 12.847044467926025 lr : 0.9702989999999999\n",
      "epoch : 0 [1939/21279] Train loss: 1.86429,Valid loss: 3.21522, time : 13.237163543701172 lr : 0.9702989999999999\n",
      "epoch : 0 [1940/21279] Train loss: 1.89669,Valid loss: 3.25679, time : 13.003263235092163 lr : 0.9702989999999999\n",
      "epoch : 0 [1941/21279] Train loss: 1.98794,Valid loss: 3.15183, time : 12.969293117523193 lr : 0.9702989999999999\n",
      "epoch : 0 [1942/21279] Train loss: 1.95507,Valid loss: 3.04033, time : 12.814603328704834 lr : 0.9702989999999999\n",
      "epoch : 0 [1943/21279] Train loss: 1.92792,Valid loss: 2.49192, time : 12.492554664611816 lr : 0.9702989999999999\n",
      "epoch : 0 [1944/21279] Train loss: 1.92740,Valid loss: 2.84972, time : 12.520437240600586 lr : 0.9702989999999999\n",
      "epoch : 0 [1945/21279] Train loss: 1.91237,Valid loss: 2.52301, time : 12.63618516921997 lr : 0.9702989999999999\n",
      "epoch : 0 [1946/21279] Train loss: 1.84980,Valid loss: 2.27344, time : 13.142322301864624 lr : 0.9702989999999999\n",
      "epoch : 0 [1947/21279] Train loss: 1.83840,Valid loss: 2.37538, time : 14.643595933914185 lr : 0.9702989999999999\n",
      "epoch : 0 [1948/21279] Train loss: 1.84221,Valid loss: 2.37425, time : 12.767536878585815 lr : 0.9702989999999999\n",
      "epoch : 0 [1949/21279] Train loss: 1.83129,Valid loss: 2.31415, time : 12.82727861404419 lr : 0.9702989999999999\n",
      "epoch : 0 [1950/21279] Train loss: 1.78891,Valid loss: 2.14799, time : 12.420894622802734 lr : 0.9702989999999999\n",
      "epoch : 0 [1951/21279] Train loss: 1.79662,Valid loss: 2.33003, time : 12.662886142730713 lr : 0.9702989999999999\n",
      "epoch : 0 [1952/21279] Train loss: 1.79502,Valid loss: 2.23457, time : 12.796152591705322 lr : 0.9702989999999999\n",
      "epoch : 0 [1953/21279] Train loss: 1.79147,Valid loss: 2.62191, time : 12.629912614822388 lr : 0.9702989999999999\n",
      "epoch : 0 [1954/21279] Train loss: 1.81478,Valid loss: 3.68422, time : 12.781448125839233 lr : 0.9702989999999999\n",
      "epoch : 0 [1955/21279] Train loss: 2.12048,Valid loss: 2.12684, time : 12.841596126556396 lr : 0.9702989999999999\n",
      "epoch : 0 [1956/21279] Train loss: 1.73980,Valid loss: 2.40518, time : 12.98754596710205 lr : 0.9702989999999999\n",
      "epoch : 0 [1957/21279] Train loss: 1.73979,Valid loss: 2.39855, time : 12.52457308769226 lr : 0.9702989999999999\n",
      "epoch : 0 [1958/21279] Train loss: 1.74425,Valid loss: 2.25970, time : 13.052538633346558 lr : 0.9702989999999999\n",
      "epoch : 0 [1959/21279] Train loss: 1.75092,Valid loss: 2.60822, time : 12.725265979766846 lr : 0.9702989999999999\n",
      "epoch : 0 [1960/21279] Train loss: 1.77400,Valid loss: 2.32429, time : 12.947608470916748 lr : 0.9702989999999999\n",
      "epoch : 0 [1961/21279] Train loss: 1.77847,Valid loss: 2.42108, time : 12.550204992294312 lr : 0.9702989999999999\n",
      "epoch : 0 [1962/21279] Train loss: 1.78359,Valid loss: 2.28441, time : 14.146442651748657 lr : 0.9702989999999999\n",
      "epoch : 0 [1963/21279] Train loss: 1.78929,Valid loss: 2.51301, time : 12.340337991714478 lr : 0.9702989999999999\n",
      "epoch : 0 [1964/21279] Train loss: 1.82334,Valid loss: 2.19351, time : 12.37276029586792 lr : 0.9702989999999999\n",
      "epoch : 0 [1965/21279] Train loss: 1.80617,Valid loss: 2.62820, time : 11.949121713638306 lr : 0.9702989999999999\n",
      "epoch : 0 [1966/21279] Train loss: 1.91231,Valid loss: 3.26565, time : 12.01894211769104 lr : 0.9702989999999999\n",
      "epoch : 0 [1967/21279] Train loss: 2.15247,Valid loss: 5.69144, time : 12.261871814727783 lr : 0.9702989999999999\n",
      "epoch : 0 [1968/21279] Train loss: 1.92965,Valid loss: 2.12869, time : 12.14526081085205 lr : 0.9702989999999999\n",
      "epoch : 0 [1969/21279] Train loss: 1.81720,Valid loss: 2.23123, time : 12.172350406646729 lr : 0.9702989999999999\n",
      "epoch : 0 [1970/21279] Train loss: 1.73206,Valid loss: 2.20801, time : 12.562815189361572 lr : 0.9702989999999999\n",
      "epoch : 0 [1971/21279] Train loss: 1.73213,Valid loss: 2.54409, time : 12.008568286895752 lr : 0.9702989999999999\n",
      "epoch : 0 [1972/21279] Train loss: 1.70704,Valid loss: 2.60453, time : 12.445502758026123 lr : 0.9702989999999999\n",
      "epoch : 0 [1973/21279] Train loss: 1.77095,Valid loss: 2.51055, time : 12.379554510116577 lr : 0.9702989999999999\n",
      "epoch : 0 [1974/21279] Train loss: 1.78440,Valid loss: 2.84660, time : 14.127755880355835 lr : 0.9702989999999999\n",
      "epoch : 0 [1975/21279] Train loss: 1.97900,Valid loss: 3.45612, time : 11.764464139938354 lr : 0.9702989999999999\n",
      "epoch : 0 [1976/21279] Train loss: 2.27043,Valid loss: 3.02845, time : 12.107617139816284 lr : 0.9702989999999999\n",
      "epoch : 0 [1977/21279] Train loss: 2.30579,Valid loss: 2.72143, time : 12.081550121307373 lr : 0.9702989999999999\n",
      "epoch : 0 [1978/21279] Train loss: 2.19555,Valid loss: 3.10070, time : 12.537914037704468 lr : 0.9702989999999999\n",
      "epoch : 0 [1979/21279] Train loss: 2.18576,Valid loss: 3.13242, time : 12.568007469177246 lr : 0.9702989999999999\n",
      "epoch : 0 [1980/21279] Train loss: 2.05558,Valid loss: 3.21433, time : 12.757808923721313 lr : 0.9702989999999999\n",
      "epoch : 0 [1981/21279] Train loss: 2.00269,Valid loss: 2.98666, time : 12.715286016464233 lr : 0.9702989999999999\n",
      "epoch : 0 [1982/21279] Train loss: 1.85435,Valid loss: 2.66076, time : 13.095741510391235 lr : 0.9702989999999999\n",
      "epoch : 0 [1983/21279] Train loss: 1.82229,Valid loss: 2.13987, time : 12.781198263168335 lr : 0.9702989999999999\n",
      "epoch : 0 [1984/21279] Train loss: 1.76016,Valid loss: 2.40088, time : 13.015976190567017 lr : 0.9702989999999999\n",
      "epoch : 0 [1985/21279] Train loss: 1.76183,Valid loss: 2.19050, time : 13.1029794216156 lr : 0.9702989999999999\n",
      "epoch : 0 [1986/21279] Train loss: 1.69489,Valid loss: 2.18175, time : 12.858710289001465 lr : 0.9702989999999999\n",
      "epoch : 0 [1987/21279] Train loss: 1.74447,Valid loss: 2.15074, time : 12.354776859283447 lr : 0.9702989999999999\n",
      "epoch : 0 [1988/21279] Train loss: 1.74713,Valid loss: 2.41807, time : 14.31693172454834 lr : 0.9702989999999999\n",
      "epoch : 0 [1989/21279] Train loss: 1.73877,Valid loss: 2.15423, time : 12.323115587234497 lr : 0.9702989999999999\n",
      "epoch : 0 [1990/21279] Train loss: 1.70477,Valid loss: 2.31150, time : 12.555817365646362 lr : 0.9702989999999999\n",
      "epoch : 0 [1991/21279] Train loss: 1.72984,Valid loss: 2.11112, time : 12.72217607498169 lr : 0.9702989999999999\n",
      "epoch : 0 [1992/21279] Train loss: 1.70199,Valid loss: 2.34853, time : 12.283536911010742 lr : 0.9702989999999999\n",
      "epoch : 0 [1993/21279] Train loss: 1.72448,Valid loss: 2.21341, time : 12.524802684783936 lr : 0.9702989999999999\n",
      "epoch : 0 [1994/21279] Train loss: 1.75232,Valid loss: 3.32379, time : 12.451429605484009 lr : 0.9702989999999999\n",
      "epoch : 0 [1995/21279] Train loss: 1.76408,Valid loss: 2.40063, time : 12.361782789230347 lr : 0.9702989999999999\n",
      "epoch : 0 [1996/21279] Train loss: 1.78251,Valid loss: 4.14714, time : 12.506522178649902 lr : 0.9702989999999999\n",
      "epoch : 0 [1997/21279] Train loss: 1.87951,Valid loss: 2.98002, time : 12.371897220611572 lr : 0.9702989999999999\n",
      "epoch : 0 [1998/21279] Train loss: 2.33705,Valid loss: 3.30682, time : 12.274867534637451 lr : 0.9702989999999999\n",
      "epoch : 0 [1999/21279] Train loss: 2.29470,Valid loss: 4.07919, time : 12.421440839767456 lr : 0.96059601\n",
      "epoch : 0 [2000/21279] Train loss: 2.42264,Valid loss: 3.24914, time : 14.367855310440063 lr : 0.96059601\n",
      "epoch : 0 [2001/21279] Train loss: 1.97685,Valid loss: 3.09351, time : 12.398358821868896 lr : 0.96059601\n",
      "epoch : 0 [2002/21279] Train loss: 1.89264,Valid loss: 2.84069, time : 12.811959505081177 lr : 0.96059601\n",
      "epoch : 0 [2003/21279] Train loss: 1.77745,Valid loss: 2.47558, time : 12.282525539398193 lr : 0.96059601\n",
      "epoch : 0 [2004/21279] Train loss: 1.72668,Valid loss: 2.36288, time : 12.611320495605469 lr : 0.96059601\n",
      "epoch : 0 [2005/21279] Train loss: 1.67572,Valid loss: 2.27597, time : 12.332392454147339 lr : 0.96059601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2006/21279] Train loss: 1.71563,Valid loss: 2.43920, time : 12.529792547225952 lr : 0.96059601\n",
      "epoch : 0 [2007/21279] Train loss: 1.69849,Valid loss: 2.20748, time : 12.322857141494751 lr : 0.96059601\n",
      "epoch : 0 [2008/21279] Train loss: 1.72649,Valid loss: 2.48922, time : 12.40959620475769 lr : 0.96059601\n",
      "epoch : 0 [2009/21279] Train loss: 1.70551,Valid loss: 2.28570, time : 12.87293553352356 lr : 0.96059601\n",
      "epoch : 0 [2010/21279] Train loss: 1.72271,Valid loss: 2.45901, time : 12.220920324325562 lr : 0.96059601\n",
      "epoch : 0 [2011/21279] Train loss: 1.68002,Valid loss: 2.10004, time : 12.498003005981445 lr : 0.96059601\n",
      "epoch : 0 [2012/21279] Train loss: 1.66256,Valid loss: 2.28522, time : 12.660335779190063 lr : 0.96059601\n",
      "epoch : 0 [2013/21279] Train loss: 1.61954,Valid loss: 2.04198, time : 12.746720790863037 lr : 0.96059601\n",
      "epoch : 0 [2014/21279] Train loss: 1.62188,Valid loss: 2.28402, time : 13.092591285705566 lr : 0.96059601\n",
      "epoch : 0 [2015/21279] Train loss: 1.64995,Valid loss: 2.27570, time : 12.619178295135498 lr : 0.96059601\n",
      "epoch : 0 [2016/21279] Train loss: 1.66257,Valid loss: 2.21712, time : 14.857314109802246 lr : 0.96059601\n",
      "epoch : 0 [2017/21279] Train loss: 1.65572,Valid loss: 2.16961, time : 13.087404727935791 lr : 0.96059601\n",
      "epoch : 0 [2018/21279] Train loss: 1.71002,Valid loss: 2.21559, time : 12.03670334815979 lr : 0.96059601\n",
      "epoch : 0 [2019/21279] Train loss: 1.71900,Valid loss: 2.49120, time : 12.657852172851562 lr : 0.96059601\n",
      "epoch : 0 [2020/21279] Train loss: 1.77838,Valid loss: 2.16193, time : 12.763009548187256 lr : 0.96059601\n",
      "epoch : 0 [2021/21279] Train loss: 1.70791,Valid loss: 2.10177, time : 12.233381032943726 lr : 0.96059601\n",
      "epoch : 0 [2022/21279] Train loss: 1.69506,Valid loss: 2.16049, time : 12.205039739608765 lr : 0.96059601\n",
      "epoch : 0 [2023/21279] Train loss: 1.65612,Valid loss: 2.23099, time : 12.463121175765991 lr : 0.96059601\n",
      "epoch : 0 [2024/21279] Train loss: 1.66784,Valid loss: 2.19980, time : 12.323609590530396 lr : 0.96059601\n",
      "epoch : 0 [2025/21279] Train loss: 1.68130,Valid loss: 2.05261, time : 11.804519653320312 lr : 0.96059601\n",
      "epoch : 0 [2026/21279] Train loss: 1.65031,Valid loss: 2.08338, time : 12.192403078079224 lr : 0.96059601\n",
      "epoch : 0 [2027/21279] Train loss: 1.65998,Valid loss: 2.17754, time : 12.072268962860107 lr : 0.96059601\n",
      "epoch : 0 [2028/21279] Train loss: 1.61456,Valid loss: 2.12234, time : 12.216182470321655 lr : 0.96059601\n",
      "epoch : 0 [2029/21279] Train loss: 1.62736,Valid loss: 2.06834, time : 11.8231360912323 lr : 0.96059601\n",
      "epoch : 0 [2030/21279] Train loss: 1.60358,Valid loss: 2.00000, time : 12.438916444778442 lr : 0.96059601\n",
      "epoch : 0 [2031/21279] Train loss: 1.61317,Valid loss: 2.06238, time : 12.034867525100708 lr : 0.96059601\n",
      "epoch : 0 [2032/21279] Train loss: 1.61837,Valid loss: 2.18884, time : 14.854613542556763 lr : 0.96059601\n",
      "epoch : 0 [2033/21279] Train loss: 1.64087,Valid loss: 2.18549, time : 12.430391073226929 lr : 0.96059601\n",
      "epoch : 0 [2034/21279] Train loss: 1.65684,Valid loss: 2.40267, time : 12.38293194770813 lr : 0.96059601\n",
      "epoch : 0 [2035/21279] Train loss: 1.70265,Valid loss: 2.24266, time : 12.754438638687134 lr : 0.96059601\n",
      "epoch : 0 [2036/21279] Train loss: 1.82343,Valid loss: 3.24458, time : 12.34507417678833 lr : 0.96059601\n",
      "epoch : 0 [2037/21279] Train loss: 2.13467,Valid loss: 2.56575, time : 12.763513565063477 lr : 0.96059601\n",
      "epoch : 0 [2038/21279] Train loss: 1.89983,Valid loss: 2.80209, time : 11.754646062850952 lr : 0.96059601\n",
      "epoch : 0 [2039/21279] Train loss: 2.01591,Valid loss: 2.75084, time : 12.323976516723633 lr : 0.96059601\n",
      "epoch : 0 [2040/21279] Train loss: 1.93822,Valid loss: 2.82066, time : 12.071176290512085 lr : 0.96059601\n",
      "epoch : 0 [2041/21279] Train loss: 2.03154,Valid loss: 3.14237, time : 12.146788597106934 lr : 0.96059601\n",
      "epoch : 0 [2042/21279] Train loss: 2.04265,Valid loss: 5.40971, time : 12.028159379959106 lr : 0.96059601\n",
      "epoch : 0 [2043/21279] Train loss: 2.19768,Valid loss: 2.59078, time : 12.358692169189453 lr : 0.96059601\n",
      "epoch : 0 [2044/21279] Train loss: 1.76449,Valid loss: 2.96349, time : 14.03117322921753 lr : 0.96059601\n",
      "epoch : 0 [2045/21279] Train loss: 1.72089,Valid loss: 2.32307, time : 12.908474206924438 lr : 0.96059601\n",
      "epoch : 0 [2046/21279] Train loss: 1.64698,Valid loss: 2.15834, time : 12.756043195724487 lr : 0.96059601\n",
      "epoch : 0 [2047/21279] Train loss: 1.67547,Valid loss: 2.14864, time : 12.866201162338257 lr : 0.96059601\n",
      "epoch : 0 [2048/21279] Train loss: 1.67620,Valid loss: 2.52126, time : 12.633763074874878 lr : 0.96059601\n",
      "epoch : 0 [2049/21279] Train loss: 1.65200,Valid loss: 2.15211, time : 12.878240823745728 lr : 0.96059601\n",
      "epoch : 0 [2050/21279] Train loss: 1.61152,Valid loss: 2.01180, time : 12.564005136489868 lr : 0.96059601\n",
      "epoch : 0 [2051/21279] Train loss: 1.60823,Valid loss: 2.25337, time : 12.812601089477539 lr : 0.96059601\n",
      "epoch : 0 [2052/21279] Train loss: 1.57658,Valid loss: 2.16685, time : 12.601311445236206 lr : 0.96059601\n",
      "epoch : 0 [2053/21279] Train loss: 1.61341,Valid loss: 2.27609, time : 12.690162420272827 lr : 0.96059601\n",
      "epoch : 0 [2054/21279] Train loss: 1.60807,Valid loss: 2.04538, time : 12.603081226348877 lr : 0.96059601\n",
      "epoch : 0 [2055/21279] Train loss: 1.64793,Valid loss: 2.19189, time : 12.776121854782104 lr : 0.96059601\n",
      "epoch : 0 [2056/21279] Train loss: 1.63589,Valid loss: 2.16623, time : 13.01613163948059 lr : 0.96059601\n",
      "epoch : 0 [2057/21279] Train loss: 1.63599,Valid loss: 2.20671, time : 12.691599369049072 lr : 0.96059601\n",
      "epoch : 0 [2058/21279] Train loss: 1.59925,Valid loss: 1.96080, time : 18.256956338882446 lr : 0.96059601\n",
      "epoch : 0 [2059/21279] Train loss: 1.59788,Valid loss: 2.12871, time : 13.085758686065674 lr : 0.96059601\n",
      "epoch : 0 [2060/21279] Train loss: 1.57744,Valid loss: 1.90791, time : 13.093283653259277 lr : 0.96059601\n",
      "epoch : 0 [2061/21279] Train loss: 1.58652,Valid loss: 2.17872, time : 12.842417478561401 lr : 0.96059601\n",
      "epoch : 0 [2062/21279] Train loss: 1.61443,Valid loss: 2.15332, time : 12.911143064498901 lr : 0.96059601\n",
      "epoch : 0 [2063/21279] Train loss: 1.58306,Valid loss: 1.95120, time : 13.045516967773438 lr : 0.96059601\n",
      "epoch : 0 [2064/21279] Train loss: 1.59478,Valid loss: 2.00278, time : 12.76748251914978 lr : 0.96059601\n",
      "epoch : 0 [2065/21279] Train loss: 1.54033,Valid loss: 1.90093, time : 12.90268063545227 lr : 0.96059601\n",
      "epoch : 0 [2066/21279] Train loss: 1.55427,Valid loss: 1.90438, time : 12.604313850402832 lr : 0.96059601\n",
      "epoch : 0 [2067/21279] Train loss: 1.50908,Valid loss: 1.99550, time : 12.645702123641968 lr : 0.96059601\n",
      "epoch : 0 [2068/21279] Train loss: 1.52075,Valid loss: 1.94099, time : 12.586477041244507 lr : 0.96059601\n",
      "epoch : 0 [2069/21279] Train loss: 1.54092,Valid loss: 2.12080, time : 12.750484228134155 lr : 0.96059601\n",
      "epoch : 0 [2070/21279] Train loss: 1.56789,Valid loss: 2.12382, time : 16.71074938774109 lr : 0.96059601\n",
      "epoch : 0 [2071/21279] Train loss: 1.60927,Valid loss: 2.39497, time : 12.403144836425781 lr : 0.96059601\n",
      "epoch : 0 [2072/21279] Train loss: 1.58257,Valid loss: 2.46438, time : 12.584946632385254 lr : 0.96059601\n",
      "epoch : 0 [2073/21279] Train loss: 1.76199,Valid loss: 5.29887, time : 12.320792436599731 lr : 0.96059601\n",
      "epoch : 0 [2074/21279] Train loss: 1.74307,Valid loss: 5.31605, time : 12.724767923355103 lr : 0.96059601\n",
      "epoch : 0 [2075/21279] Train loss: 1.74728,Valid loss: 2.72794, time : 12.558534860610962 lr : 0.96059601\n",
      "epoch : 0 [2076/21279] Train loss: 1.92315,Valid loss: 4.71521, time : 12.678602933883667 lr : 0.96059601\n",
      "epoch : 0 [2077/21279] Train loss: 2.06105,Valid loss: 3.33578, time : 12.686763525009155 lr : 0.96059601\n",
      "epoch : 0 [2078/21279] Train loss: 1.84438,Valid loss: 3.11024, time : 12.813907623291016 lr : 0.96059601\n",
      "epoch : 0 [2079/21279] Train loss: 1.82145,Valid loss: 3.19203, time : 12.689708948135376 lr : 0.96059601\n",
      "epoch : 0 [2080/21279] Train loss: 2.05312,Valid loss: 3.95003, time : 12.397278785705566 lr : 0.96059601\n",
      "epoch : 0 [2081/21279] Train loss: 1.83675,Valid loss: 2.62765, time : 12.499536275863647 lr : 0.96059601\n",
      "epoch : 0 [2082/21279] Train loss: 1.78998,Valid loss: 3.72175, time : 12.594753742218018 lr : 0.96059601\n",
      "epoch : 0 [2083/21279] Train loss: 1.76065,Valid loss: 2.26404, time : 12.548107862472534 lr : 0.96059601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2084/21279] Train loss: 1.69786,Valid loss: 2.21364, time : 12.644892930984497 lr : 0.96059601\n",
      "epoch : 0 [2085/21279] Train loss: 1.56100,Valid loss: 2.04639, time : 12.648136854171753 lr : 0.96059601\n",
      "epoch : 0 [2086/21279] Train loss: 1.55930,Valid loss: 2.07083, time : 13.922905206680298 lr : 0.96059601\n",
      "epoch : 0 [2087/21279] Train loss: 1.54697,Valid loss: 1.98478, time : 11.82938814163208 lr : 0.96059601\n",
      "epoch : 0 [2088/21279] Train loss: 1.53444,Valid loss: 1.97581, time : 12.200911521911621 lr : 0.96059601\n",
      "epoch : 0 [2089/21279] Train loss: 1.53693,Valid loss: 1.95460, time : 12.52385663986206 lr : 0.96059601\n",
      "epoch : 0 [2090/21279] Train loss: 1.51448,Valid loss: 1.93854, time : 11.866459846496582 lr : 0.96059601\n",
      "epoch : 0 [2091/21279] Train loss: 1.49774,Valid loss: 1.97541, time : 12.432287693023682 lr : 0.96059601\n",
      "epoch : 0 [2092/21279] Train loss: 1.48390,Valid loss: 2.06499, time : 12.112679243087769 lr : 0.96059601\n",
      "epoch : 0 [2093/21279] Train loss: 1.48214,Valid loss: 1.96516, time : 12.297544956207275 lr : 0.96059601\n",
      "epoch : 0 [2094/21279] Train loss: 1.50181,Valid loss: 1.99039, time : 12.64168667793274 lr : 0.96059601\n",
      "epoch : 0 [2095/21279] Train loss: 1.52876,Valid loss: 2.08102, time : 12.199570417404175 lr : 0.96059601\n",
      "epoch : 0 [2096/21279] Train loss: 1.55680,Valid loss: 2.06188, time : 12.269958972930908 lr : 0.96059601\n",
      "epoch : 0 [2097/21279] Train loss: 1.55396,Valid loss: 2.07182, time : 12.49377703666687 lr : 0.96059601\n",
      "epoch : 0 [2098/21279] Train loss: 1.53162,Valid loss: 2.09996, time : 14.215139627456665 lr : 0.96059601\n",
      "epoch : 0 [2099/21279] Train loss: 1.55908,Valid loss: 1.90887, time : 12.494641542434692 lr : 0.96059601\n",
      "epoch : 0 [2100/21279] Train loss: 1.49393,Valid loss: 1.92962, time : 12.982804775238037 lr : 0.96059601\n",
      "epoch : 0 [2101/21279] Train loss: 1.52643,Valid loss: 1.88694, time : 12.662710189819336 lr : 0.96059601\n",
      "epoch : 0 [2102/21279] Train loss: 1.51307,Valid loss: 1.85685, time : 12.95590877532959 lr : 0.96059601\n",
      "epoch : 0 [2103/21279] Train loss: 1.49852,Valid loss: 1.94636, time : 12.795918703079224 lr : 0.96059601\n",
      "epoch : 0 [2104/21279] Train loss: 1.48701,Valid loss: 1.80247, time : 12.911358833312988 lr : 0.96059601\n",
      "epoch : 0 [2105/21279] Train loss: 1.51019,Valid loss: 1.94043, time : 12.787784099578857 lr : 0.96059601\n",
      "epoch : 0 [2106/21279] Train loss: 1.47081,Valid loss: 1.86688, time : 12.736110925674438 lr : 0.96059601\n",
      "epoch : 0 [2107/21279] Train loss: 1.49354,Valid loss: 2.24862, time : 12.851023435592651 lr : 0.96059601\n",
      "epoch : 0 [2108/21279] Train loss: 1.48508,Valid loss: 2.00139, time : 12.892740249633789 lr : 0.96059601\n",
      "epoch : 0 [2109/21279] Train loss: 1.49923,Valid loss: 1.97208, time : 12.242249488830566 lr : 0.96059601\n",
      "epoch : 0 [2110/21279] Train loss: 1.50664,Valid loss: 2.04218, time : 12.563978433609009 lr : 0.96059601\n",
      "epoch : 0 [2111/21279] Train loss: 1.49444,Valid loss: 2.49130, time : 12.337636232376099 lr : 0.96059601\n",
      "epoch : 0 [2112/21279] Train loss: 1.49221,Valid loss: 2.27383, time : 12.098296403884888 lr : 0.96059601\n",
      "epoch : 0 [2113/21279] Train loss: 1.49668,Valid loss: 2.33960, time : 12.492812633514404 lr : 0.96059601\n",
      "epoch : 0 [2114/21279] Train loss: 1.52333,Valid loss: 2.12593, time : 14.311883211135864 lr : 0.96059601\n",
      "epoch : 0 [2115/21279] Train loss: 1.62313,Valid loss: 3.96528, time : 12.628846883773804 lr : 0.96059601\n",
      "epoch : 0 [2116/21279] Train loss: 2.02403,Valid loss: 2.31707, time : 12.5123872756958 lr : 0.96059601\n",
      "epoch : 0 [2117/21279] Train loss: 1.82402,Valid loss: 2.90502, time : 12.36233139038086 lr : 0.96059601\n",
      "epoch : 0 [2118/21279] Train loss: 1.76839,Valid loss: 2.26909, time : 12.538204193115234 lr : 0.96059601\n",
      "epoch : 0 [2119/21279] Train loss: 1.64164,Valid loss: 2.19280, time : 12.357641458511353 lr : 0.96059601\n",
      "epoch : 0 [2120/21279] Train loss: 1.49822,Valid loss: 1.91802, time : 12.65427851676941 lr : 0.96059601\n",
      "epoch : 0 [2121/21279] Train loss: 1.47187,Valid loss: 1.91466, time : 12.454698085784912 lr : 0.96059601\n",
      "epoch : 0 [2122/21279] Train loss: 1.46618,Valid loss: 1.88493, time : 12.693971395492554 lr : 0.96059601\n",
      "epoch : 0 [2123/21279] Train loss: 1.45763,Valid loss: 1.77089, time : 12.62818193435669 lr : 0.96059601\n",
      "epoch : 0 [2124/21279] Train loss: 1.46482,Valid loss: 1.98277, time : 12.630998849868774 lr : 0.96059601\n",
      "epoch : 0 [2125/21279] Train loss: 1.51185,Valid loss: 1.83121, time : 12.121773958206177 lr : 0.96059601\n",
      "epoch : 0 [2126/21279] Train loss: 1.45870,Valid loss: 1.87260, time : 12.418698072433472 lr : 0.96059601\n",
      "epoch : 0 [2127/21279] Train loss: 1.45085,Valid loss: 1.76831, time : 14.086673021316528 lr : 0.96059601\n",
      "epoch : 0 [2128/21279] Train loss: 1.48143,Valid loss: 1.96134, time : 12.649320125579834 lr : 0.96059601\n",
      "epoch : 0 [2129/21279] Train loss: 1.49995,Valid loss: 1.93483, time : 12.604889869689941 lr : 0.96059601\n",
      "epoch : 0 [2130/21279] Train loss: 1.46406,Valid loss: 1.81476, time : 12.732380390167236 lr : 0.96059601\n",
      "epoch : 0 [2131/21279] Train loss: 1.44501,Valid loss: 2.14648, time : 12.652513265609741 lr : 0.96059601\n",
      "epoch : 0 [2132/21279] Train loss: 1.44491,Valid loss: 1.92153, time : 11.928964376449585 lr : 0.96059601\n",
      "epoch : 0 [2133/21279] Train loss: 1.46936,Valid loss: 2.17475, time : 12.21883773803711 lr : 0.96059601\n",
      "epoch : 0 [2134/21279] Train loss: 1.47065,Valid loss: 1.96231, time : 12.607943296432495 lr : 0.96059601\n",
      "epoch : 0 [2135/21279] Train loss: 1.50758,Valid loss: 2.25245, time : 12.17723536491394 lr : 0.96059601\n",
      "epoch : 0 [2136/21279] Train loss: 1.54494,Valid loss: 2.45545, time : 12.01851224899292 lr : 0.96059601\n",
      "epoch : 0 [2137/21279] Train loss: 1.46785,Valid loss: 2.68442, time : 12.45278787612915 lr : 0.96059601\n",
      "epoch : 0 [2138/21279] Train loss: 1.80213,Valid loss: 2.48323, time : 12.59002685546875 lr : 0.96059601\n",
      "epoch : 0 [2139/21279] Train loss: 1.86844,Valid loss: 2.23555, time : 12.261274099349976 lr : 0.96059601\n",
      "epoch : 0 [2140/21279] Train loss: 1.74718,Valid loss: 2.49263, time : 12.402474641799927 lr : 0.96059601\n",
      "epoch : 0 [2141/21279] Train loss: 1.75979,Valid loss: 2.45701, time : 11.703647375106812 lr : 0.96059601\n",
      "epoch : 0 [2142/21279] Train loss: 1.55873,Valid loss: 2.15778, time : 13.658717632293701 lr : 0.96059601\n",
      "epoch : 0 [2143/21279] Train loss: 1.58339,Valid loss: 2.25931, time : 11.980474710464478 lr : 0.96059601\n",
      "epoch : 0 [2144/21279] Train loss: 1.53415,Valid loss: 2.37704, time : 11.980417490005493 lr : 0.96059601\n",
      "epoch : 0 [2145/21279] Train loss: 1.61822,Valid loss: 2.60879, time : 11.983011722564697 lr : 0.96059601\n",
      "epoch : 0 [2146/21279] Train loss: 1.54920,Valid loss: 2.22706, time : 11.705566644668579 lr : 0.96059601\n",
      "epoch : 0 [2147/21279] Train loss: 1.54157,Valid loss: 2.37098, time : 12.413452386856079 lr : 0.96059601\n",
      "epoch : 0 [2148/21279] Train loss: 1.45511,Valid loss: 2.03192, time : 11.978858709335327 lr : 0.96059601\n",
      "epoch : 0 [2149/21279] Train loss: 1.44689,Valid loss: 1.83805, time : 12.553166389465332 lr : 0.96059601\n",
      "epoch : 0 [2150/21279] Train loss: 1.44057,Valid loss: 1.85961, time : 12.618142127990723 lr : 0.96059601\n",
      "epoch : 0 [2151/21279] Train loss: 1.48764,Valid loss: 1.95383, time : 12.96600604057312 lr : 0.96059601\n",
      "epoch : 0 [2152/21279] Train loss: 1.44847,Valid loss: 1.93848, time : 12.50680661201477 lr : 0.96059601\n",
      "epoch : 0 [2153/21279] Train loss: 1.42815,Valid loss: 1.82863, time : 12.37668228149414 lr : 0.96059601\n",
      "epoch : 0 [2154/21279] Train loss: 1.40804,Valid loss: 1.80708, time : 14.495130777359009 lr : 0.96059601\n",
      "epoch : 0 [2155/21279] Train loss: 1.38684,Valid loss: 1.87086, time : 12.746776819229126 lr : 0.96059601\n",
      "epoch : 0 [2156/21279] Train loss: 1.38811,Valid loss: 1.85882, time : 12.896444320678711 lr : 0.96059601\n",
      "epoch : 0 [2157/21279] Train loss: 1.41945,Valid loss: 1.74191, time : 12.686238765716553 lr : 0.96059601\n",
      "epoch : 0 [2158/21279] Train loss: 1.41314,Valid loss: 1.97080, time : 12.546440601348877 lr : 0.96059601\n",
      "epoch : 0 [2159/21279] Train loss: 1.41334,Valid loss: 1.92487, time : 12.205047130584717 lr : 0.96059601\n",
      "epoch : 0 [2160/21279] Train loss: 1.40497,Valid loss: 1.90259, time : 12.016634464263916 lr : 0.96059601\n",
      "epoch : 0 [2161/21279] Train loss: 1.41284,Valid loss: 1.85608, time : 11.95153260231018 lr : 0.96059601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2162/21279] Train loss: 1.41653,Valid loss: 1.96477, time : 12.220099687576294 lr : 0.96059601\n",
      "epoch : 0 [2163/21279] Train loss: 1.46164,Valid loss: 1.77321, time : 12.39795732498169 lr : 0.96059601\n",
      "epoch : 0 [2164/21279] Train loss: 1.41531,Valid loss: 2.18045, time : 12.092102766036987 lr : 0.96059601\n",
      "epoch : 0 [2165/21279] Train loss: 1.40718,Valid loss: 1.84963, time : 12.278567552566528 lr : 0.96059601\n",
      "epoch : 0 [2166/21279] Train loss: 1.43554,Valid loss: 1.78461, time : 12.050926446914673 lr : 0.96059601\n",
      "epoch : 0 [2167/21279] Train loss: 1.41726,Valid loss: 1.77183, time : 12.599772453308105 lr : 0.96059601\n",
      "epoch : 0 [2168/21279] Train loss: 1.42204,Valid loss: 1.93757, time : 14.287091493606567 lr : 0.96059601\n",
      "epoch : 0 [2169/21279] Train loss: 1.42149,Valid loss: 2.00444, time : 12.406437158584595 lr : 0.96059601\n",
      "epoch : 0 [2170/21279] Train loss: 1.41462,Valid loss: 1.78715, time : 12.292273044586182 lr : 0.96059601\n",
      "epoch : 0 [2171/21279] Train loss: 1.39732,Valid loss: 1.85814, time : 12.478208065032959 lr : 0.96059601\n",
      "epoch : 0 [2172/21279] Train loss: 1.39930,Valid loss: 1.81640, time : 12.422582387924194 lr : 0.96059601\n",
      "epoch : 0 [2173/21279] Train loss: 1.37134,Valid loss: 1.77946, time : 12.617215633392334 lr : 0.96059601\n",
      "epoch : 0 [2174/21279] Train loss: 1.36718,Valid loss: 1.81434, time : 12.378839254379272 lr : 0.96059601\n",
      "epoch : 0 [2175/21279] Train loss: 1.35671,Valid loss: 1.77858, time : 12.434704303741455 lr : 0.96059601\n",
      "epoch : 0 [2176/21279] Train loss: 1.35062,Valid loss: 1.81213, time : 12.201914548873901 lr : 0.96059601\n",
      "epoch : 0 [2177/21279] Train loss: 1.37625,Valid loss: 1.87597, time : 12.78367805480957 lr : 0.96059601\n",
      "epoch : 0 [2178/21279] Train loss: 1.36584,Valid loss: 1.75983, time : 12.651768922805786 lr : 0.96059601\n",
      "epoch : 0 [2179/21279] Train loss: 1.38111,Valid loss: 1.85576, time : 12.272228717803955 lr : 0.96059601\n",
      "epoch : 0 [2180/21279] Train loss: 1.41449,Valid loss: 1.63656, time : 14.267974853515625 lr : 0.96059601\n",
      "epoch : 0 [2181/21279] Train loss: 1.41495,Valid loss: 1.77766, time : 12.70060420036316 lr : 0.96059601\n",
      "epoch : 0 [2182/21279] Train loss: 1.38943,Valid loss: 1.82934, time : 12.293313264846802 lr : 0.96059601\n",
      "epoch : 0 [2183/21279] Train loss: 1.36758,Valid loss: 1.86681, time : 12.583039283752441 lr : 0.96059601\n",
      "epoch : 0 [2184/21279] Train loss: 1.38575,Valid loss: 1.80864, time : 12.754303455352783 lr : 0.96059601\n",
      "epoch : 0 [2185/21279] Train loss: 1.38461,Valid loss: 2.10891, time : 12.641889810562134 lr : 0.96059601\n",
      "epoch : 0 [2186/21279] Train loss: 1.39545,Valid loss: 1.81675, time : 12.498341798782349 lr : 0.96059601\n",
      "epoch : 0 [2187/21279] Train loss: 1.37125,Valid loss: 1.98401, time : 12.468339443206787 lr : 0.96059601\n",
      "epoch : 0 [2188/21279] Train loss: 1.41058,Valid loss: 1.92880, time : 12.769668340682983 lr : 0.96059601\n",
      "epoch : 0 [2189/21279] Train loss: 1.36034,Valid loss: 1.75918, time : 12.288108110427856 lr : 0.96059601\n",
      "epoch : 0 [2190/21279] Train loss: 1.42255,Valid loss: 1.90960, time : 12.375153064727783 lr : 0.96059601\n",
      "epoch : 0 [2191/21279] Train loss: 1.31804,Valid loss: 1.81446, time : 12.571606159210205 lr : 0.96059601\n",
      "epoch : 0 [2192/21279] Train loss: 1.31320,Valid loss: 1.78827, time : 12.891193389892578 lr : 0.96059601\n",
      "epoch : 0 [2193/21279] Train loss: 1.28414,Valid loss: 1.76658, time : 13.2181396484375 lr : 0.96059601\n",
      "epoch : 0 [2194/21279] Train loss: 1.30559,Valid loss: 1.68751, time : 12.542631149291992 lr : 0.96059601\n",
      "epoch : 0 [2195/21279] Train loss: 1.32807,Valid loss: 1.85550, time : 12.73934555053711 lr : 0.96059601\n",
      "epoch : 0 [2196/21279] Train loss: 1.40108,Valid loss: 2.18615, time : 15.263274431228638 lr : 0.96059601\n",
      "epoch : 0 [2197/21279] Train loss: 1.62925,Valid loss: 2.52365, time : 11.790407419204712 lr : 0.96059601\n",
      "epoch : 0 [2198/21279] Train loss: 1.74476,Valid loss: 2.04565, time : 12.260343074798584 lr : 0.96059601\n",
      "epoch : 0 [2199/21279] Train loss: 1.53588,Valid loss: 2.75345, time : 11.821732521057129 lr : 0.96059601\n",
      "epoch : 0 [2200/21279] Train loss: 1.73702,Valid loss: 3.73917, time : 12.16900086402893 lr : 0.96059601\n",
      "epoch : 0 [2201/21279] Train loss: 1.53616,Valid loss: 2.92168, time : 11.633943557739258 lr : 0.96059601\n",
      "epoch : 0 [2202/21279] Train loss: 1.70138,Valid loss: 3.61675, time : 12.154372215270996 lr : 0.96059601\n",
      "epoch : 0 [2203/21279] Train loss: 1.70145,Valid loss: 2.60795, time : 11.87279725074768 lr : 0.96059601\n",
      "epoch : 0 [2204/21279] Train loss: 1.63220,Valid loss: 2.27370, time : 12.27687382698059 lr : 0.96059601\n",
      "epoch : 0 [2205/21279] Train loss: 1.56690,Valid loss: 1.96682, time : 12.216876029968262 lr : 0.96059601\n",
      "epoch : 0 [2206/21279] Train loss: 1.52249,Valid loss: 1.72796, time : 12.309681177139282 lr : 0.96059601\n",
      "epoch : 0 [2207/21279] Train loss: 1.34603,Valid loss: 1.67289, time : 12.118417978286743 lr : 0.96059601\n",
      "epoch : 0 [2208/21279] Train loss: 1.29923,Valid loss: 1.84812, time : 14.304414749145508 lr : 0.96059601\n",
      "epoch : 0 [2209/21279] Train loss: 1.32643,Valid loss: 1.64692, time : 11.79188847541809 lr : 0.96059601\n",
      "epoch : 0 [2210/21279] Train loss: 1.34664,Valid loss: 1.83683, time : 12.09635877609253 lr : 0.96059601\n",
      "epoch : 0 [2211/21279] Train loss: 1.36782,Valid loss: 1.82616, time : 11.924457788467407 lr : 0.96059601\n",
      "epoch : 0 [2212/21279] Train loss: 1.36348,Valid loss: 1.95374, time : 12.239874601364136 lr : 0.96059601\n",
      "epoch : 0 [2213/21279] Train loss: 1.39655,Valid loss: 1.63725, time : 11.821001529693604 lr : 0.96059601\n",
      "epoch : 0 [2214/21279] Train loss: 1.37850,Valid loss: 1.88433, time : 12.044764757156372 lr : 0.96059601\n",
      "epoch : 0 [2215/21279] Train loss: 1.36362,Valid loss: 1.78562, time : 12.314380168914795 lr : 0.96059601\n",
      "epoch : 0 [2216/21279] Train loss: 1.34000,Valid loss: 1.69495, time : 12.813809156417847 lr : 0.96059601\n",
      "epoch : 0 [2217/21279] Train loss: 1.31841,Valid loss: 1.72708, time : 12.576004028320312 lr : 0.96059601\n",
      "epoch : 0 [2218/21279] Train loss: 1.29462,Valid loss: 1.79774, time : 12.76436734199524 lr : 0.96059601\n",
      "epoch : 0 [2219/21279] Train loss: 1.30074,Valid loss: 1.84566, time : 12.515476942062378 lr : 0.96059601\n",
      "epoch : 0 [2220/21279] Train loss: 1.31118,Valid loss: 1.68827, time : 14.429632186889648 lr : 0.96059601\n",
      "epoch : 0 [2221/21279] Train loss: 1.31669,Valid loss: 1.90349, time : 12.974028825759888 lr : 0.96059601\n",
      "epoch : 0 [2222/21279] Train loss: 1.31311,Valid loss: 1.80287, time : 12.794801712036133 lr : 0.96059601\n",
      "epoch : 0 [2223/21279] Train loss: 1.31482,Valid loss: 1.83366, time : 12.35880970954895 lr : 0.96059601\n",
      "epoch : 0 [2224/21279] Train loss: 1.32799,Valid loss: 1.82222, time : 12.662567138671875 lr : 0.96059601\n",
      "epoch : 0 [2225/21279] Train loss: 1.31340,Valid loss: 1.77095, time : 12.29547643661499 lr : 0.96059601\n",
      "epoch : 0 [2226/21279] Train loss: 1.33777,Valid loss: 2.13922, time : 12.743957042694092 lr : 0.96059601\n",
      "epoch : 0 [2227/21279] Train loss: 1.32115,Valid loss: 2.06452, time : 12.027894735336304 lr : 0.96059601\n",
      "epoch : 0 [2228/21279] Train loss: 1.32584,Valid loss: 7.64439, time : 12.057282447814941 lr : 0.96059601\n",
      "epoch : 0 [2229/21279] Train loss: 1.41749,Valid loss: 7.90101, time : 11.636417150497437 lr : 0.96059601\n",
      "epoch : 0 [2230/21279] Train loss: 2.22103,Valid loss: 3.31028, time : 12.103503465652466 lr : 0.96059601\n",
      "epoch : 0 [2231/21279] Train loss: 1.39710,Valid loss: 2.61076, time : 12.423300981521606 lr : 0.96059601\n",
      "epoch : 0 [2232/21279] Train loss: 1.37702,Valid loss: 2.42892, time : 12.550677299499512 lr : 0.96059601\n",
      "epoch : 0 [2233/21279] Train loss: 1.29161,Valid loss: 1.86150, time : 12.563983678817749 lr : 0.96059601\n",
      "epoch : 0 [2234/21279] Train loss: 1.26145,Valid loss: 1.67019, time : 12.715825319290161 lr : 0.96059601\n",
      "epoch : 0 [2235/21279] Train loss: 1.26050,Valid loss: 1.77270, time : 12.419440746307373 lr : 0.96059601\n",
      "epoch : 0 [2236/21279] Train loss: 1.27578,Valid loss: 1.79720, time : 13.863048315048218 lr : 0.96059601\n",
      "epoch : 0 [2237/21279] Train loss: 1.30681,Valid loss: 1.73119, time : 12.424781799316406 lr : 0.96059601\n",
      "epoch : 0 [2238/21279] Train loss: 1.30595,Valid loss: 1.87262, time : 12.787896394729614 lr : 0.96059601\n",
      "epoch : 0 [2239/21279] Train loss: 1.30819,Valid loss: 1.73213, time : 12.790079355239868 lr : 0.96059601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2240/21279] Train loss: 1.31592,Valid loss: 1.75008, time : 12.840978384017944 lr : 0.96059601\n",
      "epoch : 0 [2241/21279] Train loss: 1.32700,Valid loss: 1.81359, time : 12.798053503036499 lr : 0.96059601\n",
      "epoch : 0 [2242/21279] Train loss: 1.34714,Valid loss: 1.65069, time : 12.092742919921875 lr : 0.96059601\n",
      "epoch : 0 [2243/21279] Train loss: 1.33415,Valid loss: 1.88541, time : 12.423677444458008 lr : 0.96059601\n",
      "epoch : 0 [2244/21279] Train loss: 1.32256,Valid loss: 1.88627, time : 12.760705947875977 lr : 0.96059601\n",
      "epoch : 0 [2245/21279] Train loss: 1.33559,Valid loss: 2.08146, time : 12.740485906600952 lr : 0.96059601\n",
      "epoch : 0 [2246/21279] Train loss: 1.29417,Valid loss: 1.62027, time : 13.212660551071167 lr : 0.96059601\n",
      "epoch : 0 [2247/21279] Train loss: 1.30614,Valid loss: 1.90831, time : 12.174928665161133 lr : 0.96059601\n",
      "epoch : 0 [2248/21279] Train loss: 1.31588,Valid loss: 2.49881, time : 12.309623956680298 lr : 0.96059601\n",
      "epoch : 0 [2249/21279] Train loss: 1.34250,Valid loss: 2.02691, time : 13.615978240966797 lr : 0.96059601\n",
      "epoch : 0 [2250/21279] Train loss: 1.33158,Valid loss: 2.00526, time : 12.334173679351807 lr : 0.96059601\n",
      "epoch : 0 [2251/21279] Train loss: 1.31213,Valid loss: 1.67515, time : 11.644800424575806 lr : 0.96059601\n",
      "epoch : 0 [2252/21279] Train loss: 1.33809,Valid loss: 1.76990, time : 12.119649171829224 lr : 0.96059601\n",
      "epoch : 0 [2253/21279] Train loss: 1.26226,Valid loss: 1.83444, time : 12.665023803710938 lr : 0.96059601\n",
      "epoch : 0 [2254/21279] Train loss: 1.29474,Valid loss: 1.98949, time : 12.536104917526245 lr : 0.96059601\n",
      "epoch : 0 [2255/21279] Train loss: 1.29866,Valid loss: 1.70927, time : 12.689987897872925 lr : 0.96059601\n",
      "epoch : 0 [2256/21279] Train loss: 1.32833,Valid loss: 1.84515, time : 12.314626216888428 lr : 0.96059601\n",
      "epoch : 0 [2257/21279] Train loss: 1.28095,Valid loss: 1.78071, time : 12.375406742095947 lr : 0.96059601\n",
      "epoch : 0 [2258/21279] Train loss: 1.40542,Valid loss: 3.32006, time : 12.375304698944092 lr : 0.96059601\n",
      "epoch : 0 [2259/21279] Train loss: 2.17837,Valid loss: 2.83381, time : 12.436243295669556 lr : 0.96059601\n",
      "epoch : 0 [2260/21279] Train loss: 1.32419,Valid loss: 1.89845, time : 12.895206451416016 lr : 0.96059601\n",
      "epoch : 0 [2261/21279] Train loss: 1.28846,Valid loss: 1.69538, time : 12.365175008773804 lr : 0.96059601\n",
      "epoch : 0 [2262/21279] Train loss: 1.32934,Valid loss: 2.55715, time : 12.276926279067993 lr : 0.96059601\n",
      "epoch : 0 [2263/21279] Train loss: 1.62772,Valid loss: 2.57755, time : 12.46814775466919 lr : 0.96059601\n",
      "epoch : 0 [2264/21279] Train loss: 1.57236,Valid loss: 2.34078, time : 13.823484420776367 lr : 0.96059601\n",
      "epoch : 0 [2265/21279] Train loss: 1.57233,Valid loss: 2.35976, time : 12.38378119468689 lr : 0.96059601\n",
      "epoch : 0 [2266/21279] Train loss: 1.40607,Valid loss: 2.08287, time : 12.446829319000244 lr : 0.96059601\n",
      "epoch : 0 [2267/21279] Train loss: 1.43044,Valid loss: 2.24878, time : 12.47408652305603 lr : 0.96059601\n",
      "epoch : 0 [2268/21279] Train loss: 1.34896,Valid loss: 1.79314, time : 12.691666603088379 lr : 0.96059601\n",
      "epoch : 0 [2269/21279] Train loss: 1.31238,Valid loss: 1.87745, time : 12.512773036956787 lr : 0.96059601\n",
      "epoch : 0 [2270/21279] Train loss: 1.30221,Valid loss: 1.65366, time : 12.25804615020752 lr : 0.96059601\n",
      "epoch : 0 [2271/21279] Train loss: 1.29303,Valid loss: 1.57748, time : 12.419277906417847 lr : 0.96059601\n",
      "epoch : 0 [2272/21279] Train loss: 1.23409,Valid loss: 1.55086, time : 12.515656471252441 lr : 0.96059601\n",
      "epoch : 0 [2273/21279] Train loss: 1.25817,Valid loss: 1.57056, time : 11.951960802078247 lr : 0.96059601\n",
      "epoch : 0 [2274/21279] Train loss: 1.24318,Valid loss: 1.71571, time : 12.223693609237671 lr : 0.96059601\n",
      "epoch : 0 [2275/21279] Train loss: 1.26861,Valid loss: 1.66814, time : 12.455723524093628 lr : 0.96059601\n",
      "epoch : 0 [2276/21279] Train loss: 1.27028,Valid loss: 1.64923, time : 14.158512353897095 lr : 0.96059601\n",
      "epoch : 0 [2277/21279] Train loss: 1.27028,Valid loss: 1.72593, time : 12.298323631286621 lr : 0.96059601\n",
      "epoch : 0 [2278/21279] Train loss: 1.28529,Valid loss: 1.68312, time : 12.573348999023438 lr : 0.96059601\n",
      "epoch : 0 [2279/21279] Train loss: 1.23783,Valid loss: 1.73137, time : 12.820359468460083 lr : 0.96059601\n",
      "epoch : 0 [2280/21279] Train loss: 1.21737,Valid loss: 1.41561, time : 12.873961210250854 lr : 0.96059601\n",
      "epoch : 0 [2281/21279] Train loss: 1.23217,Valid loss: 1.68861, time : 12.557080745697021 lr : 0.96059601\n",
      "epoch : 0 [2282/21279] Train loss: 1.23792,Valid loss: 1.92287, time : 12.869781017303467 lr : 0.96059601\n",
      "epoch : 0 [2283/21279] Train loss: 1.25660,Valid loss: 1.75314, time : 12.170628547668457 lr : 0.96059601\n",
      "epoch : 0 [2284/21279] Train loss: 1.24361,Valid loss: 1.76923, time : 12.545137405395508 lr : 0.96059601\n",
      "epoch : 0 [2285/21279] Train loss: 1.22660,Valid loss: 1.72144, time : 12.952914476394653 lr : 0.96059601\n",
      "epoch : 0 [2286/21279] Train loss: 1.22798,Valid loss: 1.66695, time : 12.603474378585815 lr : 0.96059601\n",
      "epoch : 0 [2287/21279] Train loss: 1.21925,Valid loss: 1.64354, time : 12.932045221328735 lr : 0.96059601\n",
      "epoch : 0 [2288/21279] Train loss: 1.23553,Valid loss: 1.66154, time : 12.241373777389526 lr : 0.96059601\n",
      "epoch : 0 [2289/21279] Train loss: 1.24194,Valid loss: 1.77049, time : 12.327136278152466 lr : 0.96059601\n",
      "epoch : 0 [2290/21279] Train loss: 1.26022,Valid loss: 3.07243, time : 15.15184235572815 lr : 0.96059601\n",
      "epoch : 0 [2291/21279] Train loss: 1.29208,Valid loss: 3.08185, time : 11.992825508117676 lr : 0.96059601\n",
      "epoch : 0 [2292/21279] Train loss: 1.40462,Valid loss: 6.43450, time : 12.646794557571411 lr : 0.96059601\n",
      "epoch : 0 [2293/21279] Train loss: 1.74981,Valid loss: 3.77352, time : 11.95464277267456 lr : 0.96059601\n",
      "epoch : 0 [2294/21279] Train loss: 1.55419,Valid loss: 2.31328, time : 12.123319149017334 lr : 0.96059601\n",
      "epoch : 0 [2295/21279] Train loss: 1.26984,Valid loss: 2.14144, time : 11.821837663650513 lr : 0.96059601\n",
      "epoch : 0 [2296/21279] Train loss: 1.42063,Valid loss: 2.11998, time : 12.240951538085938 lr : 0.96059601\n",
      "epoch : 0 [2297/21279] Train loss: 1.40272,Valid loss: 2.09607, time : 12.200502634048462 lr : 0.96059601\n",
      "epoch : 0 [2298/21279] Train loss: 1.31370,Valid loss: 1.96457, time : 12.110087156295776 lr : 0.96059601\n",
      "epoch : 0 [2299/21279] Train loss: 1.25101,Valid loss: 1.67634, time : 12.17256760597229 lr : 0.96059601\n",
      "epoch : 0 [2300/21279] Train loss: 1.22379,Valid loss: 1.84928, time : 12.421645879745483 lr : 0.96059601\n",
      "epoch : 0 [2301/21279] Train loss: 1.20581,Valid loss: 1.70431, time : 11.953827381134033 lr : 0.96059601\n",
      "epoch : 0 [2302/21279] Train loss: 1.21804,Valid loss: 1.62771, time : 13.933308839797974 lr : 0.96059601\n",
      "epoch : 0 [2303/21279] Train loss: 1.21959,Valid loss: 1.65559, time : 11.870111227035522 lr : 0.96059601\n",
      "epoch : 0 [2304/21279] Train loss: 1.23347,Valid loss: 2.33571, time : 12.305203199386597 lr : 0.96059601\n",
      "epoch : 0 [2305/21279] Train loss: 1.24559,Valid loss: 2.84260, time : 12.751118183135986 lr : 0.96059601\n",
      "epoch : 0 [2306/21279] Train loss: 1.24927,Valid loss: 3.85380, time : 12.779912948608398 lr : 0.96059601\n",
      "epoch : 0 [2307/21279] Train loss: 1.23090,Valid loss: 2.68636, time : 12.495778799057007 lr : 0.96059601\n",
      "epoch : 0 [2308/21279] Train loss: 1.23970,Valid loss: 1.68314, time : 12.815610647201538 lr : 0.96059601\n",
      "epoch : 0 [2309/21279] Train loss: 1.24141,Valid loss: 1.73724, time : 12.695921182632446 lr : 0.96059601\n",
      "epoch : 0 [2310/21279] Train loss: 1.26333,Valid loss: 1.62167, time : 12.706010103225708 lr : 0.96059601\n",
      "epoch : 0 [2311/21279] Train loss: 1.25272,Valid loss: 1.89374, time : 12.811444997787476 lr : 0.96059601\n",
      "epoch : 0 [2312/21279] Train loss: 1.25992,Valid loss: 1.65596, time : 12.849029302597046 lr : 0.96059601\n",
      "epoch : 0 [2313/21279] Train loss: 1.21920,Valid loss: 1.78380, time : 12.76841688156128 lr : 0.96059601\n",
      "epoch : 0 [2314/21279] Train loss: 1.22508,Valid loss: 1.72292, time : 12.834152460098267 lr : 0.96059601\n",
      "epoch : 0 [2315/21279] Train loss: 1.20384,Valid loss: 1.75220, time : 12.772587537765503 lr : 0.96059601\n",
      "epoch : 0 [2316/21279] Train loss: 1.19874,Valid loss: 1.61887, time : 12.556574821472168 lr : 0.96059601\n",
      "epoch : 0 [2317/21279] Train loss: 1.23996,Valid loss: 1.91000, time : 12.552930116653442 lr : 0.96059601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2318/21279] Train loss: 1.35281,Valid loss: 2.15385, time : 14.384745121002197 lr : 0.96059601\n",
      "epoch : 0 [2319/21279] Train loss: 1.35902,Valid loss: 1.83847, time : 12.675448894500732 lr : 0.96059601\n",
      "epoch : 0 [2320/21279] Train loss: 1.41995,Valid loss: 1.88484, time : 12.721749067306519 lr : 0.96059601\n",
      "epoch : 0 [2321/21279] Train loss: 1.23367,Valid loss: 1.63409, time : 12.681811571121216 lr : 0.96059601\n",
      "epoch : 0 [2322/21279] Train loss: 1.18334,Valid loss: 1.68904, time : 12.639795064926147 lr : 0.96059601\n",
      "epoch : 0 [2323/21279] Train loss: 1.18515,Valid loss: 1.63907, time : 12.656893730163574 lr : 0.96059601\n",
      "epoch : 0 [2324/21279] Train loss: 1.18458,Valid loss: 1.47131, time : 12.749553680419922 lr : 0.96059601\n",
      "epoch : 0 [2325/21279] Train loss: 1.17869,Valid loss: 1.58852, time : 12.542418241500854 lr : 0.96059601\n",
      "epoch : 0 [2326/21279] Train loss: 1.18960,Valid loss: 1.50757, time : 12.349923372268677 lr : 0.96059601\n",
      "epoch : 0 [2327/21279] Train loss: 1.18814,Valid loss: 1.73451, time : 12.101600408554077 lr : 0.96059601\n",
      "epoch : 0 [2328/21279] Train loss: 1.15345,Valid loss: 1.66680, time : 12.832915306091309 lr : 0.96059601\n",
      "epoch : 0 [2329/21279] Train loss: 1.18746,Valid loss: 1.53188, time : 12.47254490852356 lr : 0.96059601\n",
      "epoch : 0 [2330/21279] Train loss: 1.20624,Valid loss: 1.66821, time : 14.224390029907227 lr : 0.96059601\n",
      "epoch : 0 [2331/21279] Train loss: 1.20881,Valid loss: 1.60139, time : 11.878524541854858 lr : 0.96059601\n",
      "epoch : 0 [2332/21279] Train loss: 1.15150,Valid loss: 1.66758, time : 12.014976501464844 lr : 0.96059601\n",
      "epoch : 0 [2333/21279] Train loss: 1.16972,Valid loss: 1.48883, time : 11.952727556228638 lr : 0.96059601\n",
      "epoch : 0 [2334/21279] Train loss: 1.15657,Valid loss: 1.66603, time : 12.29586935043335 lr : 0.96059601\n",
      "epoch : 0 [2335/21279] Train loss: 1.17540,Valid loss: 1.97308, time : 12.910465955734253 lr : 0.96059601\n",
      "epoch : 0 [2336/21279] Train loss: 1.22441,Valid loss: 2.39330, time : 12.561372756958008 lr : 0.96059601\n",
      "epoch : 0 [2337/21279] Train loss: 1.25304,Valid loss: 1.89992, time : 12.691575527191162 lr : 0.96059601\n",
      "epoch : 0 [2338/21279] Train loss: 1.23489,Valid loss: 2.55840, time : 12.95468544960022 lr : 0.96059601\n",
      "epoch : 0 [2339/21279] Train loss: 1.20715,Valid loss: 2.21858, time : 12.433178186416626 lr : 0.96059601\n",
      "epoch : 0 [2340/21279] Train loss: 1.24685,Valid loss: 5.51192, time : 12.82640552520752 lr : 0.96059601\n",
      "epoch : 0 [2341/21279] Train loss: 1.44797,Valid loss: 2.51286, time : 12.557225704193115 lr : 0.96059601\n",
      "epoch : 0 [2342/21279] Train loss: 1.90588,Valid loss: 3.17269, time : 12.90451431274414 lr : 0.96059601\n",
      "epoch : 0 [2343/21279] Train loss: 1.51560,Valid loss: 2.18686, time : 12.441299676895142 lr : 0.96059601\n",
      "epoch : 0 [2344/21279] Train loss: 1.52774,Valid loss: 2.55852, time : 12.583412885665894 lr : 0.96059601\n",
      "epoch : 0 [2345/21279] Train loss: 1.46380,Valid loss: 2.84865, time : 12.889160871505737 lr : 0.96059601\n",
      "epoch : 0 [2346/21279] Train loss: 1.48155,Valid loss: 2.31140, time : 15.846816778182983 lr : 0.96059601\n",
      "epoch : 0 [2347/21279] Train loss: 1.43996,Valid loss: 2.28076, time : 12.778800010681152 lr : 0.96059601\n",
      "epoch : 0 [2348/21279] Train loss: 1.37291,Valid loss: 2.02896, time : 12.038678169250488 lr : 0.96059601\n",
      "epoch : 0 [2349/21279] Train loss: 1.26837,Valid loss: 1.61351, time : 12.08025598526001 lr : 0.96059601\n",
      "epoch : 0 [2350/21279] Train loss: 1.19089,Valid loss: 1.82812, time : 12.396951913833618 lr : 0.96059601\n",
      "epoch : 0 [2351/21279] Train loss: 1.24484,Valid loss: 1.54935, time : 12.424074649810791 lr : 0.96059601\n",
      "epoch : 0 [2352/21279] Train loss: 1.21648,Valid loss: 1.51841, time : 12.072962045669556 lr : 0.96059601\n",
      "epoch : 0 [2353/21279] Train loss: 1.22211,Valid loss: 1.50866, time : 12.376097202301025 lr : 0.96059601\n",
      "epoch : 0 [2354/21279] Train loss: 1.17797,Valid loss: 1.59697, time : 12.41968846321106 lr : 0.96059601\n",
      "epoch : 0 [2355/21279] Train loss: 1.17350,Valid loss: 1.61402, time : 12.217635154724121 lr : 0.96059601\n",
      "epoch : 0 [2356/21279] Train loss: 1.16960,Valid loss: 1.58489, time : 12.466192960739136 lr : 0.96059601\n",
      "epoch : 0 [2357/21279] Train loss: 1.15599,Valid loss: 1.55842, time : 12.417874336242676 lr : 0.96059601\n",
      "epoch : 0 [2358/21279] Train loss: 1.15705,Valid loss: 1.49405, time : 12.593570470809937 lr : 0.96059601\n",
      "epoch : 0 [2359/21279] Train loss: 1.12251,Valid loss: 1.55792, time : 14.511727094650269 lr : 0.96059601\n",
      "epoch : 0 [2360/21279] Train loss: 1.12026,Valid loss: 1.97124, time : 12.990055799484253 lr : 0.96059601\n",
      "epoch : 0 [2361/21279] Train loss: 1.12440,Valid loss: 1.85479, time : 12.866359949111938 lr : 0.96059601\n",
      "epoch : 0 [2362/21279] Train loss: 1.16086,Valid loss: 1.40963, time : 12.983871459960938 lr : 0.96059601\n",
      "epoch : 0 [2363/21279] Train loss: 1.09927,Valid loss: 1.68923, time : 12.15127182006836 lr : 0.96059601\n",
      "epoch : 0 [2364/21279] Train loss: 1.13022,Valid loss: 1.64452, time : 12.445107221603394 lr : 0.96059601\n",
      "epoch : 0 [2365/21279] Train loss: 1.11074,Valid loss: 1.66821, time : 12.124394655227661 lr : 0.96059601\n",
      "epoch : 0 [2366/21279] Train loss: 1.10588,Valid loss: 1.39754, time : 12.24956226348877 lr : 0.96059601\n",
      "epoch : 0 [2367/21279] Train loss: 1.10101,Valid loss: 1.58092, time : 12.463459491729736 lr : 0.96059601\n",
      "epoch : 0 [2368/21279] Train loss: 1.09720,Valid loss: 1.56664, time : 12.577570676803589 lr : 0.96059601\n",
      "epoch : 0 [2369/21279] Train loss: 1.10987,Valid loss: 1.58161, time : 12.678999423980713 lr : 0.96059601\n",
      "epoch : 0 [2370/21279] Train loss: 1.12654,Valid loss: 1.32287, time : 12.916537046432495 lr : 0.96059601\n",
      "epoch : 0 [2371/21279] Train loss: 1.11678,Valid loss: 1.45478, time : 12.997689962387085 lr : 0.96059601\n",
      "epoch : 0 [2372/21279] Train loss: 1.12154,Valid loss: 1.52331, time : 13.083458662033081 lr : 0.96059601\n",
      "epoch : 0 [2373/21279] Train loss: 1.12685,Valid loss: 1.56320, time : 12.663436889648438 lr : 0.96059601\n",
      "epoch : 0 [2374/21279] Train loss: 1.18262,Valid loss: 1.74018, time : 14.219377517700195 lr : 0.96059601\n",
      "epoch : 0 [2375/21279] Train loss: 1.16174,Valid loss: 1.55896, time : 12.58483600616455 lr : 0.96059601\n",
      "epoch : 0 [2376/21279] Train loss: 1.16192,Valid loss: 1.66513, time : 11.946225643157959 lr : 0.96059601\n",
      "epoch : 0 [2377/21279] Train loss: 1.14362,Valid loss: 1.59381, time : 12.543558835983276 lr : 0.96059601\n",
      "epoch : 0 [2378/21279] Train loss: 1.17561,Valid loss: 1.71624, time : 12.274131298065186 lr : 0.96059601\n",
      "epoch : 0 [2379/21279] Train loss: 1.17303,Valid loss: 1.66408, time : 11.948931455612183 lr : 0.96059601\n",
      "epoch : 0 [2380/21279] Train loss: 1.13638,Valid loss: 1.55214, time : 12.252596378326416 lr : 0.96059601\n",
      "epoch : 0 [2381/21279] Train loss: 1.14752,Valid loss: 1.57805, time : 12.444730997085571 lr : 0.96059601\n",
      "epoch : 0 [2382/21279] Train loss: 1.12860,Valid loss: 1.70050, time : 12.644865274429321 lr : 0.96059601\n",
      "epoch : 0 [2383/21279] Train loss: 1.14487,Valid loss: 1.43259, time : 12.343163967132568 lr : 0.96059601\n",
      "epoch : 0 [2384/21279] Train loss: 1.12035,Valid loss: 1.53769, time : 12.436354875564575 lr : 0.96059601\n",
      "epoch : 0 [2385/21279] Train loss: 1.14973,Valid loss: 1.56523, time : 12.207034587860107 lr : 0.96059601\n",
      "epoch : 0 [2386/21279] Train loss: 1.09525,Valid loss: 1.74232, time : 14.162691354751587 lr : 0.96059601\n",
      "epoch : 0 [2387/21279] Train loss: 1.10572,Valid loss: 2.29367, time : 12.022398471832275 lr : 0.96059601\n",
      "epoch : 0 [2388/21279] Train loss: 1.17409,Valid loss: 3.10790, time : 12.427873611450195 lr : 0.96059601\n",
      "epoch : 0 [2389/21279] Train loss: 1.16441,Valid loss: 1.78999, time : 12.440613985061646 lr : 0.96059601\n",
      "epoch : 0 [2390/21279] Train loss: 1.10161,Valid loss: 1.42688, time : 12.26942753791809 lr : 0.96059601\n",
      "epoch : 0 [2391/21279] Train loss: 1.07694,Valid loss: 1.42147, time : 12.426503419876099 lr : 0.96059601\n",
      "epoch : 0 [2392/21279] Train loss: 1.08010,Valid loss: 1.47044, time : 12.598994255065918 lr : 0.96059601\n",
      "epoch : 0 [2393/21279] Train loss: 1.03512,Valid loss: 1.63948, time : 12.429577589035034 lr : 0.96059601\n",
      "epoch : 0 [2394/21279] Train loss: 1.05795,Valid loss: 1.47992, time : 12.503887414932251 lr : 0.96059601\n",
      "epoch : 0 [2395/21279] Train loss: 1.08648,Valid loss: 1.95404, time : 12.56881046295166 lr : 0.96059601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2396/21279] Train loss: 1.31377,Valid loss: 2.80937, time : 12.379296779632568 lr : 0.96059601\n",
      "epoch : 0 [2397/21279] Train loss: 1.39649,Valid loss: 2.55388, time : 12.593433856964111 lr : 0.96059601\n",
      "epoch : 0 [2398/21279] Train loss: 1.39768,Valid loss: 2.47103, time : 13.126598119735718 lr : 0.96059601\n",
      "epoch : 0 [2399/21279] Train loss: 1.54922,Valid loss: 2.02118, time : 12.663979530334473 lr : 0.96059601\n",
      "epoch : 0 [2400/21279] Train loss: 1.26702,Valid loss: 2.01037, time : 18.862640619277954 lr : 0.96059601\n",
      "epoch : 0 [2401/21279] Train loss: 1.26882,Valid loss: 3.45751, time : 13.398044109344482 lr : 0.96059601\n",
      "epoch : 0 [2402/21279] Train loss: 1.43371,Valid loss: 1.95411, time : 13.400291442871094 lr : 0.96059601\n",
      "epoch : 0 [2403/21279] Train loss: 1.19053,Valid loss: 1.76740, time : 13.360635995864868 lr : 0.96059601\n",
      "epoch : 0 [2404/21279] Train loss: 1.10881,Valid loss: 1.62981, time : 12.558648586273193 lr : 0.96059601\n",
      "epoch : 0 [2405/21279] Train loss: 1.11576,Valid loss: 1.56943, time : 12.262354373931885 lr : 0.96059601\n",
      "epoch : 0 [2406/21279] Train loss: 1.10243,Valid loss: 1.50049, time : 12.662140130996704 lr : 0.96059601\n",
      "epoch : 0 [2407/21279] Train loss: 1.10659,Valid loss: 1.48938, time : 12.595187664031982 lr : 0.96059601\n",
      "epoch : 0 [2408/21279] Train loss: 1.10995,Valid loss: 1.48276, time : 12.672733783721924 lr : 0.96059601\n",
      "epoch : 0 [2409/21279] Train loss: 1.07458,Valid loss: 1.62942, time : 12.961932182312012 lr : 0.96059601\n",
      "epoch : 0 [2410/21279] Train loss: 1.17659,Valid loss: 2.30882, time : 12.648159503936768 lr : 0.96059601\n",
      "epoch : 0 [2411/21279] Train loss: 1.16514,Valid loss: 1.55067, time : 12.830729484558105 lr : 0.96059601\n",
      "epoch : 0 [2412/21279] Train loss: 1.16269,Valid loss: 1.54721, time : 12.748701095581055 lr : 0.96059601\n",
      "epoch : 0 [2413/21279] Train loss: 1.13289,Valid loss: 1.58723, time : 12.19751763343811 lr : 0.96059601\n",
      "epoch : 0 [2414/21279] Train loss: 1.09473,Valid loss: 1.45842, time : 12.305510759353638 lr : 0.96059601\n",
      "epoch : 0 [2415/21279] Train loss: 1.11083,Valid loss: 1.37115, time : 12.217052698135376 lr : 0.96059601\n",
      "epoch : 0 [2416/21279] Train loss: 1.09395,Valid loss: 1.57507, time : 15.158802270889282 lr : 0.96059601\n",
      "epoch : 0 [2417/21279] Train loss: 1.08242,Valid loss: 1.51973, time : 11.805240154266357 lr : 0.96059601\n",
      "epoch : 0 [2418/21279] Train loss: 1.04938,Valid loss: 1.38322, time : 11.604749917984009 lr : 0.96059601\n",
      "epoch : 0 [2419/21279] Train loss: 1.09093,Valid loss: 1.37120, time : 11.596013069152832 lr : 0.96059601\n",
      "epoch : 0 [2420/21279] Train loss: 1.06788,Valid loss: 1.40689, time : 11.388705015182495 lr : 0.96059601\n",
      "epoch : 0 [2421/21279] Train loss: 1.07490,Valid loss: 1.38117, time : 12.41233229637146 lr : 0.96059601\n",
      "epoch : 0 [2422/21279] Train loss: 1.05982,Valid loss: 1.53122, time : 12.37718391418457 lr : 0.96059601\n",
      "epoch : 0 [2423/21279] Train loss: 1.04680,Valid loss: 1.49816, time : 11.143393993377686 lr : 0.96059601\n",
      "epoch : 0 [2424/21279] Train loss: 1.08450,Valid loss: 2.39006, time : 11.847754955291748 lr : 0.96059601\n",
      "epoch : 0 [2425/21279] Train loss: 1.35684,Valid loss: 3.37639, time : 11.495403051376343 lr : 0.96059601\n",
      "epoch : 0 [2426/21279] Train loss: 1.54819,Valid loss: 2.90347, time : 12.073259830474854 lr : 0.96059601\n",
      "epoch : 0 [2427/21279] Train loss: 1.24811,Valid loss: 2.45691, time : 12.08854365348816 lr : 0.96059601\n",
      "epoch : 0 [2428/21279] Train loss: 1.30981,Valid loss: 4.80370, time : 12.849632263183594 lr : 0.96059601\n",
      "epoch : 0 [2429/21279] Train loss: 1.49336,Valid loss: 2.09540, time : 15.074451684951782 lr : 0.96059601\n",
      "epoch : 0 [2430/21279] Train loss: 1.44376,Valid loss: 2.47863, time : 12.593473196029663 lr : 0.96059601\n",
      "epoch : 0 [2431/21279] Train loss: 1.21633,Valid loss: 1.74736, time : 12.838597774505615 lr : 0.96059601\n",
      "epoch : 0 [2432/21279] Train loss: 1.12403,Valid loss: 1.65374, time : 12.796083688735962 lr : 0.96059601\n",
      "epoch : 0 [2433/21279] Train loss: 1.06427,Valid loss: 1.54956, time : 12.237821102142334 lr : 0.96059601\n",
      "epoch : 0 [2434/21279] Train loss: 1.05646,Valid loss: 1.67084, time : 12.637406587600708 lr : 0.96059601\n",
      "epoch : 0 [2435/21279] Train loss: 1.06610,Valid loss: 1.60211, time : 12.109872102737427 lr : 0.96059601\n",
      "epoch : 0 [2436/21279] Train loss: 1.07757,Valid loss: 1.59471, time : 12.074831485748291 lr : 0.96059601\n",
      "epoch : 0 [2437/21279] Train loss: 1.06911,Valid loss: 1.69410, time : 11.456062078475952 lr : 0.96059601\n",
      "epoch : 0 [2438/21279] Train loss: 1.10991,Valid loss: 1.50841, time : 12.008878946304321 lr : 0.96059601\n",
      "epoch : 0 [2439/21279] Train loss: 1.10439,Valid loss: 1.59811, time : 12.102883338928223 lr : 0.96059601\n",
      "epoch : 0 [2440/21279] Train loss: 1.08408,Valid loss: 1.58595, time : 12.074790000915527 lr : 0.96059601\n",
      "epoch : 0 [2441/21279] Train loss: 1.09637,Valid loss: 1.54694, time : 12.777526617050171 lr : 0.96059601\n",
      "epoch : 0 [2442/21279] Train loss: 1.09614,Valid loss: 1.57817, time : 12.259617567062378 lr : 0.96059601\n",
      "epoch : 0 [2443/21279] Train loss: 1.09925,Valid loss: 1.61600, time : 12.643797636032104 lr : 0.96059601\n",
      "epoch : 0 [2444/21279] Train loss: 1.08172,Valid loss: 1.64206, time : 15.558485507965088 lr : 0.96059601\n",
      "epoch : 0 [2445/21279] Train loss: 1.08494,Valid loss: 1.67330, time : 12.071930646896362 lr : 0.96059601\n",
      "epoch : 0 [2446/21279] Train loss: 1.04482,Valid loss: 1.48890, time : 12.118077039718628 lr : 0.96059601\n",
      "epoch : 0 [2447/21279] Train loss: 1.06290,Valid loss: 1.52610, time : 11.8471519947052 lr : 0.96059601\n",
      "epoch : 0 [2448/21279] Train loss: 1.06127,Valid loss: 1.48367, time : 12.316007614135742 lr : 0.96059601\n",
      "epoch : 0 [2449/21279] Train loss: 1.11185,Valid loss: 1.63220, time : 12.710213899612427 lr : 0.96059601\n",
      "epoch : 0 [2450/21279] Train loss: 1.07535,Valid loss: 1.54787, time : 12.957610845565796 lr : 0.96059601\n",
      "epoch : 0 [2451/21279] Train loss: 1.10015,Valid loss: 1.62232, time : 12.647189378738403 lr : 0.96059601\n",
      "epoch : 0 [2452/21279] Train loss: 1.09382,Valid loss: 1.54918, time : 12.42824649810791 lr : 0.96059601\n",
      "epoch : 0 [2453/21279] Train loss: 1.07861,Valid loss: 1.49075, time : 11.960989236831665 lr : 0.96059601\n",
      "epoch : 0 [2454/21279] Train loss: 1.05589,Valid loss: 1.60304, time : 12.144571781158447 lr : 0.96059601\n",
      "epoch : 0 [2455/21279] Train loss: 1.05438,Valid loss: 1.41436, time : 12.443125486373901 lr : 0.96059601\n",
      "epoch : 0 [2456/21279] Train loss: 1.02456,Valid loss: 1.48200, time : 13.77215027809143 lr : 0.96059601\n",
      "epoch : 0 [2457/21279] Train loss: 1.03912,Valid loss: 1.48947, time : 12.547537088394165 lr : 0.96059601\n",
      "epoch : 0 [2458/21279] Train loss: 1.03846,Valid loss: 1.48036, time : 12.694298505783081 lr : 0.96059601\n",
      "epoch : 0 [2459/21279] Train loss: 1.04514,Valid loss: 1.40137, time : 12.41719388961792 lr : 0.96059601\n",
      "epoch : 0 [2460/21279] Train loss: 1.07004,Valid loss: 1.69514, time : 12.56728196144104 lr : 0.96059601\n",
      "epoch : 0 [2461/21279] Train loss: 1.03326,Valid loss: 1.65793, time : 12.529054164886475 lr : 0.96059601\n",
      "epoch : 0 [2462/21279] Train loss: 1.05988,Valid loss: 1.61250, time : 12.664474487304688 lr : 0.96059601\n",
      "epoch : 0 [2463/21279] Train loss: 1.05560,Valid loss: 1.52333, time : 12.702069520950317 lr : 0.96059601\n",
      "epoch : 0 [2464/21279] Train loss: 1.04860,Valid loss: 1.45747, time : 13.004830598831177 lr : 0.96059601\n",
      "epoch : 0 [2465/21279] Train loss: 1.09800,Valid loss: 1.87368, time : 12.802444458007812 lr : 0.96059601\n",
      "epoch : 0 [2466/21279] Train loss: 1.07504,Valid loss: 1.36684, time : 12.60461974143982 lr : 0.96059601\n",
      "epoch : 0 [2467/21279] Train loss: 0.99426,Valid loss: 1.41299, time : 12.597738027572632 lr : 0.96059601\n",
      "epoch : 0 [2468/21279] Train loss: 0.98544,Valid loss: 1.56118, time : 12.711625337600708 lr : 0.96059601\n",
      "epoch : 0 [2469/21279] Train loss: 1.09656,Valid loss: 2.42063, time : 12.672058820724487 lr : 0.96059601\n",
      "epoch : 0 [2470/21279] Train loss: 1.14328,Valid loss: 1.61040, time : 14.520283460617065 lr : 0.96059601\n",
      "epoch : 0 [2471/21279] Train loss: 1.22921,Valid loss: 1.68126, time : 12.497417449951172 lr : 0.96059601\n",
      "epoch : 0 [2472/21279] Train loss: 1.17817,Valid loss: 2.20409, time : 12.92104196548462 lr : 0.96059601\n",
      "epoch : 0 [2473/21279] Train loss: 1.26428,Valid loss: 1.70120, time : 12.386633157730103 lr : 0.96059601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2474/21279] Train loss: 1.03519,Valid loss: 1.56248, time : 12.55063271522522 lr : 0.96059601\n",
      "epoch : 0 [2475/21279] Train loss: 1.04575,Valid loss: 1.83672, time : 12.549434661865234 lr : 0.96059601\n",
      "epoch : 0 [2476/21279] Train loss: 1.26898,Valid loss: 2.66065, time : 12.886574268341064 lr : 0.96059601\n",
      "epoch : 0 [2477/21279] Train loss: 1.77557,Valid loss: 1.79604, time : 12.574622869491577 lr : 0.96059601\n",
      "epoch : 0 [2478/21279] Train loss: 1.25074,Valid loss: 2.80492, time : 12.619168519973755 lr : 0.96059601\n",
      "epoch : 0 [2479/21279] Train loss: 1.99515,Valid loss: 2.36808, time : 12.311544418334961 lr : 0.96059601\n",
      "epoch : 0 [2480/21279] Train loss: 1.20298,Valid loss: 1.87699, time : 12.627089262008667 lr : 0.96059601\n",
      "epoch : 0 [2481/21279] Train loss: 1.38230,Valid loss: 2.99648, time : 11.768994331359863 lr : 0.96059601\n",
      "epoch : 0 [2482/21279] Train loss: 1.64367,Valid loss: 2.39392, time : 14.087724924087524 lr : 0.96059601\n",
      "epoch : 0 [2483/21279] Train loss: 1.51152,Valid loss: 2.26239, time : 12.096791744232178 lr : 0.96059601\n",
      "epoch : 0 [2484/21279] Train loss: 1.30952,Valid loss: 1.88054, time : 12.757726907730103 lr : 0.96059601\n",
      "epoch : 0 [2485/21279] Train loss: 1.20193,Valid loss: 1.80092, time : 12.451106548309326 lr : 0.96059601\n",
      "epoch : 0 [2486/21279] Train loss: 1.12744,Valid loss: 1.66103, time : 12.556399822235107 lr : 0.96059601\n",
      "epoch : 0 [2487/21279] Train loss: 1.14443,Valid loss: 1.62390, time : 12.534228801727295 lr : 0.96059601\n",
      "epoch : 0 [2488/21279] Train loss: 1.13487,Valid loss: 1.71654, time : 12.812347650527954 lr : 0.96059601\n",
      "epoch : 0 [2489/21279] Train loss: 1.11648,Valid loss: 1.67639, time : 12.862828493118286 lr : 0.96059601\n",
      "epoch : 0 [2490/21279] Train loss: 1.09509,Valid loss: 1.60245, time : 12.42317819595337 lr : 0.96059601\n",
      "epoch : 0 [2491/21279] Train loss: 1.06550,Valid loss: 1.71054, time : 12.42976999282837 lr : 0.96059601\n",
      "epoch : 0 [2492/21279] Train loss: 1.03224,Valid loss: 1.42581, time : 12.713448762893677 lr : 0.96059601\n",
      "epoch : 0 [2493/21279] Train loss: 1.02625,Valid loss: 1.56179, time : 12.424219131469727 lr : 0.96059601\n",
      "epoch : 0 [2494/21279] Train loss: 1.01094,Valid loss: 2.06116, time : 12.748660564422607 lr : 0.96059601\n",
      "epoch : 0 [2495/21279] Train loss: 1.09829,Valid loss: 1.59227, time : 12.331078052520752 lr : 0.96059601\n",
      "epoch : 0 [2496/21279] Train loss: 1.01449,Valid loss: 1.66554, time : 12.68837022781372 lr : 0.96059601\n",
      "epoch : 0 [2497/21279] Train loss: 0.99896,Valid loss: 1.45255, time : 12.283990621566772 lr : 0.96059601\n",
      "epoch : 0 [2498/21279] Train loss: 1.00345,Valid loss: 1.61956, time : 14.479446649551392 lr : 0.96059601\n",
      "epoch : 0 [2499/21279] Train loss: 1.00574,Valid loss: 1.46673, time : 12.379799127578735 lr : 0.9509900498999999\n",
      "epoch : 0 [2500/21279] Train loss: 1.03085,Valid loss: 1.58141, time : 12.440733194351196 lr : 0.9509900498999999\n",
      "epoch : 0 [2501/21279] Train loss: 1.03560,Valid loss: 1.56777, time : 12.26950740814209 lr : 0.9509900498999999\n",
      "epoch : 0 [2502/21279] Train loss: 1.02095,Valid loss: 1.85459, time : 12.44671082496643 lr : 0.9509900498999999\n",
      "epoch : 0 [2503/21279] Train loss: 0.99587,Valid loss: 1.60055, time : 12.255026817321777 lr : 0.9509900498999999\n",
      "epoch : 0 [2504/21279] Train loss: 1.00717,Valid loss: 1.68321, time : 12.309804439544678 lr : 0.9509900498999999\n",
      "epoch : 0 [2505/21279] Train loss: 0.99612,Valid loss: 1.81533, time : 11.764307498931885 lr : 0.9509900498999999\n",
      "epoch : 0 [2506/21279] Train loss: 1.01221,Valid loss: 1.70826, time : 12.627389430999756 lr : 0.9509900498999999\n",
      "epoch : 0 [2507/21279] Train loss: 0.99493,Valid loss: 1.50380, time : 12.579468488693237 lr : 0.9509900498999999\n",
      "epoch : 0 [2508/21279] Train loss: 1.00418,Valid loss: 1.55128, time : 12.619236946105957 lr : 0.9509900498999999\n",
      "epoch : 0 [2509/21279] Train loss: 0.99055,Valid loss: 1.71739, time : 11.979630708694458 lr : 0.9509900498999999\n",
      "epoch : 0 [2510/21279] Train loss: 0.99208,Valid loss: 1.40019, time : 15.467217206954956 lr : 0.9509900498999999\n",
      "epoch : 0 [2511/21279] Train loss: 1.00458,Valid loss: 1.57468, time : 12.58733081817627 lr : 0.9509900498999999\n",
      "epoch : 0 [2512/21279] Train loss: 1.02344,Valid loss: 1.60533, time : 12.632907152175903 lr : 0.9509900498999999\n",
      "epoch : 0 [2513/21279] Train loss: 1.08253,Valid loss: 1.59833, time : 12.074402809143066 lr : 0.9509900498999999\n",
      "epoch : 0 [2514/21279] Train loss: 1.06679,Valid loss: 1.53328, time : 12.105690956115723 lr : 0.9509900498999999\n",
      "epoch : 0 [2515/21279] Train loss: 0.97802,Valid loss: 1.52220, time : 12.352855682373047 lr : 0.9509900498999999\n",
      "epoch : 0 [2516/21279] Train loss: 0.93395,Valid loss: 1.37983, time : 12.779644966125488 lr : 0.9509900498999999\n",
      "epoch : 0 [2517/21279] Train loss: 0.95055,Valid loss: 1.42650, time : 12.86070728302002 lr : 0.9509900498999999\n",
      "epoch : 0 [2518/21279] Train loss: 0.96673,Valid loss: 1.45864, time : 12.224017143249512 lr : 0.9509900498999999\n",
      "epoch : 0 [2519/21279] Train loss: 0.96603,Valid loss: 1.52265, time : 12.3800687789917 lr : 0.9509900498999999\n",
      "epoch : 0 [2520/21279] Train loss: 0.95131,Valid loss: 1.47276, time : 12.396344423294067 lr : 0.9509900498999999\n",
      "epoch : 0 [2521/21279] Train loss: 0.96336,Valid loss: 1.44271, time : 12.028475522994995 lr : 0.9509900498999999\n",
      "epoch : 0 [2522/21279] Train loss: 0.96847,Valid loss: 1.43219, time : 12.122878551483154 lr : 0.9509900498999999\n",
      "epoch : 0 [2523/21279] Train loss: 0.97475,Valid loss: 1.24856, time : 12.076275110244751 lr : 0.9509900498999999\n",
      "epoch : 0 [2524/21279] Train loss: 0.97714,Valid loss: 1.47722, time : 12.306766510009766 lr : 0.9509900498999999\n",
      "epoch : 0 [2525/21279] Train loss: 0.97630,Valid loss: 1.28691, time : 12.049545049667358 lr : 0.9509900498999999\n",
      "epoch : 0 [2526/21279] Train loss: 1.00043,Valid loss: 1.49774, time : 14.630979776382446 lr : 0.9509900498999999\n",
      "epoch : 0 [2527/21279] Train loss: 1.01092,Valid loss: 1.26611, time : 12.014113187789917 lr : 0.9509900498999999\n",
      "epoch : 0 [2528/21279] Train loss: 1.01214,Valid loss: 1.46844, time : 12.090136766433716 lr : 0.9509900498999999\n",
      "epoch : 0 [2529/21279] Train loss: 0.99819,Valid loss: 1.32687, time : 11.903877258300781 lr : 0.9509900498999999\n",
      "epoch : 0 [2530/21279] Train loss: 1.01893,Valid loss: 1.28800, time : 12.42407512664795 lr : 0.9509900498999999\n",
      "epoch : 0 [2531/21279] Train loss: 0.97760,Valid loss: 1.22938, time : 12.676887035369873 lr : 0.9509900498999999\n",
      "epoch : 0 [2532/21279] Train loss: 0.99536,Valid loss: 1.42764, time : 12.259061336517334 lr : 0.9509900498999999\n",
      "epoch : 0 [2533/21279] Train loss: 0.95196,Valid loss: 1.63352, time : 12.351646423339844 lr : 0.9509900498999999\n",
      "epoch : 0 [2534/21279] Train loss: 1.26911,Valid loss: 6.11010, time : 12.348695039749146 lr : 0.9509900498999999\n",
      "epoch : 0 [2535/21279] Train loss: 1.79894,Valid loss: 2.34206, time : 12.683493852615356 lr : 0.9509900498999999\n",
      "epoch : 0 [2536/21279] Train loss: 1.33298,Valid loss: 3.46239, time : 12.84221863746643 lr : 0.9509900498999999\n",
      "epoch : 0 [2537/21279] Train loss: 1.49572,Valid loss: 2.82442, time : 12.843101978302002 lr : 0.9509900498999999\n",
      "epoch : 0 [2538/21279] Train loss: 1.39372,Valid loss: 3.87522, time : 13.025449752807617 lr : 0.9509900498999999\n",
      "epoch : 0 [2539/21279] Train loss: 1.32744,Valid loss: 2.13659, time : 14.671631336212158 lr : 0.9509900498999999\n",
      "epoch : 0 [2540/21279] Train loss: 1.23257,Valid loss: 2.35182, time : 13.034411191940308 lr : 0.9509900498999999\n",
      "epoch : 0 [2541/21279] Train loss: 1.07811,Valid loss: 1.56573, time : 12.937840700149536 lr : 0.9509900498999999\n",
      "epoch : 0 [2542/21279] Train loss: 1.01083,Valid loss: 1.42082, time : 13.160085439682007 lr : 0.9509900498999999\n",
      "epoch : 0 [2543/21279] Train loss: 1.03333,Valid loss: 1.55577, time : 13.012478113174438 lr : 0.9509900498999999\n",
      "epoch : 0 [2544/21279] Train loss: 0.98430,Valid loss: 1.50283, time : 13.285674810409546 lr : 0.9509900498999999\n",
      "epoch : 0 [2545/21279] Train loss: 0.97834,Valid loss: 1.30654, time : 11.837385177612305 lr : 0.9509900498999999\n",
      "epoch : 0 [2546/21279] Train loss: 0.96388,Valid loss: 1.33126, time : 12.60527777671814 lr : 0.9509900498999999\n",
      "epoch : 0 [2547/21279] Train loss: 0.95650,Valid loss: 1.25101, time : 11.849337100982666 lr : 0.9509900498999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2548/21279] Train loss: 0.95977,Valid loss: 1.37067, time : 12.41135048866272 lr : 0.9509900498999999\n",
      "epoch : 0 [2549/21279] Train loss: 0.93574,Valid loss: 1.34141, time : 11.959403038024902 lr : 0.9509900498999999\n",
      "epoch : 0 [2550/21279] Train loss: 0.93866,Valid loss: 1.70707, time : 12.380141258239746 lr : 0.9509900498999999\n",
      "epoch : 0 [2551/21279] Train loss: 0.95151,Valid loss: 1.41872, time : 12.57797122001648 lr : 0.9509900498999999\n",
      "epoch : 0 [2552/21279] Train loss: 0.95073,Valid loss: 1.73121, time : 12.773714303970337 lr : 0.9509900498999999\n",
      "epoch : 0 [2553/21279] Train loss: 0.97553,Valid loss: 1.40776, time : 12.68554973602295 lr : 0.9509900498999999\n",
      "epoch : 0 [2554/21279] Train loss: 0.95716,Valid loss: 1.22087, time : 14.262469291687012 lr : 0.9509900498999999\n",
      "epoch : 0 [2555/21279] Train loss: 0.95716,Valid loss: 1.28622, time : 12.927931547164917 lr : 0.9509900498999999\n",
      "epoch : 0 [2556/21279] Train loss: 0.94533,Valid loss: 1.48884, time : 12.967152118682861 lr : 0.9509900498999999\n",
      "epoch : 0 [2557/21279] Train loss: 0.96400,Valid loss: 1.28371, time : 12.8238205909729 lr : 0.9509900498999999\n",
      "epoch : 0 [2558/21279] Train loss: 0.95397,Valid loss: 1.36624, time : 12.625012636184692 lr : 0.9509900498999999\n",
      "epoch : 0 [2559/21279] Train loss: 0.96644,Valid loss: 1.27279, time : 12.718366861343384 lr : 0.9509900498999999\n",
      "epoch : 0 [2560/21279] Train loss: 0.95181,Valid loss: 1.76020, time : 12.95330262184143 lr : 0.9509900498999999\n",
      "epoch : 0 [2561/21279] Train loss: 0.98102,Valid loss: 1.44689, time : 12.688025951385498 lr : 0.9509900498999999\n",
      "epoch : 0 [2562/21279] Train loss: 0.96003,Valid loss: 1.53053, time : 12.694077968597412 lr : 0.9509900498999999\n",
      "epoch : 0 [2563/21279] Train loss: 0.92904,Valid loss: 1.31956, time : 12.663032293319702 lr : 0.9509900498999999\n",
      "epoch : 0 [2564/21279] Train loss: 0.95004,Valid loss: 1.74279, time : 12.81494665145874 lr : 0.9509900498999999\n",
      "epoch : 0 [2565/21279] Train loss: 0.99176,Valid loss: 2.06233, time : 12.752071380615234 lr : 0.9509900498999999\n",
      "epoch : 0 [2566/21279] Train loss: 0.99055,Valid loss: 1.47163, time : 14.617431163787842 lr : 0.9509900498999999\n",
      "epoch : 0 [2567/21279] Train loss: 1.00409,Valid loss: 1.73747, time : 12.71898603439331 lr : 0.9509900498999999\n",
      "epoch : 0 [2568/21279] Train loss: 1.03114,Valid loss: 1.58769, time : 12.964739561080933 lr : 0.9509900498999999\n",
      "epoch : 0 [2569/21279] Train loss: 0.96541,Valid loss: 1.44352, time : 12.428256511688232 lr : 0.9509900498999999\n",
      "epoch : 0 [2570/21279] Train loss: 0.94849,Valid loss: 1.33399, time : 12.81258773803711 lr : 0.9509900498999999\n",
      "epoch : 0 [2571/21279] Train loss: 0.91974,Valid loss: 1.51968, time : 12.747710227966309 lr : 0.9509900498999999\n",
      "epoch : 0 [2572/21279] Train loss: 0.92008,Valid loss: 1.08242, time : 12.563447713851929 lr : 0.9509900498999999\n",
      "epoch : 0 [2573/21279] Train loss: 0.93450,Valid loss: 1.35634, time : 12.395980834960938 lr : 0.9509900498999999\n",
      "epoch : 0 [2574/21279] Train loss: 0.93696,Valid loss: 1.24243, time : 12.72075366973877 lr : 0.9509900498999999\n",
      "epoch : 0 [2575/21279] Train loss: 0.92196,Valid loss: 1.29217, time : 12.747904539108276 lr : 0.9509900498999999\n",
      "epoch : 0 [2576/21279] Train loss: 0.93776,Valid loss: 1.41560, time : 12.908779859542847 lr : 0.9509900498999999\n",
      "epoch : 0 [2577/21279] Train loss: 0.92253,Valid loss: 1.39469, time : 12.560397148132324 lr : 0.9509900498999999\n",
      "epoch : 0 [2578/21279] Train loss: 0.92151,Valid loss: 1.29695, time : 12.940056085586548 lr : 0.9509900498999999\n",
      "epoch : 0 [2579/21279] Train loss: 0.93696,Valid loss: 1.29040, time : 12.6371910572052 lr : 0.9509900498999999\n",
      "epoch : 0 [2580/21279] Train loss: 0.94181,Valid loss: 1.33763, time : 14.996248006820679 lr : 0.9509900498999999\n",
      "epoch : 0 [2581/21279] Train loss: 0.96460,Valid loss: 1.30969, time : 12.778019905090332 lr : 0.9509900498999999\n",
      "epoch : 0 [2582/21279] Train loss: 0.90343,Valid loss: 1.45841, time : 12.446194887161255 lr : 0.9509900498999999\n",
      "epoch : 0 [2583/21279] Train loss: 0.91971,Valid loss: 1.55268, time : 12.529574632644653 lr : 0.9509900498999999\n",
      "epoch : 0 [2584/21279] Train loss: 0.94168,Valid loss: 1.42520, time : 12.83713698387146 lr : 0.9509900498999999\n",
      "epoch : 0 [2585/21279] Train loss: 0.93816,Valid loss: 1.27991, time : 12.967843055725098 lr : 0.9509900498999999\n",
      "epoch : 0 [2586/21279] Train loss: 0.94122,Valid loss: 1.46580, time : 12.004201173782349 lr : 0.9509900498999999\n",
      "epoch : 0 [2587/21279] Train loss: 0.93042,Valid loss: 1.43577, time : 12.676889181137085 lr : 0.9509900498999999\n",
      "epoch : 0 [2588/21279] Train loss: 0.89021,Valid loss: 1.32902, time : 12.14817762374878 lr : 0.9509900498999999\n",
      "epoch : 0 [2589/21279] Train loss: 0.94027,Valid loss: 1.30276, time : 12.528558492660522 lr : 0.9509900498999999\n",
      "epoch : 0 [2590/21279] Train loss: 0.90394,Valid loss: 1.16249, time : 11.795233249664307 lr : 0.9509900498999999\n",
      "epoch : 0 [2591/21279] Train loss: 0.91631,Valid loss: 1.45950, time : 12.45177412033081 lr : 0.9509900498999999\n",
      "epoch : 0 [2592/21279] Train loss: 0.93530,Valid loss: 1.26716, time : 20.450565099716187 lr : 0.9509900498999999\n",
      "epoch : 0 [2593/21279] Train loss: 0.93427,Valid loss: 1.11039, time : 12.357701778411865 lr : 0.9509900498999999\n",
      "epoch : 0 [2594/21279] Train loss: 0.93620,Valid loss: 1.50353, time : 12.576032161712646 lr : 0.9509900498999999\n",
      "epoch : 0 [2595/21279] Train loss: 0.91250,Valid loss: 1.96818, time : 12.255999565124512 lr : 0.9509900498999999\n",
      "epoch : 0 [2596/21279] Train loss: 1.07423,Valid loss: 1.38468, time : 13.145160913467407 lr : 0.9509900498999999\n",
      "epoch : 0 [2597/21279] Train loss: 0.94030,Valid loss: 1.46797, time : 12.895045280456543 lr : 0.9509900498999999\n",
      "epoch : 0 [2598/21279] Train loss: 0.95351,Valid loss: 1.43624, time : 11.99656891822815 lr : 0.9509900498999999\n",
      "epoch : 0 [2599/21279] Train loss: 0.93982,Valid loss: 1.41440, time : 11.795426368713379 lr : 0.9509900498999999\n",
      "epoch : 0 [2600/21279] Train loss: 0.90993,Valid loss: 1.43419, time : 12.544306755065918 lr : 0.9509900498999999\n",
      "epoch : 0 [2601/21279] Train loss: 0.89291,Valid loss: 1.25625, time : 12.618745565414429 lr : 0.9509900498999999\n",
      "epoch : 0 [2602/21279] Train loss: 0.91618,Valid loss: 1.30887, time : 12.4548819065094 lr : 0.9509900498999999\n",
      "epoch : 0 [2603/21279] Train loss: 0.89079,Valid loss: 1.22302, time : 12.048917770385742 lr : 0.9509900498999999\n",
      "epoch : 0 [2604/21279] Train loss: 0.91934,Valid loss: 1.20463, time : 11.840650796890259 lr : 0.9509900498999999\n",
      "epoch : 0 [2605/21279] Train loss: 0.91000,Valid loss: 1.29442, time : 12.35952353477478 lr : 0.9509900498999999\n",
      "epoch : 0 [2606/21279] Train loss: 0.96979,Valid loss: 1.35307, time : 12.737584829330444 lr : 0.9509900498999999\n",
      "epoch : 0 [2607/21279] Train loss: 0.99968,Valid loss: 3.83561, time : 12.880092144012451 lr : 0.9509900498999999\n",
      "epoch : 0 [2608/21279] Train loss: 1.00815,Valid loss: 2.10492, time : 14.846900939941406 lr : 0.9509900498999999\n",
      "epoch : 0 [2609/21279] Train loss: 1.12455,Valid loss: 8.59941, time : 12.749243259429932 lr : 0.9509900498999999\n",
      "epoch : 0 [2610/21279] Train loss: 1.31809,Valid loss: 4.84356, time : 12.632052183151245 lr : 0.9509900498999999\n",
      "epoch : 0 [2611/21279] Train loss: 2.07421,Valid loss: 8.09165, time : 12.572998762130737 lr : 0.9509900498999999\n",
      "epoch : 0 [2612/21279] Train loss: 1.91419,Valid loss: 3.86360, time : 12.290460586547852 lr : 0.9509900498999999\n",
      "epoch : 0 [2613/21279] Train loss: 1.07996,Valid loss: 2.39131, time : 13.087162017822266 lr : 0.9509900498999999\n",
      "epoch : 0 [2614/21279] Train loss: 1.08985,Valid loss: 2.11899, time : 12.405730485916138 lr : 0.9509900498999999\n",
      "epoch : 0 [2615/21279] Train loss: 1.14488,Valid loss: 1.94781, time : 12.717824697494507 lr : 0.9509900498999999\n",
      "epoch : 0 [2616/21279] Train loss: 1.01499,Valid loss: 1.65547, time : 12.650209188461304 lr : 0.9509900498999999\n",
      "epoch : 0 [2617/21279] Train loss: 0.99139,Valid loss: 1.71218, time : 12.970081806182861 lr : 0.9509900498999999\n",
      "epoch : 0 [2618/21279] Train loss: 1.00274,Valid loss: 1.31011, time : 13.010687828063965 lr : 0.9509900498999999\n",
      "epoch : 0 [2619/21279] Train loss: 0.98824,Valid loss: 1.28753, time : 12.29591417312622 lr : 0.9509900498999999\n",
      "epoch : 0 [2620/21279] Train loss: 0.94961,Valid loss: 1.20125, time : 16.852590084075928 lr : 0.9509900498999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2621/21279] Train loss: 0.91586,Valid loss: 1.26117, time : 12.346925735473633 lr : 0.9509900498999999\n",
      "epoch : 0 [2622/21279] Train loss: 0.89861,Valid loss: 1.21834, time : 12.726922512054443 lr : 0.9509900498999999\n",
      "epoch : 0 [2623/21279] Train loss: 0.92788,Valid loss: 1.52056, time : 12.653240203857422 lr : 0.9509900498999999\n",
      "epoch : 0 [2624/21279] Train loss: 0.91917,Valid loss: 1.28499, time : 12.389906167984009 lr : 0.9509900498999999\n",
      "epoch : 0 [2625/21279] Train loss: 0.94026,Valid loss: 1.24179, time : 12.53123950958252 lr : 0.9509900498999999\n",
      "epoch : 0 [2626/21279] Train loss: 0.95994,Valid loss: 1.85515, time : 12.418903112411499 lr : 0.9509900498999999\n",
      "epoch : 0 [2627/21279] Train loss: 1.23805,Valid loss: 1.83093, time : 12.84696340560913 lr : 0.9509900498999999\n",
      "epoch : 0 [2628/21279] Train loss: 1.29892,Valid loss: 1.98099, time : 12.827715396881104 lr : 0.9509900498999999\n",
      "epoch : 0 [2629/21279] Train loss: 1.24199,Valid loss: 1.66519, time : 12.85149073600769 lr : 0.9509900498999999\n",
      "epoch : 0 [2630/21279] Train loss: 1.03980,Valid loss: 1.49044, time : 12.661738395690918 lr : 0.9509900498999999\n",
      "epoch : 0 [2631/21279] Train loss: 1.03348,Valid loss: 1.21008, time : 12.768033742904663 lr : 0.9509900498999999\n",
      "epoch : 0 [2632/21279] Train loss: 0.95225,Valid loss: 1.22266, time : 13.034468412399292 lr : 0.9509900498999999\n",
      "epoch : 0 [2633/21279] Train loss: 0.90768,Valid loss: 1.18090, time : 12.901723384857178 lr : 0.9509900498999999\n",
      "epoch : 0 [2634/21279] Train loss: 0.91491,Valid loss: 1.15983, time : 12.953727960586548 lr : 0.9509900498999999\n",
      "epoch : 0 [2635/21279] Train loss: 0.86190,Valid loss: 1.08695, time : 12.439297914505005 lr : 0.9509900498999999\n",
      "epoch : 0 [2636/21279] Train loss: 0.87014,Valid loss: 1.11227, time : 13.978021144866943 lr : 0.9509900498999999\n",
      "epoch : 0 [2637/21279] Train loss: 0.88165,Valid loss: 1.17693, time : 11.992655038833618 lr : 0.9509900498999999\n",
      "epoch : 0 [2638/21279] Train loss: 0.86300,Valid loss: 1.20131, time : 11.639039993286133 lr : 0.9509900498999999\n",
      "epoch : 0 [2639/21279] Train loss: 0.88207,Valid loss: 1.16007, time : 12.031935930252075 lr : 0.9509900498999999\n",
      "epoch : 0 [2640/21279] Train loss: 0.85636,Valid loss: 1.19224, time : 12.726596355438232 lr : 0.9509900498999999\n",
      "epoch : 0 [2641/21279] Train loss: 0.89284,Valid loss: 1.22643, time : 12.270090103149414 lr : 0.9509900498999999\n",
      "epoch : 0 [2642/21279] Train loss: 0.87369,Valid loss: 1.24785, time : 12.1218740940094 lr : 0.9509900498999999\n",
      "epoch : 0 [2643/21279] Train loss: 0.86800,Valid loss: 1.12272, time : 12.630198001861572 lr : 0.9509900498999999\n",
      "epoch : 0 [2644/21279] Train loss: 0.87799,Valid loss: 1.18219, time : 12.109666347503662 lr : 0.9509900498999999\n",
      "epoch : 0 [2645/21279] Train loss: 0.90362,Valid loss: 1.15190, time : 12.244828462600708 lr : 0.9509900498999999\n",
      "epoch : 0 [2646/21279] Train loss: 0.85999,Valid loss: 1.26803, time : 12.718106985092163 lr : 0.9509900498999999\n",
      "epoch : 0 [2647/21279] Train loss: 0.86640,Valid loss: 1.14871, time : 12.48101806640625 lr : 0.9509900498999999\n",
      "epoch : 0 [2648/21279] Train loss: 0.89384,Valid loss: 1.28484, time : 12.290282249450684 lr : 0.9509900498999999\n",
      "epoch : 0 [2649/21279] Train loss: 0.85578,Valid loss: 1.27583, time : 14.263680219650269 lr : 0.9509900498999999\n",
      "epoch : 0 [2650/21279] Train loss: 0.87004,Valid loss: 1.28176, time : 12.345740556716919 lr : 0.9509900498999999\n",
      "epoch : 0 [2651/21279] Train loss: 0.88058,Valid loss: 1.32748, time : 11.6658616065979 lr : 0.9509900498999999\n",
      "epoch : 0 [2652/21279] Train loss: 0.88118,Valid loss: 1.18580, time : 12.250010967254639 lr : 0.9509900498999999\n",
      "epoch : 0 [2653/21279] Train loss: 0.85315,Valid loss: 1.42845, time : 12.231775999069214 lr : 0.9509900498999999\n",
      "epoch : 0 [2654/21279] Train loss: 0.87236,Valid loss: 1.13697, time : 12.340444326400757 lr : 0.9509900498999999\n",
      "epoch : 0 [2655/21279] Train loss: 0.84948,Valid loss: 1.21132, time : 11.533095836639404 lr : 0.9509900498999999\n",
      "epoch : 0 [2656/21279] Train loss: 0.90209,Valid loss: 1.27110, time : 11.786210775375366 lr : 0.9509900498999999\n",
      "epoch : 0 [2657/21279] Train loss: 0.84559,Valid loss: 1.19163, time : 12.663955450057983 lr : 0.9509900498999999\n",
      "epoch : 0 [2658/21279] Train loss: 0.90171,Valid loss: 1.17144, time : 11.979110956192017 lr : 0.9509900498999999\n",
      "epoch : 0 [2659/21279] Train loss: 0.87195,Valid loss: 1.29468, time : 11.368922472000122 lr : 0.9509900498999999\n",
      "epoch : 0 [2660/21279] Train loss: 0.85201,Valid loss: 1.18730, time : 11.997119665145874 lr : 0.9509900498999999\n",
      "epoch : 0 [2661/21279] Train loss: 0.85631,Valid loss: 1.11994, time : 12.061725616455078 lr : 0.9509900498999999\n",
      "epoch : 0 [2662/21279] Train loss: 0.88303,Valid loss: 1.36846, time : 12.74024248123169 lr : 0.9509900498999999\n",
      "epoch : 0 [2663/21279] Train loss: 0.89816,Valid loss: 1.36809, time : 12.059088230133057 lr : 0.9509900498999999\n",
      "epoch : 0 [2664/21279] Train loss: 0.93303,Valid loss: 1.45025, time : 15.416350603103638 lr : 0.9509900498999999\n",
      "epoch : 0 [2665/21279] Train loss: 0.91079,Valid loss: 1.11935, time : 11.837702751159668 lr : 0.9509900498999999\n",
      "epoch : 0 [2666/21279] Train loss: 0.90246,Valid loss: 1.27961, time : 12.154338836669922 lr : 0.9509900498999999\n",
      "epoch : 0 [2667/21279] Train loss: 0.89740,Valid loss: 1.42435, time : 11.91333556175232 lr : 0.9509900498999999\n",
      "epoch : 0 [2668/21279] Train loss: 0.89904,Valid loss: 1.46309, time : 12.449060440063477 lr : 0.9509900498999999\n",
      "epoch : 0 [2669/21279] Train loss: 0.89345,Valid loss: 1.33327, time : 12.038039207458496 lr : 0.9509900498999999\n",
      "epoch : 0 [2670/21279] Train loss: 0.86926,Valid loss: 1.32699, time : 12.9356369972229 lr : 0.9509900498999999\n",
      "epoch : 0 [2671/21279] Train loss: 0.82739,Valid loss: 1.37811, time : 13.227551221847534 lr : 0.9509900498999999\n",
      "epoch : 0 [2672/21279] Train loss: 0.89340,Valid loss: 1.39667, time : 12.75518798828125 lr : 0.9509900498999999\n",
      "epoch : 0 [2673/21279] Train loss: 0.84730,Valid loss: 1.33547, time : 12.739295482635498 lr : 0.9509900498999999\n",
      "epoch : 0 [2674/21279] Train loss: 0.85707,Valid loss: 1.47847, time : 13.433834791183472 lr : 0.9509900498999999\n",
      "epoch : 0 [2675/21279] Train loss: 0.86571,Valid loss: 1.43611, time : 13.487736463546753 lr : 0.9509900498999999\n",
      "epoch : 0 [2676/21279] Train loss: 0.85099,Valid loss: 1.77824, time : 15.507148027420044 lr : 0.9509900498999999\n",
      "epoch : 0 [2677/21279] Train loss: 0.86701,Valid loss: 1.47649, time : 12.454154968261719 lr : 0.9509900498999999\n",
      "epoch : 0 [2678/21279] Train loss: 0.84340,Valid loss: 1.49949, time : 12.625679016113281 lr : 0.9509900498999999\n",
      "epoch : 0 [2679/21279] Train loss: 0.86096,Valid loss: 1.18516, time : 12.48839807510376 lr : 0.9509900498999999\n",
      "epoch : 0 [2680/21279] Train loss: 0.85777,Valid loss: 1.49088, time : 12.565322637557983 lr : 0.9509900498999999\n",
      "epoch : 0 [2681/21279] Train loss: 0.85139,Valid loss: 1.14609, time : 12.794996738433838 lr : 0.9509900498999999\n",
      "epoch : 0 [2682/21279] Train loss: 0.82852,Valid loss: 1.27870, time : 12.56507396697998 lr : 0.9509900498999999\n",
      "epoch : 0 [2683/21279] Train loss: 0.83715,Valid loss: 1.29580, time : 12.818035364151001 lr : 0.9509900498999999\n",
      "epoch : 0 [2684/21279] Train loss: 0.86276,Valid loss: 1.40707, time : 13.1798677444458 lr : 0.9509900498999999\n",
      "epoch : 0 [2685/21279] Train loss: 0.82511,Valid loss: 1.17863, time : 12.48307728767395 lr : 0.9509900498999999\n",
      "epoch : 0 [2686/21279] Train loss: 0.86797,Valid loss: 1.40639, time : 12.5520601272583 lr : 0.9509900498999999\n",
      "epoch : 0 [2687/21279] Train loss: 0.87139,Valid loss: 1.22870, time : 12.628467321395874 lr : 0.9509900498999999\n",
      "epoch : 0 [2688/21279] Train loss: 0.88138,Valid loss: 1.46205, time : 12.981716394424438 lr : 0.9509900498999999\n",
      "epoch : 0 [2689/21279] Train loss: 0.86109,Valid loss: 1.42882, time : 12.32103705406189 lr : 0.9509900498999999\n",
      "epoch : 0 [2690/21279] Train loss: 0.87251,Valid loss: 1.24441, time : 19.008551359176636 lr : 0.9509900498999999\n",
      "epoch : 0 [2691/21279] Train loss: 0.87835,Valid loss: 1.35337, time : 12.258246660232544 lr : 0.9509900498999999\n",
      "epoch : 0 [2692/21279] Train loss: 0.91108,Valid loss: 2.56530, time : 13.015972137451172 lr : 0.9509900498999999\n",
      "epoch : 0 [2693/21279] Train loss: 1.47754,Valid loss: 2.28345, time : 12.745439052581787 lr : 0.9509900498999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2694/21279] Train loss: 1.61849,Valid loss: 3.40239, time : 12.815024852752686 lr : 0.9509900498999999\n",
      "epoch : 0 [2695/21279] Train loss: 1.32153,Valid loss: 1.83090, time : 13.082966089248657 lr : 0.9509900498999999\n",
      "epoch : 0 [2696/21279] Train loss: 0.99960,Valid loss: 1.91937, time : 11.366324424743652 lr : 0.9509900498999999\n",
      "epoch : 0 [2697/21279] Train loss: 1.06602,Valid loss: 1.66228, time : 11.714917659759521 lr : 0.9509900498999999\n",
      "epoch : 0 [2698/21279] Train loss: 1.07708,Valid loss: 1.72795, time : 12.387201309204102 lr : 0.9509900498999999\n",
      "epoch : 0 [2699/21279] Train loss: 1.02692,Valid loss: 2.39895, time : 12.751849889755249 lr : 0.9509900498999999\n",
      "epoch : 0 [2700/21279] Train loss: 1.07242,Valid loss: 2.05176, time : 12.442394733428955 lr : 0.9509900498999999\n",
      "epoch : 0 [2701/21279] Train loss: 0.95346,Valid loss: 1.56135, time : 12.695178747177124 lr : 0.9509900498999999\n",
      "epoch : 0 [2702/21279] Train loss: 0.95403,Valid loss: 1.44206, time : 14.87740969657898 lr : 0.9509900498999999\n",
      "epoch : 0 [2703/21279] Train loss: 0.90868,Valid loss: 1.38230, time : 12.841110706329346 lr : 0.9509900498999999\n",
      "epoch : 0 [2704/21279] Train loss: 0.90919,Valid loss: 1.52457, time : 12.217693567276001 lr : 0.9509900498999999\n",
      "epoch : 0 [2705/21279] Train loss: 0.91024,Valid loss: 1.42911, time : 12.758557796478271 lr : 0.9509900498999999\n",
      "epoch : 0 [2706/21279] Train loss: 0.89505,Valid loss: 1.75916, time : 12.207895040512085 lr : 0.9509900498999999\n",
      "epoch : 0 [2707/21279] Train loss: 0.88160,Valid loss: 1.44996, time : 13.086170673370361 lr : 0.9509900498999999\n",
      "epoch : 0 [2708/21279] Train loss: 0.84907,Valid loss: 1.16701, time : 12.416276693344116 lr : 0.9509900498999999\n",
      "epoch : 0 [2709/21279] Train loss: 0.83161,Valid loss: 1.12866, time : 12.220841884613037 lr : 0.9509900498999999\n",
      "epoch : 0 [2710/21279] Train loss: 0.81879,Valid loss: 1.25705, time : 12.532280683517456 lr : 0.9509900498999999\n",
      "epoch : 0 [2711/21279] Train loss: 0.83728,Valid loss: 1.05047, time : 11.827619552612305 lr : 0.9509900498999999\n",
      "epoch : 0 [2712/21279] Train loss: 0.82903,Valid loss: 1.14189, time : 12.15906572341919 lr : 0.9509900498999999\n",
      "epoch : 0 [2713/21279] Train loss: 0.80708,Valid loss: 1.40562, time : 12.278183937072754 lr : 0.9509900498999999\n",
      "epoch : 0 [2714/21279] Train loss: 0.87729,Valid loss: 1.34451, time : 12.297998189926147 lr : 0.9509900498999999\n",
      "epoch : 0 [2715/21279] Train loss: 1.06577,Valid loss: 2.17686, time : 12.398682832717896 lr : 0.9509900498999999\n",
      "epoch : 0 [2716/21279] Train loss: 1.26807,Valid loss: 1.49075, time : 12.760408878326416 lr : 0.9509900498999999\n",
      "epoch : 0 [2717/21279] Train loss: 0.96097,Valid loss: 1.38248, time : 12.789111375808716 lr : 0.9509900498999999\n",
      "epoch : 0 [2718/21279] Train loss: 0.88624,Valid loss: 1.20193, time : 14.736345291137695 lr : 0.9509900498999999\n",
      "epoch : 0 [2719/21279] Train loss: 0.84750,Valid loss: 1.20437, time : 12.323236227035522 lr : 0.9509900498999999\n",
      "epoch : 0 [2720/21279] Train loss: 0.83205,Valid loss: 1.17009, time : 12.247193574905396 lr : 0.9509900498999999\n",
      "epoch : 0 [2721/21279] Train loss: 0.79226,Valid loss: 1.23016, time : 11.847965717315674 lr : 0.9509900498999999\n",
      "epoch : 0 [2722/21279] Train loss: 0.82778,Valid loss: 1.13494, time : 12.407890319824219 lr : 0.9509900498999999\n",
      "epoch : 0 [2723/21279] Train loss: 0.82496,Valid loss: 1.08858, time : 11.663561344146729 lr : 0.9509900498999999\n",
      "epoch : 0 [2724/21279] Train loss: 0.83629,Valid loss: 1.12837, time : 11.907099485397339 lr : 0.9509900498999999\n",
      "epoch : 0 [2725/21279] Train loss: 0.83130,Valid loss: 1.03630, time : 12.074753284454346 lr : 0.9509900498999999\n",
      "epoch : 0 [2726/21279] Train loss: 0.84408,Valid loss: 1.07288, time : 11.693146705627441 lr : 0.9509900498999999\n",
      "epoch : 0 [2727/21279] Train loss: 0.82989,Valid loss: 1.01370, time : 11.939939498901367 lr : 0.9509900498999999\n",
      "epoch : 0 [2728/21279] Train loss: 0.82289,Valid loss: 1.01392, time : 12.42989468574524 lr : 0.9509900498999999\n",
      "epoch : 0 [2729/21279] Train loss: 0.82316,Valid loss: 1.45746, time : 12.39661717414856 lr : 0.9509900498999999\n",
      "epoch : 0 [2730/21279] Train loss: 0.93752,Valid loss: 3.41054, time : 15.282041072845459 lr : 0.9509900498999999\n",
      "epoch : 0 [2731/21279] Train loss: 1.27341,Valid loss: 2.16809, time : 12.099271535873413 lr : 0.9509900498999999\n",
      "epoch : 0 [2732/21279] Train loss: 0.97120,Valid loss: 1.38544, time : 12.169121265411377 lr : 0.9509900498999999\n",
      "epoch : 0 [2733/21279] Train loss: 0.93977,Valid loss: 1.58133, time : 12.67710256576538 lr : 0.9509900498999999\n",
      "epoch : 0 [2734/21279] Train loss: 0.88422,Valid loss: 1.25591, time : 12.021094799041748 lr : 0.9509900498999999\n",
      "epoch : 0 [2735/21279] Train loss: 0.87944,Valid loss: 1.29829, time : 12.023327827453613 lr : 0.9509900498999999\n",
      "epoch : 0 [2736/21279] Train loss: 0.84016,Valid loss: 1.14124, time : 11.497784614562988 lr : 0.9509900498999999\n",
      "epoch : 0 [2737/21279] Train loss: 0.86432,Valid loss: 1.32492, time : 12.173863887786865 lr : 0.9509900498999999\n",
      "epoch : 0 [2738/21279] Train loss: 0.84993,Valid loss: 1.36021, time : 12.269101858139038 lr : 0.9509900498999999\n",
      "epoch : 0 [2739/21279] Train loss: 0.84147,Valid loss: 1.41662, time : 12.75191855430603 lr : 0.9509900498999999\n",
      "epoch : 0 [2740/21279] Train loss: 0.83306,Valid loss: 1.20772, time : 12.10739254951477 lr : 0.9509900498999999\n",
      "epoch : 0 [2741/21279] Train loss: 0.82877,Valid loss: 1.38089, time : 12.279796361923218 lr : 0.9509900498999999\n",
      "epoch : 0 [2742/21279] Train loss: 0.81824,Valid loss: 1.16532, time : 12.343676090240479 lr : 0.9509900498999999\n",
      "epoch : 0 [2743/21279] Train loss: 0.81110,Valid loss: 1.22895, time : 12.842267513275146 lr : 0.9509900498999999\n",
      "epoch : 0 [2744/21279] Train loss: 0.82477,Valid loss: 1.14355, time : 12.90957236289978 lr : 0.9509900498999999\n",
      "epoch : 0 [2745/21279] Train loss: 0.79733,Valid loss: 1.08506, time : 12.360743761062622 lr : 0.9509900498999999\n",
      "epoch : 0 [2746/21279] Train loss: 0.80963,Valid loss: 1.12694, time : 14.226871013641357 lr : 0.9509900498999999\n",
      "epoch : 0 [2747/21279] Train loss: 0.83861,Valid loss: 1.21792, time : 12.046416997909546 lr : 0.9509900498999999\n",
      "epoch : 0 [2748/21279] Train loss: 0.81361,Valid loss: 1.31374, time : 11.716522216796875 lr : 0.9509900498999999\n",
      "epoch : 0 [2749/21279] Train loss: 0.81993,Valid loss: 1.08503, time : 11.791059970855713 lr : 0.9509900498999999\n",
      "epoch : 0 [2750/21279] Train loss: 0.83091,Valid loss: 1.50267, time : 11.89278769493103 lr : 0.9509900498999999\n",
      "epoch : 0 [2751/21279] Train loss: 0.81963,Valid loss: 1.44516, time : 12.224470376968384 lr : 0.9509900498999999\n",
      "epoch : 0 [2752/21279] Train loss: 0.85812,Valid loss: 1.25266, time : 12.479448795318604 lr : 0.9509900498999999\n",
      "epoch : 0 [2753/21279] Train loss: 0.79565,Valid loss: 1.34760, time : 12.21188735961914 lr : 0.9509900498999999\n",
      "epoch : 0 [2754/21279] Train loss: 0.84300,Valid loss: 1.30511, time : 12.865925073623657 lr : 0.9509900498999999\n",
      "epoch : 0 [2755/21279] Train loss: 0.82340,Valid loss: 1.22779, time : 12.560377597808838 lr : 0.9509900498999999\n",
      "epoch : 0 [2756/21279] Train loss: 0.83620,Valid loss: 1.24206, time : 12.908544540405273 lr : 0.9509900498999999\n",
      "epoch : 0 [2757/21279] Train loss: 0.82176,Valid loss: 1.17601, time : 13.159526586532593 lr : 0.9509900498999999\n",
      "epoch : 0 [2758/21279] Train loss: 0.80508,Valid loss: 1.27720, time : 12.850397825241089 lr : 0.9509900498999999\n",
      "epoch : 0 [2759/21279] Train loss: 0.82082,Valid loss: 1.20752, time : 14.161126375198364 lr : 0.9509900498999999\n",
      "epoch : 0 [2760/21279] Train loss: 0.85828,Valid loss: 1.69173, time : 12.560421466827393 lr : 0.9509900498999999\n",
      "epoch : 0 [2761/21279] Train loss: 0.85459,Valid loss: 1.54432, time : 13.009258031845093 lr : 0.9509900498999999\n",
      "epoch : 0 [2762/21279] Train loss: 0.87329,Valid loss: 1.16144, time : 12.315557479858398 lr : 0.9509900498999999\n",
      "epoch : 0 [2763/21279] Train loss: 0.79658,Valid loss: 1.01770, time : 12.99687671661377 lr : 0.9509900498999999\n",
      "epoch : 0 [2764/21279] Train loss: 0.79165,Valid loss: 1.15246, time : 12.694782018661499 lr : 0.9509900498999999\n",
      "epoch : 0 [2765/21279] Train loss: 0.78067,Valid loss: 1.24951, time : 12.654749870300293 lr : 0.9509900498999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2766/21279] Train loss: 0.81351,Valid loss: 1.07290, time : 12.17188549041748 lr : 0.9509900498999999\n",
      "epoch : 0 [2767/21279] Train loss: 0.79328,Valid loss: 1.44940, time : 12.24856448173523 lr : 0.9509900498999999\n",
      "epoch : 0 [2768/21279] Train loss: 0.82309,Valid loss: 5.64332, time : 12.691197156906128 lr : 0.9509900498999999\n",
      "epoch : 0 [2769/21279] Train loss: 0.88607,Valid loss: 1.27008, time : 12.973433494567871 lr : 0.9509900498999999\n",
      "epoch : 0 [2770/21279] Train loss: 0.91631,Valid loss: 1.72349, time : 12.463257789611816 lr : 0.9509900498999999\n",
      "epoch : 0 [2771/21279] Train loss: 0.80149,Valid loss: 1.38800, time : 12.762433528900146 lr : 0.9509900498999999\n",
      "epoch : 0 [2772/21279] Train loss: 0.80021,Valid loss: 1.48116, time : 12.679940700531006 lr : 0.9509900498999999\n",
      "epoch : 0 [2773/21279] Train loss: 0.80179,Valid loss: 1.37692, time : 12.60569143295288 lr : 0.9509900498999999\n",
      "epoch : 0 [2774/21279] Train loss: 0.81622,Valid loss: 1.31337, time : 14.869816303253174 lr : 0.9509900498999999\n",
      "epoch : 0 [2775/21279] Train loss: 0.81336,Valid loss: 1.15804, time : 12.94909954071045 lr : 0.9509900498999999\n",
      "epoch : 0 [2776/21279] Train loss: 0.83779,Valid loss: 1.30455, time : 12.633245706558228 lr : 0.9509900498999999\n",
      "epoch : 0 [2777/21279] Train loss: 0.84429,Valid loss: 1.41760, time : 12.708909273147583 lr : 0.9509900498999999\n",
      "epoch : 0 [2778/21279] Train loss: 0.85231,Valid loss: 1.36655, time : 12.496142625808716 lr : 0.9509900498999999\n",
      "epoch : 0 [2779/21279] Train loss: 0.87243,Valid loss: 1.37277, time : 13.028337717056274 lr : 0.9509900498999999\n",
      "epoch : 0 [2780/21279] Train loss: 0.83279,Valid loss: 1.22640, time : 13.052969455718994 lr : 0.9509900498999999\n",
      "epoch : 0 [2781/21279] Train loss: 0.85758,Valid loss: 1.16294, time : 12.658315896987915 lr : 0.9509900498999999\n",
      "epoch : 0 [2782/21279] Train loss: 0.82104,Valid loss: 1.09952, time : 12.899408102035522 lr : 0.9509900498999999\n",
      "epoch : 0 [2783/21279] Train loss: 0.85522,Valid loss: 1.32785, time : 12.95847225189209 lr : 0.9509900498999999\n",
      "epoch : 0 [2784/21279] Train loss: 0.93688,Valid loss: 2.47408, time : 13.228889465332031 lr : 0.9509900498999999\n",
      "epoch : 0 [2785/21279] Train loss: 1.34861,Valid loss: 1.62113, time : 13.211828231811523 lr : 0.9509900498999999\n",
      "epoch : 0 [2786/21279] Train loss: 0.88510,Valid loss: 1.40636, time : 14.714845657348633 lr : 0.9509900498999999\n",
      "epoch : 0 [2787/21279] Train loss: 0.90880,Valid loss: 1.38924, time : 12.02853012084961 lr : 0.9509900498999999\n",
      "epoch : 0 [2788/21279] Train loss: 0.93864,Valid loss: 1.83825, time : 12.871718168258667 lr : 0.9509900498999999\n",
      "epoch : 0 [2789/21279] Train loss: 1.16564,Valid loss: 3.21597, time : 12.10770845413208 lr : 0.9509900498999999\n",
      "epoch : 0 [2790/21279] Train loss: 1.22139,Valid loss: 1.46237, time : 12.500741958618164 lr : 0.9509900498999999\n",
      "epoch : 0 [2791/21279] Train loss: 0.94573,Valid loss: 2.11296, time : 13.065041303634644 lr : 0.9509900498999999\n",
      "epoch : 0 [2792/21279] Train loss: 0.88843,Valid loss: 1.46180, time : 12.208457231521606 lr : 0.9509900498999999\n",
      "epoch : 0 [2793/21279] Train loss: 0.86068,Valid loss: 1.16300, time : 12.345664262771606 lr : 0.9509900498999999\n",
      "epoch : 0 [2794/21279] Train loss: 0.82937,Valid loss: 1.30356, time : 13.04603123664856 lr : 0.9509900498999999\n",
      "epoch : 0 [2795/21279] Train loss: 0.82901,Valid loss: 1.18526, time : 12.569118976593018 lr : 0.9509900498999999\n",
      "epoch : 0 [2796/21279] Train loss: 0.81466,Valid loss: 1.06768, time : 12.64695405960083 lr : 0.9509900498999999\n",
      "epoch : 0 [2797/21279] Train loss: 0.79748,Valid loss: 1.24394, time : 12.929156303405762 lr : 0.9509900498999999\n",
      "epoch : 0 [2798/21279] Train loss: 0.79690,Valid loss: 1.14376, time : 13.162399053573608 lr : 0.9509900498999999\n",
      "epoch : 0 [2799/21279] Train loss: 0.80541,Valid loss: 1.30616, time : 13.136750221252441 lr : 0.9509900498999999\n",
      "epoch : 0 [2800/21279] Train loss: 0.75747,Valid loss: 1.23519, time : 20.007502794265747 lr : 0.9509900498999999\n",
      "epoch : 0 [2801/21279] Train loss: 0.80090,Valid loss: 1.31528, time : 12.783807039260864 lr : 0.9509900498999999\n",
      "epoch : 0 [2802/21279] Train loss: 0.77086,Valid loss: 1.08935, time : 12.717012882232666 lr : 0.9509900498999999\n",
      "epoch : 0 [2803/21279] Train loss: 0.78909,Valid loss: 1.31492, time : 12.883045196533203 lr : 0.9509900498999999\n",
      "epoch : 0 [2804/21279] Train loss: 0.76323,Valid loss: 1.18187, time : 13.103853702545166 lr : 0.9509900498999999\n",
      "epoch : 0 [2805/21279] Train loss: 0.76588,Valid loss: 1.29284, time : 13.047397375106812 lr : 0.9509900498999999\n",
      "epoch : 0 [2806/21279] Train loss: 0.77526,Valid loss: 1.25613, time : 13.062044143676758 lr : 0.9509900498999999\n",
      "epoch : 0 [2807/21279] Train loss: 0.75289,Valid loss: 1.28147, time : 12.736407041549683 lr : 0.9509900498999999\n",
      "epoch : 0 [2808/21279] Train loss: 0.80817,Valid loss: 1.62070, time : 12.625632286071777 lr : 0.9509900498999999\n",
      "epoch : 0 [2809/21279] Train loss: 0.79965,Valid loss: 1.25056, time : 12.62159514427185 lr : 0.9509900498999999\n",
      "epoch : 0 [2810/21279] Train loss: 0.78581,Valid loss: 1.14156, time : 12.037906169891357 lr : 0.9509900498999999\n",
      "epoch : 0 [2811/21279] Train loss: 0.78399,Valid loss: 1.30037, time : 12.332422971725464 lr : 0.9509900498999999\n",
      "epoch : 0 [2812/21279] Train loss: 0.79474,Valid loss: 1.33724, time : 15.375331401824951 lr : 0.9509900498999999\n",
      "epoch : 0 [2813/21279] Train loss: 0.82710,Valid loss: 1.45314, time : 12.087559461593628 lr : 0.9509900498999999\n",
      "epoch : 0 [2814/21279] Train loss: 0.81368,Valid loss: 1.60308, time : 12.296094179153442 lr : 0.9509900498999999\n",
      "epoch : 0 [2815/21279] Train loss: 0.84288,Valid loss: 1.58339, time : 12.46462345123291 lr : 0.9509900498999999\n",
      "epoch : 0 [2816/21279] Train loss: 0.79643,Valid loss: 1.18562, time : 12.506568670272827 lr : 0.9509900498999999\n",
      "epoch : 0 [2817/21279] Train loss: 0.78301,Valid loss: 1.18382, time : 12.719274997711182 lr : 0.9509900498999999\n",
      "epoch : 0 [2818/21279] Train loss: 0.76831,Valid loss: 1.15914, time : 12.759472370147705 lr : 0.9509900498999999\n",
      "epoch : 0 [2819/21279] Train loss: 0.75040,Valid loss: 1.11852, time : 13.066038608551025 lr : 0.9509900498999999\n",
      "epoch : 0 [2820/21279] Train loss: 0.73735,Valid loss: 1.89872, time : 13.233778953552246 lr : 0.9509900498999999\n",
      "epoch : 0 [2821/21279] Train loss: 0.84524,Valid loss: 1.52392, time : 13.117055416107178 lr : 0.9509900498999999\n",
      "epoch : 0 [2822/21279] Train loss: 0.77424,Valid loss: 1.35213, time : 12.802044868469238 lr : 0.9509900498999999\n",
      "epoch : 0 [2823/21279] Train loss: 0.78105,Valid loss: 1.36839, time : 12.397472381591797 lr : 0.9509900498999999\n",
      "epoch : 0 [2824/21279] Train loss: 0.78981,Valid loss: 1.22487, time : 12.720509052276611 lr : 0.9509900498999999\n",
      "epoch : 0 [2825/21279] Train loss: 0.76853,Valid loss: 1.18802, time : 12.594421863555908 lr : 0.9509900498999999\n",
      "epoch : 0 [2826/21279] Train loss: 0.74611,Valid loss: 1.16297, time : 12.752055883407593 lr : 0.9509900498999999\n",
      "epoch : 0 [2827/21279] Train loss: 0.72835,Valid loss: 1.36768, time : 12.475576639175415 lr : 0.9509900498999999\n",
      "epoch : 0 [2828/21279] Train loss: 0.73526,Valid loss: 1.19537, time : 14.621450662612915 lr : 0.9509900498999999\n",
      "epoch : 0 [2829/21279] Train loss: 0.71105,Valid loss: 1.30272, time : 12.382875919342041 lr : 0.9509900498999999\n",
      "epoch : 0 [2830/21279] Train loss: 0.71522,Valid loss: 1.33297, time : 12.62610936164856 lr : 0.9509900498999999\n",
      "epoch : 0 [2831/21279] Train loss: 0.99936,Valid loss: 2.11246, time : 12.4850332736969 lr : 0.9509900498999999\n",
      "epoch : 0 [2832/21279] Train loss: 0.95815,Valid loss: 1.33428, time : 12.600942850112915 lr : 0.9509900498999999\n",
      "epoch : 0 [2833/21279] Train loss: 0.78796,Valid loss: 1.24953, time : 12.671881675720215 lr : 0.9509900498999999\n",
      "epoch : 0 [2834/21279] Train loss: 0.75154,Valid loss: 1.22334, time : 13.085936307907104 lr : 0.9509900498999999\n",
      "epoch : 0 [2835/21279] Train loss: 0.72285,Valid loss: 1.15513, time : 12.755703926086426 lr : 0.9509900498999999\n",
      "epoch : 0 [2836/21279] Train loss: 0.72368,Valid loss: 1.23894, time : 12.933712244033813 lr : 0.9509900498999999\n",
      "epoch : 0 [2837/21279] Train loss: 0.73354,Valid loss: 1.27168, time : 12.793956995010376 lr : 0.9509900498999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2838/21279] Train loss: 0.77537,Valid loss: 1.12601, time : 12.74875283241272 lr : 0.9509900498999999\n",
      "epoch : 0 [2839/21279] Train loss: 0.74571,Valid loss: 1.25576, time : 12.775610446929932 lr : 0.9509900498999999\n",
      "epoch : 0 [2840/21279] Train loss: 0.76546,Valid loss: 1.04632, time : 13.82476258277893 lr : 0.9509900498999999\n",
      "epoch : 0 [2841/21279] Train loss: 0.77664,Valid loss: 1.33196, time : 12.229522466659546 lr : 0.9509900498999999\n",
      "epoch : 0 [2842/21279] Train loss: 0.77431,Valid loss: 1.15467, time : 12.477795600891113 lr : 0.9509900498999999\n",
      "epoch : 0 [2843/21279] Train loss: 0.80079,Valid loss: 1.13480, time : 12.561350584030151 lr : 0.9509900498999999\n",
      "epoch : 0 [2844/21279] Train loss: 0.76283,Valid loss: 1.25399, time : 12.523926973342896 lr : 0.9509900498999999\n",
      "epoch : 0 [2845/21279] Train loss: 0.78229,Valid loss: 1.53821, time : 12.34049367904663 lr : 0.9509900498999999\n",
      "epoch : 0 [2846/21279] Train loss: 0.77586,Valid loss: 1.15629, time : 11.936272859573364 lr : 0.9509900498999999\n",
      "epoch : 0 [2847/21279] Train loss: 0.76024,Valid loss: 1.14068, time : 12.327289342880249 lr : 0.9509900498999999\n",
      "epoch : 0 [2848/21279] Train loss: 0.74394,Valid loss: 1.10571, time : 11.960987091064453 lr : 0.9509900498999999\n",
      "epoch : 0 [2849/21279] Train loss: 0.77223,Valid loss: 1.29531, time : 12.049907922744751 lr : 0.9509900498999999\n",
      "epoch : 0 [2850/21279] Train loss: 0.75267,Valid loss: 1.22521, time : 12.790491580963135 lr : 0.9509900498999999\n",
      "epoch : 0 [2851/21279] Train loss: 0.74119,Valid loss: 1.05540, time : 12.499056339263916 lr : 0.9509900498999999\n",
      "epoch : 0 [2852/21279] Train loss: 0.73430,Valid loss: 1.00457, time : 12.930233478546143 lr : 0.9509900498999999\n",
      "epoch : 0 [2853/21279] Train loss: 0.74725,Valid loss: 1.15678, time : 12.317508459091187 lr : 0.9509900498999999\n",
      "epoch : 0 [2854/21279] Train loss: 0.73681,Valid loss: 1.19368, time : 12.54192566871643 lr : 0.9509900498999999\n",
      "epoch : 0 [2855/21279] Train loss: 0.77794,Valid loss: 1.33276, time : 12.79042100906372 lr : 0.9509900498999999\n",
      "epoch : 0 [2856/21279] Train loss: 0.76492,Valid loss: 1.05863, time : 14.570116758346558 lr : 0.9509900498999999\n",
      "epoch : 0 [2857/21279] Train loss: 0.77703,Valid loss: 1.55351, time : 12.428194761276245 lr : 0.9509900498999999\n",
      "epoch : 0 [2858/21279] Train loss: 0.79288,Valid loss: 1.51837, time : 12.600004196166992 lr : 0.9509900498999999\n",
      "epoch : 0 [2859/21279] Train loss: 0.82226,Valid loss: 1.16159, time : 13.048866510391235 lr : 0.9509900498999999\n",
      "epoch : 0 [2860/21279] Train loss: 0.80429,Valid loss: 1.43801, time : 12.921160459518433 lr : 0.9509900498999999\n",
      "epoch : 0 [2861/21279] Train loss: 0.99768,Valid loss: 4.52770, time : 12.561800003051758 lr : 0.9509900498999999\n",
      "epoch : 0 [2862/21279] Train loss: 1.52044,Valid loss: 1.66489, time : 12.753231763839722 lr : 0.9509900498999999\n",
      "epoch : 0 [2863/21279] Train loss: 0.89376,Valid loss: 1.90736, time : 12.509544610977173 lr : 0.9509900498999999\n",
      "epoch : 0 [2864/21279] Train loss: 0.98536,Valid loss: 1.96262, time : 12.672982454299927 lr : 0.9509900498999999\n",
      "epoch : 0 [2865/21279] Train loss: 1.23834,Valid loss: 1.37414, time : 12.647505521774292 lr : 0.9509900498999999\n",
      "epoch : 0 [2866/21279] Train loss: 0.88811,Valid loss: 1.58626, time : 13.072295904159546 lr : 0.9509900498999999\n",
      "epoch : 0 [2867/21279] Train loss: 0.86132,Valid loss: 1.36561, time : 13.071712017059326 lr : 0.9509900498999999\n",
      "epoch : 0 [2868/21279] Train loss: 0.81390,Valid loss: 1.26486, time : 13.00545620918274 lr : 0.9509900498999999\n",
      "epoch : 0 [2869/21279] Train loss: 0.77615,Valid loss: 1.11426, time : 16.31826400756836 lr : 0.9509900498999999\n",
      "epoch : 0 [2870/21279] Train loss: 0.77499,Valid loss: 1.23865, time : 12.95984935760498 lr : 0.9509900498999999\n",
      "epoch : 0 [2871/21279] Train loss: 0.75054,Valid loss: 1.10794, time : 13.462746858596802 lr : 0.9509900498999999\n",
      "epoch : 0 [2872/21279] Train loss: 0.74301,Valid loss: 1.28747, time : 13.474190711975098 lr : 0.9509900498999999\n",
      "epoch : 0 [2873/21279] Train loss: 0.73425,Valid loss: 1.12069, time : 12.766376972198486 lr : 0.9509900498999999\n",
      "epoch : 0 [2874/21279] Train loss: 0.77723,Valid loss: 1.05749, time : 12.723742485046387 lr : 0.9509900498999999\n",
      "epoch : 0 [2875/21279] Train loss: 0.75492,Valid loss: 1.18462, time : 13.244008779525757 lr : 0.9509900498999999\n",
      "epoch : 0 [2876/21279] Train loss: 0.76790,Valid loss: 1.00967, time : 13.164301872253418 lr : 0.9509900498999999\n",
      "epoch : 0 [2877/21279] Train loss: 0.77629,Valid loss: 1.15962, time : 13.325860023498535 lr : 0.9509900498999999\n",
      "epoch : 0 [2878/21279] Train loss: 0.75833,Valid loss: 0.90248, time : 12.835624694824219 lr : 0.9509900498999999\n",
      "epoch : 0 [2879/21279] Train loss: 0.74754,Valid loss: 1.20009, time : 13.08171820640564 lr : 0.9509900498999999\n",
      "epoch : 0 [2880/21279] Train loss: 0.72210,Valid loss: 1.05954, time : 12.595690965652466 lr : 0.9509900498999999\n",
      "epoch : 0 [2881/21279] Train loss: 0.73367,Valid loss: 1.16673, time : 12.931461811065674 lr : 0.9509900498999999\n",
      "epoch : 0 [2882/21279] Train loss: 0.77749,Valid loss: 1.08784, time : 12.422861337661743 lr : 0.9509900498999999\n",
      "epoch : 0 [2883/21279] Train loss: 0.72897,Valid loss: 1.22206, time : 12.539860725402832 lr : 0.9509900498999999\n",
      "epoch : 0 [2884/21279] Train loss: 0.72597,Valid loss: 1.18640, time : 15.131605863571167 lr : 0.9509900498999999\n",
      "epoch : 0 [2885/21279] Train loss: 0.72589,Valid loss: 1.10795, time : 12.627782583236694 lr : 0.9509900498999999\n",
      "epoch : 0 [2886/21279] Train loss: 0.69989,Valid loss: 1.22753, time : 12.646304368972778 lr : 0.9509900498999999\n",
      "epoch : 0 [2887/21279] Train loss: 0.72433,Valid loss: 1.24010, time : 12.868777751922607 lr : 0.9509900498999999\n",
      "epoch : 0 [2888/21279] Train loss: 0.71388,Valid loss: 1.08998, time : 12.885067701339722 lr : 0.9509900498999999\n",
      "epoch : 0 [2889/21279] Train loss: 0.69675,Valid loss: 2.18905, time : 12.477771759033203 lr : 0.9509900498999999\n",
      "epoch : 0 [2890/21279] Train loss: 0.72991,Valid loss: 1.34849, time : 12.891700744628906 lr : 0.9509900498999999\n",
      "epoch : 0 [2891/21279] Train loss: 0.74130,Valid loss: 1.16150, time : 12.7031569480896 lr : 0.9509900498999999\n",
      "epoch : 0 [2892/21279] Train loss: 0.69842,Valid loss: 1.13657, time : 12.961601734161377 lr : 0.9509900498999999\n",
      "epoch : 0 [2893/21279] Train loss: 0.70442,Valid loss: 1.15783, time : 12.770121097564697 lr : 0.9509900498999999\n",
      "epoch : 0 [2894/21279] Train loss: 0.71338,Valid loss: 1.34991, time : 12.78906536102295 lr : 0.9509900498999999\n",
      "epoch : 0 [2895/21279] Train loss: 0.71215,Valid loss: 0.99823, time : 12.447925329208374 lr : 0.9509900498999999\n",
      "epoch : 0 [2896/21279] Train loss: 0.75039,Valid loss: 1.41782, time : 14.537733554840088 lr : 0.9509900498999999\n",
      "epoch : 0 [2897/21279] Train loss: 0.76325,Valid loss: 1.43633, time : 12.39844799041748 lr : 0.9509900498999999\n",
      "epoch : 0 [2898/21279] Train loss: 0.74379,Valid loss: 1.23042, time : 12.675854682922363 lr : 0.9509900498999999\n",
      "epoch : 0 [2899/21279] Train loss: 0.71921,Valid loss: 1.38722, time : 12.849249601364136 lr : 0.9509900498999999\n",
      "epoch : 0 [2900/21279] Train loss: 0.73551,Valid loss: 1.21643, time : 12.980325937271118 lr : 0.9509900498999999\n",
      "epoch : 0 [2901/21279] Train loss: 0.72896,Valid loss: 1.28409, time : 12.75896430015564 lr : 0.9509900498999999\n",
      "epoch : 0 [2902/21279] Train loss: 0.76130,Valid loss: 1.03653, time : 13.27479887008667 lr : 0.9509900498999999\n",
      "epoch : 0 [2903/21279] Train loss: 0.75139,Valid loss: 1.33394, time : 13.15355396270752 lr : 0.9509900498999999\n",
      "epoch : 0 [2904/21279] Train loss: 0.76248,Valid loss: 1.14429, time : 12.928279876708984 lr : 0.9509900498999999\n",
      "epoch : 0 [2905/21279] Train loss: 0.75919,Valid loss: 1.18377, time : 12.670303583145142 lr : 0.9509900498999999\n",
      "epoch : 0 [2906/21279] Train loss: 0.79165,Valid loss: 1.18915, time : 12.837785482406616 lr : 0.9509900498999999\n",
      "epoch : 0 [2907/21279] Train loss: 0.77688,Valid loss: 1.11373, time : 13.087619304656982 lr : 0.9509900498999999\n",
      "epoch : 0 [2908/21279] Train loss: 0.78670,Valid loss: 1.12987, time : 12.960989713668823 lr : 0.9509900498999999\n",
      "epoch : 0 [2909/21279] Train loss: 0.76149,Valid loss: 0.98644, time : 12.777837991714478 lr : 0.9509900498999999\n",
      "epoch : 0 [2910/21279] Train loss: 0.78968,Valid loss: 1.15558, time : 20.500569343566895 lr : 0.9509900498999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2911/21279] Train loss: 0.78187,Valid loss: 3.01116, time : 12.944546937942505 lr : 0.9509900498999999\n",
      "epoch : 0 [2912/21279] Train loss: 0.88449,Valid loss: 1.04205, time : 12.642431497573853 lr : 0.9509900498999999\n",
      "epoch : 0 [2913/21279] Train loss: 0.75296,Valid loss: 1.30310, time : 12.249051809310913 lr : 0.9509900498999999\n",
      "epoch : 0 [2914/21279] Train loss: 0.74040,Valid loss: 1.32557, time : 12.356626510620117 lr : 0.9509900498999999\n",
      "epoch : 0 [2915/21279] Train loss: 0.73216,Valid loss: 1.15303, time : 12.265696048736572 lr : 0.9509900498999999\n",
      "epoch : 0 [2916/21279] Train loss: 0.72251,Valid loss: 1.24573, time : 12.792699813842773 lr : 0.9509900498999999\n",
      "epoch : 0 [2917/21279] Train loss: 0.72068,Valid loss: 1.05560, time : 13.212721347808838 lr : 0.9509900498999999\n",
      "epoch : 0 [2918/21279] Train loss: 0.73249,Valid loss: 1.12391, time : 13.19373869895935 lr : 0.9509900498999999\n",
      "epoch : 0 [2919/21279] Train loss: 0.73874,Valid loss: 1.29113, time : 13.532281160354614 lr : 0.9509900498999999\n",
      "epoch : 0 [2920/21279] Train loss: 0.72766,Valid loss: 1.03610, time : 13.358636379241943 lr : 0.9509900498999999\n",
      "epoch : 0 [2921/21279] Train loss: 0.74484,Valid loss: 0.98899, time : 13.677975416183472 lr : 0.9509900498999999\n",
      "epoch : 0 [2922/21279] Train loss: 0.73127,Valid loss: 1.37927, time : 23.85629153251648 lr : 0.9509900498999999\n",
      "epoch : 0 [2923/21279] Train loss: 0.69077,Valid loss: 0.97613, time : 13.029695510864258 lr : 0.9509900498999999\n",
      "epoch : 0 [2924/21279] Train loss: 0.72428,Valid loss: 1.23531, time : 13.406928300857544 lr : 0.9509900498999999\n",
      "epoch : 0 [2925/21279] Train loss: 0.72281,Valid loss: 0.97475, time : 13.131812810897827 lr : 0.9509900498999999\n",
      "epoch : 0 [2926/21279] Train loss: 0.72375,Valid loss: 1.34050, time : 13.097454309463501 lr : 0.9509900498999999\n",
      "epoch : 0 [2927/21279] Train loss: 0.73669,Valid loss: 1.17823, time : 12.866750955581665 lr : 0.9509900498999999\n",
      "epoch : 0 [2928/21279] Train loss: 0.69784,Valid loss: 1.08145, time : 12.963745832443237 lr : 0.9509900498999999\n",
      "epoch : 0 [2929/21279] Train loss: 0.70007,Valid loss: 1.20020, time : 12.654014110565186 lr : 0.9509900498999999\n",
      "epoch : 0 [2930/21279] Train loss: 0.68624,Valid loss: 1.05218, time : 12.423638105392456 lr : 0.9509900498999999\n",
      "epoch : 0 [2931/21279] Train loss: 0.69222,Valid loss: 1.43320, time : 12.566913366317749 lr : 0.9509900498999999\n",
      "epoch : 0 [2932/21279] Train loss: 0.81553,Valid loss: 1.93339, time : 12.65103554725647 lr : 0.9509900498999999\n",
      "epoch : 0 [2933/21279] Train loss: 0.76164,Valid loss: 1.29456, time : 11.775416612625122 lr : 0.9509900498999999\n",
      "epoch : 0 [2934/21279] Train loss: 0.75763,Valid loss: 1.08412, time : 12.4251229763031 lr : 0.9509900498999999\n",
      "epoch : 0 [2935/21279] Train loss: 0.72344,Valid loss: 1.23323, time : 11.881733894348145 lr : 0.9509900498999999\n",
      "epoch : 0 [2936/21279] Train loss: 0.70159,Valid loss: 1.17332, time : 12.37591290473938 lr : 0.9509900498999999\n",
      "epoch : 0 [2937/21279] Train loss: 0.72847,Valid loss: 0.89065, time : 11.894917488098145 lr : 0.9509900498999999\n",
      "epoch : 0 [2938/21279] Train loss: 0.72267,Valid loss: 1.11959, time : 14.372992515563965 lr : 0.9509900498999999\n",
      "epoch : 0 [2939/21279] Train loss: 0.70330,Valid loss: 0.95538, time : 12.490342140197754 lr : 0.9509900498999999\n",
      "epoch : 0 [2940/21279] Train loss: 0.69240,Valid loss: 1.39652, time : 12.620152950286865 lr : 0.9509900498999999\n",
      "epoch : 0 [2941/21279] Train loss: 0.70368,Valid loss: 0.89863, time : 12.577943563461304 lr : 0.9509900498999999\n",
      "epoch : 0 [2942/21279] Train loss: 0.68803,Valid loss: 1.11801, time : 12.331292152404785 lr : 0.9509900498999999\n",
      "epoch : 0 [2943/21279] Train loss: 0.69198,Valid loss: 1.09905, time : 12.284115076065063 lr : 0.9509900498999999\n",
      "epoch : 0 [2944/21279] Train loss: 0.70704,Valid loss: 1.26521, time : 12.671794891357422 lr : 0.9509900498999999\n",
      "epoch : 0 [2945/21279] Train loss: 0.69542,Valid loss: 1.20535, time : 12.499922513961792 lr : 0.9509900498999999\n",
      "epoch : 0 [2946/21279] Train loss: 0.70458,Valid loss: 1.24741, time : 12.983177185058594 lr : 0.9509900498999999\n",
      "epoch : 0 [2947/21279] Train loss: 0.69015,Valid loss: 1.28910, time : 12.787765979766846 lr : 0.9509900498999999\n",
      "epoch : 0 [2948/21279] Train loss: 0.72773,Valid loss: 2.04518, time : 12.460864305496216 lr : 0.9509900498999999\n",
      "epoch : 0 [2949/21279] Train loss: 0.67634,Valid loss: 1.20769, time : 12.369241714477539 lr : 0.9509900498999999\n",
      "epoch : 0 [2950/21279] Train loss: 0.74502,Valid loss: 3.16940, time : 14.412277460098267 lr : 0.9509900498999999\n",
      "epoch : 0 [2951/21279] Train loss: 0.97160,Valid loss: 2.96067, time : 12.555890560150146 lr : 0.9509900498999999\n",
      "epoch : 0 [2952/21279] Train loss: 1.33813,Valid loss: 3.16737, time : 12.495846509933472 lr : 0.9509900498999999\n",
      "epoch : 0 [2953/21279] Train loss: 1.04446,Valid loss: 2.20508, time : 11.819875240325928 lr : 0.9509900498999999\n",
      "epoch : 0 [2954/21279] Train loss: 1.11284,Valid loss: 2.01563, time : 12.230677127838135 lr : 0.9509900498999999\n",
      "epoch : 0 [2955/21279] Train loss: 0.94193,Valid loss: 1.97811, time : 12.427756547927856 lr : 0.9509900498999999\n",
      "epoch : 0 [2956/21279] Train loss: 1.21625,Valid loss: 1.27482, time : 12.63459587097168 lr : 0.9509900498999999\n",
      "epoch : 0 [2957/21279] Train loss: 0.85729,Valid loss: 1.30863, time : 12.348806858062744 lr : 0.9509900498999999\n",
      "epoch : 0 [2958/21279] Train loss: 0.82577,Valid loss: 1.17006, time : 12.702754259109497 lr : 0.9509900498999999\n",
      "epoch : 0 [2959/21279] Train loss: 0.75187,Valid loss: 1.27319, time : 12.489156723022461 lr : 0.9509900498999999\n",
      "epoch : 0 [2960/21279] Train loss: 0.71435,Valid loss: 1.31933, time : 12.594810247421265 lr : 0.9509900498999999\n",
      "epoch : 0 [2961/21279] Train loss: 0.74590,Valid loss: 1.04368, time : 12.78379774093628 lr : 0.9509900498999999\n",
      "epoch : 0 [2962/21279] Train loss: 0.72064,Valid loss: 1.29238, time : 12.615069389343262 lr : 0.9509900498999999\n",
      "epoch : 0 [2963/21279] Train loss: 0.72084,Valid loss: 1.13709, time : 12.778478622436523 lr : 0.9509900498999999\n",
      "epoch : 0 [2964/21279] Train loss: 0.75693,Valid loss: 1.33773, time : 12.626799821853638 lr : 0.9509900498999999\n",
      "epoch : 0 [2965/21279] Train loss: 0.72641,Valid loss: 1.36602, time : 12.644651412963867 lr : 0.9509900498999999\n",
      "epoch : 0 [2966/21279] Train loss: 0.74484,Valid loss: 1.21415, time : 14.135157108306885 lr : 0.9509900498999999\n",
      "epoch : 0 [2967/21279] Train loss: 0.78184,Valid loss: 1.31715, time : 13.17103099822998 lr : 0.9509900498999999\n",
      "epoch : 0 [2968/21279] Train loss: 0.78475,Valid loss: 1.01242, time : 12.914650201797485 lr : 0.9509900498999999\n",
      "epoch : 0 [2969/21279] Train loss: 0.75622,Valid loss: 1.09738, time : 12.925350189208984 lr : 0.9509900498999999\n",
      "epoch : 0 [2970/21279] Train loss: 0.73235,Valid loss: 1.08567, time : 12.570730447769165 lr : 0.9509900498999999\n",
      "epoch : 0 [2971/21279] Train loss: 0.73852,Valid loss: 1.19457, time : 12.467402219772339 lr : 0.9509900498999999\n",
      "epoch : 0 [2972/21279] Train loss: 0.69751,Valid loss: 1.08705, time : 12.757766246795654 lr : 0.9509900498999999\n",
      "epoch : 0 [2973/21279] Train loss: 0.68066,Valid loss: 1.08830, time : 12.825685739517212 lr : 0.9509900498999999\n",
      "epoch : 0 [2974/21279] Train loss: 0.71764,Valid loss: 0.98939, time : 12.537378311157227 lr : 0.9509900498999999\n",
      "epoch : 0 [2975/21279] Train loss: 0.69399,Valid loss: 1.10611, time : 12.68002963066101 lr : 0.9509900498999999\n",
      "epoch : 0 [2976/21279] Train loss: 0.69429,Valid loss: 1.36612, time : 12.566897869110107 lr : 0.9509900498999999\n",
      "epoch : 0 [2977/21279] Train loss: 0.70638,Valid loss: 1.38518, time : 12.585567712783813 lr : 0.9509900498999999\n",
      "epoch : 0 [2978/21279] Train loss: 0.70010,Valid loss: 1.09101, time : 12.578906297683716 lr : 0.9509900498999999\n",
      "epoch : 0 [2979/21279] Train loss: 0.69616,Valid loss: 0.98997, time : 13.577780723571777 lr : 0.9509900498999999\n",
      "epoch : 0 [2980/21279] Train loss: 0.65035,Valid loss: 1.27663, time : 12.14005994796753 lr : 0.9509900498999999\n",
      "epoch : 0 [2981/21279] Train loss: 0.68249,Valid loss: 1.14476, time : 11.678664207458496 lr : 0.9509900498999999\n",
      "epoch : 0 [2982/21279] Train loss: 0.69218,Valid loss: 1.19079, time : 12.29150104522705 lr : 0.9509900498999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [2983/21279] Train loss: 0.67947,Valid loss: 1.20148, time : 12.992031574249268 lr : 0.9509900498999999\n",
      "epoch : 0 [2984/21279] Train loss: 0.66929,Valid loss: 1.09069, time : 12.616580724716187 lr : 0.9509900498999999\n",
      "epoch : 0 [2985/21279] Train loss: 0.65986,Valid loss: 0.95390, time : 12.79565167427063 lr : 0.9509900498999999\n",
      "epoch : 0 [2986/21279] Train loss: 0.69309,Valid loss: 1.28855, time : 12.805094480514526 lr : 0.9509900498999999\n",
      "epoch : 0 [2987/21279] Train loss: 0.68312,Valid loss: 1.13131, time : 13.007441759109497 lr : 0.9509900498999999\n",
      "epoch : 0 [2988/21279] Train loss: 0.66987,Valid loss: 1.18388, time : 13.366820812225342 lr : 0.9509900498999999\n",
      "epoch : 0 [2989/21279] Train loss: 0.68264,Valid loss: 1.12487, time : 13.0923752784729 lr : 0.9509900498999999\n",
      "epoch : 0 [2990/21279] Train loss: 0.71112,Valid loss: 1.06583, time : 13.212641954421997 lr : 0.9509900498999999\n",
      "epoch : 0 [2991/21279] Train loss: 0.67055,Valid loss: 1.06428, time : 13.048264026641846 lr : 0.9509900498999999\n",
      "epoch : 0 [2992/21279] Train loss: 0.67992,Valid loss: 0.98245, time : 13.281033515930176 lr : 0.9509900498999999\n",
      "epoch : 0 [2993/21279] Train loss: 0.66215,Valid loss: 1.38952, time : 12.921897172927856 lr : 0.9509900498999999\n",
      "epoch : 0 [2994/21279] Train loss: 0.63906,Valid loss: 1.10879, time : 14.613486528396606 lr : 0.9509900498999999\n",
      "epoch : 0 [2995/21279] Train loss: 0.64338,Valid loss: 1.01725, time : 12.572810411453247 lr : 0.9509900498999999\n",
      "epoch : 0 [2996/21279] Train loss: 0.64082,Valid loss: 0.91398, time : 12.922731399536133 lr : 0.9509900498999999\n",
      "epoch : 0 [2997/21279] Train loss: 0.66572,Valid loss: 0.86912, time : 12.760135889053345 lr : 0.9509900498999999\n",
      "epoch : 0 [2998/21279] Train loss: 0.68598,Valid loss: 1.05120, time : 12.305199146270752 lr : 0.9509900498999999\n",
      "epoch : 0 [2999/21279] Train loss: 0.66855,Valid loss: 1.00088, time : 12.580699682235718 lr : 0.9414801494009999\n",
      "epoch : 0 [3000/21279] Train loss: 0.67683,Valid loss: 1.14299, time : 12.233808040618896 lr : 0.9414801494009999\n",
      "epoch : 0 [3001/21279] Train loss: 0.65106,Valid loss: 1.30065, time : 12.632756233215332 lr : 0.9414801494009999\n",
      "epoch : 0 [3002/21279] Train loss: 0.67199,Valid loss: 1.17605, time : 13.111315727233887 lr : 0.9414801494009999\n",
      "epoch : 0 [3003/21279] Train loss: 0.63893,Valid loss: 1.97462, time : 13.003289699554443 lr : 0.9414801494009999\n",
      "epoch : 0 [3004/21279] Train loss: 0.70699,Valid loss: 1.31220, time : 12.744583129882812 lr : 0.9414801494009999\n",
      "epoch : 0 [3005/21279] Train loss: 0.70210,Valid loss: 1.19748, time : 12.886301755905151 lr : 0.9414801494009999\n",
      "epoch : 0 [3006/21279] Train loss: 0.67115,Valid loss: 1.81735, time : 16.60903787612915 lr : 0.9414801494009999\n",
      "epoch : 0 [3007/21279] Train loss: 0.68314,Valid loss: 2.14743, time : 12.121548652648926 lr : 0.9414801494009999\n",
      "epoch : 0 [3008/21279] Train loss: 0.74964,Valid loss: 1.77892, time : 11.653173923492432 lr : 0.9414801494009999\n",
      "epoch : 0 [3009/21279] Train loss: 0.70738,Valid loss: 1.28399, time : 12.002991914749146 lr : 0.9414801494009999\n",
      "epoch : 0 [3010/21279] Train loss: 0.71633,Valid loss: 1.20584, time : 12.112112998962402 lr : 0.9414801494009999\n",
      "epoch : 0 [3011/21279] Train loss: 0.69028,Valid loss: 1.40627, time : 11.8775475025177 lr : 0.9414801494009999\n",
      "epoch : 0 [3012/21279] Train loss: 0.67048,Valid loss: 1.28318, time : 12.372405767440796 lr : 0.9414801494009999\n",
      "epoch : 0 [3013/21279] Train loss: 0.66327,Valid loss: 1.32044, time : 12.730322122573853 lr : 0.9414801494009999\n",
      "epoch : 0 [3014/21279] Train loss: 0.64926,Valid loss: 1.09237, time : 12.896352291107178 lr : 0.9414801494009999\n",
      "epoch : 0 [3015/21279] Train loss: 0.64088,Valid loss: 1.24924, time : 12.80614972114563 lr : 0.9414801494009999\n",
      "epoch : 0 [3016/21279] Train loss: 0.65890,Valid loss: 1.16542, time : 12.573021173477173 lr : 0.9414801494009999\n",
      "epoch : 0 [3017/21279] Train loss: 0.63359,Valid loss: 1.04072, time : 12.029563188552856 lr : 0.9414801494009999\n",
      "epoch : 0 [3018/21279] Train loss: 0.65453,Valid loss: 1.16320, time : 11.9011070728302 lr : 0.9414801494009999\n",
      "epoch : 0 [3019/21279] Train loss: 0.65315,Valid loss: 1.05957, time : 11.801594972610474 lr : 0.9414801494009999\n",
      "epoch : 0 [3020/21279] Train loss: 0.69648,Valid loss: 1.19281, time : 13.844192028045654 lr : 0.9414801494009999\n",
      "epoch : 0 [3021/21279] Train loss: 0.69065,Valid loss: 2.15143, time : 11.535764217376709 lr : 0.9414801494009999\n",
      "epoch : 0 [3022/21279] Train loss: 0.63677,Valid loss: 1.29016, time : 12.263976812362671 lr : 0.9414801494009999\n",
      "epoch : 0 [3023/21279] Train loss: 0.67418,Valid loss: 2.55387, time : 12.326308727264404 lr : 0.9414801494009999\n",
      "epoch : 0 [3024/21279] Train loss: 0.68159,Valid loss: 1.92160, time : 11.895297288894653 lr : 0.9414801494009999\n",
      "epoch : 0 [3025/21279] Train loss: 0.67737,Valid loss: 1.54613, time : 12.422220468521118 lr : 0.9414801494009999\n",
      "epoch : 0 [3026/21279] Train loss: 0.66184,Valid loss: 1.20611, time : 11.756491661071777 lr : 0.9414801494009999\n",
      "epoch : 0 [3027/21279] Train loss: 0.68355,Valid loss: 1.94007, time : 12.31260871887207 lr : 0.9414801494009999\n",
      "epoch : 0 [3028/21279] Train loss: 0.71317,Valid loss: 1.36083, time : 11.507770299911499 lr : 0.9414801494009999\n",
      "epoch : 0 [3029/21279] Train loss: 0.67926,Valid loss: 1.05176, time : 11.893850564956665 lr : 0.9414801494009999\n",
      "epoch : 0 [3030/21279] Train loss: 0.69816,Valid loss: 0.97279, time : 11.751208066940308 lr : 0.9414801494009999\n",
      "epoch : 0 [3031/21279] Train loss: 0.68960,Valid loss: 0.96045, time : 12.377756834030151 lr : 0.9414801494009999\n",
      "epoch : 0 [3032/21279] Train loss: 0.70514,Valid loss: 1.08509, time : 14.060648918151855 lr : 0.9414801494009999\n",
      "epoch : 0 [3033/21279] Train loss: 0.66776,Valid loss: 0.97621, time : 11.934752225875854 lr : 0.9414801494009999\n",
      "epoch : 0 [3034/21279] Train loss: 0.66722,Valid loss: 1.09200, time : 11.529106378555298 lr : 0.9414801494009999\n",
      "epoch : 0 [3035/21279] Train loss: 0.70653,Valid loss: 1.51027, time : 12.180306196212769 lr : 0.9414801494009999\n",
      "epoch : 0 [3036/21279] Train loss: 0.68968,Valid loss: 2.61496, time : 12.285854578018188 lr : 0.9414801494009999\n",
      "epoch : 0 [3037/21279] Train loss: 0.74228,Valid loss: 1.03727, time : 12.21584177017212 lr : 0.9414801494009999\n",
      "epoch : 0 [3038/21279] Train loss: 0.68722,Valid loss: 0.99473, time : 12.636391639709473 lr : 0.9414801494009999\n",
      "epoch : 0 [3039/21279] Train loss: 0.68191,Valid loss: 1.20909, time : 11.891269445419312 lr : 0.9414801494009999\n",
      "epoch : 0 [3040/21279] Train loss: 0.66678,Valid loss: 0.90056, time : 12.110575199127197 lr : 0.9414801494009999\n",
      "epoch : 0 [3041/21279] Train loss: 0.68823,Valid loss: 1.12615, time : 11.94401478767395 lr : 0.9414801494009999\n",
      "epoch : 0 [3042/21279] Train loss: 0.66691,Valid loss: 1.69511, time : 12.119507312774658 lr : 0.9414801494009999\n",
      "epoch : 0 [3043/21279] Train loss: 0.78762,Valid loss: 1.98707, time : 11.719174861907959 lr : 0.9414801494009999\n",
      "epoch : 0 [3044/21279] Train loss: 0.91350,Valid loss: 2.10624, time : 12.043800830841064 lr : 0.9414801494009999\n",
      "epoch : 0 [3045/21279] Train loss: 1.18933,Valid loss: 2.09471, time : 11.782871007919312 lr : 0.9414801494009999\n",
      "epoch : 0 [3046/21279] Train loss: 1.07698,Valid loss: 2.01428, time : 12.00905990600586 lr : 0.9414801494009999\n",
      "epoch : 0 [3047/21279] Train loss: 0.93870,Valid loss: 3.22709, time : 12.273141622543335 lr : 0.9414801494009999\n",
      "epoch : 0 [3048/21279] Train loss: 1.02670,Valid loss: 1.97226, time : 21.284769296646118 lr : 0.9414801494009999\n",
      "epoch : 0 [3049/21279] Train loss: 0.73786,Valid loss: 1.63889, time : 12.113314151763916 lr : 0.9414801494009999\n",
      "epoch : 0 [3050/21279] Train loss: 0.89925,Valid loss: 1.80035, time : 12.465744495391846 lr : 0.9414801494009999\n",
      "epoch : 0 [3051/21279] Train loss: 0.76559,Valid loss: 1.93230, time : 12.645410537719727 lr : 0.9414801494009999\n",
      "epoch : 0 [3052/21279] Train loss: 0.72140,Valid loss: 1.53519, time : 12.669365644454956 lr : 0.9414801494009999\n",
      "epoch : 0 [3053/21279] Train loss: 0.68734,Valid loss: 1.40481, time : 12.742054462432861 lr : 0.9414801494009999\n",
      "epoch : 0 [3054/21279] Train loss: 0.67269,Valid loss: 0.82556, time : 12.339684247970581 lr : 0.9414801494009999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3055/21279] Train loss: 0.64931,Valid loss: 1.06180, time : 12.660974264144897 lr : 0.9414801494009999\n",
      "epoch : 0 [3056/21279] Train loss: 0.65219,Valid loss: 1.55406, time : 12.815367460250854 lr : 0.9414801494009999\n",
      "epoch : 0 [3057/21279] Train loss: 0.67988,Valid loss: 1.95447, time : 12.54345965385437 lr : 0.9414801494009999\n",
      "epoch : 0 [3058/21279] Train loss: 0.88678,Valid loss: 9.23954, time : 12.526455640792847 lr : 0.9414801494009999\n",
      "epoch : 0 [3059/21279] Train loss: 1.73770,Valid loss: 5.05362, time : 13.069568395614624 lr : 0.9414801494009999\n",
      "epoch : 0 [3060/21279] Train loss: 1.21096,Valid loss: 5.14366, time : 15.054331302642822 lr : 0.9414801494009999\n",
      "epoch : 0 [3061/21279] Train loss: 1.54974,Valid loss: 2.47950, time : 13.024780511856079 lr : 0.9414801494009999\n",
      "epoch : 0 [3062/21279] Train loss: 1.06869,Valid loss: 2.88186, time : 12.71330213546753 lr : 0.9414801494009999\n",
      "epoch : 0 [3063/21279] Train loss: 1.34448,Valid loss: 1.89562, time : 12.02882194519043 lr : 0.9414801494009999\n",
      "epoch : 0 [3064/21279] Train loss: 1.14256,Valid loss: 3.74659, time : 12.506624221801758 lr : 0.9414801494009999\n",
      "epoch : 0 [3065/21279] Train loss: 0.84354,Valid loss: 2.39761, time : 13.16220211982727 lr : 0.9414801494009999\n",
      "epoch : 0 [3066/21279] Train loss: 0.88571,Valid loss: 1.97722, time : 12.245027542114258 lr : 0.9414801494009999\n",
      "epoch : 0 [3067/21279] Train loss: 0.74801,Valid loss: 1.29834, time : 12.484267711639404 lr : 0.9414801494009999\n",
      "epoch : 0 [3068/21279] Train loss: 0.69000,Valid loss: 1.17883, time : 12.327976703643799 lr : 0.9414801494009999\n",
      "epoch : 0 [3069/21279] Train loss: 0.69016,Valid loss: 1.09154, time : 12.301756143569946 lr : 0.9414801494009999\n",
      "epoch : 0 [3070/21279] Train loss: 0.67100,Valid loss: 1.01753, time : 12.672497749328613 lr : 0.9414801494009999\n",
      "epoch : 0 [3071/21279] Train loss: 0.69288,Valid loss: 1.11407, time : 13.035489797592163 lr : 0.9414801494009999\n",
      "epoch : 0 [3072/21279] Train loss: 0.66948,Valid loss: 1.19955, time : 13.100470781326294 lr : 0.9414801494009999\n",
      "epoch : 0 [3073/21279] Train loss: 0.64736,Valid loss: 1.06913, time : 12.89319920539856 lr : 0.9414801494009999\n",
      "epoch : 0 [3074/21279] Train loss: 0.66139,Valid loss: 1.10788, time : 12.816206455230713 lr : 0.9414801494009999\n",
      "epoch : 0 [3075/21279] Train loss: 0.63626,Valid loss: 1.09280, time : 12.359939575195312 lr : 0.9414801494009999\n",
      "epoch : 0 [3076/21279] Train loss: 0.64553,Valid loss: 1.04492, time : 14.679274559020996 lr : 0.9414801494009999\n",
      "epoch : 0 [3077/21279] Train loss: 0.63670,Valid loss: 0.89930, time : 12.946857690811157 lr : 0.9414801494009999\n",
      "epoch : 0 [3078/21279] Train loss: 0.64887,Valid loss: 1.12972, time : 12.688233613967896 lr : 0.9414801494009999\n",
      "epoch : 0 [3079/21279] Train loss: 0.63721,Valid loss: 0.96008, time : 12.933815479278564 lr : 0.9414801494009999\n",
      "epoch : 0 [3080/21279] Train loss: 0.65738,Valid loss: 1.02027, time : 12.261243343353271 lr : 0.9414801494009999\n",
      "epoch : 0 [3081/21279] Train loss: 0.65010,Valid loss: 1.02988, time : 12.52578592300415 lr : 0.9414801494009999\n",
      "epoch : 0 [3082/21279] Train loss: 0.65373,Valid loss: 1.17483, time : 12.911561012268066 lr : 0.9414801494009999\n",
      "epoch : 0 [3083/21279] Train loss: 0.63658,Valid loss: 1.13576, time : 13.082087993621826 lr : 0.9414801494009999\n",
      "epoch : 0 [3084/21279] Train loss: 0.62653,Valid loss: 1.65831, time : 13.115141868591309 lr : 0.9414801494009999\n",
      "epoch : 0 [3085/21279] Train loss: 0.75652,Valid loss: 1.27875, time : 13.106199979782104 lr : 0.9414801494009999\n",
      "epoch : 0 [3086/21279] Train loss: 0.70111,Valid loss: 1.38604, time : 13.06238341331482 lr : 0.9414801494009999\n",
      "epoch : 0 [3087/21279] Train loss: 0.65251,Valid loss: 1.13929, time : 12.125494241714478 lr : 0.9414801494009999\n",
      "epoch : 0 [3088/21279] Train loss: 0.65759,Valid loss: 1.14545, time : 12.24441909790039 lr : 0.9414801494009999\n",
      "epoch : 0 [3089/21279] Train loss: 0.65253,Valid loss: 1.17108, time : 13.551587104797363 lr : 0.9414801494009999\n",
      "epoch : 0 [3090/21279] Train loss: 0.62920,Valid loss: 1.24895, time : 12.337077856063843 lr : 0.9414801494009999\n",
      "epoch : 0 [3091/21279] Train loss: 0.64371,Valid loss: 0.89429, time : 12.593758344650269 lr : 0.9414801494009999\n",
      "epoch : 0 [3092/21279] Train loss: 0.64072,Valid loss: 1.09966, time : 12.425217866897583 lr : 0.9414801494009999\n",
      "epoch : 0 [3093/21279] Train loss: 0.63563,Valid loss: 1.13531, time : 12.144197225570679 lr : 0.9414801494009999\n",
      "epoch : 0 [3094/21279] Train loss: 0.61972,Valid loss: 1.21427, time : 11.902029514312744 lr : 0.9414801494009999\n",
      "epoch : 0 [3095/21279] Train loss: 0.62222,Valid loss: 1.13507, time : 11.980533838272095 lr : 0.9414801494009999\n",
      "epoch : 0 [3096/21279] Train loss: 0.63235,Valid loss: 0.95414, time : 12.331022262573242 lr : 0.9414801494009999\n",
      "epoch : 0 [3097/21279] Train loss: 0.63264,Valid loss: 0.87726, time : 12.126142263412476 lr : 0.9414801494009999\n",
      "epoch : 0 [3098/21279] Train loss: 0.62996,Valid loss: 0.83830, time : 12.422698020935059 lr : 0.9414801494009999\n",
      "epoch : 0 [3099/21279] Train loss: 0.61263,Valid loss: 1.04106, time : 12.193933010101318 lr : 0.9414801494009999\n",
      "epoch : 0 [3100/21279] Train loss: 0.63377,Valid loss: 0.88874, time : 12.26145076751709 lr : 0.9414801494009999\n",
      "epoch : 0 [3101/21279] Train loss: 0.62291,Valid loss: 1.06679, time : 12.34393310546875 lr : 0.9414801494009999\n",
      "epoch : 0 [3102/21279] Train loss: 0.63807,Valid loss: 1.09685, time : 12.455247640609741 lr : 0.9414801494009999\n",
      "epoch : 0 [3103/21279] Train loss: 0.61622,Valid loss: 1.05306, time : 12.781155824661255 lr : 0.9414801494009999\n",
      "epoch : 0 [3104/21279] Train loss: 0.62227,Valid loss: 1.02321, time : 13.776400089263916 lr : 0.9414801494009999\n",
      "epoch : 0 [3105/21279] Train loss: 0.61125,Valid loss: 0.90869, time : 12.392230033874512 lr : 0.9414801494009999\n",
      "epoch : 0 [3106/21279] Train loss: 0.62673,Valid loss: 1.07610, time : 12.497233390808105 lr : 0.9414801494009999\n",
      "epoch : 0 [3107/21279] Train loss: 0.59577,Valid loss: 1.01704, time : 12.621023893356323 lr : 0.9414801494009999\n",
      "epoch : 0 [3108/21279] Train loss: 0.62909,Valid loss: 1.09023, time : 12.375430345535278 lr : 0.9414801494009999\n",
      "epoch : 0 [3109/21279] Train loss: 0.61963,Valid loss: 1.16135, time : 12.464528322219849 lr : 0.9414801494009999\n",
      "epoch : 0 [3110/21279] Train loss: 0.64116,Valid loss: 1.24009, time : 12.43420147895813 lr : 0.9414801494009999\n",
      "epoch : 0 [3111/21279] Train loss: 0.65877,Valid loss: 1.16094, time : 12.799578666687012 lr : 0.9414801494009999\n",
      "epoch : 0 [3112/21279] Train loss: 0.64389,Valid loss: 0.92329, time : 12.654101133346558 lr : 0.9414801494009999\n",
      "epoch : 0 [3113/21279] Train loss: 0.62487,Valid loss: 0.95063, time : 12.377368450164795 lr : 0.9414801494009999\n",
      "epoch : 0 [3114/21279] Train loss: 0.65486,Valid loss: 0.96144, time : 12.374751091003418 lr : 0.9414801494009999\n",
      "epoch : 0 [3115/21279] Train loss: 0.61766,Valid loss: 1.12618, time : 12.245832920074463 lr : 0.9414801494009999\n",
      "epoch : 0 [3116/21279] Train loss: 0.62670,Valid loss: 0.92038, time : 14.252289772033691 lr : 0.9414801494009999\n",
      "epoch : 0 [3117/21279] Train loss: 0.62111,Valid loss: 1.13449, time : 12.540694236755371 lr : 0.9414801494009999\n",
      "epoch : 0 [3118/21279] Train loss: 0.60901,Valid loss: 1.11494, time : 12.81625247001648 lr : 0.9414801494009999\n",
      "epoch : 0 [3119/21279] Train loss: 0.60552,Valid loss: 1.30951, time : 12.22987151145935 lr : 0.9414801494009999\n",
      "epoch : 0 [3120/21279] Train loss: 0.67759,Valid loss: 1.41102, time : 12.512415647506714 lr : 0.9414801494009999\n",
      "epoch : 0 [3121/21279] Train loss: 0.66153,Valid loss: 1.10846, time : 12.019391536712646 lr : 0.9414801494009999\n",
      "epoch : 0 [3122/21279] Train loss: 0.61993,Valid loss: 1.07588, time : 12.616422176361084 lr : 0.9414801494009999\n",
      "epoch : 0 [3123/21279] Train loss: 0.62385,Valid loss: 1.73252, time : 12.341358184814453 lr : 0.9414801494009999\n",
      "epoch : 0 [3124/21279] Train loss: 0.70844,Valid loss: 1.77405, time : 12.708377122879028 lr : 0.9414801494009999\n",
      "epoch : 0 [3125/21279] Train loss: 0.76155,Valid loss: 1.94306, time : 11.915382862091064 lr : 0.9414801494009999\n",
      "epoch : 0 [3126/21279] Train loss: 0.69593,Valid loss: 1.35641, time : 12.599653720855713 lr : 0.9414801494009999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3127/21279] Train loss: 0.67861,Valid loss: 0.84086, time : 12.629479169845581 lr : 0.9414801494009999\n",
      "epoch : 0 [3128/21279] Train loss: 0.64419,Valid loss: 1.15917, time : 12.382011651992798 lr : 0.9414801494009999\n",
      "epoch : 0 [3129/21279] Train loss: 0.63929,Valid loss: 0.97092, time : 12.504655838012695 lr : 0.9414801494009999\n",
      "epoch : 0 [3130/21279] Train loss: 0.64232,Valid loss: 1.63976, time : 18.93877387046814 lr : 0.9414801494009999\n",
      "epoch : 0 [3131/21279] Train loss: 0.64341,Valid loss: 1.09058, time : 12.086425304412842 lr : 0.9414801494009999\n",
      "epoch : 0 [3132/21279] Train loss: 0.64848,Valid loss: 1.18640, time : 12.466018438339233 lr : 0.9414801494009999\n",
      "epoch : 0 [3133/21279] Train loss: 0.63970,Valid loss: 1.12043, time : 12.45583987236023 lr : 0.9414801494009999\n",
      "epoch : 0 [3134/21279] Train loss: 0.61603,Valid loss: 1.26846, time : 12.581801414489746 lr : 0.9414801494009999\n",
      "epoch : 0 [3135/21279] Train loss: 0.64528,Valid loss: 1.10358, time : 12.71087908744812 lr : 0.9414801494009999\n",
      "epoch : 0 [3136/21279] Train loss: 0.61830,Valid loss: 1.11494, time : 12.857182025909424 lr : 0.9414801494009999\n",
      "epoch : 0 [3137/21279] Train loss: 0.63553,Valid loss: 0.97336, time : 12.77104139328003 lr : 0.9414801494009999\n",
      "epoch : 0 [3138/21279] Train loss: 0.63375,Valid loss: 0.92308, time : 13.132009744644165 lr : 0.9414801494009999\n",
      "epoch : 0 [3139/21279] Train loss: 0.61923,Valid loss: 1.05015, time : 12.826803207397461 lr : 0.9414801494009999\n",
      "epoch : 0 [3140/21279] Train loss: 0.59964,Valid loss: 1.01074, time : 12.71284794807434 lr : 0.9414801494009999\n",
      "epoch : 0 [3141/21279] Train loss: 0.62051,Valid loss: 1.06121, time : 11.861446619033813 lr : 0.9414801494009999\n",
      "epoch : 0 [3142/21279] Train loss: 0.61299,Valid loss: 1.22350, time : 14.225109577178955 lr : 0.9414801494009999\n",
      "epoch : 0 [3143/21279] Train loss: 0.62966,Valid loss: 1.00179, time : 12.014432668685913 lr : 0.9414801494009999\n",
      "epoch : 0 [3144/21279] Train loss: 0.61713,Valid loss: 0.80973, time : 12.677862167358398 lr : 0.9414801494009999\n",
      "epoch : 0 [3145/21279] Train loss: 0.61324,Valid loss: 0.98850, time : 13.051973342895508 lr : 0.9414801494009999\n",
      "epoch : 0 [3146/21279] Train loss: 0.61899,Valid loss: 1.10189, time : 12.627232551574707 lr : 0.9414801494009999\n",
      "epoch : 0 [3147/21279] Train loss: 0.61400,Valid loss: 1.02958, time : 12.695345401763916 lr : 0.9414801494009999\n",
      "epoch : 0 [3148/21279] Train loss: 0.59232,Valid loss: 1.13777, time : 12.371350049972534 lr : 0.9414801494009999\n",
      "epoch : 0 [3149/21279] Train loss: 0.60097,Valid loss: 1.07432, time : 12.825424432754517 lr : 0.9414801494009999\n",
      "epoch : 0 [3150/21279] Train loss: 0.61873,Valid loss: 0.88923, time : 12.00899362564087 lr : 0.9414801494009999\n",
      "epoch : 0 [3151/21279] Train loss: 0.60206,Valid loss: 1.30383, time : 12.313528776168823 lr : 0.9414801494009999\n",
      "epoch : 0 [3152/21279] Train loss: 0.60113,Valid loss: 0.98044, time : 11.660287141799927 lr : 0.9414801494009999\n",
      "epoch : 0 [3153/21279] Train loss: 0.59101,Valid loss: 1.10109, time : 12.431488275527954 lr : 0.9414801494009999\n",
      "epoch : 0 [3154/21279] Train loss: 0.61062,Valid loss: 0.92645, time : 11.848647832870483 lr : 0.9414801494009999\n",
      "epoch : 0 [3155/21279] Train loss: 0.62231,Valid loss: 0.99196, time : 11.625763893127441 lr : 0.9414801494009999\n",
      "epoch : 0 [3156/21279] Train loss: 0.62553,Valid loss: 0.86285, time : 12.034489154815674 lr : 0.9414801494009999\n",
      "epoch : 0 [3157/21279] Train loss: 0.62668,Valid loss: 0.95524, time : 12.760411977767944 lr : 0.9414801494009999\n",
      "epoch : 0 [3158/21279] Train loss: 0.65707,Valid loss: 1.13046, time : 14.715766429901123 lr : 0.9414801494009999\n",
      "epoch : 0 [3159/21279] Train loss: 0.63076,Valid loss: 1.11865, time : 12.819596767425537 lr : 0.9414801494009999\n",
      "epoch : 0 [3160/21279] Train loss: 0.64386,Valid loss: 1.04886, time : 12.94866418838501 lr : 0.9414801494009999\n",
      "epoch : 0 [3161/21279] Train loss: 0.67051,Valid loss: 1.59397, time : 12.750426054000854 lr : 0.9414801494009999\n",
      "epoch : 0 [3162/21279] Train loss: 0.69917,Valid loss: 4.58505, time : 12.780948162078857 lr : 0.9414801494009999\n",
      "epoch : 0 [3163/21279] Train loss: 1.07251,Valid loss: 1.85070, time : 12.84532642364502 lr : 0.9414801494009999\n",
      "epoch : 0 [3164/21279] Train loss: 1.00542,Valid loss: 1.27491, time : 13.137361764907837 lr : 0.9414801494009999\n",
      "epoch : 0 [3165/21279] Train loss: 0.70254,Valid loss: 1.24576, time : 12.310533285140991 lr : 0.9414801494009999\n",
      "epoch : 0 [3166/21279] Train loss: 0.68128,Valid loss: 1.26319, time : 12.508791208267212 lr : 0.9414801494009999\n",
      "epoch : 0 [3167/21279] Train loss: 0.69061,Valid loss: 1.19768, time : 12.401679515838623 lr : 0.9414801494009999\n",
      "epoch : 0 [3168/21279] Train loss: 0.63793,Valid loss: 0.95424, time : 12.568723201751709 lr : 0.9414801494009999\n",
      "epoch : 0 [3169/21279] Train loss: 0.65273,Valid loss: 1.13212, time : 12.979641914367676 lr : 0.9414801494009999\n",
      "epoch : 0 [3170/21279] Train loss: 0.63883,Valid loss: 0.90849, time : 17.47366213798523 lr : 0.9414801494009999\n",
      "epoch : 0 [3171/21279] Train loss: 0.62087,Valid loss: 0.98741, time : 12.498812437057495 lr : 0.9414801494009999\n",
      "epoch : 0 [3172/21279] Train loss: 0.58703,Valid loss: 0.84572, time : 12.458248376846313 lr : 0.9414801494009999\n",
      "epoch : 0 [3173/21279] Train loss: 0.58451,Valid loss: 0.82280, time : 12.905614852905273 lr : 0.9414801494009999\n",
      "epoch : 0 [3174/21279] Train loss: 0.60131,Valid loss: 1.11999, time : 13.114649057388306 lr : 0.9414801494009999\n",
      "epoch : 0 [3175/21279] Train loss: 0.61166,Valid loss: 0.90794, time : 12.395575284957886 lr : 0.9414801494009999\n",
      "epoch : 0 [3176/21279] Train loss: 0.60939,Valid loss: 0.88421, time : 12.232413291931152 lr : 0.9414801494009999\n",
      "epoch : 0 [3177/21279] Train loss: 0.63077,Valid loss: 1.13132, time : 12.998998880386353 lr : 0.9414801494009999\n",
      "epoch : 0 [3178/21279] Train loss: 0.62820,Valid loss: 1.06911, time : 12.785222053527832 lr : 0.9414801494009999\n",
      "epoch : 0 [3179/21279] Train loss: 0.60722,Valid loss: 0.96562, time : 13.153349876403809 lr : 0.9414801494009999\n",
      "epoch : 0 [3180/21279] Train loss: 0.62171,Valid loss: 0.81293, time : 12.59340524673462 lr : 0.9414801494009999\n",
      "epoch : 0 [3181/21279] Train loss: 0.61290,Valid loss: 0.95251, time : 13.169055223464966 lr : 0.9414801494009999\n",
      "epoch : 0 [3182/21279] Train loss: 0.58894,Valid loss: 0.87560, time : 13.471483945846558 lr : 0.9414801494009999\n",
      "epoch : 0 [3183/21279] Train loss: 0.60886,Valid loss: 0.85472, time : 12.890344381332397 lr : 0.9414801494009999\n",
      "epoch : 0 [3184/21279] Train loss: 0.59307,Valid loss: 0.87960, time : 12.807276487350464 lr : 0.9414801494009999\n",
      "epoch : 0 [3185/21279] Train loss: 0.61783,Valid loss: 1.05325, time : 12.914687156677246 lr : 0.9414801494009999\n",
      "epoch : 0 [3186/21279] Train loss: 0.63243,Valid loss: 1.40496, time : 15.388741731643677 lr : 0.9414801494009999\n",
      "epoch : 0 [3187/21279] Train loss: 0.68112,Valid loss: 1.28594, time : 13.180099725723267 lr : 0.9414801494009999\n",
      "epoch : 0 [3188/21279] Train loss: 0.67310,Valid loss: 1.15513, time : 12.322151899337769 lr : 0.9414801494009999\n",
      "epoch : 0 [3189/21279] Train loss: 0.62834,Valid loss: 1.10995, time : 12.892482280731201 lr : 0.9414801494009999\n",
      "epoch : 0 [3190/21279] Train loss: 0.62146,Valid loss: 1.05732, time : 12.592947721481323 lr : 0.9414801494009999\n",
      "epoch : 0 [3191/21279] Train loss: 0.63658,Valid loss: 0.88834, time : 11.994813442230225 lr : 0.9414801494009999\n",
      "epoch : 0 [3192/21279] Train loss: 0.60206,Valid loss: 1.00319, time : 12.473736763000488 lr : 0.9414801494009999\n",
      "epoch : 0 [3193/21279] Train loss: 0.59468,Valid loss: 1.11748, time : 12.937373161315918 lr : 0.9414801494009999\n",
      "epoch : 0 [3194/21279] Train loss: 0.60000,Valid loss: 1.02979, time : 12.690814018249512 lr : 0.9414801494009999\n",
      "epoch : 0 [3195/21279] Train loss: 0.59184,Valid loss: 1.09367, time : 12.42261791229248 lr : 0.9414801494009999\n",
      "epoch : 0 [3196/21279] Train loss: 0.58986,Valid loss: 0.88633, time : 12.876303672790527 lr : 0.9414801494009999\n",
      "epoch : 0 [3197/21279] Train loss: 0.57729,Valid loss: 1.08790, time : 13.022460699081421 lr : 0.9414801494009999\n",
      "epoch : 0 [3198/21279] Train loss: 0.60442,Valid loss: 1.04762, time : 13.07068395614624 lr : 0.9414801494009999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3199/21279] Train loss: 0.60235,Valid loss: 1.09699, time : 15.184834241867065 lr : 0.9414801494009999\n",
      "epoch : 0 [3200/21279] Train loss: 0.68784,Valid loss: 1.40032, time : 12.65035629272461 lr : 0.9414801494009999\n",
      "epoch : 0 [3201/21279] Train loss: 0.94514,Valid loss: 1.84036, time : 12.510462760925293 lr : 0.9414801494009999\n",
      "epoch : 0 [3202/21279] Train loss: 0.98788,Valid loss: 1.45070, time : 12.919450283050537 lr : 0.9414801494009999\n",
      "epoch : 0 [3203/21279] Train loss: 0.85415,Valid loss: 1.47873, time : 12.1730375289917 lr : 0.9414801494009999\n",
      "epoch : 0 [3204/21279] Train loss: 0.73620,Valid loss: 1.33168, time : 12.711597919464111 lr : 0.9414801494009999\n",
      "epoch : 0 [3205/21279] Train loss: 0.67553,Valid loss: 1.04419, time : 12.691314935684204 lr : 0.9414801494009999\n",
      "epoch : 0 [3206/21279] Train loss: 0.62164,Valid loss: 0.88458, time : 12.333355188369751 lr : 0.9414801494009999\n",
      "epoch : 0 [3207/21279] Train loss: 0.61618,Valid loss: 0.86434, time : 12.379780292510986 lr : 0.9414801494009999\n",
      "epoch : 0 [3208/21279] Train loss: 0.60853,Valid loss: 0.92403, time : 12.776145696640015 lr : 0.9414801494009999\n",
      "epoch : 0 [3209/21279] Train loss: 0.60859,Valid loss: 1.14332, time : 12.671419858932495 lr : 0.9414801494009999\n",
      "epoch : 0 [3210/21279] Train loss: 0.60847,Valid loss: 0.95526, time : 12.918559551239014 lr : 0.9414801494009999\n",
      "epoch : 0 [3211/21279] Train loss: 0.59321,Valid loss: 0.89498, time : 13.146829605102539 lr : 0.9414801494009999\n",
      "epoch : 0 [3212/21279] Train loss: 0.59501,Valid loss: 0.76362, time : 12.690704584121704 lr : 0.9414801494009999\n",
      "epoch : 0 [3213/21279] Train loss: 0.58147,Valid loss: 1.00168, time : 12.211793661117554 lr : 0.9414801494009999\n",
      "epoch : 0 [3214/21279] Train loss: 0.58381,Valid loss: 1.08670, time : 13.42118239402771 lr : 0.9414801494009999\n",
      "epoch : 0 [3215/21279] Train loss: 0.62174,Valid loss: 1.54143, time : 11.928465366363525 lr : 0.9414801494009999\n",
      "epoch : 0 [3216/21279] Train loss: 0.64191,Valid loss: 1.48591, time : 12.434667825698853 lr : 0.9414801494009999\n",
      "epoch : 0 [3217/21279] Train loss: 0.90030,Valid loss: 4.85018, time : 13.245736360549927 lr : 0.9414801494009999\n",
      "epoch : 0 [3218/21279] Train loss: 1.06214,Valid loss: 1.62890, time : 12.068307638168335 lr : 0.9414801494009999\n",
      "epoch : 0 [3219/21279] Train loss: 0.76913,Valid loss: 1.38157, time : 12.448873519897461 lr : 0.9414801494009999\n",
      "epoch : 0 [3220/21279] Train loss: 0.69079,Valid loss: 1.43750, time : 12.136951684951782 lr : 0.9414801494009999\n",
      "epoch : 0 [3221/21279] Train loss: 0.67454,Valid loss: 1.28031, time : 12.333008527755737 lr : 0.9414801494009999\n",
      "epoch : 0 [3222/21279] Train loss: 0.61413,Valid loss: 1.22634, time : 12.199293375015259 lr : 0.9414801494009999\n",
      "epoch : 0 [3223/21279] Train loss: 0.61604,Valid loss: 1.14452, time : 12.713691711425781 lr : 0.9414801494009999\n",
      "epoch : 0 [3224/21279] Train loss: 0.58979,Valid loss: 1.12990, time : 12.85124158859253 lr : 0.9414801494009999\n",
      "epoch : 0 [3225/21279] Train loss: 0.59080,Valid loss: 1.21340, time : 12.61038589477539 lr : 0.9414801494009999\n",
      "epoch : 0 [3226/21279] Train loss: 0.60805,Valid loss: 1.06607, time : 15.319828748703003 lr : 0.9414801494009999\n",
      "epoch : 0 [3227/21279] Train loss: 0.56866,Valid loss: 1.10503, time : 12.422323226928711 lr : 0.9414801494009999\n",
      "epoch : 0 [3228/21279] Train loss: 0.58903,Valid loss: 0.89895, time : 11.694764375686646 lr : 0.9414801494009999\n",
      "epoch : 0 [3229/21279] Train loss: 0.61018,Valid loss: 1.12500, time : 11.467304468154907 lr : 0.9414801494009999\n",
      "epoch : 0 [3230/21279] Train loss: 0.58359,Valid loss: 1.22679, time : 12.07918119430542 lr : 0.9414801494009999\n",
      "epoch : 0 [3231/21279] Train loss: 0.59000,Valid loss: 1.03910, time : 11.933863401412964 lr : 0.9414801494009999\n",
      "epoch : 0 [3232/21279] Train loss: 0.58043,Valid loss: 1.04115, time : 12.088790655136108 lr : 0.9414801494009999\n",
      "epoch : 0 [3233/21279] Train loss: 0.61780,Valid loss: 1.07217, time : 11.986271142959595 lr : 0.9414801494009999\n",
      "epoch : 0 [3234/21279] Train loss: 0.60981,Valid loss: 1.12977, time : 12.366255044937134 lr : 0.9414801494009999\n",
      "epoch : 0 [3235/21279] Train loss: 0.58643,Valid loss: 0.94666, time : 11.753621816635132 lr : 0.9414801494009999\n",
      "epoch : 0 [3236/21279] Train loss: 0.57171,Valid loss: 1.02280, time : 12.064959526062012 lr : 0.9414801494009999\n",
      "epoch : 0 [3237/21279] Train loss: 0.57582,Valid loss: 1.14817, time : 12.196870565414429 lr : 0.9414801494009999\n",
      "epoch : 0 [3238/21279] Train loss: 0.56625,Valid loss: 1.06125, time : 12.2592031955719 lr : 0.9414801494009999\n",
      "epoch : 0 [3239/21279] Train loss: 0.57816,Valid loss: 0.94665, time : 12.147890090942383 lr : 0.9414801494009999\n",
      "epoch : 0 [3240/21279] Train loss: 0.59651,Valid loss: 1.24216, time : 14.33806586265564 lr : 0.9414801494009999\n",
      "epoch : 0 [3241/21279] Train loss: 0.58484,Valid loss: 1.24494, time : 12.782761096954346 lr : 0.9414801494009999\n",
      "epoch : 0 [3242/21279] Train loss: 0.59240,Valid loss: 0.88714, time : 12.408019304275513 lr : 0.9414801494009999\n",
      "epoch : 0 [3243/21279] Train loss: 0.56106,Valid loss: 0.93861, time : 12.116652011871338 lr : 0.9414801494009999\n",
      "epoch : 0 [3244/21279] Train loss: 0.56063,Valid loss: 3.14480, time : 12.571370124816895 lr : 0.9414801494009999\n",
      "epoch : 0 [3245/21279] Train loss: 0.96271,Valid loss: 7.76852, time : 12.791161298751831 lr : 0.9414801494009999\n",
      "epoch : 0 [3246/21279] Train loss: 0.91103,Valid loss: 2.52862, time : 12.602981805801392 lr : 0.9414801494009999\n",
      "epoch : 0 [3247/21279] Train loss: 0.93124,Valid loss: 1.60645, time : 12.673659563064575 lr : 0.9414801494009999\n",
      "epoch : 0 [3248/21279] Train loss: 0.64374,Valid loss: 1.35532, time : 11.948258399963379 lr : 0.9414801494009999\n",
      "epoch : 0 [3249/21279] Train loss: 0.61167,Valid loss: 1.11092, time : 12.08552098274231 lr : 0.9414801494009999\n",
      "epoch : 0 [3250/21279] Train loss: 0.60245,Valid loss: 1.40758, time : 12.58803653717041 lr : 0.9414801494009999\n",
      "epoch : 0 [3251/21279] Train loss: 0.59035,Valid loss: 1.08599, time : 12.3343026638031 lr : 0.9414801494009999\n",
      "epoch : 0 [3252/21279] Train loss: 0.58452,Valid loss: 1.46059, time : 15.916358232498169 lr : 0.9414801494009999\n",
      "epoch : 0 [3253/21279] Train loss: 0.59215,Valid loss: 1.27132, time : 12.319723844528198 lr : 0.9414801494009999\n",
      "epoch : 0 [3254/21279] Train loss: 0.55796,Valid loss: 0.98849, time : 12.181823015213013 lr : 0.9414801494009999\n",
      "epoch : 0 [3255/21279] Train loss: 0.56312,Valid loss: 1.20475, time : 12.038769721984863 lr : 0.9414801494009999\n",
      "epoch : 0 [3256/21279] Train loss: 0.56828,Valid loss: 0.89491, time : 11.831542015075684 lr : 0.9414801494009999\n",
      "epoch : 0 [3257/21279] Train loss: 0.56674,Valid loss: 1.09540, time : 11.904107809066772 lr : 0.9414801494009999\n",
      "epoch : 0 [3258/21279] Train loss: 0.56678,Valid loss: 0.88914, time : 12.653287887573242 lr : 0.9414801494009999\n",
      "epoch : 0 [3259/21279] Train loss: 0.56373,Valid loss: 1.00080, time : 12.531638622283936 lr : 0.9414801494009999\n",
      "epoch : 0 [3260/21279] Train loss: 0.56040,Valid loss: 1.05996, time : 12.442819595336914 lr : 0.9414801494009999\n",
      "epoch : 0 [3261/21279] Train loss: 0.59393,Valid loss: 1.06803, time : 12.603349924087524 lr : 0.9414801494009999\n",
      "epoch : 0 [3262/21279] Train loss: 0.58098,Valid loss: 1.17593, time : 12.94947600364685 lr : 0.9414801494009999\n",
      "epoch : 0 [3263/21279] Train loss: 0.55158,Valid loss: 0.95408, time : 12.46332049369812 lr : 0.9414801494009999\n",
      "epoch : 0 [3264/21279] Train loss: 0.54346,Valid loss: 0.69937, time : 12.47701382637024 lr : 0.9414801494009999\n",
      "epoch : 0 [3265/21279] Train loss: 0.58499,Valid loss: 1.02418, time : 12.014615297317505 lr : 0.9414801494009999\n",
      "epoch : 0 [3266/21279] Train loss: 0.56434,Valid loss: 0.80962, time : 12.869747877120972 lr : 0.9414801494009999\n",
      "epoch : 0 [3267/21279] Train loss: 0.54846,Valid loss: 1.13771, time : 11.875528812408447 lr : 0.9414801494009999\n",
      "epoch : 0 [3268/21279] Train loss: 0.55406,Valid loss: 0.94810, time : 14.668990135192871 lr : 0.9414801494009999\n",
      "epoch : 0 [3269/21279] Train loss: 0.55413,Valid loss: 1.00072, time : 12.25761890411377 lr : 0.9414801494009999\n",
      "epoch : 0 [3270/21279] Train loss: 0.55754,Valid loss: 0.83045, time : 12.251417636871338 lr : 0.9414801494009999\n",
      "epoch : 0 [3271/21279] Train loss: 0.56045,Valid loss: 0.92783, time : 12.074376821517944 lr : 0.9414801494009999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3272/21279] Train loss: 0.58012,Valid loss: 1.13800, time : 11.860382080078125 lr : 0.9414801494009999\n",
      "epoch : 0 [3273/21279] Train loss: 0.57372,Valid loss: 0.95853, time : 12.229009628295898 lr : 0.9414801494009999\n",
      "epoch : 0 [3274/21279] Train loss: 0.57348,Valid loss: 1.07193, time : 12.114859819412231 lr : 0.9414801494009999\n",
      "epoch : 0 [3275/21279] Train loss: 0.55094,Valid loss: 1.01000, time : 12.71428918838501 lr : 0.9414801494009999\n",
      "epoch : 0 [3276/21279] Train loss: 0.56495,Valid loss: 0.93259, time : 12.047304630279541 lr : 0.9414801494009999\n",
      "epoch : 0 [3277/21279] Train loss: 0.57072,Valid loss: 0.93440, time : 13.06447696685791 lr : 0.9414801494009999\n",
      "epoch : 0 [3278/21279] Train loss: 0.55910,Valid loss: 1.00946, time : 12.592250108718872 lr : 0.9414801494009999\n",
      "epoch : 0 [3279/21279] Train loss: 0.55786,Valid loss: 0.98696, time : 13.155513048171997 lr : 0.9414801494009999\n",
      "epoch : 0 [3280/21279] Train loss: 0.55636,Valid loss: 0.99237, time : 14.078559398651123 lr : 0.9414801494009999\n",
      "epoch : 0 [3281/21279] Train loss: 0.59603,Valid loss: 1.16612, time : 12.167424201965332 lr : 0.9414801494009999\n",
      "epoch : 0 [3282/21279] Train loss: 0.58650,Valid loss: 1.16193, time : 12.187223672866821 lr : 0.9414801494009999\n",
      "epoch : 0 [3283/21279] Train loss: 0.61576,Valid loss: 3.39396, time : 12.220987319946289 lr : 0.9414801494009999\n",
      "epoch : 0 [3284/21279] Train loss: 0.68267,Valid loss: 1.09062, time : 12.055916547775269 lr : 0.9414801494009999\n",
      "epoch : 0 [3285/21279] Train loss: 0.65549,Valid loss: 1.55881, time : 11.948463439941406 lr : 0.9414801494009999\n",
      "epoch : 0 [3286/21279] Train loss: 0.68611,Valid loss: 1.95913, time : 12.176669597625732 lr : 0.9414801494009999\n",
      "epoch : 0 [3287/21279] Train loss: 1.08241,Valid loss: 2.06156, time : 11.817200183868408 lr : 0.9414801494009999\n",
      "epoch : 0 [3288/21279] Train loss: 0.86641,Valid loss: 1.90537, time : 12.034220933914185 lr : 0.9414801494009999\n",
      "epoch : 0 [3289/21279] Train loss: 0.87976,Valid loss: 1.92755, time : 12.0518217086792 lr : 0.9414801494009999\n",
      "epoch : 0 [3290/21279] Train loss: 0.76219,Valid loss: 1.84908, time : 11.781376600265503 lr : 0.9414801494009999\n",
      "epoch : 0 [3291/21279] Train loss: 0.81097,Valid loss: 2.26743, time : 12.022297143936157 lr : 0.9414801494009999\n",
      "epoch : 0 [3292/21279] Train loss: 0.83898,Valid loss: 1.12986, time : 11.930437326431274 lr : 0.9414801494009999\n",
      "epoch : 0 [3293/21279] Train loss: 0.68319,Valid loss: 1.12393, time : 12.655072927474976 lr : 0.9414801494009999\n",
      "epoch : 0 [3294/21279] Train loss: 0.61602,Valid loss: 0.92371, time : 12.551673650741577 lr : 0.9414801494009999\n",
      "epoch : 0 [3295/21279] Train loss: 0.59536,Valid loss: 0.87261, time : 12.817808628082275 lr : 0.9414801494009999\n",
      "epoch : 0 [3296/21279] Train loss: 0.56266,Valid loss: 0.93015, time : 14.646177768707275 lr : 0.9414801494009999\n",
      "epoch : 0 [3297/21279] Train loss: 0.57107,Valid loss: 0.87688, time : 12.480601072311401 lr : 0.9414801494009999\n",
      "epoch : 0 [3298/21279] Train loss: 0.57659,Valid loss: 0.86786, time : 12.89647650718689 lr : 0.9414801494009999\n",
      "epoch : 0 [3299/21279] Train loss: 0.57643,Valid loss: 0.79220, time : 12.301977634429932 lr : 0.9414801494009999\n",
      "epoch : 0 [3300/21279] Train loss: 0.58130,Valid loss: 0.94129, time : 12.386131048202515 lr : 0.9414801494009999\n",
      "epoch : 0 [3301/21279] Train loss: 0.57322,Valid loss: 0.79121, time : 12.218959331512451 lr : 0.9414801494009999\n",
      "epoch : 0 [3302/21279] Train loss: 0.58582,Valid loss: 0.90467, time : 12.124717950820923 lr : 0.9414801494009999\n",
      "epoch : 0 [3303/21279] Train loss: 0.58927,Valid loss: 0.79507, time : 12.059450626373291 lr : 0.9414801494009999\n",
      "epoch : 0 [3304/21279] Train loss: 0.58068,Valid loss: 0.82798, time : 11.882610559463501 lr : 0.9414801494009999\n",
      "epoch : 0 [3305/21279] Train loss: 0.54840,Valid loss: 0.80748, time : 12.19436240196228 lr : 0.9414801494009999\n",
      "epoch : 0 [3306/21279] Train loss: 0.56870,Valid loss: 0.97817, time : 12.43521523475647 lr : 0.9414801494009999\n",
      "epoch : 0 [3307/21279] Train loss: 0.53934,Valid loss: 0.86818, time : 11.926874160766602 lr : 0.9414801494009999\n",
      "epoch : 0 [3308/21279] Train loss: 0.55833,Valid loss: 1.02833, time : 12.032663822174072 lr : 0.9414801494009999\n",
      "epoch : 0 [3309/21279] Train loss: 0.56764,Valid loss: 0.69089, time : 13.907399892807007 lr : 0.9414801494009999\n",
      "epoch : 0 [3310/21279] Train loss: 0.57577,Valid loss: 0.94287, time : 12.406765699386597 lr : 0.9414801494009999\n",
      "epoch : 0 [3311/21279] Train loss: 0.52394,Valid loss: 0.83161, time : 12.42948865890503 lr : 0.9414801494009999\n",
      "epoch : 0 [3312/21279] Train loss: 0.53552,Valid loss: 1.06646, time : 11.659674644470215 lr : 0.9414801494009999\n",
      "epoch : 0 [3313/21279] Train loss: 0.55667,Valid loss: 0.94533, time : 12.861212730407715 lr : 0.9414801494009999\n",
      "epoch : 0 [3314/21279] Train loss: 0.54173,Valid loss: 0.98998, time : 12.398646831512451 lr : 0.9414801494009999\n",
      "epoch : 0 [3315/21279] Train loss: 0.52520,Valid loss: 0.67317, time : 12.665807723999023 lr : 0.9414801494009999\n",
      "epoch : 0 [3316/21279] Train loss: 0.55609,Valid loss: 0.89007, time : 12.346068859100342 lr : 0.9414801494009999\n",
      "epoch : 0 [3317/21279] Train loss: 0.54748,Valid loss: 0.95231, time : 12.459043979644775 lr : 0.9414801494009999\n",
      "epoch : 0 [3318/21279] Train loss: 0.56533,Valid loss: 1.00422, time : 12.080159664154053 lr : 0.9414801494009999\n",
      "epoch : 0 [3319/21279] Train loss: 0.56571,Valid loss: 0.94954, time : 12.142395257949829 lr : 0.9414801494009999\n",
      "epoch : 0 [3320/21279] Train loss: 0.60341,Valid loss: 0.93370, time : 11.537291765213013 lr : 0.9414801494009999\n",
      "epoch : 0 [3321/21279] Train loss: 0.57756,Valid loss: 0.99754, time : 12.356815338134766 lr : 0.9414801494009999\n",
      "epoch : 0 [3322/21279] Train loss: 0.56998,Valid loss: 0.80242, time : 11.679772138595581 lr : 0.9414801494009999\n",
      "epoch : 0 [3323/21279] Train loss: 0.56302,Valid loss: 1.00358, time : 12.091965675354004 lr : 0.9414801494009999\n",
      "epoch : 0 [3324/21279] Train loss: 0.56249,Valid loss: 0.84418, time : 14.720566034317017 lr : 0.9414801494009999\n",
      "epoch : 0 [3325/21279] Train loss: 0.56504,Valid loss: 0.87559, time : 12.62830376625061 lr : 0.9414801494009999\n",
      "epoch : 0 [3326/21279] Train loss: 0.56516,Valid loss: 0.76420, time : 12.59792685508728 lr : 0.9414801494009999\n",
      "epoch : 0 [3327/21279] Train loss: 0.54466,Valid loss: 0.98197, time : 12.64666748046875 lr : 0.9414801494009999\n",
      "epoch : 0 [3328/21279] Train loss: 0.54794,Valid loss: 0.84707, time : 13.133200645446777 lr : 0.9414801494009999\n",
      "epoch : 0 [3329/21279] Train loss: 0.53372,Valid loss: 1.01468, time : 12.877683639526367 lr : 0.9414801494009999\n",
      "epoch : 0 [3330/21279] Train loss: 0.56040,Valid loss: 0.78242, time : 12.954773902893066 lr : 0.9414801494009999\n",
      "epoch : 0 [3331/21279] Train loss: 0.56627,Valid loss: 0.88554, time : 12.04015851020813 lr : 0.9414801494009999\n",
      "epoch : 0 [3332/21279] Train loss: 0.55947,Valid loss: 0.82870, time : 12.759608268737793 lr : 0.9414801494009999\n",
      "epoch : 0 [3333/21279] Train loss: 0.52936,Valid loss: 0.78848, time : 12.920477151870728 lr : 0.9414801494009999\n",
      "epoch : 0 [3334/21279] Train loss: 0.53045,Valid loss: 1.03169, time : 12.745058298110962 lr : 0.9414801494009999\n",
      "epoch : 0 [3335/21279] Train loss: 0.66135,Valid loss: 1.15323, time : 12.993498802185059 lr : 0.9414801494009999\n",
      "epoch : 0 [3336/21279] Train loss: 0.70474,Valid loss: 1.53257, time : 15.019092321395874 lr : 0.9414801494009999\n",
      "epoch : 0 [3337/21279] Train loss: 1.01437,Valid loss: 1.15834, time : 12.510457515716553 lr : 0.9414801494009999\n",
      "epoch : 0 [3338/21279] Train loss: 0.67433,Valid loss: 1.31029, time : 12.69632339477539 lr : 0.9414801494009999\n",
      "epoch : 0 [3339/21279] Train loss: 0.64610,Valid loss: 1.18223, time : 12.809894323348999 lr : 0.9414801494009999\n",
      "epoch : 0 [3340/21279] Train loss: 0.59709,Valid loss: 1.23484, time : 12.529210090637207 lr : 0.9414801494009999\n",
      "epoch : 0 [3341/21279] Train loss: 0.57933,Valid loss: 0.74171, time : 12.445876598358154 lr : 0.9414801494009999\n",
      "epoch : 0 [3342/21279] Train loss: 0.57058,Valid loss: 0.97191, time : 12.46647834777832 lr : 0.9414801494009999\n",
      "epoch : 0 [3343/21279] Train loss: 0.55402,Valid loss: 0.87275, time : 12.209028244018555 lr : 0.9414801494009999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3344/21279] Train loss: 0.56510,Valid loss: 0.88773, time : 11.905102729797363 lr : 0.9414801494009999\n",
      "epoch : 0 [3345/21279] Train loss: 0.56621,Valid loss: 0.80053, time : 11.455352067947388 lr : 0.9414801494009999\n",
      "epoch : 0 [3346/21279] Train loss: 0.55122,Valid loss: 0.66040, time : 12.209579467773438 lr : 0.9414801494009999\n",
      "epoch : 0 [3347/21279] Train loss: 0.53274,Valid loss: 0.81810, time : 11.49461030960083 lr : 0.9414801494009999\n",
      "epoch : 0 [3348/21279] Train loss: 0.55822,Valid loss: 0.91604, time : 11.800683975219727 lr : 0.9414801494009999\n",
      "epoch : 0 [3349/21279] Train loss: 0.54425,Valid loss: 0.76539, time : 11.472675561904907 lr : 0.9414801494009999\n",
      "epoch : 0 [3350/21279] Train loss: 0.54850,Valid loss: 0.94379, time : 14.32838225364685 lr : 0.9414801494009999\n",
      "epoch : 0 [3351/21279] Train loss: 0.53923,Valid loss: 1.11671, time : 11.986329555511475 lr : 0.9414801494009999\n",
      "epoch : 0 [3352/21279] Train loss: 0.53707,Valid loss: 0.86522, time : 12.083474397659302 lr : 0.9414801494009999\n",
      "epoch : 0 [3353/21279] Train loss: 0.53217,Valid loss: 0.93222, time : 11.946393966674805 lr : 0.9414801494009999\n",
      "epoch : 0 [3354/21279] Train loss: 0.52531,Valid loss: 0.65694, time : 11.794114828109741 lr : 0.9414801494009999\n",
      "epoch : 0 [3355/21279] Train loss: 0.53669,Valid loss: 0.82647, time : 12.03569221496582 lr : 0.9414801494009999\n",
      "epoch : 0 [3356/21279] Train loss: 0.53596,Valid loss: 0.85849, time : 11.87856650352478 lr : 0.9414801494009999\n",
      "epoch : 0 [3357/21279] Train loss: 0.54187,Valid loss: 0.93927, time : 11.817630529403687 lr : 0.9414801494009999\n",
      "epoch : 0 [3358/21279] Train loss: 0.55043,Valid loss: 0.83950, time : 12.22602915763855 lr : 0.9414801494009999\n",
      "epoch : 0 [3359/21279] Train loss: 0.54126,Valid loss: 0.67220, time : 12.22148060798645 lr : 0.9414801494009999\n",
      "epoch : 0 [3360/21279] Train loss: 0.53826,Valid loss: 0.82367, time : 12.112147569656372 lr : 0.9414801494009999\n",
      "epoch : 0 [3361/21279] Train loss: 0.52237,Valid loss: 0.82874, time : 11.70152735710144 lr : 0.9414801494009999\n",
      "epoch : 0 [3362/21279] Train loss: 0.53031,Valid loss: 0.65987, time : 13.509302854537964 lr : 0.9414801494009999\n",
      "epoch : 0 [3363/21279] Train loss: 0.53158,Valid loss: 0.83426, time : 11.788075923919678 lr : 0.9414801494009999\n",
      "epoch : 0 [3364/21279] Train loss: 0.52784,Valid loss: 0.91189, time : 12.16743540763855 lr : 0.9414801494009999\n",
      "epoch : 0 [3365/21279] Train loss: 0.52908,Valid loss: 0.85345, time : 11.70772123336792 lr : 0.9414801494009999\n",
      "epoch : 0 [3366/21279] Train loss: 0.51642,Valid loss: 0.88138, time : 11.952668905258179 lr : 0.9414801494009999\n",
      "epoch : 0 [3367/21279] Train loss: 0.52595,Valid loss: 0.65157, time : 12.213374614715576 lr : 0.9414801494009999\n",
      "epoch : 0 [3368/21279] Train loss: 0.49856,Valid loss: 0.88641, time : 11.995550870895386 lr : 0.9414801494009999\n",
      "epoch : 0 [3369/21279] Train loss: 0.52040,Valid loss: 0.82789, time : 12.362195014953613 lr : 0.9414801494009999\n",
      "epoch : 0 [3370/21279] Train loss: 0.51667,Valid loss: 0.90856, time : 12.166975975036621 lr : 0.9414801494009999\n",
      "epoch : 0 [3371/21279] Train loss: 0.56165,Valid loss: 0.99775, time : 11.820688724517822 lr : 0.9414801494009999\n",
      "epoch : 0 [3372/21279] Train loss: 0.55650,Valid loss: 0.99547, time : 11.771821022033691 lr : 0.9414801494009999\n",
      "epoch : 0 [3373/21279] Train loss: 0.54280,Valid loss: 0.84581, time : 12.286350727081299 lr : 0.9414801494009999\n",
      "epoch : 0 [3374/21279] Train loss: 0.52624,Valid loss: 0.91488, time : 11.981083869934082 lr : 0.9414801494009999\n",
      "epoch : 0 [3375/21279] Train loss: 0.53949,Valid loss: 0.82335, time : 11.40322208404541 lr : 0.9414801494009999\n",
      "epoch : 0 [3376/21279] Train loss: 0.52049,Valid loss: 0.69856, time : 11.458375215530396 lr : 0.9414801494009999\n",
      "epoch : 0 [3377/21279] Train loss: 0.51968,Valid loss: 0.92975, time : 11.472193717956543 lr : 0.9414801494009999\n",
      "epoch : 0 [3378/21279] Train loss: 0.55281,Valid loss: 0.70358, time : 14.106735706329346 lr : 0.9414801494009999\n",
      "epoch : 0 [3379/21279] Train loss: 0.53064,Valid loss: 1.25257, time : 11.847934007644653 lr : 0.9414801494009999\n",
      "epoch : 0 [3380/21279] Train loss: 0.52840,Valid loss: 0.76415, time : 11.677932500839233 lr : 0.9414801494009999\n",
      "epoch : 0 [3381/21279] Train loss: 0.55605,Valid loss: 1.19494, time : 12.284286975860596 lr : 0.9414801494009999\n",
      "epoch : 0 [3382/21279] Train loss: 0.56315,Valid loss: 1.06765, time : 11.949878692626953 lr : 0.9414801494009999\n",
      "epoch : 0 [3383/21279] Train loss: 0.75797,Valid loss: 1.02026, time : 11.987882137298584 lr : 0.9414801494009999\n",
      "epoch : 0 [3384/21279] Train loss: 0.65919,Valid loss: 0.67039, time : 12.843673706054688 lr : 0.9414801494009999\n",
      "epoch : 0 [3385/21279] Train loss: 0.53363,Valid loss: 0.67459, time : 12.20166015625 lr : 0.9414801494009999\n",
      "epoch : 0 [3386/21279] Train loss: 0.52283,Valid loss: 0.83504, time : 12.380517721176147 lr : 0.9414801494009999\n",
      "epoch : 0 [3387/21279] Train loss: 0.51293,Valid loss: 0.68094, time : 12.712345361709595 lr : 0.9414801494009999\n",
      "epoch : 0 [3388/21279] Train loss: 0.51458,Valid loss: 0.78976, time : 12.9251229763031 lr : 0.9414801494009999\n",
      "epoch : 0 [3389/21279] Train loss: 0.52266,Valid loss: 0.67861, time : 12.59502363204956 lr : 0.9414801494009999\n",
      "epoch : 0 [3390/21279] Train loss: 0.52565,Valid loss: 0.66034, time : 15.5791916847229 lr : 0.9414801494009999\n",
      "epoch : 0 [3391/21279] Train loss: 0.53114,Valid loss: 0.89771, time : 12.702402353286743 lr : 0.9414801494009999\n",
      "epoch : 0 [3392/21279] Train loss: 0.53444,Valid loss: 0.99306, time : 11.903616666793823 lr : 0.9414801494009999\n",
      "epoch : 0 [3393/21279] Train loss: 0.55025,Valid loss: 1.00765, time : 11.971157312393188 lr : 0.9414801494009999\n",
      "epoch : 0 [3394/21279] Train loss: 0.52732,Valid loss: 0.91951, time : 11.661317110061646 lr : 0.9414801494009999\n",
      "epoch : 0 [3395/21279] Train loss: 0.54761,Valid loss: 0.81083, time : 11.592329025268555 lr : 0.9414801494009999\n",
      "epoch : 0 [3396/21279] Train loss: 0.56573,Valid loss: 0.92372, time : 12.673822164535522 lr : 0.9414801494009999\n",
      "epoch : 0 [3397/21279] Train loss: 0.51609,Valid loss: 1.02915, time : 12.37044072151184 lr : 0.9414801494009999\n",
      "epoch : 0 [3398/21279] Train loss: 0.54548,Valid loss: 1.15828, time : 12.076020240783691 lr : 0.9414801494009999\n",
      "epoch : 0 [3399/21279] Train loss: 0.56208,Valid loss: 0.78292, time : 12.90120267868042 lr : 0.9414801494009999\n",
      "epoch : 0 [3400/21279] Train loss: 0.56857,Valid loss: 0.93207, time : 12.187459945678711 lr : 0.9414801494009999\n",
      "epoch : 0 [3401/21279] Train loss: 0.53235,Valid loss: 0.68881, time : 11.788529872894287 lr : 0.9414801494009999\n",
      "epoch : 0 [3402/21279] Train loss: 0.54761,Valid loss: 1.01865, time : 11.916142463684082 lr : 0.9414801494009999\n",
      "epoch : 0 [3403/21279] Train loss: 0.55425,Valid loss: 0.72415, time : 12.728481769561768 lr : 0.9414801494009999\n",
      "epoch : 0 [3404/21279] Train loss: 0.56534,Valid loss: 0.83954, time : 12.527957439422607 lr : 0.9414801494009999\n",
      "epoch : 0 [3405/21279] Train loss: 0.56208,Valid loss: 0.83870, time : 11.913124561309814 lr : 0.9414801494009999\n",
      "epoch : 0 [3406/21279] Train loss: 0.55121,Valid loss: 1.04986, time : 13.663068294525146 lr : 0.9414801494009999\n",
      "epoch : 0 [3407/21279] Train loss: 0.54198,Valid loss: 0.97273, time : 11.934783697128296 lr : 0.9414801494009999\n",
      "epoch : 0 [3408/21279] Train loss: 0.54096,Valid loss: 0.90327, time : 11.608082294464111 lr : 0.9414801494009999\n",
      "epoch : 0 [3409/21279] Train loss: 0.57939,Valid loss: 1.18308, time : 12.699508666992188 lr : 0.9414801494009999\n",
      "epoch : 0 [3410/21279] Train loss: 0.57017,Valid loss: 1.00748, time : 12.237025737762451 lr : 0.9414801494009999\n",
      "epoch : 0 [3411/21279] Train loss: 0.53664,Valid loss: 0.77568, time : 12.513137102127075 lr : 0.9414801494009999\n",
      "epoch : 0 [3412/21279] Train loss: 0.53618,Valid loss: 0.86239, time : 12.384439706802368 lr : 0.9414801494009999\n",
      "epoch : 0 [3413/21279] Train loss: 0.53166,Valid loss: 0.77581, time : 12.856736421585083 lr : 0.9414801494009999\n",
      "epoch : 0 [3414/21279] Train loss: 0.54643,Valid loss: 0.70298, time : 12.206820964813232 lr : 0.9414801494009999\n",
      "epoch : 0 [3415/21279] Train loss: 0.51092,Valid loss: 0.92002, time : 12.146288633346558 lr : 0.9414801494009999\n",
      "epoch : 0 [3416/21279] Train loss: 0.53211,Valid loss: 0.75623, time : 11.472198486328125 lr : 0.9414801494009999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3417/21279] Train loss: 0.53803,Valid loss: 0.76584, time : 11.87417721748352 lr : 0.9414801494009999\n",
      "epoch : 0 [3418/21279] Train loss: 0.50999,Valid loss: 0.65473, time : 12.17015266418457 lr : 0.9414801494009999\n",
      "epoch : 0 [3419/21279] Train loss: 0.49606,Valid loss: 0.88420, time : 14.749756336212158 lr : 0.9414801494009999\n",
      "epoch : 0 [3420/21279] Train loss: 0.52504,Valid loss: 0.78787, time : 11.933556079864502 lr : 0.9414801494009999\n",
      "epoch : 0 [3421/21279] Train loss: 0.52273,Valid loss: 0.66227, time : 12.288264036178589 lr : 0.9414801494009999\n",
      "epoch : 0 [3422/21279] Train loss: 0.50519,Valid loss: 0.97443, time : 12.04464077949524 lr : 0.9414801494009999\n",
      "epoch : 0 [3423/21279] Train loss: 0.52160,Valid loss: 0.99596, time : 11.869939804077148 lr : 0.9414801494009999\n",
      "epoch : 0 [3424/21279] Train loss: 0.52926,Valid loss: 1.00702, time : 11.929860591888428 lr : 0.9414801494009999\n",
      "epoch : 0 [3425/21279] Train loss: 0.53790,Valid loss: 0.94483, time : 11.596354961395264 lr : 0.9414801494009999\n",
      "epoch : 0 [3426/21279] Train loss: 0.55457,Valid loss: 0.94480, time : 11.61537480354309 lr : 0.9414801494009999\n",
      "epoch : 0 [3427/21279] Train loss: 0.52251,Valid loss: 0.71127, time : 12.443017959594727 lr : 0.9414801494009999\n",
      "epoch : 0 [3428/21279] Train loss: 0.54393,Valid loss: 0.79702, time : 12.74381685256958 lr : 0.9414801494009999\n",
      "epoch : 0 [3429/21279] Train loss: 0.51270,Valid loss: 0.70363, time : 12.67257809638977 lr : 0.9414801494009999\n",
      "epoch : 0 [3430/21279] Train loss: 0.52483,Valid loss: 0.83181, time : 13.209151029586792 lr : 0.9414801494009999\n",
      "epoch : 0 [3431/21279] Train loss: 0.51958,Valid loss: 0.93357, time : 12.997986555099487 lr : 0.9414801494009999\n",
      "epoch : 0 [3432/21279] Train loss: 0.49914,Valid loss: 0.87505, time : 13.643574476242065 lr : 0.9414801494009999\n",
      "epoch : 0 [3433/21279] Train loss: 0.50862,Valid loss: 0.94419, time : 12.993937492370605 lr : 0.9414801494009999\n",
      "epoch : 0 [3434/21279] Train loss: 0.49710,Valid loss: 0.91527, time : 15.588988542556763 lr : 0.9414801494009999\n",
      "epoch : 0 [3435/21279] Train loss: 0.51716,Valid loss: 0.91249, time : 12.187605619430542 lr : 0.9414801494009999\n",
      "epoch : 0 [3436/21279] Train loss: 0.57969,Valid loss: 1.50317, time : 12.862691879272461 lr : 0.9414801494009999\n",
      "epoch : 0 [3437/21279] Train loss: 1.06856,Valid loss: 1.15920, time : 12.496163129806519 lr : 0.9414801494009999\n",
      "epoch : 0 [3438/21279] Train loss: 0.77883,Valid loss: 1.16725, time : 12.596382141113281 lr : 0.9414801494009999\n",
      "epoch : 0 [3439/21279] Train loss: 0.66462,Valid loss: 1.15690, time : 12.359293699264526 lr : 0.9414801494009999\n",
      "epoch : 0 [3440/21279] Train loss: 0.61207,Valid loss: 0.99440, time : 11.84692096710205 lr : 0.9414801494009999\n",
      "epoch : 0 [3441/21279] Train loss: 0.54676,Valid loss: 1.03190, time : 12.50601053237915 lr : 0.9414801494009999\n",
      "epoch : 0 [3442/21279] Train loss: 0.53626,Valid loss: 0.67168, time : 12.229033708572388 lr : 0.9414801494009999\n",
      "epoch : 0 [3443/21279] Train loss: 0.52760,Valid loss: 0.92572, time : 13.006973505020142 lr : 0.9414801494009999\n",
      "epoch : 0 [3444/21279] Train loss: 0.54073,Valid loss: 1.38058, time : 12.608621835708618 lr : 0.9414801494009999\n",
      "epoch : 0 [3445/21279] Train loss: 0.55119,Valid loss: 0.72664, time : 12.624762058258057 lr : 0.9414801494009999\n",
      "epoch : 0 [3446/21279] Train loss: 0.52954,Valid loss: 0.68905, time : 15.716082334518433 lr : 0.9414801494009999\n",
      "epoch : 0 [3447/21279] Train loss: 0.52776,Valid loss: 1.63739, time : 11.980165719985962 lr : 0.9414801494009999\n",
      "epoch : 0 [3448/21279] Train loss: 0.53698,Valid loss: 0.94002, time : 11.873694658279419 lr : 0.9414801494009999\n",
      "epoch : 0 [3449/21279] Train loss: 0.53064,Valid loss: 2.45410, time : 12.3518967628479 lr : 0.9414801494009999\n",
      "epoch : 0 [3450/21279] Train loss: 0.53406,Valid loss: 0.73556, time : 12.382829904556274 lr : 0.9414801494009999\n",
      "epoch : 0 [3451/21279] Train loss: 0.53864,Valid loss: 0.72850, time : 12.42901611328125 lr : 0.9414801494009999\n",
      "epoch : 0 [3452/21279] Train loss: 0.50275,Valid loss: 0.68628, time : 12.333025932312012 lr : 0.9414801494009999\n",
      "epoch : 0 [3453/21279] Train loss: 0.52268,Valid loss: 0.78962, time : 12.049873352050781 lr : 0.9414801494009999\n",
      "epoch : 0 [3454/21279] Train loss: 0.66143,Valid loss: 1.91914, time : 11.950288772583008 lr : 0.9414801494009999\n",
      "epoch : 0 [3455/21279] Train loss: 0.67431,Valid loss: 1.73021, time : 12.423691987991333 lr : 0.9414801494009999\n",
      "epoch : 0 [3456/21279] Train loss: 0.69323,Valid loss: 1.60179, time : 12.821150779724121 lr : 0.9414801494009999\n",
      "epoch : 0 [3457/21279] Train loss: 0.98016,Valid loss: 4.03495, time : 12.328750133514404 lr : 0.9414801494009999\n",
      "epoch : 0 [3458/21279] Train loss: 0.93489,Valid loss: 2.05604, time : 12.520836591720581 lr : 0.9414801494009999\n",
      "epoch : 0 [3459/21279] Train loss: 0.92687,Valid loss: 3.19350, time : 12.466726064682007 lr : 0.9414801494009999\n",
      "epoch : 0 [3460/21279] Train loss: 1.05617,Valid loss: 2.51924, time : 17.772825717926025 lr : 0.9414801494009999\n",
      "epoch : 0 [3461/21279] Train loss: 1.24734,Valid loss: 3.47174, time : 11.893102884292603 lr : 0.9414801494009999\n",
      "epoch : 0 [3462/21279] Train loss: 0.94651,Valid loss: 2.14504, time : 12.549344301223755 lr : 0.9414801494009999\n",
      "epoch : 0 [3463/21279] Train loss: 0.82862,Valid loss: 1.90953, time : 11.967387676239014 lr : 0.9414801494009999\n",
      "epoch : 0 [3464/21279] Train loss: 0.65394,Valid loss: 0.96751, time : 12.220522403717041 lr : 0.9414801494009999\n",
      "epoch : 0 [3465/21279] Train loss: 0.58171,Valid loss: 0.99070, time : 11.861987352371216 lr : 0.9414801494009999\n",
      "epoch : 0 [3466/21279] Train loss: 0.55625,Valid loss: 0.79194, time : 12.528238534927368 lr : 0.9414801494009999\n",
      "epoch : 0 [3467/21279] Train loss: 0.56627,Valid loss: 1.03023, time : 12.786892890930176 lr : 0.9414801494009999\n",
      "epoch : 0 [3468/21279] Train loss: 0.55596,Valid loss: 1.39352, time : 12.903462648391724 lr : 0.9414801494009999\n",
      "epoch : 0 [3469/21279] Train loss: 1.04394,Valid loss: 1.12480, time : 13.014090538024902 lr : 0.9414801494009999\n",
      "epoch : 0 [3470/21279] Train loss: 0.57824,Valid loss: 1.28624, time : 12.884481430053711 lr : 0.9414801494009999\n",
      "epoch : 0 [3471/21279] Train loss: 0.54107,Valid loss: 0.87457, time : 12.635705709457397 lr : 0.9414801494009999\n",
      "epoch : 0 [3472/21279] Train loss: 0.53550,Valid loss: 1.10689, time : 21.472957134246826 lr : 0.9414801494009999\n",
      "epoch : 0 [3473/21279] Train loss: 0.53457,Valid loss: 0.85076, time : 12.952707052230835 lr : 0.9414801494009999\n",
      "epoch : 0 [3474/21279] Train loss: 0.52881,Valid loss: 1.07257, time : 12.841638088226318 lr : 0.9414801494009999\n",
      "epoch : 0 [3475/21279] Train loss: 0.51265,Valid loss: 0.74711, time : 12.889953136444092 lr : 0.9414801494009999\n",
      "epoch : 0 [3476/21279] Train loss: 0.52109,Valid loss: 1.03829, time : 13.160305261611938 lr : 0.9414801494009999\n",
      "epoch : 0 [3477/21279] Train loss: 0.52427,Valid loss: 0.79947, time : 12.855602979660034 lr : 0.9414801494009999\n",
      "epoch : 0 [3478/21279] Train loss: 0.50453,Valid loss: 0.74611, time : 13.044402599334717 lr : 0.9414801494009999\n",
      "epoch : 0 [3479/21279] Train loss: 0.51885,Valid loss: 0.79893, time : 12.95683765411377 lr : 0.9414801494009999\n",
      "epoch : 0 [3480/21279] Train loss: 0.51150,Valid loss: 1.24110, time : 12.986136198043823 lr : 0.9414801494009999\n",
      "epoch : 0 [3481/21279] Train loss: 0.57419,Valid loss: 1.77074, time : 13.08608078956604 lr : 0.9414801494009999\n",
      "epoch : 0 [3482/21279] Train loss: 0.50328,Valid loss: 1.01537, time : 12.481626033782959 lr : 0.9414801494009999\n",
      "epoch : 0 [3483/21279] Train loss: 0.52631,Valid loss: 1.09636, time : 13.060954093933105 lr : 0.9414801494009999\n",
      "epoch : 0 [3484/21279] Train loss: 0.50767,Valid loss: 1.12079, time : 12.658479690551758 lr : 0.9414801494009999\n",
      "epoch : 0 [3485/21279] Train loss: 0.50293,Valid loss: 1.10141, time : 13.104982376098633 lr : 0.9414801494009999\n",
      "epoch : 0 [3486/21279] Train loss: 0.48692,Valid loss: 0.93584, time : 13.121797561645508 lr : 0.9414801494009999\n",
      "epoch : 0 [3487/21279] Train loss: 0.53130,Valid loss: 0.92294, time : 12.759212732315063 lr : 0.9414801494009999\n",
      "epoch : 0 [3488/21279] Train loss: 0.50890,Valid loss: 0.81178, time : 18.045090675354004 lr : 0.9414801494009999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3489/21279] Train loss: 0.53546,Valid loss: 0.96043, time : 12.014861822128296 lr : 0.9414801494009999\n",
      "epoch : 0 [3490/21279] Train loss: 0.51107,Valid loss: 1.11985, time : 12.557540893554688 lr : 0.9414801494009999\n",
      "epoch : 0 [3491/21279] Train loss: 0.50391,Valid loss: 0.98713, time : 13.057382345199585 lr : 0.9414801494009999\n",
      "epoch : 0 [3492/21279] Train loss: 0.51656,Valid loss: 1.07648, time : 12.436765193939209 lr : 0.9414801494009999\n",
      "epoch : 0 [3493/21279] Train loss: 0.52037,Valid loss: 0.70336, time : 12.56402587890625 lr : 0.9414801494009999\n",
      "epoch : 0 [3494/21279] Train loss: 0.50926,Valid loss: 0.72611, time : 12.742666482925415 lr : 0.9414801494009999\n",
      "epoch : 0 [3495/21279] Train loss: 0.49980,Valid loss: 0.72893, time : 12.30281138420105 lr : 0.9414801494009999\n",
      "epoch : 0 [3496/21279] Train loss: 0.50177,Valid loss: 0.71307, time : 11.826518535614014 lr : 0.9414801494009999\n",
      "epoch : 0 [3497/21279] Train loss: 0.48949,Valid loss: 0.88470, time : 12.21642518043518 lr : 0.9414801494009999\n",
      "epoch : 0 [3498/21279] Train loss: 0.49093,Valid loss: 0.90492, time : 12.178359746932983 lr : 0.9414801494009999\n",
      "epoch : 0 [3499/21279] Train loss: 0.47779,Valid loss: 0.71571, time : 12.037780284881592 lr : 0.9320653479069899\n",
      "epoch : 0 [3500/21279] Train loss: 0.49774,Valid loss: 0.89289, time : 12.000532150268555 lr : 0.9320653479069899\n",
      "epoch : 0 [3501/21279] Train loss: 0.48918,Valid loss: 0.71445, time : 12.01632308959961 lr : 0.9320653479069899\n",
      "epoch : 0 [3502/21279] Train loss: 0.49234,Valid loss: 0.71261, time : 12.465162992477417 lr : 0.9320653479069899\n",
      "epoch : 0 [3503/21279] Train loss: 0.46920,Valid loss: 0.63481, time : 12.584768056869507 lr : 0.9320653479069899\n",
      "epoch : 0 [3504/21279] Train loss: 0.48554,Valid loss: 0.71855, time : 13.695296049118042 lr : 0.9320653479069899\n",
      "epoch : 0 [3505/21279] Train loss: 0.49541,Valid loss: 0.69134, time : 12.435366868972778 lr : 0.9320653479069899\n",
      "epoch : 0 [3506/21279] Train loss: 0.48399,Valid loss: 0.70694, time : 12.142252922058105 lr : 0.9320653479069899\n",
      "epoch : 0 [3507/21279] Train loss: 0.49897,Valid loss: 0.69428, time : 12.21168565750122 lr : 0.9320653479069899\n",
      "epoch : 0 [3508/21279] Train loss: 0.48902,Valid loss: 0.72996, time : 12.349920272827148 lr : 0.9320653479069899\n",
      "epoch : 0 [3509/21279] Train loss: 0.50335,Valid loss: 0.91971, time : 12.258882761001587 lr : 0.9320653479069899\n",
      "epoch : 0 [3510/21279] Train loss: 0.48189,Valid loss: 1.00494, time : 12.493446350097656 lr : 0.9320653479069899\n",
      "epoch : 0 [3511/21279] Train loss: 0.49855,Valid loss: 1.20352, time : 12.385327100753784 lr : 0.9320653479069899\n",
      "epoch : 0 [3512/21279] Train loss: 0.52534,Valid loss: 1.03468, time : 11.494741439819336 lr : 0.9320653479069899\n",
      "epoch : 0 [3513/21279] Train loss: 0.51157,Valid loss: 1.14524, time : 12.038772106170654 lr : 0.9320653479069899\n",
      "epoch : 0 [3514/21279] Train loss: 0.54280,Valid loss: 0.88245, time : 12.583885669708252 lr : 0.9320653479069899\n",
      "epoch : 0 [3515/21279] Train loss: 0.50194,Valid loss: 0.96528, time : 12.21538257598877 lr : 0.9320653479069899\n",
      "epoch : 0 [3516/21279] Train loss: 0.50875,Valid loss: 0.91607, time : 14.073740243911743 lr : 0.9320653479069899\n",
      "epoch : 0 [3517/21279] Train loss: 0.47839,Valid loss: 1.15219, time : 12.469135761260986 lr : 0.9320653479069899\n",
      "epoch : 0 [3518/21279] Train loss: 0.66326,Valid loss: 2.81289, time : 12.234287023544312 lr : 0.9320653479069899\n",
      "epoch : 0 [3519/21279] Train loss: 0.84072,Valid loss: 5.24616, time : 12.211337089538574 lr : 0.9320653479069899\n",
      "epoch : 0 [3520/21279] Train loss: 0.90737,Valid loss: 1.49239, time : 12.107645988464355 lr : 0.9320653479069899\n",
      "epoch : 0 [3521/21279] Train loss: 0.61863,Valid loss: 1.34765, time : 11.517918109893799 lr : 0.9320653479069899\n",
      "epoch : 0 [3522/21279] Train loss: 0.72576,Valid loss: 1.44078, time : 12.558408737182617 lr : 0.9320653479069899\n",
      "epoch : 0 [3523/21279] Train loss: 0.76480,Valid loss: 1.33884, time : 11.99031662940979 lr : 0.9320653479069899\n",
      "epoch : 0 [3524/21279] Train loss: 0.61122,Valid loss: 0.90681, time : 12.500260829925537 lr : 0.9320653479069899\n",
      "epoch : 0 [3525/21279] Train loss: 0.54461,Valid loss: 0.89920, time : 12.712499141693115 lr : 0.9320653479069899\n",
      "epoch : 0 [3526/21279] Train loss: 0.52937,Valid loss: 1.07508, time : 12.907166481018066 lr : 0.9320653479069899\n",
      "epoch : 0 [3527/21279] Train loss: 0.53554,Valid loss: 0.88306, time : 13.031379461288452 lr : 0.9320653479069899\n",
      "epoch : 0 [3528/21279] Train loss: 0.49352,Valid loss: 0.98860, time : 12.898119688034058 lr : 0.9320653479069899\n",
      "epoch : 0 [3529/21279] Train loss: 0.48531,Valid loss: 0.88335, time : 12.322894096374512 lr : 0.9320653479069899\n",
      "epoch : 0 [3530/21279] Train loss: 0.49840,Valid loss: 0.95234, time : 23.17381978034973 lr : 0.9320653479069899\n",
      "epoch : 0 [3531/21279] Train loss: 0.48008,Valid loss: 0.85363, time : 12.52504563331604 lr : 0.9320653479069899\n",
      "epoch : 0 [3532/21279] Train loss: 0.51417,Valid loss: 0.99405, time : 12.802608251571655 lr : 0.9320653479069899\n",
      "epoch : 0 [3533/21279] Train loss: 0.48597,Valid loss: 0.86031, time : 13.076132535934448 lr : 0.9320653479069899\n",
      "epoch : 0 [3534/21279] Train loss: 0.50208,Valid loss: 0.72997, time : 12.781329870223999 lr : 0.9320653479069899\n",
      "epoch : 0 [3535/21279] Train loss: 0.48658,Valid loss: 0.94977, time : 12.672019481658936 lr : 0.9320653479069899\n",
      "epoch : 0 [3536/21279] Train loss: 0.49399,Valid loss: 0.65190, time : 12.642393112182617 lr : 0.9320653479069899\n",
      "epoch : 0 [3537/21279] Train loss: 0.48634,Valid loss: 0.85112, time : 12.703316688537598 lr : 0.9320653479069899\n",
      "epoch : 0 [3538/21279] Train loss: 0.48156,Valid loss: 0.89487, time : 12.410304307937622 lr : 0.9320653479069899\n",
      "epoch : 0 [3539/21279] Train loss: 0.46006,Valid loss: 0.88232, time : 12.538655281066895 lr : 0.9320653479069899\n",
      "epoch : 0 [3540/21279] Train loss: 0.46541,Valid loss: 0.92526, time : 12.25783109664917 lr : 0.9320653479069899\n",
      "epoch : 0 [3541/21279] Train loss: 0.46673,Valid loss: 0.65336, time : 11.967346906661987 lr : 0.9320653479069899\n",
      "epoch : 0 [3542/21279] Train loss: 0.47824,Valid loss: 1.07681, time : 18.312882661819458 lr : 0.9320653479069899\n",
      "epoch : 0 [3543/21279] Train loss: 0.47589,Valid loss: 0.68335, time : 12.77995252609253 lr : 0.9320653479069899\n",
      "epoch : 0 [3544/21279] Train loss: 0.47166,Valid loss: 0.72798, time : 12.68259596824646 lr : 0.9320653479069899\n",
      "epoch : 0 [3545/21279] Train loss: 0.45620,Valid loss: 0.66670, time : 12.765742778778076 lr : 0.9320653479069899\n",
      "epoch : 0 [3546/21279] Train loss: 0.51272,Valid loss: 0.78425, time : 12.322810888290405 lr : 0.9320653479069899\n",
      "epoch : 0 [3547/21279] Train loss: 0.48179,Valid loss: 0.63854, time : 12.725288152694702 lr : 0.9320653479069899\n",
      "epoch : 0 [3548/21279] Train loss: 0.48073,Valid loss: 0.78696, time : 12.18165397644043 lr : 0.9320653479069899\n",
      "epoch : 0 [3549/21279] Train loss: 0.47431,Valid loss: 0.68582, time : 12.623192310333252 lr : 0.9320653479069899\n",
      "epoch : 0 [3550/21279] Train loss: 0.47716,Valid loss: 0.65304, time : 12.660140991210938 lr : 0.9320653479069899\n",
      "epoch : 0 [3551/21279] Train loss: 0.48153,Valid loss: 0.73500, time : 12.415766716003418 lr : 0.9320653479069899\n",
      "epoch : 0 [3552/21279] Train loss: 0.47498,Valid loss: 0.92192, time : 13.165756702423096 lr : 0.9320653479069899\n",
      "epoch : 0 [3553/21279] Train loss: 0.47467,Valid loss: 0.83075, time : 11.49586033821106 lr : 0.9320653479069899\n",
      "epoch : 0 [3554/21279] Train loss: 0.49582,Valid loss: 0.64900, time : 12.050203084945679 lr : 0.9320653479069899\n",
      "epoch : 0 [3555/21279] Train loss: 0.48145,Valid loss: 0.78957, time : 12.52431344985962 lr : 0.9320653479069899\n",
      "epoch : 0 [3556/21279] Train loss: 0.48892,Valid loss: 0.65481, time : 12.304973602294922 lr : 0.9320653479069899\n",
      "epoch : 0 [3557/21279] Train loss: 0.47199,Valid loss: 0.61424, time : 12.507838249206543 lr : 0.9320653479069899\n",
      "epoch : 0 [3558/21279] Train loss: 0.48830,Valid loss: 0.94173, time : 14.68361783027649 lr : 0.9320653479069899\n",
      "epoch : 0 [3559/21279] Train loss: 0.49772,Valid loss: 0.64864, time : 13.049428462982178 lr : 0.9320653479069899\n",
      "epoch : 0 [3560/21279] Train loss: 0.48783,Valid loss: 0.86705, time : 12.823460102081299 lr : 0.9320653479069899\n",
      "epoch : 0 [3561/21279] Train loss: 0.49708,Valid loss: 1.81770, time : 12.727720737457275 lr : 0.9320653479069899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3562/21279] Train loss: 0.50001,Valid loss: 0.83681, time : 12.891029119491577 lr : 0.9320653479069899\n",
      "epoch : 0 [3563/21279] Train loss: 0.49847,Valid loss: 0.72730, time : 13.238446235656738 lr : 0.9320653479069899\n",
      "epoch : 0 [3564/21279] Train loss: 0.50002,Valid loss: 0.64291, time : 12.534640789031982 lr : 0.9320653479069899\n",
      "epoch : 0 [3565/21279] Train loss: 0.47236,Valid loss: 0.71842, time : 12.99548602104187 lr : 0.9320653479069899\n",
      "epoch : 0 [3566/21279] Train loss: 0.47355,Valid loss: 0.69079, time : 12.833388805389404 lr : 0.9320653479069899\n",
      "epoch : 0 [3567/21279] Train loss: 0.47209,Valid loss: 0.83341, time : 12.865448713302612 lr : 0.9320653479069899\n",
      "epoch : 0 [3568/21279] Train loss: 0.47364,Valid loss: 0.69425, time : 12.093527555465698 lr : 0.9320653479069899\n",
      "epoch : 0 [3569/21279] Train loss: 0.48669,Valid loss: 0.89564, time : 12.394728183746338 lr : 0.9320653479069899\n",
      "epoch : 0 [3570/21279] Train loss: 0.49315,Valid loss: 0.93661, time : 14.896553754806519 lr : 0.9320653479069899\n",
      "epoch : 0 [3571/21279] Train loss: 0.45962,Valid loss: 1.03851, time : 12.585174798965454 lr : 0.9320653479069899\n",
      "epoch : 0 [3572/21279] Train loss: 0.45462,Valid loss: 1.10224, time : 12.831188201904297 lr : 0.9320653479069899\n",
      "epoch : 0 [3573/21279] Train loss: 0.46003,Valid loss: 0.80853, time : 13.089888095855713 lr : 0.9320653479069899\n",
      "epoch : 0 [3574/21279] Train loss: 0.46796,Valid loss: 0.85328, time : 12.609250783920288 lr : 0.9320653479069899\n",
      "epoch : 0 [3575/21279] Train loss: 0.46563,Valid loss: 0.81906, time : 12.602344036102295 lr : 0.9320653479069899\n",
      "epoch : 0 [3576/21279] Train loss: 0.48747,Valid loss: 0.95116, time : 12.595008134841919 lr : 0.9320653479069899\n",
      "epoch : 0 [3577/21279] Train loss: 0.54141,Valid loss: 0.89847, time : 12.327589750289917 lr : 0.9320653479069899\n",
      "epoch : 0 [3578/21279] Train loss: 0.51475,Valid loss: 0.92315, time : 12.757763385772705 lr : 0.9320653479069899\n",
      "epoch : 0 [3579/21279] Train loss: 0.52905,Valid loss: 0.69733, time : 12.023791313171387 lr : 0.9320653479069899\n",
      "epoch : 0 [3580/21279] Train loss: 0.49202,Valid loss: 0.85571, time : 12.572133302688599 lr : 0.9320653479069899\n",
      "epoch : 0 [3581/21279] Train loss: 0.51641,Valid loss: 0.67706, time : 12.217180013656616 lr : 0.9320653479069899\n",
      "epoch : 0 [3582/21279] Train loss: 0.50908,Valid loss: 0.94426, time : 12.10642147064209 lr : 0.9320653479069899\n",
      "epoch : 0 [3583/21279] Train loss: 0.50273,Valid loss: 0.89195, time : 12.417953968048096 lr : 0.9320653479069899\n",
      "epoch : 0 [3584/21279] Train loss: 0.50003,Valid loss: 0.65913, time : 12.500365018844604 lr : 0.9320653479069899\n",
      "epoch : 0 [3585/21279] Train loss: 0.48464,Valid loss: 0.83613, time : 12.022872686386108 lr : 0.9320653479069899\n",
      "epoch : 0 [3586/21279] Train loss: 0.48097,Valid loss: 0.67935, time : 14.686532020568848 lr : 0.9320653479069899\n",
      "epoch : 0 [3587/21279] Train loss: 0.46240,Valid loss: 0.86049, time : 12.608337640762329 lr : 0.9320653479069899\n",
      "epoch : 0 [3588/21279] Train loss: 0.47942,Valid loss: 0.79767, time : 12.944366931915283 lr : 0.9320653479069899\n",
      "epoch : 0 [3589/21279] Train loss: 0.49391,Valid loss: 0.97347, time : 13.094062328338623 lr : 0.9320653479069899\n",
      "epoch : 0 [3590/21279] Train loss: 0.50521,Valid loss: 0.97702, time : 12.900482654571533 lr : 0.9320653479069899\n",
      "epoch : 0 [3591/21279] Train loss: 0.59402,Valid loss: 4.66856, time : 12.958223581314087 lr : 0.9320653479069899\n",
      "epoch : 0 [3592/21279] Train loss: 1.01851,Valid loss: 2.56131, time : 12.742191791534424 lr : 0.9320653479069899\n",
      "epoch : 0 [3593/21279] Train loss: 0.60793,Valid loss: 3.04576, time : 12.82995319366455 lr : 0.9320653479069899\n",
      "epoch : 0 [3594/21279] Train loss: 0.55260,Valid loss: 1.34937, time : 12.922569513320923 lr : 0.9320653479069899\n",
      "epoch : 0 [3595/21279] Train loss: 0.53543,Valid loss: 1.28593, time : 12.774016857147217 lr : 0.9320653479069899\n",
      "epoch : 0 [3596/21279] Train loss: 0.51349,Valid loss: 0.88098, time : 12.622799158096313 lr : 0.9320653479069899\n",
      "epoch : 0 [3597/21279] Train loss: 0.51428,Valid loss: 0.76322, time : 12.30931544303894 lr : 0.9320653479069899\n",
      "epoch : 0 [3598/21279] Train loss: 0.52850,Valid loss: 1.33054, time : 12.192914962768555 lr : 0.9320653479069899\n",
      "epoch : 0 [3599/21279] Train loss: 0.51737,Valid loss: 0.82034, time : 14.59835147857666 lr : 0.9320653479069899\n",
      "epoch : 0 [3600/21279] Train loss: 0.53258,Valid loss: 0.92912, time : 12.638185977935791 lr : 0.9320653479069899\n",
      "epoch : 0 [3601/21279] Train loss: 0.49071,Valid loss: 0.63771, time : 13.05351209640503 lr : 0.9320653479069899\n",
      "epoch : 0 [3602/21279] Train loss: 0.46915,Valid loss: 0.58217, time : 13.190357208251953 lr : 0.9320653479069899\n",
      "epoch : 0 [3603/21279] Train loss: 0.47613,Valid loss: 0.68675, time : 12.862026691436768 lr : 0.9320653479069899\n",
      "epoch : 0 [3604/21279] Train loss: 0.48618,Valid loss: 0.72879, time : 12.649107456207275 lr : 0.9320653479069899\n",
      "epoch : 0 [3605/21279] Train loss: 0.48871,Valid loss: 0.76084, time : 12.626383543014526 lr : 0.9320653479069899\n",
      "epoch : 0 [3606/21279] Train loss: 0.46449,Valid loss: 0.80852, time : 12.933002948760986 lr : 0.9320653479069899\n",
      "epoch : 0 [3607/21279] Train loss: 0.50114,Valid loss: 0.63528, time : 12.939916372299194 lr : 0.9320653479069899\n",
      "epoch : 0 [3608/21279] Train loss: 0.48338,Valid loss: 0.76627, time : 12.396495819091797 lr : 0.9320653479069899\n",
      "epoch : 0 [3609/21279] Train loss: 0.46903,Valid loss: 0.65526, time : 12.674173831939697 lr : 0.9320653479069899\n",
      "epoch : 0 [3610/21279] Train loss: 0.47894,Valid loss: 0.64198, time : 12.616435050964355 lr : 0.9320653479069899\n",
      "epoch : 0 [3611/21279] Train loss: 0.49696,Valid loss: 0.69692, time : 12.601124048233032 lr : 0.9320653479069899\n",
      "epoch : 0 [3612/21279] Train loss: 0.48650,Valid loss: 0.64342, time : 12.322985887527466 lr : 0.9320653479069899\n",
      "epoch : 0 [3613/21279] Train loss: 0.48219,Valid loss: 0.87286, time : 12.443959712982178 lr : 0.9320653479069899\n",
      "epoch : 0 [3614/21279] Train loss: 0.50256,Valid loss: 0.66019, time : 14.638978958129883 lr : 0.9320653479069899\n",
      "epoch : 0 [3615/21279] Train loss: 0.47316,Valid loss: 1.26986, time : 12.604614734649658 lr : 0.9320653479069899\n",
      "epoch : 0 [3616/21279] Train loss: 0.48669,Valid loss: 0.79400, time : 12.769469738006592 lr : 0.9320653479069899\n",
      "epoch : 0 [3617/21279] Train loss: 0.50791,Valid loss: 0.87902, time : 12.128803014755249 lr : 0.9320653479069899\n",
      "epoch : 0 [3618/21279] Train loss: 0.49632,Valid loss: 0.63004, time : 12.831382274627686 lr : 0.9320653479069899\n",
      "epoch : 0 [3619/21279] Train loss: 0.48641,Valid loss: 1.06977, time : 12.846329927444458 lr : 0.9320653479069899\n",
      "epoch : 0 [3620/21279] Train loss: 0.46834,Valid loss: 0.91900, time : 12.725170135498047 lr : 0.9320653479069899\n",
      "epoch : 0 [3621/21279] Train loss: 0.50412,Valid loss: 0.73861, time : 12.641495943069458 lr : 0.9320653479069899\n",
      "epoch : 0 [3622/21279] Train loss: 0.47652,Valid loss: 0.61328, time : 12.86349368095398 lr : 0.9320653479069899\n",
      "epoch : 0 [3623/21279] Train loss: 0.46051,Valid loss: 0.78287, time : 12.763542413711548 lr : 0.9320653479069899\n",
      "epoch : 0 [3624/21279] Train loss: 0.47638,Valid loss: 1.02949, time : 12.357925176620483 lr : 0.9320653479069899\n",
      "epoch : 0 [3625/21279] Train loss: 0.64898,Valid loss: 4.59657, time : 12.745458841323853 lr : 0.9320653479069899\n",
      "epoch : 0 [3626/21279] Train loss: 1.43560,Valid loss: 1.45439, time : 14.661324501037598 lr : 0.9320653479069899\n",
      "epoch : 0 [3627/21279] Train loss: 0.67008,Valid loss: 1.94019, time : 12.63173246383667 lr : 0.9320653479069899\n",
      "epoch : 0 [3628/21279] Train loss: 0.78103,Valid loss: 1.34330, time : 12.767207622528076 lr : 0.9320653479069899\n",
      "epoch : 0 [3629/21279] Train loss: 0.64497,Valid loss: 1.43167, time : 12.51774001121521 lr : 0.9320653479069899\n",
      "epoch : 0 [3630/21279] Train loss: 0.56861,Valid loss: 1.31699, time : 12.881295680999756 lr : 0.9320653479069899\n",
      "epoch : 0 [3631/21279] Train loss: 0.50554,Valid loss: 0.85040, time : 13.114944458007812 lr : 0.9320653479069899\n",
      "epoch : 0 [3632/21279] Train loss: 0.52453,Valid loss: 0.81129, time : 12.730298519134521 lr : 0.9320653479069899\n",
      "epoch : 0 [3633/21279] Train loss: 0.49363,Valid loss: 0.79770, time : 12.99163007736206 lr : 0.9320653479069899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3634/21279] Train loss: 0.49137,Valid loss: 0.70922, time : 12.84322476387024 lr : 0.9320653479069899\n",
      "epoch : 0 [3635/21279] Train loss: 0.48430,Valid loss: 0.78089, time : 13.01398754119873 lr : 0.9320653479069899\n",
      "epoch : 0 [3636/21279] Train loss: 0.47222,Valid loss: 0.72394, time : 12.231327772140503 lr : 0.9320653479069899\n",
      "epoch : 0 [3637/21279] Train loss: 0.46127,Valid loss: 0.71713, time : 12.263696908950806 lr : 0.9320653479069899\n",
      "epoch : 0 [3638/21279] Train loss: 0.45974,Valid loss: 0.70883, time : 12.203615427017212 lr : 0.9320653479069899\n",
      "epoch : 0 [3639/21279] Train loss: 0.45821,Valid loss: 0.73889, time : 12.357778072357178 lr : 0.9320653479069899\n",
      "epoch : 0 [3640/21279] Train loss: 0.47646,Valid loss: 0.91719, time : 14.1509690284729 lr : 0.9320653479069899\n",
      "epoch : 0 [3641/21279] Train loss: 0.47020,Valid loss: 0.68058, time : 12.327698469161987 lr : 0.9320653479069899\n",
      "epoch : 0 [3642/21279] Train loss: 0.47716,Valid loss: 0.59317, time : 12.77692699432373 lr : 0.9320653479069899\n",
      "epoch : 0 [3643/21279] Train loss: 0.49045,Valid loss: 0.61985, time : 12.538500785827637 lr : 0.9320653479069899\n",
      "epoch : 0 [3644/21279] Train loss: 0.46184,Valid loss: 1.33620, time : 12.587751626968384 lr : 0.9320653479069899\n",
      "epoch : 0 [3645/21279] Train loss: 0.56097,Valid loss: 1.88979, time : 13.001784324645996 lr : 0.9320653479069899\n",
      "epoch : 0 [3646/21279] Train loss: 0.52269,Valid loss: 0.90465, time : 12.478940963745117 lr : 0.9320653479069899\n",
      "epoch : 0 [3647/21279] Train loss: 0.51261,Valid loss: 0.78601, time : 12.231410026550293 lr : 0.9320653479069899\n",
      "epoch : 0 [3648/21279] Train loss: 0.48292,Valid loss: 0.92600, time : 12.379663467407227 lr : 0.9320653479069899\n",
      "epoch : 0 [3649/21279] Train loss: 0.50851,Valid loss: 0.79915, time : 12.644380807876587 lr : 0.9320653479069899\n",
      "epoch : 0 [3650/21279] Train loss: 0.48652,Valid loss: 0.98499, time : 12.89204478263855 lr : 0.9320653479069899\n",
      "epoch : 0 [3651/21279] Train loss: 0.47958,Valid loss: 0.93988, time : 12.761940717697144 lr : 0.9320653479069899\n",
      "epoch : 0 [3652/21279] Train loss: 0.46296,Valid loss: 0.75388, time : 14.830500364303589 lr : 0.9320653479069899\n",
      "epoch : 0 [3653/21279] Train loss: 0.46682,Valid loss: 0.96908, time : 13.185370206832886 lr : 0.9320653479069899\n",
      "epoch : 0 [3654/21279] Train loss: 0.44868,Valid loss: 0.89786, time : 12.944975852966309 lr : 0.9320653479069899\n",
      "epoch : 0 [3655/21279] Train loss: 0.46449,Valid loss: 0.67148, time : 13.31807279586792 lr : 0.9320653479069899\n",
      "epoch : 0 [3656/21279] Train loss: 0.45540,Valid loss: 0.62791, time : 12.827219247817993 lr : 0.9320653479069899\n",
      "epoch : 0 [3657/21279] Train loss: 0.46209,Valid loss: 0.86843, time : 13.282124519348145 lr : 0.9320653479069899\n",
      "epoch : 0 [3658/21279] Train loss: 0.46056,Valid loss: 0.68955, time : 13.021679878234863 lr : 0.9320653479069899\n",
      "epoch : 0 [3659/21279] Train loss: 0.45152,Valid loss: 0.73837, time : 13.038774251937866 lr : 0.9320653479069899\n",
      "epoch : 0 [3660/21279] Train loss: 0.46452,Valid loss: 0.68417, time : 12.946071147918701 lr : 0.9320653479069899\n",
      "epoch : 0 [3661/21279] Train loss: 0.48231,Valid loss: 0.66548, time : 13.284578800201416 lr : 0.9320653479069899\n",
      "epoch : 0 [3662/21279] Train loss: 0.45628,Valid loss: 0.78016, time : 13.50341510772705 lr : 0.9320653479069899\n",
      "epoch : 0 [3663/21279] Train loss: 0.44877,Valid loss: 0.79487, time : 13.059610843658447 lr : 0.9320653479069899\n",
      "epoch : 0 [3664/21279] Train loss: 0.46867,Valid loss: 0.75664, time : 12.846998929977417 lr : 0.9320653479069899\n",
      "epoch : 0 [3665/21279] Train loss: 0.45481,Valid loss: 0.75092, time : 13.057719945907593 lr : 0.9320653479069899\n",
      "epoch : 0 [3666/21279] Train loss: 0.47325,Valid loss: 0.89817, time : 12.036513328552246 lr : 0.9320653479069899\n",
      "epoch : 0 [3667/21279] Train loss: 0.47420,Valid loss: 0.78687, time : 12.430209159851074 lr : 0.9320653479069899\n",
      "epoch : 0 [3668/21279] Train loss: 0.47818,Valid loss: 0.70808, time : 14.353813648223877 lr : 0.9320653479069899\n",
      "epoch : 0 [3669/21279] Train loss: 0.45900,Valid loss: 0.59978, time : 12.67771029472351 lr : 0.9320653479069899\n",
      "epoch : 0 [3670/21279] Train loss: 0.46708,Valid loss: 0.82787, time : 11.979610681533813 lr : 0.9320653479069899\n",
      "epoch : 0 [3671/21279] Train loss: 0.48136,Valid loss: 0.77476, time : 12.559850215911865 lr : 0.9320653479069899\n",
      "epoch : 0 [3672/21279] Train loss: 0.47962,Valid loss: 0.89196, time : 12.742039442062378 lr : 0.9320653479069899\n",
      "epoch : 0 [3673/21279] Train loss: 0.48077,Valid loss: 0.92269, time : 12.61937928199768 lr : 0.9320653479069899\n",
      "epoch : 0 [3674/21279] Train loss: 0.48471,Valid loss: 0.83112, time : 12.721463680267334 lr : 0.9320653479069899\n",
      "epoch : 0 [3675/21279] Train loss: 0.46287,Valid loss: 0.97993, time : 12.805987119674683 lr : 0.9320653479069899\n",
      "epoch : 0 [3676/21279] Train loss: 0.46429,Valid loss: 1.71799, time : 12.893200159072876 lr : 0.9320653479069899\n",
      "epoch : 0 [3677/21279] Train loss: 0.52337,Valid loss: 0.84519, time : 13.169391632080078 lr : 0.9320653479069899\n",
      "epoch : 0 [3678/21279] Train loss: 0.55695,Valid loss: 0.90571, time : 12.870054483413696 lr : 0.9320653479069899\n",
      "epoch : 0 [3679/21279] Train loss: 0.54336,Valid loss: 0.64877, time : 12.222557783126831 lr : 0.9320653479069899\n",
      "epoch : 0 [3680/21279] Train loss: 0.54137,Valid loss: 1.04367, time : 14.56094741821289 lr : 0.9320653479069899\n",
      "epoch : 0 [3681/21279] Train loss: 0.72956,Valid loss: 1.63695, time : 12.461464643478394 lr : 0.9320653479069899\n",
      "epoch : 0 [3682/21279] Train loss: 0.77768,Valid loss: 1.06082, time : 12.867844343185425 lr : 0.9320653479069899\n",
      "epoch : 0 [3683/21279] Train loss: 0.55924,Valid loss: 0.88303, time : 12.99373459815979 lr : 0.9320653479069899\n",
      "epoch : 0 [3684/21279] Train loss: 0.51289,Valid loss: 0.77582, time : 12.808382511138916 lr : 0.9320653479069899\n",
      "epoch : 0 [3685/21279] Train loss: 0.50201,Valid loss: 0.65495, time : 12.263491868972778 lr : 0.9320653479069899\n",
      "epoch : 0 [3686/21279] Train loss: 0.47295,Valid loss: 0.62604, time : 12.501378297805786 lr : 0.9320653479069899\n",
      "epoch : 0 [3687/21279] Train loss: 0.45689,Valid loss: 0.71899, time : 12.21428894996643 lr : 0.9320653479069899\n",
      "epoch : 0 [3688/21279] Train loss: 0.45719,Valid loss: 0.59839, time : 12.414645433425903 lr : 0.9320653479069899\n",
      "epoch : 0 [3689/21279] Train loss: 0.46144,Valid loss: 0.62118, time : 12.37353777885437 lr : 0.9320653479069899\n",
      "epoch : 0 [3690/21279] Train loss: 0.46323,Valid loss: 0.93178, time : 12.280839920043945 lr : 0.9320653479069899\n",
      "epoch : 0 [3691/21279] Train loss: 0.44982,Valid loss: 0.88894, time : 12.698084831237793 lr : 0.9320653479069899\n",
      "epoch : 0 [3692/21279] Train loss: 0.45145,Valid loss: 0.81242, time : 14.667566299438477 lr : 0.9320653479069899\n",
      "epoch : 0 [3693/21279] Train loss: 0.44474,Valid loss: 0.86753, time : 12.484904527664185 lr : 0.9320653479069899\n",
      "epoch : 0 [3694/21279] Train loss: 0.43753,Valid loss: 1.10212, time : 12.489506006240845 lr : 0.9320653479069899\n",
      "epoch : 0 [3695/21279] Train loss: 0.46542,Valid loss: 0.67971, time : 12.398081302642822 lr : 0.9320653479069899\n",
      "epoch : 0 [3696/21279] Train loss: 0.45458,Valid loss: 0.68633, time : 12.356329202651978 lr : 0.9320653479069899\n",
      "epoch : 0 [3697/21279] Train loss: 0.46608,Valid loss: 0.60173, time : 12.010159015655518 lr : 0.9320653479069899\n",
      "epoch : 0 [3698/21279] Train loss: 0.45036,Valid loss: 0.63609, time : 12.09608006477356 lr : 0.9320653479069899\n",
      "epoch : 0 [3699/21279] Train loss: 0.45910,Valid loss: 0.60608, time : 12.359925270080566 lr : 0.9320653479069899\n",
      "epoch : 0 [3700/21279] Train loss: 0.46471,Valid loss: 0.63491, time : 12.554830074310303 lr : 0.9320653479069899\n",
      "epoch : 0 [3701/21279] Train loss: 0.45451,Valid loss: 0.80978, time : 12.469207763671875 lr : 0.9320653479069899\n",
      "epoch : 0 [3702/21279] Train loss: 0.42065,Valid loss: 0.83718, time : 12.651803255081177 lr : 0.9320653479069899\n",
      "epoch : 0 [3703/21279] Train loss: 0.43602,Valid loss: 0.88606, time : 12.37762999534607 lr : 0.9320653479069899\n",
      "epoch : 0 [3704/21279] Train loss: 0.43570,Valid loss: 0.63161, time : 12.384647130966187 lr : 0.9320653479069899\n",
      "epoch : 0 [3705/21279] Train loss: 0.46439,Valid loss: 0.60023, time : 13.144840478897095 lr : 0.9320653479069899\n",
      "epoch : 0 [3706/21279] Train loss: 0.45258,Valid loss: 0.64502, time : 12.946441888809204 lr : 0.9320653479069899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3707/21279] Train loss: 0.44139,Valid loss: 0.68073, time : 13.037774801254272 lr : 0.9320653479069899\n",
      "epoch : 0 [3708/21279] Train loss: 0.45025,Valid loss: 0.58006, time : 14.575669288635254 lr : 0.9320653479069899\n",
      "epoch : 0 [3709/21279] Train loss: 0.44028,Valid loss: 0.81596, time : 13.000950336456299 lr : 0.9320653479069899\n",
      "epoch : 0 [3710/21279] Train loss: 0.44944,Valid loss: 0.67920, time : 12.918215990066528 lr : 0.9320653479069899\n",
      "epoch : 0 [3711/21279] Train loss: 0.46228,Valid loss: 0.87552, time : 12.980267524719238 lr : 0.9320653479069899\n",
      "epoch : 0 [3712/21279] Train loss: 0.44846,Valid loss: 0.61077, time : 12.966789960861206 lr : 0.9320653479069899\n",
      "epoch : 0 [3713/21279] Train loss: 0.47191,Valid loss: 1.06346, time : 13.187034606933594 lr : 0.9320653479069899\n",
      "epoch : 0 [3714/21279] Train loss: 0.43759,Valid loss: 0.82266, time : 12.078485250473022 lr : 0.9320653479069899\n",
      "epoch : 0 [3715/21279] Train loss: 0.43210,Valid loss: 0.67690, time : 12.38076663017273 lr : 0.9320653479069899\n",
      "epoch : 0 [3716/21279] Train loss: 0.49785,Valid loss: 0.94360, time : 12.660212755203247 lr : 0.9320653479069899\n",
      "epoch : 0 [3717/21279] Train loss: 0.55206,Valid loss: 2.73656, time : 12.801817178726196 lr : 0.9320653479069899\n",
      "epoch : 0 [3718/21279] Train loss: 0.51190,Valid loss: 0.99863, time : 12.612252235412598 lr : 0.9320653479069899\n",
      "epoch : 0 [3719/21279] Train loss: 0.50830,Valid loss: 0.93221, time : 12.604218482971191 lr : 0.9320653479069899\n",
      "epoch : 0 [3720/21279] Train loss: 0.43961,Valid loss: 0.84193, time : 12.855268716812134 lr : 0.9320653479069899\n",
      "epoch : 0 [3721/21279] Train loss: 0.46088,Valid loss: 1.03851, time : 15.009356260299683 lr : 0.9320653479069899\n",
      "epoch : 0 [3722/21279] Train loss: 0.46385,Valid loss: 0.75946, time : 12.170679569244385 lr : 0.9320653479069899\n",
      "epoch : 0 [3723/21279] Train loss: 0.46042,Valid loss: 0.65246, time : 12.437710046768188 lr : 0.9320653479069899\n",
      "epoch : 0 [3724/21279] Train loss: 0.46100,Valid loss: 0.82122, time : 12.18398380279541 lr : 0.9320653479069899\n",
      "epoch : 0 [3725/21279] Train loss: 0.45166,Valid loss: 0.67216, time : 12.546173095703125 lr : 0.9320653479069899\n",
      "epoch : 0 [3726/21279] Train loss: 0.44055,Valid loss: 0.75732, time : 12.058014869689941 lr : 0.9320653479069899\n",
      "epoch : 0 [3727/21279] Train loss: 0.43990,Valid loss: 0.60348, time : 12.519548416137695 lr : 0.9320653479069899\n",
      "epoch : 0 [3728/21279] Train loss: 0.45550,Valid loss: 0.78402, time : 12.773815870285034 lr : 0.9320653479069899\n",
      "epoch : 0 [3729/21279] Train loss: 0.43437,Valid loss: 0.67889, time : 12.796481370925903 lr : 0.9320653479069899\n",
      "epoch : 0 [3730/21279] Train loss: 0.43715,Valid loss: 0.64157, time : 12.73998498916626 lr : 0.9320653479069899\n",
      "epoch : 0 [3731/21279] Train loss: 0.43890,Valid loss: 0.65922, time : 12.531766176223755 lr : 0.9320653479069899\n",
      "epoch : 0 [3732/21279] Train loss: 0.44585,Valid loss: 0.85326, time : 12.749767780303955 lr : 0.9320653479069899\n",
      "epoch : 0 [3733/21279] Train loss: 0.43824,Valid loss: 0.62434, time : 12.960447072982788 lr : 0.9320653479069899\n",
      "epoch : 0 [3734/21279] Train loss: 0.42655,Valid loss: 0.69245, time : 12.834043741226196 lr : 0.9320653479069899\n",
      "epoch : 0 [3735/21279] Train loss: 0.43249,Valid loss: 0.62137, time : 12.654091119766235 lr : 0.9320653479069899\n",
      "epoch : 0 [3736/21279] Train loss: 0.45449,Valid loss: 0.63401, time : 14.374412059783936 lr : 0.9320653479069899\n",
      "epoch : 0 [3737/21279] Train loss: 0.44187,Valid loss: 0.64082, time : 12.517897605895996 lr : 0.9320653479069899\n",
      "epoch : 0 [3738/21279] Train loss: 0.44821,Valid loss: 0.68252, time : 12.499346256256104 lr : 0.9320653479069899\n",
      "epoch : 0 [3739/21279] Train loss: 0.42011,Valid loss: 0.62824, time : 12.831006526947021 lr : 0.9320653479069899\n",
      "epoch : 0 [3740/21279] Train loss: 0.43329,Valid loss: 0.62070, time : 12.681259393692017 lr : 0.9320653479069899\n",
      "epoch : 0 [3741/21279] Train loss: 0.43394,Valid loss: 0.66412, time : 13.0025315284729 lr : 0.9320653479069899\n",
      "epoch : 0 [3742/21279] Train loss: 0.43123,Valid loss: 0.68930, time : 12.863895654678345 lr : 0.9320653479069899\n",
      "epoch : 0 [3743/21279] Train loss: 0.41905,Valid loss: 0.58532, time : 12.877485990524292 lr : 0.9320653479069899\n",
      "epoch : 0 [3744/21279] Train loss: 0.44610,Valid loss: 0.66433, time : 12.740690469741821 lr : 0.9320653479069899\n",
      "epoch : 0 [3745/21279] Train loss: 0.43243,Valid loss: 0.56215, time : 12.701112985610962 lr : 0.9320653479069899\n",
      "epoch : 0 [3746/21279] Train loss: 0.42338,Valid loss: 0.64640, time : 11.92312741279602 lr : 0.9320653479069899\n",
      "epoch : 0 [3747/21279] Train loss: 0.44061,Valid loss: 0.56144, time : 12.135645627975464 lr : 0.9320653479069899\n",
      "epoch : 0 [3748/21279] Train loss: 0.42121,Valid loss: 0.79071, time : 14.109984636306763 lr : 0.9320653479069899\n",
      "epoch : 0 [3749/21279] Train loss: 0.41184,Valid loss: 0.74627, time : 11.979400157928467 lr : 0.9320653479069899\n",
      "epoch : 0 [3750/21279] Train loss: 0.44041,Valid loss: 1.04112, time : 11.87865161895752 lr : 0.9320653479069899\n",
      "epoch : 0 [3751/21279] Train loss: 0.43027,Valid loss: 0.57867, time : 12.231545209884644 lr : 0.9320653479069899\n",
      "epoch : 0 [3752/21279] Train loss: 0.45127,Valid loss: 0.61543, time : 12.238337278366089 lr : 0.9320653479069899\n",
      "epoch : 0 [3753/21279] Train loss: 0.45491,Valid loss: 0.59420, time : 12.441281080245972 lr : 0.9320653479069899\n",
      "epoch : 0 [3754/21279] Train loss: 0.44722,Valid loss: 0.64557, time : 12.399926900863647 lr : 0.9320653479069899\n",
      "epoch : 0 [3755/21279] Train loss: 0.45469,Valid loss: 0.59929, time : 12.036659955978394 lr : 0.9320653479069899\n",
      "epoch : 0 [3756/21279] Train loss: 0.48181,Valid loss: 0.59399, time : 12.418662309646606 lr : 0.9320653479069899\n",
      "epoch : 0 [3757/21279] Train loss: 0.46645,Valid loss: 0.81311, time : 12.042076587677002 lr : 0.9320653479069899\n",
      "epoch : 0 [3758/21279] Train loss: 0.45060,Valid loss: 0.67709, time : 12.319815397262573 lr : 0.9320653479069899\n",
      "epoch : 0 [3759/21279] Train loss: 0.45726,Valid loss: 0.83368, time : 12.216135740280151 lr : 0.9320653479069899\n",
      "epoch : 0 [3760/21279] Train loss: 0.42675,Valid loss: 0.86568, time : 12.660247325897217 lr : 0.9320653479069899\n",
      "epoch : 0 [3761/21279] Train loss: 0.42966,Valid loss: 0.54730, time : 11.86378526687622 lr : 0.9320653479069899\n",
      "epoch : 0 [3762/21279] Train loss: 0.43032,Valid loss: 0.63949, time : 22.559549808502197 lr : 0.9320653479069899\n",
      "epoch : 0 [3763/21279] Train loss: 0.44144,Valid loss: 0.73704, time : 11.527408361434937 lr : 0.9320653479069899\n",
      "epoch : 0 [3764/21279] Train loss: 0.42394,Valid loss: 0.68164, time : 12.030537605285645 lr : 0.9320653479069899\n",
      "epoch : 0 [3765/21279] Train loss: 0.41610,Valid loss: 0.82143, time : 12.342028617858887 lr : 0.9320653479069899\n",
      "epoch : 0 [3766/21279] Train loss: 0.41797,Valid loss: 0.60122, time : 12.363385677337646 lr : 0.9320653479069899\n",
      "epoch : 0 [3767/21279] Train loss: 0.41514,Valid loss: 0.78763, time : 12.403156757354736 lr : 0.9320653479069899\n",
      "epoch : 0 [3768/21279] Train loss: 0.43261,Valid loss: 0.54254, time : 12.791513442993164 lr : 0.9320653479069899\n",
      "epoch : 0 [3769/21279] Train loss: 0.42146,Valid loss: 1.11768, time : 12.23857855796814 lr : 0.9320653479069899\n",
      "epoch : 0 [3770/21279] Train loss: 0.43630,Valid loss: 0.55869, time : 12.574131727218628 lr : 0.9320653479069899\n",
      "epoch : 0 [3771/21279] Train loss: 0.42620,Valid loss: 0.79555, time : 12.289294242858887 lr : 0.9320653479069899\n",
      "epoch : 0 [3772/21279] Train loss: 0.45057,Valid loss: 0.79535, time : 12.543001890182495 lr : 0.9320653479069899\n",
      "epoch : 0 [3773/21279] Train loss: 0.44943,Valid loss: 0.67037, time : 13.229891061782837 lr : 0.9320653479069899\n",
      "epoch : 0 [3774/21279] Train loss: 0.45083,Valid loss: 0.78052, time : 14.610648155212402 lr : 0.9320653479069899\n",
      "epoch : 0 [3775/21279] Train loss: 0.45805,Valid loss: 0.78862, time : 12.606557846069336 lr : 0.9320653479069899\n",
      "epoch : 0 [3776/21279] Train loss: 0.43479,Valid loss: 0.66976, time : 12.575273990631104 lr : 0.9320653479069899\n",
      "epoch : 0 [3777/21279] Train loss: 0.42011,Valid loss: 0.98364, time : 11.509806156158447 lr : 0.9320653479069899\n",
      "epoch : 0 [3778/21279] Train loss: 0.43372,Valid loss: 0.64000, time : 12.56681203842163 lr : 0.9320653479069899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3779/21279] Train loss: 0.44940,Valid loss: 0.90091, time : 12.883806228637695 lr : 0.9320653479069899\n",
      "epoch : 0 [3780/21279] Train loss: 0.44736,Valid loss: 0.82808, time : 12.915379524230957 lr : 0.9320653479069899\n",
      "epoch : 0 [3781/21279] Train loss: 0.43016,Valid loss: 0.62057, time : 13.110613346099854 lr : 0.9320653479069899\n",
      "epoch : 0 [3782/21279] Train loss: 0.44783,Valid loss: 0.66264, time : 12.605066299438477 lr : 0.9320653479069899\n",
      "epoch : 0 [3783/21279] Train loss: 0.45264,Valid loss: 0.69007, time : 13.04783296585083 lr : 0.9320653479069899\n",
      "epoch : 0 [3784/21279] Train loss: 0.43491,Valid loss: 0.60999, time : 12.330165386199951 lr : 0.9320653479069899\n",
      "epoch : 0 [3785/21279] Train loss: 0.43916,Valid loss: 0.58925, time : 12.643773794174194 lr : 0.9320653479069899\n",
      "epoch : 0 [3786/21279] Train loss: 0.42403,Valid loss: 0.63388, time : 12.82482385635376 lr : 0.9320653479069899\n",
      "epoch : 0 [3787/21279] Train loss: 0.42719,Valid loss: 1.14321, time : 12.009418487548828 lr : 0.9320653479069899\n",
      "epoch : 0 [3788/21279] Train loss: 0.42748,Valid loss: 0.92820, time : 11.922837495803833 lr : 0.9320653479069899\n",
      "epoch : 0 [3789/21279] Train loss: 0.42397,Valid loss: 0.55079, time : 11.930070400238037 lr : 0.9320653479069899\n",
      "epoch : 0 [3790/21279] Train loss: 0.40059,Valid loss: 1.10490, time : 14.405670642852783 lr : 0.9320653479069899\n",
      "epoch : 0 [3791/21279] Train loss: 0.46634,Valid loss: 0.89767, time : 12.523112773895264 lr : 0.9320653479069899\n",
      "epoch : 0 [3792/21279] Train loss: 0.58446,Valid loss: 3.30308, time : 12.191057920455933 lr : 0.9320653479069899\n",
      "epoch : 0 [3793/21279] Train loss: 1.05144,Valid loss: 1.39947, time : 12.145721197128296 lr : 0.9320653479069899\n",
      "epoch : 0 [3794/21279] Train loss: 1.05999,Valid loss: 2.86653, time : 12.772297620773315 lr : 0.9320653479069899\n",
      "epoch : 0 [3795/21279] Train loss: 1.26884,Valid loss: 1.35611, time : 12.732624769210815 lr : 0.9320653479069899\n",
      "epoch : 0 [3796/21279] Train loss: 0.84175,Valid loss: 1.31801, time : 12.498103141784668 lr : 0.9320653479069899\n",
      "epoch : 0 [3797/21279] Train loss: 0.66134,Valid loss: 1.42116, time : 12.089380502700806 lr : 0.9320653479069899\n",
      "epoch : 0 [3798/21279] Train loss: 0.89178,Valid loss: 1.75193, time : 12.670973062515259 lr : 0.9320653479069899\n",
      "epoch : 0 [3799/21279] Train loss: 0.83611,Valid loss: 1.74188, time : 12.371007442474365 lr : 0.9320653479069899\n",
      "epoch : 0 [3800/21279] Train loss: 0.83497,Valid loss: 0.99383, time : 12.785268783569336 lr : 0.9320653479069899\n",
      "epoch : 0 [3801/21279] Train loss: 0.60025,Valid loss: 1.13949, time : 12.67272424697876 lr : 0.9320653479069899\n",
      "epoch : 0 [3802/21279] Train loss: 0.51547,Valid loss: 0.97494, time : 14.433102130889893 lr : 0.9320653479069899\n",
      "epoch : 0 [3803/21279] Train loss: 0.52215,Valid loss: 0.74192, time : 12.910886764526367 lr : 0.9320653479069899\n",
      "epoch : 0 [3804/21279] Train loss: 0.47954,Valid loss: 0.68833, time : 12.878886222839355 lr : 0.9320653479069899\n",
      "epoch : 0 [3805/21279] Train loss: 0.46912,Valid loss: 0.73723, time : 12.804224491119385 lr : 0.9320653479069899\n",
      "epoch : 0 [3806/21279] Train loss: 0.45555,Valid loss: 0.73727, time : 12.654146432876587 lr : 0.9320653479069899\n",
      "epoch : 0 [3807/21279] Train loss: 0.44729,Valid loss: 0.68086, time : 12.397563695907593 lr : 0.9320653479069899\n",
      "epoch : 0 [3808/21279] Train loss: 0.44598,Valid loss: 0.63661, time : 12.418023109436035 lr : 0.9320653479069899\n",
      "epoch : 0 [3809/21279] Train loss: 0.43426,Valid loss: 0.64840, time : 11.550730228424072 lr : 0.9320653479069899\n",
      "epoch : 0 [3810/21279] Train loss: 0.43834,Valid loss: 0.69829, time : 12.397746562957764 lr : 0.9320653479069899\n",
      "epoch : 0 [3811/21279] Train loss: 0.41393,Valid loss: 0.75047, time : 11.728607892990112 lr : 0.9320653479069899\n",
      "epoch : 0 [3812/21279] Train loss: 0.42697,Valid loss: 0.61849, time : 12.217382669448853 lr : 0.9320653479069899\n",
      "epoch : 0 [3813/21279] Train loss: 0.42898,Valid loss: 0.70165, time : 12.213020086288452 lr : 0.9320653479069899\n",
      "epoch : 0 [3814/21279] Train loss: 0.41573,Valid loss: 0.83456, time : 12.514512062072754 lr : 0.9320653479069899\n",
      "epoch : 0 [3815/21279] Train loss: 0.41732,Valid loss: 0.62492, time : 13.291840076446533 lr : 0.9320653479069899\n",
      "epoch : 0 [3816/21279] Train loss: 0.40155,Valid loss: 0.59671, time : 12.492814302444458 lr : 0.9320653479069899\n",
      "epoch : 0 [3817/21279] Train loss: 0.42872,Valid loss: 0.84069, time : 12.780274629592896 lr : 0.9320653479069899\n",
      "epoch : 0 [3818/21279] Train loss: 0.41885,Valid loss: 1.01476, time : 14.545729398727417 lr : 0.9320653479069899\n",
      "epoch : 0 [3819/21279] Train loss: 0.40507,Valid loss: 0.54554, time : 12.6121187210083 lr : 0.9320653479069899\n",
      "epoch : 0 [3820/21279] Train loss: 0.40965,Valid loss: 0.60757, time : 12.726504564285278 lr : 0.9320653479069899\n",
      "epoch : 0 [3821/21279] Train loss: 0.41811,Valid loss: 0.55875, time : 12.39238429069519 lr : 0.9320653479069899\n",
      "epoch : 0 [3822/21279] Train loss: 0.43626,Valid loss: 0.94150, time : 12.379992723464966 lr : 0.9320653479069899\n",
      "epoch : 0 [3823/21279] Train loss: 0.44254,Valid loss: 0.54996, time : 12.563593626022339 lr : 0.9320653479069899\n",
      "epoch : 0 [3824/21279] Train loss: 0.41124,Valid loss: 0.81131, time : 12.586958885192871 lr : 0.9320653479069899\n",
      "epoch : 0 [3825/21279] Train loss: 0.41145,Valid loss: 0.53809, time : 12.48705768585205 lr : 0.9320653479069899\n",
      "epoch : 0 [3826/21279] Train loss: 0.40414,Valid loss: 0.85844, time : 12.520827054977417 lr : 0.9320653479069899\n",
      "epoch : 0 [3827/21279] Train loss: 0.40645,Valid loss: 0.52096, time : 12.120843887329102 lr : 0.9320653479069899\n",
      "epoch : 0 [3828/21279] Train loss: 0.40740,Valid loss: 0.61115, time : 11.85736894607544 lr : 0.9320653479069899\n",
      "epoch : 0 [3829/21279] Train loss: 0.40266,Valid loss: 0.51988, time : 12.338832378387451 lr : 0.9320653479069899\n",
      "epoch : 0 [3830/21279] Train loss: 0.43060,Valid loss: 0.58219, time : 12.454627275466919 lr : 0.9320653479069899\n",
      "epoch : 0 [3831/21279] Train loss: 0.42894,Valid loss: 0.61359, time : 16.133492708206177 lr : 0.9320653479069899\n",
      "epoch : 0 [3832/21279] Train loss: 0.45105,Valid loss: 0.60083, time : 12.444599866867065 lr : 0.9320653479069899\n",
      "epoch : 0 [3833/21279] Train loss: 0.41335,Valid loss: 0.66287, time : 13.147011995315552 lr : 0.9320653479069899\n",
      "epoch : 0 [3834/21279] Train loss: 0.42929,Valid loss: 1.31539, time : 12.818898677825928 lr : 0.9320653479069899\n",
      "epoch : 0 [3835/21279] Train loss: 1.01734,Valid loss: 4.60030, time : 13.249077081680298 lr : 0.9320653479069899\n",
      "epoch : 0 [3836/21279] Train loss: 1.22071,Valid loss: 1.42200, time : 13.044914484024048 lr : 0.9320653479069899\n",
      "epoch : 0 [3837/21279] Train loss: 0.98103,Valid loss: 2.21090, time : 12.877776384353638 lr : 0.9320653479069899\n",
      "epoch : 0 [3838/21279] Train loss: 0.56358,Valid loss: 0.87830, time : 12.309853792190552 lr : 0.9320653479069899\n",
      "epoch : 0 [3839/21279] Train loss: 0.51183,Valid loss: 0.83787, time : 12.852268695831299 lr : 0.9320653479069899\n",
      "epoch : 0 [3840/21279] Train loss: 0.51100,Valid loss: 0.72801, time : 13.20840048789978 lr : 0.9320653479069899\n",
      "epoch : 0 [3841/21279] Train loss: 0.44218,Valid loss: 0.57580, time : 12.727636337280273 lr : 0.9320653479069899\n",
      "epoch : 0 [3842/21279] Train loss: 0.45234,Valid loss: 0.80846, time : 13.016192197799683 lr : 0.9320653479069899\n",
      "epoch : 0 [3843/21279] Train loss: 0.44704,Valid loss: 0.81173, time : 12.84727430343628 lr : 0.9320653479069899\n",
      "epoch : 0 [3844/21279] Train loss: 0.43584,Valid loss: 0.61841, time : 12.726072311401367 lr : 0.9320653479069899\n",
      "epoch : 0 [3845/21279] Train loss: 0.43284,Valid loss: 0.57858, time : 13.004443168640137 lr : 0.9320653479069899\n",
      "epoch : 0 [3846/21279] Train loss: 0.41987,Valid loss: 0.63944, time : 14.861671686172485 lr : 0.9320653479069899\n",
      "epoch : 0 [3847/21279] Train loss: 0.42428,Valid loss: 0.56568, time : 12.862711429595947 lr : 0.9320653479069899\n",
      "epoch : 0 [3848/21279] Train loss: 0.43154,Valid loss: 0.76269, time : 12.631637573242188 lr : 0.9320653479069899\n",
      "epoch : 0 [3849/21279] Train loss: 0.42416,Valid loss: 0.89799, time : 13.14249873161316 lr : 0.9320653479069899\n",
      "epoch : 0 [3850/21279] Train loss: 0.43418,Valid loss: 0.59203, time : 13.098238945007324 lr : 0.9320653479069899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3851/21279] Train loss: 0.40875,Valid loss: 0.60723, time : 13.176460266113281 lr : 0.9320653479069899\n",
      "epoch : 0 [3852/21279] Train loss: 0.42292,Valid loss: 0.58623, time : 12.737140417098999 lr : 0.9320653479069899\n",
      "epoch : 0 [3853/21279] Train loss: 0.41342,Valid loss: 0.57356, time : 12.971648216247559 lr : 0.9320653479069899\n",
      "epoch : 0 [3854/21279] Train loss: 0.39331,Valid loss: 0.79112, time : 12.888566255569458 lr : 0.9320653479069899\n",
      "epoch : 0 [3855/21279] Train loss: 0.40491,Valid loss: 0.57162, time : 12.85514235496521 lr : 0.9320653479069899\n",
      "epoch : 0 [3856/21279] Train loss: 0.41398,Valid loss: 0.89544, time : 12.837145566940308 lr : 0.9320653479069899\n",
      "epoch : 0 [3857/21279] Train loss: 0.43388,Valid loss: 0.74362, time : 12.941643238067627 lr : 0.9320653479069899\n",
      "epoch : 0 [3858/21279] Train loss: 0.42359,Valid loss: 0.66353, time : 14.84425973892212 lr : 0.9320653479069899\n",
      "epoch : 0 [3859/21279] Train loss: 0.45382,Valid loss: 0.66940, time : 12.313734769821167 lr : 0.9320653479069899\n",
      "epoch : 0 [3860/21279] Train loss: 0.43185,Valid loss: 0.65410, time : 12.852478981018066 lr : 0.9320653479069899\n",
      "epoch : 0 [3861/21279] Train loss: 0.43820,Valid loss: 0.64801, time : 12.44406533241272 lr : 0.9320653479069899\n",
      "epoch : 0 [3862/21279] Train loss: 0.42555,Valid loss: 0.62073, time : 12.567525148391724 lr : 0.9320653479069899\n",
      "epoch : 0 [3863/21279] Train loss: 0.43681,Valid loss: 0.81901, time : 12.471997022628784 lr : 0.9320653479069899\n",
      "epoch : 0 [3864/21279] Train loss: 0.44352,Valid loss: 0.61048, time : 12.747823238372803 lr : 0.9320653479069899\n",
      "epoch : 0 [3865/21279] Train loss: 0.44877,Valid loss: 0.78320, time : 13.08119511604309 lr : 0.9320653479069899\n",
      "epoch : 0 [3866/21279] Train loss: 0.42674,Valid loss: 0.85332, time : 13.02239203453064 lr : 0.9320653479069899\n",
      "epoch : 0 [3867/21279] Train loss: 0.41419,Valid loss: 0.66951, time : 13.156095743179321 lr : 0.9320653479069899\n",
      "epoch : 0 [3868/21279] Train loss: 0.42388,Valid loss: 0.74930, time : 13.176530361175537 lr : 0.9320653479069899\n",
      "epoch : 0 [3869/21279] Train loss: 0.40131,Valid loss: 0.75520, time : 13.59801959991455 lr : 0.9320653479069899\n",
      "epoch : 0 [3870/21279] Train loss: 0.42925,Valid loss: 0.69305, time : 13.149890422821045 lr : 0.9320653479069899\n",
      "epoch : 0 [3871/21279] Train loss: 0.39162,Valid loss: 0.63146, time : 13.491684436798096 lr : 0.9320653479069899\n",
      "epoch : 0 [3872/21279] Train loss: 0.39879,Valid loss: 0.59501, time : 15.328249454498291 lr : 0.9320653479069899\n",
      "epoch : 0 [3873/21279] Train loss: 0.41213,Valid loss: 0.59498, time : 12.88477087020874 lr : 0.9320653479069899\n",
      "epoch : 0 [3874/21279] Train loss: 0.40486,Valid loss: 0.57444, time : 12.95528769493103 lr : 0.9320653479069899\n",
      "epoch : 0 [3875/21279] Train loss: 0.40323,Valid loss: 0.76168, time : 12.956261157989502 lr : 0.9320653479069899\n",
      "epoch : 0 [3876/21279] Train loss: 0.42234,Valid loss: 0.52046, time : 13.145982503890991 lr : 0.9320653479069899\n",
      "epoch : 0 [3877/21279] Train loss: 0.41150,Valid loss: 0.58905, time : 13.29731822013855 lr : 0.9320653479069899\n",
      "epoch : 0 [3878/21279] Train loss: 0.39632,Valid loss: 0.52139, time : 13.281655073165894 lr : 0.9320653479069899\n",
      "epoch : 0 [3879/21279] Train loss: 0.39842,Valid loss: 0.57965, time : 13.01578140258789 lr : 0.9320653479069899\n",
      "epoch : 0 [3880/21279] Train loss: 0.38708,Valid loss: 0.75498, time : 13.106036901473999 lr : 0.9320653479069899\n",
      "epoch : 0 [3881/21279] Train loss: 0.40483,Valid loss: 0.57853, time : 12.942934036254883 lr : 0.9320653479069899\n",
      "epoch : 0 [3882/21279] Train loss: 0.42763,Valid loss: 0.59975, time : 12.964168787002563 lr : 0.9320653479069899\n",
      "epoch : 0 [3883/21279] Train loss: 0.40569,Valid loss: 0.54275, time : 12.66614031791687 lr : 0.9320653479069899\n",
      "epoch : 0 [3884/21279] Train loss: 0.41801,Valid loss: 0.89617, time : 12.799403429031372 lr : 0.9320653479069899\n",
      "epoch : 0 [3885/21279] Train loss: 0.39698,Valid loss: 0.75905, time : 12.38618803024292 lr : 0.9320653479069899\n",
      "epoch : 0 [3886/21279] Train loss: 0.42581,Valid loss: 0.52068, time : 12.919877767562866 lr : 0.9320653479069899\n",
      "epoch : 0 [3887/21279] Train loss: 0.40357,Valid loss: 0.74404, time : 12.273839712142944 lr : 0.9320653479069899\n",
      "epoch : 0 [3888/21279] Train loss: 0.40483,Valid loss: 0.74808, time : 14.07580852508545 lr : 0.9320653479069899\n",
      "epoch : 0 [3889/21279] Train loss: 0.41451,Valid loss: 0.83052, time : 12.335754871368408 lr : 0.9320653479069899\n",
      "epoch : 0 [3890/21279] Train loss: 0.44970,Valid loss: 2.29523, time : 12.725997924804688 lr : 0.9320653479069899\n",
      "epoch : 0 [3891/21279] Train loss: 0.60884,Valid loss: 1.72343, time : 12.824235916137695 lr : 0.9320653479069899\n",
      "epoch : 0 [3892/21279] Train loss: 1.00970,Valid loss: 2.60026, time : 12.521902561187744 lr : 0.9320653479069899\n",
      "epoch : 0 [3893/21279] Train loss: 0.65410,Valid loss: 0.80003, time : 12.72639799118042 lr : 0.9320653479069899\n",
      "epoch : 0 [3894/21279] Train loss: 0.51384,Valid loss: 0.96562, time : 12.169644355773926 lr : 0.9320653479069899\n",
      "epoch : 0 [3895/21279] Train loss: 0.46325,Valid loss: 0.58846, time : 12.226859331130981 lr : 0.9320653479069899\n",
      "epoch : 0 [3896/21279] Train loss: 0.42396,Valid loss: 0.92264, time : 12.456129550933838 lr : 0.9320653479069899\n",
      "epoch : 0 [3897/21279] Train loss: 0.43438,Valid loss: 0.76989, time : 12.80473279953003 lr : 0.9320653479069899\n",
      "epoch : 0 [3898/21279] Train loss: 0.44279,Valid loss: 0.56366, time : 13.156395673751831 lr : 0.9320653479069899\n",
      "epoch : 0 [3899/21279] Train loss: 0.41242,Valid loss: 0.64316, time : 12.668319940567017 lr : 0.9320653479069899\n",
      "epoch : 0 [3900/21279] Train loss: 0.41122,Valid loss: 0.67834, time : 13.016628980636597 lr : 0.9320653479069899\n",
      "epoch : 0 [3901/21279] Train loss: 0.42860,Valid loss: 0.60644, time : 15.242866516113281 lr : 0.9320653479069899\n",
      "epoch : 0 [3902/21279] Train loss: 0.40509,Valid loss: 0.66452, time : 13.137004137039185 lr : 0.9320653479069899\n",
      "epoch : 0 [3903/21279] Train loss: 0.40444,Valid loss: 0.60661, time : 12.853589296340942 lr : 0.9320653479069899\n",
      "epoch : 0 [3904/21279] Train loss: 0.39400,Valid loss: 0.67664, time : 12.81304407119751 lr : 0.9320653479069899\n",
      "epoch : 0 [3905/21279] Train loss: 0.42329,Valid loss: 0.67401, time : 13.005879163742065 lr : 0.9320653479069899\n",
      "epoch : 0 [3906/21279] Train loss: 0.41656,Valid loss: 0.64228, time : 12.715764045715332 lr : 0.9320653479069899\n",
      "epoch : 0 [3907/21279] Train loss: 0.40850,Valid loss: 0.72073, time : 12.932599306106567 lr : 0.9320653479069899\n",
      "epoch : 0 [3908/21279] Train loss: 0.42804,Valid loss: 0.86447, time : 13.04145622253418 lr : 0.9320653479069899\n",
      "epoch : 0 [3909/21279] Train loss: 0.41298,Valid loss: 0.56101, time : 13.141247749328613 lr : 0.9320653479069899\n",
      "epoch : 0 [3910/21279] Train loss: 0.41235,Valid loss: 1.06884, time : 12.84125566482544 lr : 0.9320653479069899\n",
      "epoch : 0 [3911/21279] Train loss: 0.41941,Valid loss: 0.90999, time : 12.123128414154053 lr : 0.9320653479069899\n",
      "epoch : 0 [3912/21279] Train loss: 0.40458,Valid loss: 0.73071, time : 12.700068712234497 lr : 0.9320653479069899\n",
      "epoch : 0 [3913/21279] Train loss: 0.41010,Valid loss: 0.60174, time : 12.75136137008667 lr : 0.9320653479069899\n",
      "epoch : 0 [3914/21279] Train loss: 0.41283,Valid loss: 0.54849, time : 12.579334735870361 lr : 0.9320653479069899\n",
      "epoch : 0 [3915/21279] Train loss: 0.40541,Valid loss: 0.77773, time : 12.448672533035278 lr : 0.9320653479069899\n",
      "epoch : 0 [3916/21279] Train loss: 0.42760,Valid loss: 1.03869, time : 14.598849296569824 lr : 0.9320653479069899\n",
      "epoch : 0 [3917/21279] Train loss: 0.41100,Valid loss: 0.80873, time : 12.547546863555908 lr : 0.9320653479069899\n",
      "epoch : 0 [3918/21279] Train loss: 0.50450,Valid loss: 0.84322, time : 12.352860450744629 lr : 0.9320653479069899\n",
      "epoch : 0 [3919/21279] Train loss: 0.45546,Valid loss: 0.60303, time : 12.630374670028687 lr : 0.9320653479069899\n",
      "epoch : 0 [3920/21279] Train loss: 0.42774,Valid loss: 0.58266, time : 12.854689121246338 lr : 0.9320653479069899\n",
      "epoch : 0 [3921/21279] Train loss: 0.43829,Valid loss: 0.66146, time : 12.807305812835693 lr : 0.9320653479069899\n",
      "epoch : 0 [3922/21279] Train loss: 0.41821,Valid loss: 0.57420, time : 12.872879028320312 lr : 0.9320653479069899\n",
      "epoch : 0 [3923/21279] Train loss: 0.44155,Valid loss: 0.65717, time : 12.909976482391357 lr : 0.9320653479069899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3924/21279] Train loss: 0.42190,Valid loss: 0.55621, time : 12.652858972549438 lr : 0.9320653479069899\n",
      "epoch : 0 [3925/21279] Train loss: 0.40387,Valid loss: 0.55014, time : 11.880833625793457 lr : 0.9320653479069899\n",
      "epoch : 0 [3926/21279] Train loss: 0.41315,Valid loss: 0.56203, time : 12.063462734222412 lr : 0.9320653479069899\n",
      "epoch : 0 [3927/21279] Train loss: 0.40823,Valid loss: 0.64636, time : 12.562098264694214 lr : 0.9320653479069899\n",
      "epoch : 0 [3928/21279] Train loss: 0.41365,Valid loss: 0.88856, time : 14.691197633743286 lr : 0.9320653479069899\n",
      "epoch : 0 [3929/21279] Train loss: 0.44680,Valid loss: 0.56395, time : 12.487646579742432 lr : 0.9320653479069899\n",
      "epoch : 0 [3930/21279] Train loss: 0.42589,Valid loss: 1.32158, time : 12.907156467437744 lr : 0.9320653479069899\n",
      "epoch : 0 [3931/21279] Train loss: 0.42360,Valid loss: 0.53652, time : 12.035483837127686 lr : 0.9320653479069899\n",
      "epoch : 0 [3932/21279] Train loss: 0.39486,Valid loss: 0.59491, time : 12.317073345184326 lr : 0.9320653479069899\n",
      "epoch : 0 [3933/21279] Train loss: 0.38777,Valid loss: 0.82393, time : 12.53755497932434 lr : 0.9320653479069899\n",
      "epoch : 0 [3934/21279] Train loss: 0.39145,Valid loss: 0.57725, time : 12.849738597869873 lr : 0.9320653479069899\n",
      "epoch : 0 [3935/21279] Train loss: 0.41425,Valid loss: 0.62410, time : 12.72643518447876 lr : 0.9320653479069899\n",
      "epoch : 0 [3936/21279] Train loss: 0.40547,Valid loss: 0.88855, time : 12.368273735046387 lr : 0.9320653479069899\n",
      "epoch : 0 [3937/21279] Train loss: 0.40342,Valid loss: 0.62650, time : 12.526634216308594 lr : 0.9320653479069899\n",
      "epoch : 0 [3938/21279] Train loss: 0.40514,Valid loss: 0.95170, time : 12.924619674682617 lr : 0.9320653479069899\n",
      "epoch : 0 [3939/21279] Train loss: 0.42152,Valid loss: 0.76284, time : 12.582127571105957 lr : 0.9320653479069899\n",
      "epoch : 0 [3940/21279] Train loss: 0.40132,Valid loss: 0.78160, time : 12.317131757736206 lr : 0.9320653479069899\n",
      "epoch : 0 [3941/21279] Train loss: 0.37883,Valid loss: 0.51455, time : 12.382205247879028 lr : 0.9320653479069899\n",
      "epoch : 0 [3942/21279] Train loss: 0.39890,Valid loss: 0.52831, time : 15.471641540527344 lr : 0.9320653479069899\n",
      "epoch : 0 [3943/21279] Train loss: 0.39176,Valid loss: 0.52301, time : 12.886515617370605 lr : 0.9320653479069899\n",
      "epoch : 0 [3944/21279] Train loss: 0.39079,Valid loss: 0.81416, time : 12.611432313919067 lr : 0.9320653479069899\n",
      "epoch : 0 [3945/21279] Train loss: 0.38496,Valid loss: 0.54218, time : 12.813343048095703 lr : 0.9320653479069899\n",
      "epoch : 0 [3946/21279] Train loss: 0.38792,Valid loss: 0.68256, time : 12.640357494354248 lr : 0.9320653479069899\n",
      "epoch : 0 [3947/21279] Train loss: 0.42135,Valid loss: 0.69602, time : 12.614837646484375 lr : 0.9320653479069899\n",
      "epoch : 0 [3948/21279] Train loss: 0.38874,Valid loss: 0.57311, time : 12.832629203796387 lr : 0.9320653479069899\n",
      "epoch : 0 [3949/21279] Train loss: 0.38432,Valid loss: 0.50982, time : 12.80749225616455 lr : 0.9320653479069899\n",
      "epoch : 0 [3950/21279] Train loss: 0.40321,Valid loss: 0.69991, time : 13.083274602890015 lr : 0.9320653479069899\n",
      "epoch : 0 [3951/21279] Train loss: 0.38083,Valid loss: 0.73647, time : 12.854542255401611 lr : 0.9320653479069899\n",
      "epoch : 0 [3952/21279] Train loss: 0.39970,Valid loss: 0.75045, time : 12.643163204193115 lr : 0.9320653479069899\n",
      "epoch : 0 [3953/21279] Train loss: 0.40795,Valid loss: 1.14381, time : 12.814314126968384 lr : 0.9320653479069899\n",
      "epoch : 0 [3954/21279] Train loss: 0.40841,Valid loss: 0.74780, time : 14.560708284378052 lr : 0.9320653479069899\n",
      "epoch : 0 [3955/21279] Train loss: 0.39225,Valid loss: 0.75498, time : 13.06527853012085 lr : 0.9320653479069899\n",
      "epoch : 0 [3956/21279] Train loss: 0.42310,Valid loss: 0.81455, time : 12.722797870635986 lr : 0.9320653479069899\n",
      "epoch : 0 [3957/21279] Train loss: 0.40020,Valid loss: 0.86757, time : 12.702906131744385 lr : 0.9320653479069899\n",
      "epoch : 0 [3958/21279] Train loss: 0.39461,Valid loss: 0.64032, time : 12.724775075912476 lr : 0.9320653479069899\n",
      "epoch : 0 [3959/21279] Train loss: 0.42366,Valid loss: 0.79324, time : 13.254334926605225 lr : 0.9320653479069899\n",
      "epoch : 0 [3960/21279] Train loss: 0.44468,Valid loss: 2.29944, time : 13.0509512424469 lr : 0.9320653479069899\n",
      "epoch : 0 [3961/21279] Train loss: 0.55928,Valid loss: 4.18260, time : 12.951097011566162 lr : 0.9320653479069899\n",
      "epoch : 0 [3962/21279] Train loss: 1.54113,Valid loss: 1.45091, time : 12.963863611221313 lr : 0.9320653479069899\n",
      "epoch : 0 [3963/21279] Train loss: 0.60035,Valid loss: 1.25815, time : 13.239775896072388 lr : 0.9320653479069899\n",
      "epoch : 0 [3964/21279] Train loss: 0.62842,Valid loss: 1.23826, time : 12.688978672027588 lr : 0.9320653479069899\n",
      "epoch : 0 [3965/21279] Train loss: 0.76994,Valid loss: 1.31847, time : 13.013323068618774 lr : 0.9320653479069899\n",
      "epoch : 0 [3966/21279] Train loss: 0.56597,Valid loss: 1.25628, time : 13.028033256530762 lr : 0.9320653479069899\n",
      "epoch : 0 [3967/21279] Train loss: 0.51248,Valid loss: 1.11026, time : 13.273887395858765 lr : 0.9320653479069899\n",
      "epoch : 0 [3968/21279] Train loss: 0.53119,Valid loss: 1.40950, time : 13.048280954360962 lr : 0.9320653479069899\n",
      "epoch : 0 [3969/21279] Train loss: 0.58734,Valid loss: 1.06406, time : 12.91710877418518 lr : 0.9320653479069899\n",
      "epoch : 0 [3970/21279] Train loss: 0.78863,Valid loss: 1.63244, time : 14.597160577774048 lr : 0.9320653479069899\n",
      "epoch : 0 [3971/21279] Train loss: 0.57309,Valid loss: 0.93084, time : 12.973934888839722 lr : 0.9320653479069899\n",
      "epoch : 0 [3972/21279] Train loss: 0.48671,Valid loss: 0.78442, time : 12.930909633636475 lr : 0.9320653479069899\n",
      "epoch : 0 [3973/21279] Train loss: 0.45075,Valid loss: 0.79979, time : 12.686239957809448 lr : 0.9320653479069899\n",
      "epoch : 0 [3974/21279] Train loss: 0.44259,Valid loss: 0.84487, time : 12.497838735580444 lr : 0.9320653479069899\n",
      "epoch : 0 [3975/21279] Train loss: 0.42119,Valid loss: 0.90508, time : 12.671233177185059 lr : 0.9320653479069899\n",
      "epoch : 0 [3976/21279] Train loss: 0.41665,Valid loss: 0.62583, time : 12.452528238296509 lr : 0.9320653479069899\n",
      "epoch : 0 [3977/21279] Train loss: 0.40988,Valid loss: 0.50032, time : 12.6375572681427 lr : 0.9320653479069899\n",
      "epoch : 0 [3978/21279] Train loss: 0.41592,Valid loss: 0.59797, time : 12.342530727386475 lr : 0.9320653479069899\n",
      "epoch : 0 [3979/21279] Train loss: 0.41560,Valid loss: 1.02781, time : 12.445217609405518 lr : 0.9320653479069899\n",
      "epoch : 0 [3980/21279] Train loss: 0.41516,Valid loss: 1.00815, time : 12.82748293876648 lr : 0.9320653479069899\n",
      "epoch : 0 [3981/21279] Train loss: 0.40459,Valid loss: 0.86254, time : 12.78979229927063 lr : 0.9320653479069899\n",
      "epoch : 0 [3982/21279] Train loss: 0.40056,Valid loss: 0.82378, time : 15.247148036956787 lr : 0.9320653479069899\n",
      "epoch : 0 [3983/21279] Train loss: 0.40920,Valid loss: 0.83486, time : 12.436913013458252 lr : 0.9320653479069899\n",
      "epoch : 0 [3984/21279] Train loss: 0.38629,Valid loss: 0.87656, time : 11.968212842941284 lr : 0.9320653479069899\n",
      "epoch : 0 [3985/21279] Train loss: 0.62218,Valid loss: 1.33684, time : 11.95437240600586 lr : 0.9320653479069899\n",
      "epoch : 0 [3986/21279] Train loss: 0.66861,Valid loss: 1.48337, time : 12.462756395339966 lr : 0.9320653479069899\n",
      "epoch : 0 [3987/21279] Train loss: 0.55347,Valid loss: 1.07793, time : 12.098727703094482 lr : 0.9320653479069899\n",
      "epoch : 0 [3988/21279] Train loss: 0.47117,Valid loss: 0.79474, time : 12.2826509475708 lr : 0.9320653479069899\n",
      "epoch : 0 [3989/21279] Train loss: 0.43376,Valid loss: 1.10350, time : 12.089216470718384 lr : 0.9320653479069899\n",
      "epoch : 0 [3990/21279] Train loss: 0.42223,Valid loss: 0.61372, time : 12.251461029052734 lr : 0.9320653479069899\n",
      "epoch : 0 [3991/21279] Train loss: 0.41121,Valid loss: 0.64989, time : 12.63268756866455 lr : 0.9320653479069899\n",
      "epoch : 0 [3992/21279] Train loss: 0.40264,Valid loss: 0.87808, time : 12.068726301193237 lr : 0.9320653479069899\n",
      "epoch : 0 [3993/21279] Train loss: 0.41154,Valid loss: 0.52331, time : 12.414796829223633 lr : 0.9320653479069899\n",
      "epoch : 0 [3994/21279] Train loss: 0.41842,Valid loss: 0.60932, time : 12.733448028564453 lr : 0.9320653479069899\n",
      "epoch : 0 [3995/21279] Train loss: 0.43977,Valid loss: 0.53378, time : 12.848693370819092 lr : 0.9320653479069899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [3996/21279] Train loss: 0.44073,Valid loss: 1.99707, time : 13.227159261703491 lr : 0.9320653479069899\n",
      "epoch : 0 [3997/21279] Train loss: 0.56687,Valid loss: 2.06724, time : 13.185062646865845 lr : 0.9320653479069899\n",
      "epoch : 0 [3998/21279] Train loss: 0.50901,Valid loss: 0.76202, time : 14.743987798690796 lr : 0.9320653479069899\n",
      "epoch : 0 [3999/21279] Train loss: 0.43386,Valid loss: 0.61674, time : 12.651503562927246 lr : 0.92274469442792\n",
      "epoch : 0 [4000/21279] Train loss: 0.43022,Valid loss: 0.73043, time : 12.651089668273926 lr : 0.92274469442792\n",
      "epoch : 0 [4001/21279] Train loss: 0.41525,Valid loss: 0.86781, time : 12.708543539047241 lr : 0.92274469442792\n",
      "epoch : 0 [4002/21279] Train loss: 0.39624,Valid loss: 0.70795, time : 12.902281761169434 lr : 0.92274469442792\n",
      "epoch : 0 [4003/21279] Train loss: 0.39589,Valid loss: 0.58215, time : 12.968499660491943 lr : 0.92274469442792\n",
      "epoch : 0 [4004/21279] Train loss: 0.39435,Valid loss: 0.63538, time : 12.881847858428955 lr : 0.92274469442792\n",
      "epoch : 0 [4005/21279] Train loss: 0.39400,Valid loss: 0.59497, time : 13.174527168273926 lr : 0.92274469442792\n",
      "epoch : 0 [4006/21279] Train loss: 0.38960,Valid loss: 2.30282, time : 13.06822919845581 lr : 0.92274469442792\n",
      "epoch : 0 [4007/21279] Train loss: 0.79182,Valid loss: 1.26347, time : 13.133273363113403 lr : 0.92274469442792\n",
      "epoch : 0 [4008/21279] Train loss: 0.51433,Valid loss: 0.67930, time : 13.270704984664917 lr : 0.92274469442792\n",
      "epoch : 0 [4009/21279] Train loss: 0.43854,Valid loss: 0.76635, time : 12.533424139022827 lr : 0.92274469442792\n",
      "epoch : 0 [4010/21279] Train loss: 0.43103,Valid loss: 0.75147, time : 12.531589984893799 lr : 0.92274469442792\n",
      "epoch : 0 [4011/21279] Train loss: 0.43274,Valid loss: 0.55252, time : 14.475074768066406 lr : 0.92274469442792\n",
      "epoch : 0 [4012/21279] Train loss: 0.40149,Valid loss: 0.53616, time : 12.713715553283691 lr : 0.92274469442792\n",
      "epoch : 0 [4013/21279] Train loss: 0.39646,Valid loss: 0.53625, time : 12.639189958572388 lr : 0.92274469442792\n",
      "epoch : 0 [4014/21279] Train loss: 0.41916,Valid loss: 0.51262, time : 12.696020364761353 lr : 0.92274469442792\n",
      "epoch : 0 [4015/21279] Train loss: 0.38638,Valid loss: 0.59101, time : 12.770716905593872 lr : 0.92274469442792\n",
      "epoch : 0 [4016/21279] Train loss: 0.39412,Valid loss: 0.62653, time : 13.0700364112854 lr : 0.92274469442792\n",
      "epoch : 0 [4017/21279] Train loss: 0.40437,Valid loss: 0.61359, time : 12.663853168487549 lr : 0.92274469442792\n",
      "epoch : 0 [4018/21279] Train loss: 0.40706,Valid loss: 0.59004, time : 12.757752656936646 lr : 0.92274469442792\n",
      "epoch : 0 [4019/21279] Train loss: 0.38558,Valid loss: 0.58510, time : 12.223705768585205 lr : 0.92274469442792\n",
      "epoch : 0 [4020/21279] Train loss: 0.38675,Valid loss: 0.58629, time : 12.615580558776855 lr : 0.92274469442792\n",
      "epoch : 0 [4021/21279] Train loss: 0.40150,Valid loss: 1.10813, time : 12.502011060714722 lr : 0.92274469442792\n",
      "epoch : 0 [4022/21279] Train loss: 0.52993,Valid loss: 1.14492, time : 12.476853370666504 lr : 0.92274469442792\n",
      "epoch : 0 [4023/21279] Train loss: 0.48232,Valid loss: 0.57775, time : 12.579503059387207 lr : 0.92274469442792\n",
      "epoch : 0 [4024/21279] Train loss: 0.42054,Valid loss: 0.81386, time : 12.200904130935669 lr : 0.92274469442792\n",
      "epoch : 0 [4025/21279] Train loss: 0.39770,Valid loss: 0.87836, time : 12.362863063812256 lr : 0.92274469442792\n",
      "epoch : 0 [4026/21279] Train loss: 0.39877,Valid loss: 0.74453, time : 14.717211246490479 lr : 0.92274469442792\n",
      "epoch : 0 [4027/21279] Train loss: 0.40392,Valid loss: 0.88306, time : 12.543524265289307 lr : 0.92274469442792\n",
      "epoch : 0 [4028/21279] Train loss: 0.39639,Valid loss: 0.88955, time : 12.775203943252563 lr : 0.92274469442792\n",
      "epoch : 0 [4029/21279] Train loss: 0.39578,Valid loss: 0.85263, time : 12.37197470664978 lr : 0.92274469442792\n",
      "epoch : 0 [4030/21279] Train loss: 0.38235,Valid loss: 0.82036, time : 12.429070472717285 lr : 0.92274469442792\n",
      "epoch : 0 [4031/21279] Train loss: 0.43106,Valid loss: 2.01039, time : 12.576124429702759 lr : 0.92274469442792\n",
      "epoch : 0 [4032/21279] Train loss: 0.40982,Valid loss: 1.12934, time : 11.876269578933716 lr : 0.92274469442792\n",
      "epoch : 0 [4033/21279] Train loss: 0.38027,Valid loss: 0.63519, time : 12.364511013031006 lr : 0.92274469442792\n",
      "epoch : 0 [4034/21279] Train loss: 0.38678,Valid loss: 1.13877, time : 11.742443084716797 lr : 0.92274469442792\n",
      "epoch : 0 [4035/21279] Train loss: 0.37682,Valid loss: 0.56642, time : 12.172837495803833 lr : 0.92274469442792\n",
      "epoch : 0 [4036/21279] Train loss: 0.38452,Valid loss: 0.58954, time : 12.159142971038818 lr : 0.92274469442792\n",
      "epoch : 0 [4037/21279] Train loss: 0.38596,Valid loss: 1.46140, time : 12.22846508026123 lr : 0.92274469442792\n",
      "epoch : 0 [4038/21279] Train loss: 0.45314,Valid loss: 0.78913, time : 13.963959693908691 lr : 0.92274469442792\n",
      "epoch : 0 [4039/21279] Train loss: 0.41650,Valid loss: 0.58967, time : 12.56411075592041 lr : 0.92274469442792\n",
      "epoch : 0 [4040/21279] Train loss: 0.40514,Valid loss: 0.75500, time : 12.749497890472412 lr : 0.92274469442792\n",
      "epoch : 0 [4041/21279] Train loss: 0.38473,Valid loss: 0.60139, time : 12.776956558227539 lr : 0.92274469442792\n",
      "epoch : 0 [4042/21279] Train loss: 0.41656,Valid loss: 0.55988, time : 12.55524206161499 lr : 0.92274469442792\n",
      "epoch : 0 [4043/21279] Train loss: 0.39957,Valid loss: 0.52299, time : 13.15812611579895 lr : 0.92274469442792\n",
      "epoch : 0 [4044/21279] Train loss: 0.40270,Valid loss: 0.59859, time : 12.837079524993896 lr : 0.92274469442792\n",
      "epoch : 0 [4045/21279] Train loss: 0.37292,Valid loss: 0.64382, time : 12.717597246170044 lr : 0.92274469442792\n",
      "epoch : 0 [4046/21279] Train loss: 0.37521,Valid loss: 0.75215, time : 12.021794557571411 lr : 0.92274469442792\n",
      "epoch : 0 [4047/21279] Train loss: 0.44422,Valid loss: 0.89338, time : 12.32913088798523 lr : 0.92274469442792\n",
      "epoch : 0 [4048/21279] Train loss: 0.39728,Valid loss: 0.59211, time : 12.652598142623901 lr : 0.92274469442792\n",
      "epoch : 0 [4049/21279] Train loss: 0.41172,Valid loss: 0.58589, time : 12.240346431732178 lr : 0.92274469442792\n",
      "epoch : 0 [4050/21279] Train loss: 0.37976,Valid loss: 0.53191, time : 12.698272705078125 lr : 0.92274469442792\n",
      "epoch : 0 [4051/21279] Train loss: 0.37229,Valid loss: 0.64141, time : 12.992834329605103 lr : 0.92274469442792\n",
      "epoch : 0 [4052/21279] Train loss: 0.37412,Valid loss: 0.62570, time : 14.688968658447266 lr : 0.92274469442792\n",
      "epoch : 0 [4053/21279] Train loss: 0.39075,Valid loss: 0.75968, time : 12.499332666397095 lr : 0.92274469442792\n",
      "epoch : 0 [4054/21279] Train loss: 0.39032,Valid loss: 0.53176, time : 12.873043537139893 lr : 0.92274469442792\n",
      "epoch : 0 [4055/21279] Train loss: 0.39208,Valid loss: 0.68478, time : 12.589905500411987 lr : 0.92274469442792\n",
      "epoch : 0 [4056/21279] Train loss: 0.37744,Valid loss: 0.54888, time : 12.021579504013062 lr : 0.92274469442792\n",
      "epoch : 0 [4057/21279] Train loss: 0.38423,Valid loss: 0.73353, time : 12.251172542572021 lr : 0.92274469442792\n",
      "epoch : 0 [4058/21279] Train loss: 0.40232,Valid loss: 0.62271, time : 11.801214456558228 lr : 0.92274469442792\n",
      "epoch : 0 [4059/21279] Train loss: 0.40831,Valid loss: 1.79530, time : 12.421197175979614 lr : 0.92274469442792\n",
      "epoch : 0 [4060/21279] Train loss: 0.39512,Valid loss: 0.61140, time : 12.847598552703857 lr : 0.92274469442792\n",
      "epoch : 0 [4061/21279] Train loss: 0.39173,Valid loss: 0.65712, time : 12.39159369468689 lr : 0.92274469442792\n",
      "epoch : 0 [4062/21279] Train loss: 0.38781,Valid loss: 0.49355, time : 12.571194410324097 lr : 0.92274469442792\n",
      "epoch : 0 [4063/21279] Train loss: 0.37125,Valid loss: 0.58725, time : 12.699245691299438 lr : 0.92274469442792\n",
      "epoch : 0 [4064/21279] Train loss: 0.39859,Valid loss: 0.56484, time : 14.326335430145264 lr : 0.92274469442792\n",
      "epoch : 0 [4065/21279] Train loss: 0.38878,Valid loss: 0.65380, time : 12.605512142181396 lr : 0.92274469442792\n",
      "epoch : 0 [4066/21279] Train loss: 0.37388,Valid loss: 0.72978, time : 12.104613304138184 lr : 0.92274469442792\n",
      "epoch : 0 [4067/21279] Train loss: 0.38835,Valid loss: 0.59248, time : 12.220409631729126 lr : 0.92274469442792\n",
      "epoch : 0 [4068/21279] Train loss: 0.38207,Valid loss: 0.90185, time : 12.0537748336792 lr : 0.92274469442792\n",
      "epoch : 0 [4069/21279] Train loss: 0.37675,Valid loss: 0.92581, time : 12.510862827301025 lr : 0.92274469442792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [4070/21279] Train loss: 0.37530,Valid loss: 0.48323, time : 12.644337892532349 lr : 0.92274469442792\n",
      "epoch : 0 [4071/21279] Train loss: 0.37206,Valid loss: 1.24688, time : 12.277207851409912 lr : 0.92274469442792\n",
      "epoch : 0 [4072/21279] Train loss: 0.49564,Valid loss: 0.51212, time : 12.557345628738403 lr : 0.92274469442792\n",
      "epoch : 0 [4073/21279] Train loss: 0.40921,Valid loss: 1.63116, time : 12.999062538146973 lr : 0.92274469442792\n",
      "epoch : 0 [4074/21279] Train loss: 0.45418,Valid loss: 0.80467, time : 13.095121145248413 lr : 0.92274469442792\n",
      "epoch : 0 [4075/21279] Train loss: 0.40448,Valid loss: 0.98831, time : 12.76815938949585 lr : 0.92274469442792\n",
      "epoch : 0 [4076/21279] Train loss: 0.42011,Valid loss: 0.76282, time : 12.648575067520142 lr : 0.92274469442792\n",
      "epoch : 0 [4077/21279] Train loss: 0.40656,Valid loss: 1.68353, time : 12.59807014465332 lr : 0.92274469442792\n",
      "epoch : 0 [4078/21279] Train loss: 0.45239,Valid loss: 1.17853, time : 12.808742046356201 lr : 0.92274469442792\n",
      "epoch : 0 [4079/21279] Train loss: 0.45101,Valid loss: 1.28627, time : 12.900115728378296 lr : 0.92274469442792\n",
      "epoch : 0 [4080/21279] Train loss: 0.40725,Valid loss: 0.95137, time : 23.291558265686035 lr : 0.92274469442792\n",
      "epoch : 0 [4081/21279] Train loss: 0.39549,Valid loss: 0.73567, time : 13.184945344924927 lr : 0.92274469442792\n",
      "epoch : 0 [4082/21279] Train loss: 0.38466,Valid loss: 0.51590, time : 12.866650104522705 lr : 0.92274469442792\n",
      "epoch : 0 [4083/21279] Train loss: 0.40223,Valid loss: 0.82026, time : 12.832322120666504 lr : 0.92274469442792\n",
      "epoch : 0 [4084/21279] Train loss: 0.36118,Valid loss: 0.60226, time : 12.961857318878174 lr : 0.92274469442792\n",
      "epoch : 0 [4085/21279] Train loss: 0.40795,Valid loss: 0.60311, time : 13.279323101043701 lr : 0.92274469442792\n",
      "epoch : 0 [4086/21279] Train loss: 0.36793,Valid loss: 0.74457, time : 12.926260709762573 lr : 0.92274469442792\n",
      "epoch : 0 [4087/21279] Train loss: 0.35959,Valid loss: 0.67641, time : 13.041941165924072 lr : 0.92274469442792\n",
      "epoch : 0 [4088/21279] Train loss: 0.37101,Valid loss: 0.72162, time : 13.126199722290039 lr : 0.92274469442792\n",
      "epoch : 0 [4089/21279] Train loss: 0.38662,Valid loss: 0.50724, time : 13.320105791091919 lr : 0.92274469442792\n",
      "epoch : 0 [4090/21279] Train loss: 0.38023,Valid loss: 0.48671, time : 12.88204574584961 lr : 0.92274469442792\n",
      "epoch : 0 [4091/21279] Train loss: 0.37959,Valid loss: 0.51698, time : 13.229315757751465 lr : 0.92274469442792\n",
      "epoch : 0 [4092/21279] Train loss: 0.40357,Valid loss: 0.49934, time : 15.288492679595947 lr : 0.92274469442792\n",
      "epoch : 0 [4093/21279] Train loss: 0.38022,Valid loss: 0.49088, time : 12.964792490005493 lr : 0.92274469442792\n",
      "epoch : 0 [4094/21279] Train loss: 0.37966,Valid loss: 0.49750, time : 12.210278034210205 lr : 0.92274469442792\n",
      "epoch : 0 [4095/21279] Train loss: 0.41335,Valid loss: 0.75686, time : 12.120833396911621 lr : 0.92274469442792\n",
      "epoch : 0 [4096/21279] Train loss: 0.40069,Valid loss: 0.49172, time : 12.771597385406494 lr : 0.92274469442792\n",
      "epoch : 0 [4097/21279] Train loss: 0.41603,Valid loss: 0.50953, time : 11.62283706665039 lr : 0.92274469442792\n",
      "epoch : 0 [4098/21279] Train loss: 0.39277,Valid loss: 0.52770, time : 12.40005087852478 lr : 0.92274469442792\n",
      "epoch : 0 [4099/21279] Train loss: 0.36624,Valid loss: 0.51753, time : 12.578927755355835 lr : 0.92274469442792\n",
      "epoch : 0 [4100/21279] Train loss: 0.38508,Valid loss: 0.57918, time : 12.11432671546936 lr : 0.92274469442792\n",
      "epoch : 0 [4101/21279] Train loss: 0.38334,Valid loss: 0.73568, time : 11.841171979904175 lr : 0.92274469442792\n",
      "epoch : 0 [4102/21279] Train loss: 0.38801,Valid loss: 0.60539, time : 11.839251041412354 lr : 0.92274469442792\n",
      "epoch : 0 [4103/21279] Train loss: 0.57336,Valid loss: 1.68652, time : 12.112293243408203 lr : 0.92274469442792\n",
      "epoch : 0 [4104/21279] Train loss: 1.31979,Valid loss: 1.06519, time : 12.449949741363525 lr : 0.92274469442792\n",
      "epoch : 0 [4105/21279] Train loss: 0.57999,Valid loss: 1.23016, time : 12.544357299804688 lr : 0.92274469442792\n",
      "epoch : 0 [4106/21279] Train loss: 0.48995,Valid loss: 0.90422, time : 12.593132495880127 lr : 0.92274469442792\n",
      "epoch : 0 [4107/21279] Train loss: 0.44691,Valid loss: 0.69198, time : 13.023643493652344 lr : 0.92274469442792\n",
      "epoch : 0 [4108/21279] Train loss: 0.42403,Valid loss: 0.53964, time : 14.37573504447937 lr : 0.92274469442792\n",
      "epoch : 0 [4109/21279] Train loss: 0.42639,Valid loss: 0.61682, time : 12.348461389541626 lr : 0.92274469442792\n",
      "epoch : 0 [4110/21279] Train loss: 0.38788,Valid loss: 0.51835, time : 12.500288724899292 lr : 0.92274469442792\n",
      "epoch : 0 [4111/21279] Train loss: 0.38914,Valid loss: 0.60198, time : 12.237094163894653 lr : 0.92274469442792\n",
      "epoch : 0 [4112/21279] Train loss: 0.38735,Valid loss: 0.74762, time : 12.489092111587524 lr : 0.92274469442792\n",
      "epoch : 0 [4113/21279] Train loss: 0.38309,Valid loss: 0.95060, time : 12.017457485198975 lr : 0.92274469442792\n",
      "epoch : 0 [4114/21279] Train loss: 0.53756,Valid loss: 2.17962, time : 12.890456199645996 lr : 0.92274469442792\n",
      "epoch : 0 [4115/21279] Train loss: 0.68779,Valid loss: 1.27124, time : 12.730000257492065 lr : 0.92274469442792\n",
      "epoch : 0 [4116/21279] Train loss: 0.50955,Valid loss: 1.41929, time : 12.792081832885742 lr : 0.92274469442792\n",
      "epoch : 0 [4117/21279] Train loss: 0.47793,Valid loss: 0.98358, time : 12.289637565612793 lr : 0.92274469442792\n",
      "epoch : 0 [4118/21279] Train loss: 0.44210,Valid loss: 0.96793, time : 13.117680788040161 lr : 0.92274469442792\n",
      "epoch : 0 [4119/21279] Train loss: 0.45013,Valid loss: 0.79301, time : 13.047546148300171 lr : 0.92274469442792\n",
      "epoch : 0 [4120/21279] Train loss: 0.40227,Valid loss: 0.75233, time : 13.063063383102417 lr : 0.92274469442792\n",
      "epoch : 0 [4121/21279] Train loss: 0.38436,Valid loss: 0.51518, time : 16.300381898880005 lr : 0.92274469442792\n",
      "epoch : 0 [4122/21279] Train loss: 0.40026,Valid loss: 0.74726, time : 12.712603092193604 lr : 0.92274469442792\n",
      "epoch : 0 [4123/21279] Train loss: 0.36969,Valid loss: 0.86162, time : 12.986024618148804 lr : 0.92274469442792\n",
      "epoch : 0 [4124/21279] Train loss: 0.38035,Valid loss: 0.97373, time : 12.786494016647339 lr : 0.92274469442792\n",
      "epoch : 0 [4125/21279] Train loss: 0.38059,Valid loss: 0.87737, time : 12.402554988861084 lr : 0.92274469442792\n",
      "epoch : 0 [4126/21279] Train loss: 0.38061,Valid loss: 0.79699, time : 12.752694606781006 lr : 0.92274469442792\n",
      "epoch : 0 [4127/21279] Train loss: 0.37827,Valid loss: 0.75804, time : 12.41463041305542 lr : 0.92274469442792\n",
      "epoch : 0 [4128/21279] Train loss: 0.38395,Valid loss: 0.61779, time : 12.727381229400635 lr : 0.92274469442792\n",
      "epoch : 0 [4129/21279] Train loss: 0.37441,Valid loss: 0.54527, time : 13.049468517303467 lr : 0.92274469442792\n",
      "epoch : 0 [4130/21279] Train loss: 0.38461,Valid loss: 0.61184, time : 12.505966901779175 lr : 0.92274469442792\n",
      "epoch : 0 [4131/21279] Train loss: 0.37326,Valid loss: 0.84041, time : 12.671006441116333 lr : 0.92274469442792\n",
      "epoch : 0 [4132/21279] Train loss: 0.36342,Valid loss: 0.81508, time : 12.824395895004272 lr : 0.92274469442792\n",
      "epoch : 0 [4133/21279] Train loss: 0.34367,Valid loss: 0.73768, time : 12.671381950378418 lr : 0.92274469442792\n",
      "epoch : 0 [4134/21279] Train loss: 0.36751,Valid loss: 0.63643, time : 12.731580018997192 lr : 0.92274469442792\n",
      "epoch : 0 [4135/21279] Train loss: 0.35942,Valid loss: 0.60193, time : 13.033555507659912 lr : 0.92274469442792\n",
      "epoch : 0 [4136/21279] Train loss: 0.38366,Valid loss: 0.61492, time : 14.604942560195923 lr : 0.92274469442792\n",
      "epoch : 0 [4137/21279] Train loss: 0.37962,Valid loss: 0.49286, time : 12.504227638244629 lr : 0.92274469442792\n",
      "epoch : 0 [4138/21279] Train loss: 0.36390,Valid loss: 0.61060, time : 12.935356616973877 lr : 0.92274469442792\n",
      "epoch : 0 [4139/21279] Train loss: 0.36595,Valid loss: 0.62591, time : 13.178752183914185 lr : 0.92274469442792\n",
      "epoch : 0 [4140/21279] Train loss: 0.38337,Valid loss: 0.48274, time : 12.694246053695679 lr : 0.92274469442792\n",
      "epoch : 0 [4141/21279] Train loss: 0.37552,Valid loss: 0.64120, time : 13.270995855331421 lr : 0.92274469442792\n",
      "epoch : 0 [4142/21279] Train loss: 0.34437,Valid loss: 0.60566, time : 12.976583480834961 lr : 0.92274469442792\n",
      "epoch : 0 [4143/21279] Train loss: 0.35282,Valid loss: 0.50283, time : 12.983156681060791 lr : 0.92274469442792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [4144/21279] Train loss: 0.37304,Valid loss: 0.48142, time : 12.646729230880737 lr : 0.92274469442792\n",
      "epoch : 0 [4145/21279] Train loss: 0.36715,Valid loss: 0.73355, time : 12.943174839019775 lr : 0.92274469442792\n",
      "epoch : 0 [4146/21279] Train loss: 0.34434,Valid loss: 0.70478, time : 13.412962436676025 lr : 0.92274469442792\n",
      "epoch : 0 [4147/21279] Train loss: 0.36740,Valid loss: 0.71864, time : 12.864818811416626 lr : 0.92274469442792\n",
      "epoch : 0 [4148/21279] Train loss: 0.35060,Valid loss: 0.83462, time : 14.919934511184692 lr : 0.92274469442792\n",
      "epoch : 0 [4149/21279] Train loss: 0.36964,Valid loss: 0.49293, time : 12.69154691696167 lr : 0.92274469442792\n",
      "epoch : 0 [4150/21279] Train loss: 0.37300,Valid loss: 0.48691, time : 13.243719339370728 lr : 0.92274469442792\n",
      "epoch : 0 [4151/21279] Train loss: 0.34743,Valid loss: 0.52164, time : 12.582675695419312 lr : 0.92274469442792\n",
      "epoch : 0 [4152/21279] Train loss: 0.35659,Valid loss: 0.54770, time : 12.888686418533325 lr : 0.92274469442792\n",
      "epoch : 0 [4153/21279] Train loss: 0.35471,Valid loss: 0.60636, time : 12.65391492843628 lr : 0.92274469442792\n",
      "epoch : 0 [4154/21279] Train loss: 0.35722,Valid loss: 0.61235, time : 12.444018363952637 lr : 0.92274469442792\n",
      "epoch : 0 [4155/21279] Train loss: 0.38391,Valid loss: 0.91388, time : 12.553890943527222 lr : 0.92274469442792\n",
      "epoch : 0 [4156/21279] Train loss: 0.42294,Valid loss: 0.83560, time : 12.45807671546936 lr : 0.92274469442792\n",
      "epoch : 0 [4157/21279] Train loss: 0.42650,Valid loss: 0.64149, time : 12.21557354927063 lr : 0.92274469442792\n",
      "epoch : 0 [4158/21279] Train loss: 0.41763,Valid loss: 0.82019, time : 12.356584548950195 lr : 0.92274469442792\n",
      "epoch : 0 [4159/21279] Train loss: 0.40416,Valid loss: 1.20422, time : 12.711711168289185 lr : 0.92274469442792\n",
      "epoch : 0 [4160/21279] Train loss: 0.40200,Valid loss: 0.66939, time : 12.034970760345459 lr : 0.92274469442792\n",
      "epoch : 0 [4161/21279] Train loss: 0.37570,Valid loss: 0.63456, time : 12.019899368286133 lr : 0.92274469442792\n",
      "epoch : 0 [4162/21279] Train loss: 0.34939,Valid loss: 0.63528, time : 14.309146404266357 lr : 0.92274469442792\n",
      "epoch : 0 [4163/21279] Train loss: 0.35927,Valid loss: 0.80973, time : 12.363197565078735 lr : 0.92274469442792\n",
      "epoch : 0 [4164/21279] Train loss: 0.36148,Valid loss: 0.62199, time : 12.267351388931274 lr : 0.92274469442792\n",
      "epoch : 0 [4165/21279] Train loss: 0.38456,Valid loss: 0.50374, time : 12.724283933639526 lr : 0.92274469442792\n",
      "epoch : 0 [4166/21279] Train loss: 0.37527,Valid loss: 0.50082, time : 12.115664958953857 lr : 0.92274469442792\n",
      "epoch : 0 [4167/21279] Train loss: 0.37587,Valid loss: 0.90101, time : 12.67867922782898 lr : 0.92274469442792\n",
      "epoch : 0 [4168/21279] Train loss: 0.40646,Valid loss: 0.81038, time : 12.956453084945679 lr : 0.92274469442792\n",
      "epoch : 0 [4169/21279] Train loss: 0.39411,Valid loss: 0.73146, time : 12.656341314315796 lr : 0.92274469442792\n",
      "epoch : 0 [4170/21279] Train loss: 0.37470,Valid loss: 0.70287, time : 12.722442865371704 lr : 0.92274469442792\n",
      "epoch : 0 [4171/21279] Train loss: 0.36115,Valid loss: 0.69390, time : 13.075985670089722 lr : 0.92274469442792\n",
      "epoch : 0 [4172/21279] Train loss: 0.37223,Valid loss: 0.69324, time : 12.168797492980957 lr : 0.92274469442792\n",
      "epoch : 0 [4173/21279] Train loss: 0.36909,Valid loss: 0.61281, time : 12.645277500152588 lr : 0.92274469442792\n",
      "epoch : 0 [4174/21279] Train loss: 0.34785,Valid loss: 0.68917, time : 16.173267602920532 lr : 0.92274469442792\n",
      "epoch : 0 [4175/21279] Train loss: 0.38033,Valid loss: 0.63231, time : 12.8431396484375 lr : 0.92274469442792\n",
      "epoch : 0 [4176/21279] Train loss: 0.37579,Valid loss: 0.69986, time : 12.71532392501831 lr : 0.92274469442792\n",
      "epoch : 0 [4177/21279] Train loss: 0.35985,Valid loss: 0.65539, time : 12.915639638900757 lr : 0.92274469442792\n",
      "epoch : 0 [4178/21279] Train loss: 0.38318,Valid loss: 0.67906, time : 12.839659690856934 lr : 0.92274469442792\n",
      "epoch : 0 [4179/21279] Train loss: 0.39932,Valid loss: 0.64599, time : 13.055680751800537 lr : 0.92274469442792\n",
      "epoch : 0 [4180/21279] Train loss: 0.41032,Valid loss: 0.76103, time : 13.329307556152344 lr : 0.92274469442792\n",
      "epoch : 0 [4181/21279] Train loss: 0.38285,Valid loss: 0.55016, time : 12.683954000473022 lr : 0.92274469442792\n",
      "epoch : 0 [4182/21279] Train loss: 0.38731,Valid loss: 0.53682, time : 12.931161403656006 lr : 0.92274469442792\n",
      "epoch : 0 [4183/21279] Train loss: 0.39311,Valid loss: 0.90943, time : 13.188700675964355 lr : 0.92274469442792\n",
      "epoch : 0 [4184/21279] Train loss: 0.38847,Valid loss: 0.66230, time : 13.262890100479126 lr : 0.92274469442792\n",
      "epoch : 0 [4185/21279] Train loss: 0.37329,Valid loss: 0.73471, time : 13.247566938400269 lr : 0.92274469442792\n",
      "epoch : 0 [4186/21279] Train loss: 0.37248,Valid loss: 0.73753, time : 12.580918550491333 lr : 0.92274469442792\n",
      "epoch : 0 [4187/21279] Train loss: 0.36867,Valid loss: 0.67043, time : 13.25206708908081 lr : 0.92274469442792\n",
      "epoch : 0 [4188/21279] Train loss: 0.35074,Valid loss: 0.79481, time : 13.306759119033813 lr : 0.92274469442792\n",
      "epoch : 0 [4189/21279] Train loss: 0.37384,Valid loss: 0.66890, time : 13.376221656799316 lr : 0.92274469442792\n",
      "epoch : 0 [4190/21279] Train loss: 0.36590,Valid loss: 0.53662, time : 19.150988817214966 lr : 0.92274469442792\n",
      "epoch : 0 [4191/21279] Train loss: 0.36688,Valid loss: 0.98227, time : 12.652479648590088 lr : 0.92274469442792\n",
      "epoch : 0 [4192/21279] Train loss: 0.36546,Valid loss: 0.99351, time : 12.54595947265625 lr : 0.92274469442792\n",
      "epoch : 0 [4193/21279] Train loss: 0.39678,Valid loss: 0.65301, time : 12.173874855041504 lr : 0.92274469442792\n",
      "epoch : 0 [4194/21279] Train loss: 0.36624,Valid loss: 0.79057, time : 11.89309549331665 lr : 0.92274469442792\n",
      "epoch : 0 [4195/21279] Train loss: 0.37622,Valid loss: 0.63288, time : 12.066943645477295 lr : 0.92274469442792\n",
      "epoch : 0 [4196/21279] Train loss: 0.37842,Valid loss: 0.49136, time : 12.121590614318848 lr : 0.92274469442792\n",
      "epoch : 0 [4197/21279] Train loss: 0.36712,Valid loss: 0.58960, time : 11.912530899047852 lr : 0.92274469442792\n",
      "epoch : 0 [4198/21279] Train loss: 0.36464,Valid loss: 0.60173, time : 11.510120153427124 lr : 0.92274469442792\n",
      "epoch : 0 [4199/21279] Train loss: 0.35857,Valid loss: 1.34065, time : 11.916854858398438 lr : 0.92274469442792\n",
      "epoch : 0 [4200/21279] Train loss: 0.64149,Valid loss: 0.83781, time : 11.791102409362793 lr : 0.92274469442792\n",
      "epoch : 0 [4201/21279] Train loss: 0.52816,Valid loss: 0.90532, time : 12.313644409179688 lr : 0.92274469442792\n",
      "epoch : 0 [4202/21279] Train loss: 0.47081,Valid loss: 0.80106, time : 13.327279806137085 lr : 0.92274469442792\n",
      "epoch : 0 [4203/21279] Train loss: 0.44186,Valid loss: 0.57937, time : 11.770787715911865 lr : 0.92274469442792\n",
      "epoch : 0 [4204/21279] Train loss: 0.38854,Valid loss: 0.73282, time : 11.161460876464844 lr : 0.92274469442792\n",
      "epoch : 0 [4205/21279] Train loss: 0.38073,Valid loss: 0.57146, time : 11.996304035186768 lr : 0.92274469442792\n",
      "epoch : 0 [4206/21279] Train loss: 0.36172,Valid loss: 0.69358, time : 12.16092300415039 lr : 0.92274469442792\n",
      "epoch : 0 [4207/21279] Train loss: 0.37569,Valid loss: 0.65992, time : 12.383273601531982 lr : 0.92274469442792\n",
      "epoch : 0 [4208/21279] Train loss: 0.36870,Valid loss: 0.70818, time : 12.27949595451355 lr : 0.92274469442792\n",
      "epoch : 0 [4209/21279] Train loss: 0.36858,Valid loss: 0.69898, time : 12.456178665161133 lr : 0.92274469442792\n",
      "epoch : 0 [4210/21279] Train loss: 0.37822,Valid loss: 0.71238, time : 12.511332988739014 lr : 0.92274469442792\n",
      "epoch : 0 [4211/21279] Train loss: 0.37177,Valid loss: 1.01856, time : 12.522452116012573 lr : 0.92274469442792\n",
      "epoch : 0 [4212/21279] Train loss: 0.36994,Valid loss: 0.61340, time : 12.826421737670898 lr : 0.92274469442792\n",
      "epoch : 0 [4213/21279] Train loss: 0.35813,Valid loss: 0.73068, time : 12.476058721542358 lr : 0.92274469442792\n",
      "epoch : 0 [4214/21279] Train loss: 0.35949,Valid loss: 0.81939, time : 12.964236497879028 lr : 0.92274469442792\n",
      "epoch : 0 [4215/21279] Train loss: 0.34835,Valid loss: 0.87469, time : 13.154032468795776 lr : 0.92274469442792\n",
      "epoch : 0 [4216/21279] Train loss: 0.36311,Valid loss: 0.78728, time : 13.600024700164795 lr : 0.92274469442792\n",
      "epoch : 0 [4217/21279] Train loss: 0.35476,Valid loss: 0.76764, time : 13.475149393081665 lr : 0.92274469442792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [4218/21279] Train loss: 0.36634,Valid loss: 0.49764, time : 16.117268562316895 lr : 0.92274469442792\n",
      "epoch : 0 [4219/21279] Train loss: 0.36484,Valid loss: 0.57863, time : 13.367289304733276 lr : 0.92274469442792\n",
      "epoch : 0 [4220/21279] Train loss: 0.35666,Valid loss: 0.66248, time : 13.099080562591553 lr : 0.92274469442792\n",
      "epoch : 0 [4221/21279] Train loss: 0.35910,Valid loss: 0.80136, time : 13.068159103393555 lr : 0.92274469442792\n",
      "epoch : 0 [4222/21279] Train loss: 0.35504,Valid loss: 0.57919, time : 13.212485313415527 lr : 0.92274469442792\n",
      "epoch : 0 [4223/21279] Train loss: 0.34615,Valid loss: 0.57620, time : 13.166695594787598 lr : 0.92274469442792\n",
      "epoch : 0 [4224/21279] Train loss: 0.36671,Valid loss: 0.86354, time : 13.164437770843506 lr : 0.92274469442792\n",
      "epoch : 0 [4225/21279] Train loss: 0.32085,Valid loss: 0.54444, time : 12.85994029045105 lr : 0.92274469442792\n",
      "epoch : 0 [4226/21279] Train loss: 0.34947,Valid loss: 0.49413, time : 12.881272554397583 lr : 0.92274469442792\n",
      "epoch : 0 [4227/21279] Train loss: 0.35120,Valid loss: 0.56999, time : 12.742277145385742 lr : 0.92274469442792\n",
      "epoch : 0 [4228/21279] Train loss: 0.34071,Valid loss: 0.56848, time : 13.287052631378174 lr : 0.92274469442792\n",
      "epoch : 0 [4229/21279] Train loss: 0.35657,Valid loss: 0.49869, time : 12.80188775062561 lr : 0.92274469442792\n",
      "epoch : 0 [4230/21279] Train loss: 0.37658,Valid loss: 0.79786, time : 12.588465452194214 lr : 0.92274469442792\n",
      "epoch : 0 [4231/21279] Train loss: 0.36762,Valid loss: 0.75973, time : 15.457582712173462 lr : 0.92274469442792\n",
      "epoch : 0 [4232/21279] Train loss: 0.36213,Valid loss: 0.55825, time : 12.821223497390747 lr : 0.92274469442792\n",
      "epoch : 0 [4233/21279] Train loss: 0.36010,Valid loss: 0.47587, time : 12.944579601287842 lr : 0.92274469442792\n",
      "epoch : 0 [4234/21279] Train loss: 0.36668,Valid loss: 0.57480, time : 12.729621887207031 lr : 0.92274469442792\n",
      "epoch : 0 [4235/21279] Train loss: 0.34304,Valid loss: 0.57054, time : 12.895140647888184 lr : 0.92274469442792\n",
      "epoch : 0 [4236/21279] Train loss: 0.36283,Valid loss: 0.79261, time : 12.035429239273071 lr : 0.92274469442792\n",
      "epoch : 0 [4237/21279] Train loss: 0.34343,Valid loss: 0.67846, time : 12.959461688995361 lr : 0.92274469442792\n",
      "epoch : 0 [4238/21279] Train loss: 0.32228,Valid loss: 0.67673, time : 13.077531337738037 lr : 0.92274469442792\n",
      "epoch : 0 [4239/21279] Train loss: 0.34438,Valid loss: 0.60301, time : 12.805038452148438 lr : 0.92274469442792\n",
      "epoch : 0 [4240/21279] Train loss: 0.34351,Valid loss: 0.63569, time : 13.138224124908447 lr : 0.92274469442792\n",
      "epoch : 0 [4241/21279] Train loss: 0.34587,Valid loss: 0.58872, time : 12.877246141433716 lr : 0.92274469442792\n",
      "epoch : 0 [4242/21279] Train loss: 0.33959,Valid loss: 0.44929, time : 12.939653158187866 lr : 0.92274469442792\n",
      "epoch : 0 [4243/21279] Train loss: 0.34215,Valid loss: 0.45869, time : 12.665547609329224 lr : 0.92274469442792\n",
      "epoch : 0 [4244/21279] Train loss: 0.34394,Valid loss: 0.61358, time : 12.82337236404419 lr : 0.92274469442792\n",
      "epoch : 0 [4245/21279] Train loss: 0.35593,Valid loss: 0.68432, time : 13.50535249710083 lr : 0.92274469442792\n",
      "epoch : 0 [4246/21279] Train loss: 0.34576,Valid loss: 0.78689, time : 14.86227536201477 lr : 0.92274469442792\n",
      "epoch : 0 [4247/21279] Train loss: 0.33111,Valid loss: 1.04379, time : 13.084564447402954 lr : 0.92274469442792\n",
      "epoch : 0 [4248/21279] Train loss: 0.47292,Valid loss: 1.34927, time : 13.525761604309082 lr : 0.92274469442792\n",
      "epoch : 0 [4249/21279] Train loss: 0.47622,Valid loss: 1.37658, time : 13.469042301177979 lr : 0.92274469442792\n",
      "epoch : 0 [4250/21279] Train loss: 0.61989,Valid loss: 2.07847, time : 13.461745500564575 lr : 0.92274469442792\n",
      "epoch : 0 [4251/21279] Train loss: 0.68986,Valid loss: 1.82824, time : 13.54068398475647 lr : 0.92274469442792\n",
      "epoch : 0 [4252/21279] Train loss: 0.90921,Valid loss: 1.96343, time : 13.349134683609009 lr : 0.92274469442792\n",
      "epoch : 0 [4253/21279] Train loss: 0.60995,Valid loss: 2.43398, time : 12.85382628440857 lr : 0.92274469442792\n",
      "epoch : 0 [4254/21279] Train loss: 0.56378,Valid loss: 1.31134, time : 12.701578378677368 lr : 0.92274469442792\n",
      "epoch : 0 [4255/21279] Train loss: 0.55544,Valid loss: 0.93859, time : 12.705720901489258 lr : 0.92274469442792\n",
      "epoch : 0 [4256/21279] Train loss: 0.42156,Valid loss: 0.79054, time : 12.204610824584961 lr : 0.92274469442792\n",
      "epoch : 0 [4257/21279] Train loss: 0.38195,Valid loss: 0.61531, time : 12.236541986465454 lr : 0.92274469442792\n",
      "epoch : 0 [4258/21279] Train loss: 0.37512,Valid loss: 0.90053, time : 14.725606679916382 lr : 0.92274469442792\n",
      "epoch : 0 [4259/21279] Train loss: 0.37356,Valid loss: 0.56654, time : 12.441542148590088 lr : 0.92274469442792\n",
      "epoch : 0 [4260/21279] Train loss: 0.37451,Valid loss: 0.69619, time : 12.249877214431763 lr : 0.92274469442792\n",
      "epoch : 0 [4261/21279] Train loss: 0.37041,Valid loss: 0.82125, time : 12.56409740447998 lr : 0.92274469442792\n",
      "epoch : 0 [4262/21279] Train loss: 0.36202,Valid loss: 0.81653, time : 12.983747005462646 lr : 0.92274469442792\n",
      "epoch : 0 [4263/21279] Train loss: 0.35120,Valid loss: 0.85084, time : 12.889667510986328 lr : 0.92274469442792\n",
      "epoch : 0 [4264/21279] Train loss: 0.35895,Valid loss: 0.59706, time : 12.205353498458862 lr : 0.92274469442792\n",
      "epoch : 0 [4265/21279] Train loss: 0.34548,Valid loss: 0.51585, time : 12.520518779754639 lr : 0.92274469442792\n",
      "epoch : 0 [4266/21279] Train loss: 0.33875,Valid loss: 0.57499, time : 12.576287031173706 lr : 0.92274469442792\n",
      "epoch : 0 [4267/21279] Train loss: 0.37022,Valid loss: 0.47912, time : 12.72010064125061 lr : 0.92274469442792\n",
      "epoch : 0 [4268/21279] Train loss: 0.36138,Valid loss: 0.46606, time : 12.98454999923706 lr : 0.92274469442792\n",
      "epoch : 0 [4269/21279] Train loss: 0.36777,Valid loss: 0.55426, time : 12.949691772460938 lr : 0.92274469442792\n",
      "epoch : 0 [4270/21279] Train loss: 0.34175,Valid loss: 0.54839, time : 12.539319515228271 lr : 0.92274469442792\n",
      "epoch : 0 [4271/21279] Train loss: 0.36306,Valid loss: 0.45037, time : 12.146156311035156 lr : 0.92274469442792\n",
      "epoch : 0 [4272/21279] Train loss: 0.35574,Valid loss: 0.44902, time : 20.75650930404663 lr : 0.92274469442792\n",
      "epoch : 0 [4273/21279] Train loss: 0.32634,Valid loss: 0.44233, time : 12.7550048828125 lr : 0.92274469442792\n",
      "epoch : 0 [4274/21279] Train loss: 0.33705,Valid loss: 0.70035, time : 12.705307245254517 lr : 0.92274469442792\n",
      "epoch : 0 [4275/21279] Train loss: 0.35845,Valid loss: 0.67334, time : 12.136693477630615 lr : 0.92274469442792\n",
      "epoch : 0 [4276/21279] Train loss: 0.34213,Valid loss: 0.69219, time : 11.425908327102661 lr : 0.92274469442792\n",
      "epoch : 0 [4277/21279] Train loss: 0.34465,Valid loss: 0.53059, time : 12.372080087661743 lr : 0.92274469442792\n",
      "epoch : 0 [4278/21279] Train loss: 0.31031,Valid loss: 0.74147, time : 12.256302118301392 lr : 0.92274469442792\n",
      "epoch : 0 [4279/21279] Train loss: 0.34005,Valid loss: 0.46933, time : 11.809305667877197 lr : 0.92274469442792\n",
      "epoch : 0 [4280/21279] Train loss: 0.34382,Valid loss: 0.90619, time : 12.541984796524048 lr : 0.92274469442792\n",
      "epoch : 0 [4281/21279] Train loss: 0.34861,Valid loss: 0.56073, time : 12.217058897018433 lr : 0.92274469442792\n",
      "epoch : 0 [4282/21279] Train loss: 0.35417,Valid loss: 0.72928, time : 13.060880899429321 lr : 0.92274469442792\n",
      "epoch : 0 [4283/21279] Train loss: 0.34729,Valid loss: 0.49295, time : 12.605101585388184 lr : 0.92274469442792\n",
      "epoch : 0 [4284/21279] Train loss: 0.33856,Valid loss: 0.47892, time : 14.607740640640259 lr : 0.92274469442792\n",
      "epoch : 0 [4285/21279] Train loss: 0.33327,Valid loss: 0.54805, time : 12.706642866134644 lr : 0.92274469442792\n",
      "epoch : 0 [4286/21279] Train loss: 0.34537,Valid loss: 0.68557, time : 13.382419109344482 lr : 0.92274469442792\n",
      "epoch : 0 [4287/21279] Train loss: 0.35249,Valid loss: 0.70468, time : 13.175442695617676 lr : 0.92274469442792\n",
      "epoch : 0 [4288/21279] Train loss: 0.36293,Valid loss: 0.46606, time : 12.793431520462036 lr : 0.92274469442792\n",
      "epoch : 0 [4289/21279] Train loss: 0.36824,Valid loss: 0.49594, time : 12.228516340255737 lr : 0.92274469442792\n",
      "epoch : 0 [4290/21279] Train loss: 0.35945,Valid loss: 0.47581, time : 13.063204526901245 lr : 0.92274469442792\n",
      "epoch : 0 [4291/21279] Train loss: 0.35561,Valid loss: 0.68831, time : 12.285842418670654 lr : 0.92274469442792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [4292/21279] Train loss: 0.36565,Valid loss: 0.71965, time : 12.72761583328247 lr : 0.92274469442792\n",
      "epoch : 0 [4293/21279] Train loss: 0.36071,Valid loss: 0.88897, time : 12.277389287948608 lr : 0.92274469442792\n",
      "epoch : 0 [4294/21279] Train loss: 0.34799,Valid loss: 0.80893, time : 12.239670753479004 lr : 0.92274469442792\n",
      "epoch : 0 [4295/21279] Train loss: 0.34116,Valid loss: 0.77608, time : 12.64586853981018 lr : 0.92274469442792\n",
      "epoch : 0 [4296/21279] Train loss: 0.33438,Valid loss: 0.44534, time : 12.650506973266602 lr : 0.92274469442792\n",
      "epoch : 0 [4297/21279] Train loss: 0.32265,Valid loss: 0.60829, time : 12.679170370101929 lr : 0.92274469442792\n",
      "epoch : 0 [4298/21279] Train loss: 0.35499,Valid loss: 0.60752, time : 11.993967294692993 lr : 0.92274469442792\n",
      "epoch : 0 [4299/21279] Train loss: 0.32995,Valid loss: 0.90242, time : 12.247474908828735 lr : 0.92274469442792\n",
      "epoch : 0 [4300/21279] Train loss: 0.33669,Valid loss: 0.43627, time : 13.46817946434021 lr : 0.92274469442792\n",
      "epoch : 0 [4301/21279] Train loss: 0.35280,Valid loss: 0.83361, time : 12.39765977859497 lr : 0.92274469442792\n",
      "epoch : 0 [4302/21279] Train loss: 0.33620,Valid loss: 0.69045, time : 12.677958488464355 lr : 0.92274469442792\n",
      "epoch : 0 [4303/21279] Train loss: 0.32460,Valid loss: 0.59149, time : 12.75524091720581 lr : 0.92274469442792\n",
      "epoch : 0 [4304/21279] Train loss: 0.32075,Valid loss: 0.70826, time : 12.46879768371582 lr : 0.92274469442792\n",
      "epoch : 0 [4305/21279] Train loss: 0.33101,Valid loss: 0.45169, time : 12.3958261013031 lr : 0.92274469442792\n",
      "epoch : 0 [4306/21279] Train loss: 0.34961,Valid loss: 0.68422, time : 12.495271682739258 lr : 0.92274469442792\n",
      "epoch : 0 [4307/21279] Train loss: 0.33885,Valid loss: 0.45993, time : 12.375401496887207 lr : 0.92274469442792\n",
      "epoch : 0 [4308/21279] Train loss: 0.34219,Valid loss: 0.53651, time : 12.594310283660889 lr : 0.92274469442792\n",
      "epoch : 0 [4309/21279] Train loss: 0.32666,Valid loss: 0.46364, time : 12.654351711273193 lr : 0.92274469442792\n",
      "epoch : 0 [4310/21279] Train loss: 0.34972,Valid loss: 0.44441, time : 12.81847071647644 lr : 0.92274469442792\n",
      "epoch : 0 [4311/21279] Train loss: 0.35474,Valid loss: 0.48003, time : 12.586721897125244 lr : 0.92274469442792\n",
      "epoch : 0 [4312/21279] Train loss: 0.32763,Valid loss: 0.54872, time : 16.151177883148193 lr : 0.92274469442792\n",
      "epoch : 0 [4313/21279] Train loss: 0.33614,Valid loss: 0.47136, time : 12.313924551010132 lr : 0.92274469442792\n",
      "epoch : 0 [4314/21279] Train loss: 0.32401,Valid loss: 0.70329, time : 12.01525330543518 lr : 0.92274469442792\n",
      "epoch : 0 [4315/21279] Train loss: 0.35275,Valid loss: 0.49842, time : 12.808632850646973 lr : 0.92274469442792\n",
      "epoch : 0 [4316/21279] Train loss: 0.35387,Valid loss: 0.74508, time : 12.404781579971313 lr : 0.92274469442792\n",
      "epoch : 0 [4317/21279] Train loss: 0.33324,Valid loss: 0.47762, time : 12.594989538192749 lr : 0.92274469442792\n",
      "epoch : 0 [4318/21279] Train loss: 0.32809,Valid loss: 0.70285, time : 12.379386901855469 lr : 0.92274469442792\n",
      "epoch : 0 [4319/21279] Train loss: 0.33135,Valid loss: 0.72516, time : 11.900883436203003 lr : 0.92274469442792\n",
      "epoch : 0 [4320/21279] Train loss: 0.34819,Valid loss: 0.48362, time : 11.939988613128662 lr : 0.92274469442792\n",
      "epoch : 0 [4321/21279] Train loss: 0.33028,Valid loss: 0.45566, time : 11.748896598815918 lr : 0.92274469442792\n",
      "epoch : 0 [4322/21279] Train loss: 0.32719,Valid loss: 0.46369, time : 11.588793754577637 lr : 0.92274469442792\n",
      "epoch : 0 [4323/21279] Train loss: 0.33741,Valid loss: 0.75846, time : 11.58460283279419 lr : 0.92274469442792\n",
      "epoch : 0 [4324/21279] Train loss: 0.34093,Valid loss: 0.50515, time : 11.65130066871643 lr : 0.92274469442792\n",
      "epoch : 0 [4325/21279] Train loss: 0.32973,Valid loss: 0.49983, time : 11.397436141967773 lr : 0.92274469442792\n",
      "epoch : 0 [4326/21279] Train loss: 0.34394,Valid loss: 0.48276, time : 12.026848316192627 lr : 0.92274469442792\n",
      "epoch : 0 [4327/21279] Train loss: 0.35806,Valid loss: 0.47887, time : 12.703517436981201 lr : 0.92274469442792\n",
      "epoch : 0 [4328/21279] Train loss: 0.34637,Valid loss: 0.48569, time : 13.646300077438354 lr : 0.92274469442792\n",
      "epoch : 0 [4329/21279] Train loss: 0.34197,Valid loss: 0.45838, time : 12.350502967834473 lr : 0.92274469442792\n",
      "epoch : 0 [4330/21279] Train loss: 0.35342,Valid loss: 0.48772, time : 12.2561194896698 lr : 0.92274469442792\n",
      "epoch : 0 [4331/21279] Train loss: 0.36349,Valid loss: 0.50286, time : 12.041682243347168 lr : 0.92274469442792\n",
      "epoch : 0 [4332/21279] Train loss: 0.36151,Valid loss: 0.59868, time : 11.30021357536316 lr : 0.92274469442792\n",
      "epoch : 0 [4333/21279] Train loss: 0.34454,Valid loss: 0.47724, time : 11.801246881484985 lr : 0.92274469442792\n",
      "epoch : 0 [4334/21279] Train loss: 0.36080,Valid loss: 0.54701, time : 12.874365091323853 lr : 0.92274469442792\n",
      "epoch : 0 [4335/21279] Train loss: 0.37953,Valid loss: 0.69153, time : 12.29185175895691 lr : 0.92274469442792\n",
      "epoch : 0 [4336/21279] Train loss: 0.34691,Valid loss: 0.68470, time : 12.564032077789307 lr : 0.92274469442792\n",
      "epoch : 0 [4337/21279] Train loss: 0.34685,Valid loss: 0.59035, time : 12.183963298797607 lr : 0.92274469442792\n",
      "epoch : 0 [4338/21279] Train loss: 0.32920,Valid loss: 0.49149, time : 12.847900390625 lr : 0.92274469442792\n",
      "epoch : 0 [4339/21279] Train loss: 0.34627,Valid loss: 0.48844, time : 12.162427425384521 lr : 0.92274469442792\n",
      "epoch : 0 [4340/21279] Train loss: 0.32747,Valid loss: 0.47166, time : 12.07936954498291 lr : 0.92274469442792\n",
      "epoch : 0 [4341/21279] Train loss: 0.35366,Valid loss: 0.47474, time : 13.911088705062866 lr : 0.92274469442792\n",
      "epoch : 0 [4342/21279] Train loss: 0.35654,Valid loss: 0.46659, time : 11.72581434249878 lr : 0.92274469442792\n",
      "epoch : 0 [4343/21279] Train loss: 0.32674,Valid loss: 0.47771, time : 11.880094051361084 lr : 0.92274469442792\n",
      "epoch : 0 [4344/21279] Train loss: 0.33376,Valid loss: 0.44224, time : 11.964203596115112 lr : 0.92274469442792\n",
      "epoch : 0 [4345/21279] Train loss: 0.32563,Valid loss: 0.44546, time : 12.195794820785522 lr : 0.92274469442792\n",
      "epoch : 0 [4346/21279] Train loss: 0.32745,Valid loss: 0.44101, time : 11.984779596328735 lr : 0.92274469442792\n",
      "epoch : 0 [4347/21279] Train loss: 0.33235,Valid loss: 0.43231, time : 12.427762746810913 lr : 0.92274469442792\n",
      "epoch : 0 [4348/21279] Train loss: 0.34470,Valid loss: 0.43184, time : 12.62503433227539 lr : 0.92274469442792\n",
      "epoch : 0 [4349/21279] Train loss: 0.35853,Valid loss: 0.51477, time : 11.959288597106934 lr : 0.92274469442792\n",
      "epoch : 0 [4350/21279] Train loss: 0.36960,Valid loss: 0.47208, time : 11.993894338607788 lr : 0.92274469442792\n",
      "epoch : 0 [4351/21279] Train loss: 0.34278,Valid loss: 0.61798, time : 12.292943954467773 lr : 0.92274469442792\n",
      "epoch : 0 [4352/21279] Train loss: 0.34809,Valid loss: 0.58213, time : 12.739629030227661 lr : 0.92274469442792\n",
      "epoch : 0 [4353/21279] Train loss: 0.33071,Valid loss: 0.62041, time : 11.979714632034302 lr : 0.92274469442792\n",
      "epoch : 0 [4354/21279] Train loss: 0.34912,Valid loss: 0.52875, time : 12.830839395523071 lr : 0.92274469442792\n",
      "epoch : 0 [4355/21279] Train loss: 0.32831,Valid loss: 0.56812, time : 12.471994161605835 lr : 0.92274469442792\n",
      "epoch : 0 [4356/21279] Train loss: 0.33041,Valid loss: 0.43430, time : 14.467290878295898 lr : 0.92274469442792\n",
      "epoch : 0 [4357/21279] Train loss: 0.35865,Valid loss: 1.35615, time : 12.243751764297485 lr : 0.92274469442792\n",
      "epoch : 0 [4358/21279] Train loss: 0.52404,Valid loss: 0.89573, time : 11.70439100265503 lr : 0.92274469442792\n",
      "epoch : 0 [4359/21279] Train loss: 0.44826,Valid loss: 2.12980, time : 11.905099391937256 lr : 0.92274469442792\n",
      "epoch : 0 [4360/21279] Train loss: 0.43950,Valid loss: 0.79108, time : 12.686932563781738 lr : 0.92274469442792\n",
      "epoch : 0 [4361/21279] Train loss: 0.44125,Valid loss: 2.63820, time : 12.17838430404663 lr : 0.92274469442792\n",
      "epoch : 0 [4362/21279] Train loss: 0.64503,Valid loss: 1.63876, time : 11.722384452819824 lr : 0.92274469442792\n",
      "epoch : 0 [4363/21279] Train loss: 0.73611,Valid loss: 1.62950, time : 12.233479022979736 lr : 0.92274469442792\n",
      "epoch : 0 [4364/21279] Train loss: 0.49857,Valid loss: 0.70686, time : 12.173752307891846 lr : 0.92274469442792\n",
      "epoch : 0 [4365/21279] Train loss: 0.41653,Valid loss: 0.78665, time : 13.161376237869263 lr : 0.92274469442792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [4366/21279] Train loss: 0.40117,Valid loss: 0.54206, time : 12.16736888885498 lr : 0.92274469442792\n",
      "epoch : 0 [4367/21279] Train loss: 0.38166,Valid loss: 0.67102, time : 11.948765516281128 lr : 0.92274469442792\n",
      "epoch : 0 [4368/21279] Train loss: 0.37783,Valid loss: 0.50494, time : 14.615635395050049 lr : 0.92274469442792\n",
      "epoch : 0 [4369/21279] Train loss: 0.37982,Valid loss: 0.66802, time : 12.145346641540527 lr : 0.92274469442792\n",
      "epoch : 0 [4370/21279] Train loss: 0.36063,Valid loss: 0.48677, time : 12.274199962615967 lr : 0.92274469442792\n",
      "epoch : 0 [4371/21279] Train loss: 0.35381,Valid loss: 0.47221, time : 11.93342638015747 lr : 0.92274469442792\n",
      "epoch : 0 [4372/21279] Train loss: 0.35544,Valid loss: 0.71784, time : 11.919773817062378 lr : 0.92274469442792\n",
      "epoch : 0 [4373/21279] Train loss: 0.34740,Valid loss: 0.44560, time : 12.284388065338135 lr : 0.92274469442792\n",
      "epoch : 0 [4374/21279] Train loss: 0.33470,Valid loss: 0.46982, time : 12.359545469284058 lr : 0.92274469442792\n",
      "epoch : 0 [4375/21279] Train loss: 0.34813,Valid loss: 0.44927, time : 12.313867807388306 lr : 0.92274469442792\n",
      "epoch : 0 [4376/21279] Train loss: 0.34378,Valid loss: 0.77031, time : 12.49340271949768 lr : 0.92274469442792\n",
      "epoch : 0 [4377/21279] Train loss: 0.34579,Valid loss: 0.67983, time : 11.917534589767456 lr : 0.92274469442792\n",
      "epoch : 0 [4378/21279] Train loss: 0.35880,Valid loss: 0.75729, time : 12.171887397766113 lr : 0.92274469442792\n",
      "epoch : 0 [4379/21279] Train loss: 0.33808,Valid loss: 0.67968, time : 12.622526168823242 lr : 0.92274469442792\n",
      "epoch : 0 [4380/21279] Train loss: 0.32686,Valid loss: 0.66102, time : 12.623213291168213 lr : 0.92274469442792\n",
      "epoch : 0 [4381/21279] Train loss: 0.32263,Valid loss: 0.53118, time : 12.857203006744385 lr : 0.92274469442792\n",
      "epoch : 0 [4382/21279] Train loss: 0.34369,Valid loss: 0.70886, time : 14.590300798416138 lr : 0.92274469442792\n",
      "epoch : 0 [4383/21279] Train loss: 0.32700,Valid loss: 0.44122, time : 12.85416030883789 lr : 0.92274469442792\n",
      "epoch : 0 [4384/21279] Train loss: 0.32259,Valid loss: 0.50465, time : 12.400148868560791 lr : 0.92274469442792\n",
      "epoch : 0 [4385/21279] Train loss: 0.34080,Valid loss: 0.51775, time : 11.73176622390747 lr : 0.92274469442792\n",
      "epoch : 0 [4386/21279] Train loss: 0.34104,Valid loss: 0.70043, time : 11.416529178619385 lr : 0.92274469442792\n",
      "epoch : 0 [4387/21279] Train loss: 0.33334,Valid loss: 0.51730, time : 11.532348394393921 lr : 0.92274469442792\n",
      "epoch : 0 [4388/21279] Train loss: 0.33585,Valid loss: 0.69954, time : 12.11528205871582 lr : 0.92274469442792\n",
      "epoch : 0 [4389/21279] Train loss: 0.31941,Valid loss: 0.45154, time : 12.420916318893433 lr : 0.92274469442792\n",
      "epoch : 0 [4390/21279] Train loss: 0.32777,Valid loss: 0.46033, time : 12.057100296020508 lr : 0.92274469442792\n",
      "epoch : 0 [4391/21279] Train loss: 0.34508,Valid loss: 0.66324, time : 12.408370018005371 lr : 0.92274469442792\n",
      "epoch : 0 [4392/21279] Train loss: 0.33659,Valid loss: 0.76032, time : 11.239439487457275 lr : 0.92274469442792\n",
      "epoch : 0 [4393/21279] Train loss: 0.32102,Valid loss: 0.65500, time : 12.433057308197021 lr : 0.92274469442792\n",
      "epoch : 0 [4394/21279] Train loss: 0.32220,Valid loss: 0.64465, time : 14.02503776550293 lr : 0.92274469442792\n",
      "epoch : 0 [4395/21279] Train loss: 0.31818,Valid loss: 0.50534, time : 12.910548448562622 lr : 0.92274469442792\n",
      "epoch : 0 [4396/21279] Train loss: 0.31454,Valid loss: 0.67526, time : 12.044540405273438 lr : 0.92274469442792\n",
      "epoch : 0 [4397/21279] Train loss: 0.32051,Valid loss: 0.65681, time : 12.144787788391113 lr : 0.92274469442792\n",
      "epoch : 0 [4398/21279] Train loss: 0.31892,Valid loss: 0.66070, time : 12.357444047927856 lr : 0.92274469442792\n",
      "epoch : 0 [4399/21279] Train loss: 0.30803,Valid loss: 0.41948, time : 12.494301080703735 lr : 0.92274469442792\n",
      "epoch : 0 [4400/21279] Train loss: 0.32735,Valid loss: 0.65519, time : 12.752622842788696 lr : 0.92274469442792\n",
      "epoch : 0 [4401/21279] Train loss: 0.31980,Valid loss: 0.66210, time : 12.820595502853394 lr : 0.92274469442792\n",
      "epoch : 0 [4402/21279] Train loss: 0.33635,Valid loss: 0.43793, time : 12.899016380310059 lr : 0.92274469442792\n",
      "epoch : 0 [4403/21279] Train loss: 0.30902,Valid loss: 1.31554, time : 12.695837020874023 lr : 0.92274469442792\n",
      "epoch : 0 [4404/21279] Train loss: 0.33186,Valid loss: 0.69910, time : 12.061724185943604 lr : 0.92274469442792\n",
      "epoch : 0 [4405/21279] Train loss: 0.31272,Valid loss: 0.66327, time : 12.14362096786499 lr : 0.92274469442792\n",
      "epoch : 0 [4406/21279] Train loss: 0.33249,Valid loss: 0.63494, time : 11.975733995437622 lr : 0.92274469442792\n",
      "epoch : 0 [4407/21279] Train loss: 0.37849,Valid loss: 0.78276, time : 12.78538990020752 lr : 0.92274469442792\n",
      "epoch : 0 [4408/21279] Train loss: 0.43127,Valid loss: 0.82392, time : 12.638316631317139 lr : 0.92274469442792\n",
      "epoch : 0 [4409/21279] Train loss: 0.37176,Valid loss: 0.73319, time : 11.665295839309692 lr : 0.92274469442792\n",
      "epoch : 0 [4410/21279] Train loss: 0.36653,Valid loss: 0.58439, time : 13.97957730293274 lr : 0.92274469442792\n",
      "epoch : 0 [4411/21279] Train loss: 0.33078,Valid loss: 0.46623, time : 12.325356006622314 lr : 0.92274469442792\n",
      "epoch : 0 [4412/21279] Train loss: 0.32945,Valid loss: 0.58489, time : 12.095750331878662 lr : 0.92274469442792\n",
      "epoch : 0 [4413/21279] Train loss: 0.36071,Valid loss: 0.67244, time : 12.43705153465271 lr : 0.92274469442792\n",
      "epoch : 0 [4414/21279] Train loss: 0.32671,Valid loss: 0.79159, time : 12.879187107086182 lr : 0.92274469442792\n",
      "epoch : 0 [4415/21279] Train loss: 0.30959,Valid loss: 0.65804, time : 12.386670589447021 lr : 0.92274469442792\n",
      "epoch : 0 [4416/21279] Train loss: 0.32682,Valid loss: 0.47878, time : 12.012086153030396 lr : 0.92274469442792\n",
      "epoch : 0 [4417/21279] Train loss: 0.34623,Valid loss: 0.61884, time : 11.959261894226074 lr : 0.92274469442792\n",
      "epoch : 0 [4418/21279] Train loss: 0.32458,Valid loss: 0.44037, time : 12.74173355102539 lr : 0.92274469442792\n",
      "epoch : 0 [4419/21279] Train loss: 0.32539,Valid loss: 0.43102, time : 11.996514320373535 lr : 0.92274469442792\n",
      "epoch : 0 [4420/21279] Train loss: 0.32697,Valid loss: 0.43923, time : 12.35884428024292 lr : 0.92274469442792\n",
      "epoch : 0 [4421/21279] Train loss: 0.33058,Valid loss: 0.66052, time : 12.100862264633179 lr : 0.92274469442792\n",
      "epoch : 0 [4422/21279] Train loss: 0.33184,Valid loss: 0.45991, time : 14.39272928237915 lr : 0.92274469442792\n",
      "epoch : 0 [4423/21279] Train loss: 0.35994,Valid loss: 0.69238, time : 12.504825115203857 lr : 0.92274469442792\n",
      "epoch : 0 [4424/21279] Train loss: 0.33368,Valid loss: 0.64024, time : 12.19135046005249 lr : 0.92274469442792\n",
      "epoch : 0 [4425/21279] Train loss: 0.31602,Valid loss: 0.59199, time : 12.670170545578003 lr : 0.92274469442792\n",
      "epoch : 0 [4426/21279] Train loss: 0.34828,Valid loss: 0.69963, time : 11.924642562866211 lr : 0.92274469442792\n",
      "epoch : 0 [4427/21279] Train loss: 0.33777,Valid loss: 0.76780, time : 11.867290735244751 lr : 0.92274469442792\n",
      "epoch : 0 [4428/21279] Train loss: 0.33756,Valid loss: 0.46761, time : 11.930537700653076 lr : 0.92274469442792\n",
      "epoch : 0 [4429/21279] Train loss: 0.31850,Valid loss: 0.72745, time : 12.547330617904663 lr : 0.92274469442792\n",
      "epoch : 0 [4430/21279] Train loss: 0.34886,Valid loss: 1.06734, time : 12.76815128326416 lr : 0.92274469442792\n",
      "epoch : 0 [4431/21279] Train loss: 0.42773,Valid loss: 0.98311, time : 12.562544584274292 lr : 0.92274469442792\n",
      "epoch : 0 [4432/21279] Train loss: 0.52380,Valid loss: 1.91614, time : 12.743873834609985 lr : 0.92274469442792\n",
      "epoch : 0 [4433/21279] Train loss: 0.83076,Valid loss: 0.79131, time : 12.950123071670532 lr : 0.92274469442792\n",
      "epoch : 0 [4434/21279] Train loss: 0.59339,Valid loss: 1.55789, time : 12.938067436218262 lr : 0.92274469442792\n",
      "epoch : 0 [4435/21279] Train loss: 0.77505,Valid loss: 0.86809, time : 12.345080614089966 lr : 0.92274469442792\n",
      "epoch : 0 [4436/21279] Train loss: 0.41421,Valid loss: 0.53363, time : 12.32883882522583 lr : 0.92274469442792\n",
      "epoch : 0 [4437/21279] Train loss: 0.35960,Valid loss: 0.46409, time : 12.10289978981018 lr : 0.92274469442792\n",
      "epoch : 0 [4438/21279] Train loss: 0.35755,Valid loss: 0.53026, time : 15.166136741638184 lr : 0.92274469442792\n",
      "epoch : 0 [4439/21279] Train loss: 0.33066,Valid loss: 0.51690, time : 13.378907442092896 lr : 0.92274469442792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [4440/21279] Train loss: 0.33232,Valid loss: 0.53986, time : 12.38451886177063 lr : 0.92274469442792\n",
      "epoch : 0 [4441/21279] Train loss: 0.34139,Valid loss: 0.44153, time : 12.816766738891602 lr : 0.92274469442792\n",
      "epoch : 0 [4442/21279] Train loss: 0.33513,Valid loss: 0.42786, time : 13.019991159439087 lr : 0.92274469442792\n",
      "epoch : 0 [4443/21279] Train loss: 0.35591,Valid loss: 0.43964, time : 12.939472675323486 lr : 0.92274469442792\n",
      "epoch : 0 [4444/21279] Train loss: 0.34314,Valid loss: 0.43445, time : 11.786344289779663 lr : 0.92274469442792\n",
      "epoch : 0 [4445/21279] Train loss: 0.32382,Valid loss: 0.44429, time : 11.71757173538208 lr : 0.92274469442792\n",
      "epoch : 0 [4446/21279] Train loss: 0.32211,Valid loss: 0.41865, time : 11.68004322052002 lr : 0.92274469442792\n",
      "epoch : 0 [4447/21279] Train loss: 0.30576,Valid loss: 0.42791, time : 12.462132453918457 lr : 0.92274469442792\n",
      "epoch : 0 [4448/21279] Train loss: 0.32393,Valid loss: 0.42697, time : 11.737127780914307 lr : 0.92274469442792\n",
      "epoch : 0 [4449/21279] Train loss: 0.32602,Valid loss: 0.42961, time : 12.221312046051025 lr : 0.92274469442792\n",
      "epoch : 0 [4450/21279] Train loss: 0.32491,Valid loss: 0.43237, time : 12.660112142562866 lr : 0.92274469442792\n",
      "epoch : 0 [4451/21279] Train loss: 0.31377,Valid loss: 0.41592, time : 15.026951789855957 lr : 0.92274469442792\n",
      "epoch : 0 [4452/21279] Train loss: 0.31838,Valid loss: 0.40938, time : 13.025552034378052 lr : 0.92274469442792\n",
      "epoch : 0 [4453/21279] Train loss: 0.31470,Valid loss: 0.40595, time : 12.902865648269653 lr : 0.92274469442792\n",
      "epoch : 0 [4454/21279] Train loss: 0.30929,Valid loss: 0.72201, time : 12.888977289199829 lr : 0.92274469442792\n",
      "epoch : 0 [4455/21279] Train loss: 0.29460,Valid loss: 0.55403, time : 13.216806650161743 lr : 0.92274469442792\n",
      "epoch : 0 [4456/21279] Train loss: 0.32855,Valid loss: 0.46578, time : 12.940730333328247 lr : 0.92274469442792\n",
      "epoch : 0 [4457/21279] Train loss: 0.35549,Valid loss: 0.45096, time : 13.106823205947876 lr : 0.92274469442792\n",
      "epoch : 0 [4458/21279] Train loss: 0.32784,Valid loss: 0.45136, time : 12.75124454498291 lr : 0.92274469442792\n",
      "epoch : 0 [4459/21279] Train loss: 0.33118,Valid loss: 0.42185, time : 12.972244024276733 lr : 0.92274469442792\n",
      "epoch : 0 [4460/21279] Train loss: 0.32016,Valid loss: 0.43931, time : 12.66840147972107 lr : 0.92274469442792\n",
      "epoch : 0 [4461/21279] Train loss: 0.31730,Valid loss: 0.45507, time : 12.954107761383057 lr : 0.92274469442792\n",
      "epoch : 0 [4462/21279] Train loss: 0.34104,Valid loss: 0.45739, time : 12.925784587860107 lr : 0.92274469442792\n",
      "epoch : 0 [4463/21279] Train loss: 0.33446,Valid loss: 0.42816, time : 12.88281536102295 lr : 0.92274469442792\n",
      "epoch : 0 [4464/21279] Train loss: 0.33092,Valid loss: 0.43174, time : 13.055374383926392 lr : 0.92274469442792\n",
      "epoch : 0 [4465/21279] Train loss: 0.30209,Valid loss: 0.43325, time : 13.113312005996704 lr : 0.92274469442792\n",
      "epoch : 0 [4466/21279] Train loss: 0.30708,Valid loss: 0.56364, time : 14.888890981674194 lr : 0.92274469442792\n",
      "epoch : 0 [4467/21279] Train loss: 0.35861,Valid loss: 0.58957, time : 12.761180400848389 lr : 0.92274469442792\n",
      "epoch : 0 [4468/21279] Train loss: 0.32339,Valid loss: 0.45686, time : 12.9181809425354 lr : 0.92274469442792\n",
      "epoch : 0 [4469/21279] Train loss: 0.30671,Valid loss: 0.48307, time : 12.798555612564087 lr : 0.92274469442792\n",
      "epoch : 0 [4470/21279] Train loss: 0.31090,Valid loss: 0.45719, time : 11.918864965438843 lr : 0.92274469442792\n",
      "epoch : 0 [4471/21279] Train loss: 0.31386,Valid loss: 0.66102, time : 12.150793552398682 lr : 0.92274469442792\n",
      "epoch : 0 [4472/21279] Train loss: 0.43267,Valid loss: 0.94109, time : 12.377788782119751 lr : 0.92274469442792\n",
      "epoch : 0 [4473/21279] Train loss: 0.48985,Valid loss: 1.67338, time : 12.653769731521606 lr : 0.92274469442792\n",
      "epoch : 0 [4474/21279] Train loss: 0.68472,Valid loss: 0.93846, time : 12.181413650512695 lr : 0.92274469442792\n",
      "epoch : 0 [4475/21279] Train loss: 0.42270,Valid loss: 0.78891, time : 12.086531639099121 lr : 0.92274469442792\n",
      "epoch : 0 [4476/21279] Train loss: 0.36090,Valid loss: 0.50569, time : 12.404188394546509 lr : 0.92274469442792\n",
      "epoch : 0 [4477/21279] Train loss: 0.35252,Valid loss: 0.47997, time : 12.686037302017212 lr : 0.92274469442792\n",
      "epoch : 0 [4478/21279] Train loss: 0.33205,Valid loss: 0.46192, time : 14.331537961959839 lr : 0.92274469442792\n",
      "epoch : 0 [4479/21279] Train loss: 0.32824,Valid loss: 0.45275, time : 12.492366790771484 lr : 0.92274469442792\n",
      "epoch : 0 [4480/21279] Train loss: 0.31575,Valid loss: 0.57197, time : 12.499783754348755 lr : 0.92274469442792\n",
      "epoch : 0 [4481/21279] Train loss: 0.34807,Valid loss: 0.46198, time : 12.161472797393799 lr : 0.92274469442792\n",
      "epoch : 0 [4482/21279] Train loss: 0.35713,Valid loss: 0.51250, time : 12.579986333847046 lr : 0.92274469442792\n",
      "epoch : 0 [4483/21279] Train loss: 0.32667,Valid loss: 0.48605, time : 12.708759307861328 lr : 0.92274469442792\n",
      "epoch : 0 [4484/21279] Train loss: 0.31217,Valid loss: 0.56163, time : 12.82265043258667 lr : 0.92274469442792\n",
      "epoch : 0 [4485/21279] Train loss: 0.33790,Valid loss: 0.48979, time : 12.484850406646729 lr : 0.92274469442792\n",
      "epoch : 0 [4486/21279] Train loss: 0.32775,Valid loss: 0.45715, time : 12.320797204971313 lr : 0.92274469442792\n",
      "epoch : 0 [4487/21279] Train loss: 0.33242,Valid loss: 0.44051, time : 12.578438520431519 lr : 0.92274469442792\n",
      "epoch : 0 [4488/21279] Train loss: 0.32781,Valid loss: 0.45074, time : 12.684643507003784 lr : 0.92274469442792\n",
      "epoch : 0 [4489/21279] Train loss: 0.32762,Valid loss: 0.46960, time : 12.44617486000061 lr : 0.92274469442792\n",
      "epoch : 0 [4490/21279] Train loss: 0.34018,Valid loss: 0.46045, time : 12.630100011825562 lr : 0.92274469442792\n",
      "epoch : 0 [4491/21279] Train loss: 0.31609,Valid loss: 0.83335, time : 12.85184121131897 lr : 0.92274469442792\n",
      "epoch : 0 [4492/21279] Train loss: 0.31881,Valid loss: 0.47093, time : 18.526986122131348 lr : 0.92274469442792\n",
      "epoch : 0 [4493/21279] Train loss: 0.33231,Valid loss: 0.43549, time : 13.392831087112427 lr : 0.92274469442792\n",
      "epoch : 0 [4494/21279] Train loss: 0.30619,Valid loss: 0.46656, time : 13.014389991760254 lr : 0.92274469442792\n",
      "epoch : 0 [4495/21279] Train loss: 0.32648,Valid loss: 0.54331, time : 13.231927633285522 lr : 0.92274469442792\n",
      "epoch : 0 [4496/21279] Train loss: 0.31672,Valid loss: 0.44668, time : 13.108176708221436 lr : 0.92274469442792\n",
      "epoch : 0 [4497/21279] Train loss: 0.30773,Valid loss: 0.46711, time : 12.970948934555054 lr : 0.92274469442792\n",
      "epoch : 0 [4498/21279] Train loss: 0.32370,Valid loss: 0.64532, time : 13.059574604034424 lr : 0.92274469442792\n",
      "epoch : 0 [4499/21279] Train loss: 0.36819,Valid loss: 0.56673, time : 13.42145586013794 lr : 0.9135172474836407\n",
      "epoch : 0 [4500/21279] Train loss: 0.32226,Valid loss: 0.45376, time : 13.122780799865723 lr : 0.9135172474836407\n",
      "epoch : 0 [4501/21279] Train loss: 0.31845,Valid loss: 0.57205, time : 13.05944275856018 lr : 0.9135172474836407\n",
      "epoch : 0 [4502/21279] Train loss: 0.32054,Valid loss: 0.44091, time : 13.107263565063477 lr : 0.9135172474836407\n",
      "epoch : 0 [4503/21279] Train loss: 0.31253,Valid loss: 0.55951, time : 12.722455739974976 lr : 0.9135172474836407\n",
      "epoch : 0 [4504/21279] Train loss: 0.34697,Valid loss: 0.45601, time : 18.742300510406494 lr : 0.9135172474836407\n",
      "epoch : 0 [4505/21279] Train loss: 0.32513,Valid loss: 0.43555, time : 12.998111009597778 lr : 0.9135172474836407\n",
      "epoch : 0 [4506/21279] Train loss: 0.30568,Valid loss: 0.43795, time : 12.433457851409912 lr : 0.9135172474836407\n",
      "epoch : 0 [4507/21279] Train loss: 0.31613,Valid loss: 0.69172, time : 12.2326078414917 lr : 0.9135172474836407\n",
      "epoch : 0 [4508/21279] Train loss: 0.33604,Valid loss: 0.65490, time : 12.847540855407715 lr : 0.9135172474836407\n",
      "epoch : 0 [4509/21279] Train loss: 0.31342,Valid loss: 0.45704, time : 12.83706283569336 lr : 0.9135172474836407\n",
      "epoch : 0 [4510/21279] Train loss: 0.33469,Valid loss: 0.43790, time : 12.685112953186035 lr : 0.9135172474836407\n",
      "epoch : 0 [4511/21279] Train loss: 0.32216,Valid loss: 0.47624, time : 12.669979333877563 lr : 0.9135172474836407\n",
      "epoch : 0 [4512/21279] Train loss: 0.33137,Valid loss: 0.46659, time : 12.31583547592163 lr : 0.9135172474836407\n",
      "epoch : 0 [4513/21279] Train loss: 0.32540,Valid loss: 0.45119, time : 12.063065528869629 lr : 0.9135172474836407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [4514/21279] Train loss: 0.32381,Valid loss: 0.48963, time : 12.909282684326172 lr : 0.9135172474836407\n",
      "epoch : 0 [4515/21279] Train loss: 0.32923,Valid loss: 0.43989, time : 12.754148244857788 lr : 0.9135172474836407\n",
      "epoch : 0 [4516/21279] Train loss: 0.32185,Valid loss: 0.44834, time : 12.60048532485962 lr : 0.9135172474836407\n",
      "epoch : 0 [4517/21279] Train loss: 0.30960,Valid loss: 0.44999, time : 12.378232717514038 lr : 0.9135172474836407\n",
      "epoch : 0 [4518/21279] Train loss: 0.30717,Valid loss: 0.42802, time : 12.332618951797485 lr : 0.9135172474836407\n",
      "epoch : 0 [4519/21279] Train loss: 0.31358,Valid loss: 0.43476, time : 12.158812284469604 lr : 0.9135172474836407\n",
      "epoch : 0 [4520/21279] Train loss: 0.32764,Valid loss: 0.44079, time : 14.347561120986938 lr : 0.9135172474836407\n",
      "epoch : 0 [4521/21279] Train loss: 0.32863,Valid loss: 0.45197, time : 12.405471086502075 lr : 0.9135172474836407\n",
      "epoch : 0 [4522/21279] Train loss: 0.32145,Valid loss: 0.42695, time : 12.433594226837158 lr : 0.9135172474836407\n",
      "epoch : 0 [4523/21279] Train loss: 0.34159,Valid loss: 0.45231, time : 12.829426765441895 lr : 0.9135172474836407\n",
      "epoch : 0 [4524/21279] Train loss: 0.33573,Valid loss: 0.45186, time : 12.362184762954712 lr : 0.9135172474836407\n",
      "epoch : 0 [4525/21279] Train loss: 0.32407,Valid loss: 0.47523, time : 13.041166305541992 lr : 0.9135172474836407\n",
      "epoch : 0 [4526/21279] Train loss: 0.32577,Valid loss: 0.45519, time : 12.835750102996826 lr : 0.9135172474836407\n",
      "epoch : 0 [4527/21279] Train loss: 0.33741,Valid loss: 0.46398, time : 13.201529502868652 lr : 0.9135172474836407\n",
      "epoch : 0 [4528/21279] Train loss: 0.32460,Valid loss: 0.44018, time : 12.993218421936035 lr : 0.9135172474836407\n",
      "epoch : 0 [4529/21279] Train loss: 0.30806,Valid loss: 0.73434, time : 12.637367725372314 lr : 0.9135172474836407\n",
      "epoch : 0 [4530/21279] Train loss: 0.29770,Valid loss: 0.43317, time : 11.703905582427979 lr : 0.9135172474836407\n",
      "epoch : 0 [4531/21279] Train loss: 0.31908,Valid loss: 0.62237, time : 12.120418548583984 lr : 0.9135172474836407\n",
      "epoch : 0 [4532/21279] Train loss: 0.47377,Valid loss: 1.68096, time : 15.05138897895813 lr : 0.9135172474836407\n",
      "epoch : 0 [4533/21279] Train loss: 0.48324,Valid loss: 1.39128, time : 11.888689041137695 lr : 0.9135172474836407\n",
      "epoch : 0 [4534/21279] Train loss: 0.84088,Valid loss: 1.69898, time : 12.050482988357544 lr : 0.9135172474836407\n",
      "epoch : 0 [4535/21279] Train loss: 0.44783,Valid loss: 0.58124, time : 12.781704902648926 lr : 0.9135172474836407\n",
      "epoch : 0 [4536/21279] Train loss: 0.36498,Valid loss: 0.66537, time : 12.527050256729126 lr : 0.9135172474836407\n",
      "epoch : 0 [4537/21279] Train loss: 0.35413,Valid loss: 0.50188, time : 12.314598560333252 lr : 0.9135172474836407\n",
      "epoch : 0 [4538/21279] Train loss: 0.34247,Valid loss: 0.48595, time : 12.161401748657227 lr : 0.9135172474836407\n",
      "epoch : 0 [4539/21279] Train loss: 0.36036,Valid loss: 0.84157, time : 11.803666591644287 lr : 0.9135172474836407\n",
      "epoch : 0 [4540/21279] Train loss: 0.43578,Valid loss: 2.91432, time : 12.07160210609436 lr : 0.9135172474836407\n",
      "epoch : 0 [4541/21279] Train loss: 0.40497,Valid loss: 0.60015, time : 11.182554244995117 lr : 0.9135172474836407\n",
      "epoch : 0 [4542/21279] Train loss: 0.35485,Valid loss: 0.54576, time : 12.139582633972168 lr : 0.9135172474836407\n",
      "epoch : 0 [4543/21279] Train loss: 0.35960,Valid loss: 0.55012, time : 11.673553228378296 lr : 0.9135172474836407\n",
      "epoch : 0 [4544/21279] Train loss: 0.34212,Valid loss: 0.48053, time : 12.360431909561157 lr : 0.9135172474836407\n",
      "epoch : 0 [4545/21279] Train loss: 0.34880,Valid loss: 0.45735, time : 11.469701051712036 lr : 0.9135172474836407\n",
      "epoch : 0 [4546/21279] Train loss: 0.31653,Valid loss: 0.44289, time : 12.505212545394897 lr : 0.9135172474836407\n",
      "epoch : 0 [4547/21279] Train loss: 0.30886,Valid loss: 0.43857, time : 12.066542625427246 lr : 0.9135172474836407\n",
      "epoch : 0 [4548/21279] Train loss: 0.34031,Valid loss: 0.48148, time : 15.045132160186768 lr : 0.9135172474836407\n",
      "epoch : 0 [4549/21279] Train loss: 0.31613,Valid loss: 0.47020, time : 11.751482725143433 lr : 0.9135172474836407\n",
      "epoch : 0 [4550/21279] Train loss: 0.33991,Valid loss: 0.62044, time : 12.19644021987915 lr : 0.9135172474836407\n",
      "epoch : 0 [4551/21279] Train loss: 0.73004,Valid loss: 1.11826, time : 12.07317590713501 lr : 0.9135172474836407\n",
      "epoch : 0 [4552/21279] Train loss: 0.43721,Valid loss: 0.90213, time : 12.552581548690796 lr : 0.9135172474836407\n",
      "epoch : 0 [4553/21279] Train loss: 0.39701,Valid loss: 0.48805, time : 12.367515325546265 lr : 0.9135172474836407\n",
      "epoch : 0 [4554/21279] Train loss: 0.32678,Valid loss: 0.50243, time : 12.359431982040405 lr : 0.9135172474836407\n",
      "epoch : 0 [4555/21279] Train loss: 0.33773,Valid loss: 1.33388, time : 12.301080465316772 lr : 0.9135172474836407\n",
      "epoch : 0 [4556/21279] Train loss: 0.47503,Valid loss: 1.31115, time : 12.222563743591309 lr : 0.9135172474836407\n",
      "epoch : 0 [4557/21279] Train loss: 0.49913,Valid loss: 0.69861, time : 12.153834581375122 lr : 0.9135172474836407\n",
      "epoch : 0 [4558/21279] Train loss: 0.53918,Valid loss: 0.93910, time : 12.028652429580688 lr : 0.9135172474836407\n",
      "epoch : 0 [4559/21279] Train loss: 0.52348,Valid loss: 0.68355, time : 12.446178197860718 lr : 0.9135172474836407\n",
      "epoch : 0 [4560/21279] Train loss: 0.40557,Valid loss: 0.53726, time : 12.160661935806274 lr : 0.9135172474836407\n",
      "epoch : 0 [4561/21279] Train loss: 0.36555,Valid loss: 0.49038, time : 14.028483390808105 lr : 0.9135172474836407\n",
      "epoch : 0 [4562/21279] Train loss: 0.34609,Valid loss: 0.55619, time : 11.889809131622314 lr : 0.9135172474836407\n",
      "epoch : 0 [4563/21279] Train loss: 0.34679,Valid loss: 0.46418, time : 12.44003415107727 lr : 0.9135172474836407\n",
      "epoch : 0 [4564/21279] Train loss: 0.32996,Valid loss: 0.47826, time : 12.55505919456482 lr : 0.9135172474836407\n",
      "epoch : 0 [4565/21279] Train loss: 0.32194,Valid loss: 0.47769, time : 12.551612138748169 lr : 0.9135172474836407\n",
      "epoch : 0 [4566/21279] Train loss: 0.32180,Valid loss: 0.46958, time : 12.64704418182373 lr : 0.9135172474836407\n",
      "epoch : 0 [4567/21279] Train loss: 0.33641,Valid loss: 0.44639, time : 12.65040373802185 lr : 0.9135172474836407\n",
      "epoch : 0 [4568/21279] Train loss: 0.33314,Valid loss: 0.43959, time : 12.633972406387329 lr : 0.9135172474836407\n",
      "epoch : 0 [4569/21279] Train loss: 0.32481,Valid loss: 0.44097, time : 12.597342014312744 lr : 0.9135172474836407\n",
      "epoch : 0 [4570/21279] Train loss: 0.31711,Valid loss: 0.46981, time : 12.518739700317383 lr : 0.9135172474836407\n",
      "epoch : 0 [4571/21279] Train loss: 0.35508,Valid loss: 0.45720, time : 12.449477910995483 lr : 0.9135172474836407\n",
      "epoch : 0 [4572/21279] Train loss: 0.32156,Valid loss: 0.44514, time : 12.213591575622559 lr : 0.9135172474836407\n",
      "epoch : 0 [4573/21279] Train loss: 0.31749,Valid loss: 0.57286, time : 12.599629878997803 lr : 0.9135172474836407\n",
      "epoch : 0 [4574/21279] Train loss: 0.30661,Valid loss: 0.43584, time : 12.4306058883667 lr : 0.9135172474836407\n",
      "epoch : 0 [4575/21279] Train loss: 0.32898,Valid loss: 0.43667, time : 12.001945972442627 lr : 0.9135172474836407\n",
      "epoch : 0 [4576/21279] Train loss: 0.31147,Valid loss: 0.43454, time : 14.039013624191284 lr : 0.9135172474836407\n",
      "epoch : 0 [4577/21279] Train loss: 0.32381,Valid loss: 0.42578, time : 11.641921043395996 lr : 0.9135172474836407\n",
      "epoch : 0 [4578/21279] Train loss: 0.31428,Valid loss: 0.42326, time : 12.224409818649292 lr : 0.9135172474836407\n",
      "epoch : 0 [4579/21279] Train loss: 0.29662,Valid loss: 0.44854, time : 12.43708324432373 lr : 0.9135172474836407\n",
      "epoch : 0 [4580/21279] Train loss: 0.31591,Valid loss: 0.43520, time : 12.334259510040283 lr : 0.9135172474836407\n",
      "epoch : 0 [4581/21279] Train loss: 0.30967,Valid loss: 0.44389, time : 12.579988241195679 lr : 0.9135172474836407\n",
      "epoch : 0 [4582/21279] Train loss: 0.29201,Valid loss: 0.44473, time : 11.894884586334229 lr : 0.9135172474836407\n",
      "epoch : 0 [4583/21279] Train loss: 0.31282,Valid loss: 0.43880, time : 12.731146097183228 lr : 0.9135172474836407\n",
      "epoch : 0 [4584/21279] Train loss: 0.30719,Valid loss: 0.43825, time : 12.681660413742065 lr : 0.9135172474836407\n",
      "epoch : 0 [4585/21279] Train loss: 0.29244,Valid loss: 0.43236, time : 12.177003145217896 lr : 0.9135172474836407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [4586/21279] Train loss: 0.31336,Valid loss: 0.43619, time : 12.099249601364136 lr : 0.9135172474836407\n",
      "epoch : 0 [4587/21279] Train loss: 0.30870,Valid loss: 0.42245, time : 12.341465473175049 lr : 0.9135172474836407\n",
      "epoch : 0 [4588/21279] Train loss: 0.30988,Valid loss: 0.44546, time : 14.727178573608398 lr : 0.9135172474836407\n",
      "epoch : 0 [4589/21279] Train loss: 0.31090,Valid loss: 0.41015, time : 12.57773470878601 lr : 0.9135172474836407\n",
      "epoch : 0 [4590/21279] Train loss: 0.31019,Valid loss: 0.43505, time : 12.297872066497803 lr : 0.9135172474836407\n",
      "epoch : 0 [4591/21279] Train loss: 0.31028,Valid loss: 0.42125, time : 12.137362480163574 lr : 0.9135172474836407\n",
      "epoch : 0 [4592/21279] Train loss: 0.30807,Valid loss: 0.43888, time : 12.570972204208374 lr : 0.9135172474836407\n",
      "epoch : 0 [4593/21279] Train loss: 0.29866,Valid loss: 0.41136, time : 12.276866436004639 lr : 0.9135172474836407\n",
      "epoch : 0 [4594/21279] Train loss: 0.29058,Valid loss: 0.43637, time : 12.635673761367798 lr : 0.9135172474836407\n",
      "epoch : 0 [4595/21279] Train loss: 0.29030,Valid loss: 0.44414, time : 12.224451303482056 lr : 0.9135172474836407\n",
      "epoch : 0 [4596/21279] Train loss: 0.29006,Valid loss: 0.41448, time : 11.994620561599731 lr : 0.9135172474836407\n",
      "epoch : 0 [4597/21279] Train loss: 0.30615,Valid loss: 0.42425, time : 11.99841594696045 lr : 0.9135172474836407\n",
      "epoch : 0 [4598/21279] Train loss: 0.30135,Valid loss: 0.43838, time : 12.165791034698486 lr : 0.9135172474836407\n",
      "epoch : 0 [4599/21279] Train loss: 0.29886,Valid loss: 0.49661, time : 12.721560001373291 lr : 0.9135172474836407\n",
      "epoch : 0 [4600/21279] Train loss: 0.35959,Valid loss: 0.47075, time : 12.50456690788269 lr : 0.9135172474836407\n",
      "epoch : 0 [4601/21279] Train loss: 0.30759,Valid loss: 0.44357, time : 12.66194224357605 lr : 0.9135172474836407\n",
      "epoch : 0 [4602/21279] Train loss: 0.29832,Valid loss: 0.40833, time : 17.137650966644287 lr : 0.9135172474836407\n",
      "epoch : 0 [4603/21279] Train loss: 0.29601,Valid loss: 0.42660, time : 12.45546579360962 lr : 0.9135172474836407\n",
      "epoch : 0 [4604/21279] Train loss: 0.31171,Valid loss: 0.41720, time : 12.479520797729492 lr : 0.9135172474836407\n",
      "epoch : 0 [4605/21279] Train loss: 0.30513,Valid loss: 0.43702, time : 12.546543836593628 lr : 0.9135172474836407\n",
      "epoch : 0 [4606/21279] Train loss: 0.29834,Valid loss: 0.42659, time : 12.393354415893555 lr : 0.9135172474836407\n",
      "epoch : 0 [4607/21279] Train loss: 0.30335,Valid loss: 0.45495, time : 12.764139652252197 lr : 0.9135172474836407\n",
      "epoch : 0 [4608/21279] Train loss: 0.29963,Valid loss: 0.43074, time : 11.99885082244873 lr : 0.9135172474836407\n",
      "epoch : 0 [4609/21279] Train loss: 0.30798,Valid loss: 0.42813, time : 11.653508186340332 lr : 0.9135172474836407\n",
      "epoch : 0 [4610/21279] Train loss: 0.30584,Valid loss: 0.42598, time : 12.324926376342773 lr : 0.9135172474836407\n",
      "epoch : 0 [4611/21279] Train loss: 0.30642,Valid loss: 0.42054, time : 12.108695030212402 lr : 0.9135172474836407\n",
      "epoch : 0 [4612/21279] Train loss: 0.29566,Valid loss: 0.41992, time : 12.602527141571045 lr : 0.9135172474836407\n",
      "epoch : 0 [4613/21279] Train loss: 0.29602,Valid loss: 0.43290, time : 13.192009925842285 lr : 0.9135172474836407\n",
      "epoch : 0 [4614/21279] Train loss: 0.31288,Valid loss: 0.72658, time : 14.597251892089844 lr : 0.9135172474836407\n",
      "epoch : 0 [4615/21279] Train loss: 0.30639,Valid loss: 0.42242, time : 12.512116432189941 lr : 0.9135172474836407\n",
      "epoch : 0 [4616/21279] Train loss: 0.29920,Valid loss: 0.44296, time : 11.916313886642456 lr : 0.9135172474836407\n",
      "epoch : 0 [4617/21279] Train loss: 0.29010,Valid loss: 0.68231, time : 12.017137289047241 lr : 0.9135172474836407\n",
      "epoch : 0 [4618/21279] Train loss: 0.32802,Valid loss: 0.63660, time : 12.55342984199524 lr : 0.9135172474836407\n",
      "epoch : 0 [4619/21279] Train loss: 0.30847,Valid loss: 0.43109, time : 12.770344495773315 lr : 0.9135172474836407\n",
      "epoch : 0 [4620/21279] Train loss: 0.30223,Valid loss: 0.45807, time : 11.979195833206177 lr : 0.9135172474836407\n",
      "epoch : 0 [4621/21279] Train loss: 0.31433,Valid loss: 0.57264, time : 12.431622505187988 lr : 0.9135172474836407\n",
      "epoch : 0 [4622/21279] Train loss: 0.30290,Valid loss: 0.59144, time : 11.851680278778076 lr : 0.9135172474836407\n",
      "epoch : 0 [4623/21279] Train loss: 0.30549,Valid loss: 0.79180, time : 11.935717105865479 lr : 0.9135172474836407\n",
      "epoch : 0 [4624/21279] Train loss: 0.31494,Valid loss: 0.40433, time : 12.56798529624939 lr : 0.9135172474836407\n",
      "epoch : 0 [4625/21279] Train loss: 0.32353,Valid loss: 0.42577, time : 12.371716737747192 lr : 0.9135172474836407\n",
      "epoch : 0 [4626/21279] Train loss: 0.30129,Valid loss: 0.42489, time : 12.187698125839233 lr : 0.9135172474836407\n",
      "epoch : 0 [4627/21279] Train loss: 0.33048,Valid loss: 0.45999, time : 12.448711395263672 lr : 0.9135172474836407\n",
      "epoch : 0 [4628/21279] Train loss: 0.31846,Valid loss: 0.45339, time : 12.662556171417236 lr : 0.9135172474836407\n",
      "epoch : 0 [4629/21279] Train loss: 0.32091,Valid loss: 0.42096, time : 13.294952392578125 lr : 0.9135172474836407\n",
      "epoch : 0 [4630/21279] Train loss: 0.32390,Valid loss: 0.44416, time : 14.898561954498291 lr : 0.9135172474836407\n",
      "epoch : 0 [4631/21279] Train loss: 0.30222,Valid loss: 0.41932, time : 12.568279027938843 lr : 0.9135172474836407\n",
      "epoch : 0 [4632/21279] Train loss: 0.30419,Valid loss: 0.40593, time : 12.772871255874634 lr : 0.9135172474836407\n",
      "epoch : 0 [4633/21279] Train loss: 0.29736,Valid loss: 0.41431, time : 12.202590942382812 lr : 0.9135172474836407\n",
      "epoch : 0 [4634/21279] Train loss: 0.31351,Valid loss: 0.41338, time : 12.746354818344116 lr : 0.9135172474836407\n",
      "epoch : 0 [4635/21279] Train loss: 0.32004,Valid loss: 0.43442, time : 12.5110764503479 lr : 0.9135172474836407\n",
      "epoch : 0 [4636/21279] Train loss: 0.30687,Valid loss: 0.67607, time : 12.431570053100586 lr : 0.9135172474836407\n",
      "epoch : 0 [4637/21279] Train loss: 0.32595,Valid loss: 0.41658, time : 11.999800443649292 lr : 0.9135172474836407\n",
      "epoch : 0 [4638/21279] Train loss: 0.30771,Valid loss: 0.46718, time : 12.375731229782104 lr : 0.9135172474836407\n",
      "epoch : 0 [4639/21279] Train loss: 0.34791,Valid loss: 0.90365, time : 12.474189043045044 lr : 0.9135172474836407\n",
      "epoch : 0 [4640/21279] Train loss: 0.31320,Valid loss: 0.42402, time : 12.548832893371582 lr : 0.9135172474836407\n",
      "epoch : 0 [4641/21279] Train loss: 0.28287,Valid loss: 0.41614, time : 11.886945247650146 lr : 0.9135172474836407\n",
      "epoch : 0 [4642/21279] Train loss: 0.29280,Valid loss: 0.41228, time : 14.898133516311646 lr : 0.9135172474836407\n",
      "epoch : 0 [4643/21279] Train loss: 0.28483,Valid loss: 0.40306, time : 12.420879602432251 lr : 0.9135172474836407\n",
      "epoch : 0 [4644/21279] Train loss: 0.31842,Valid loss: 0.46717, time : 12.915636539459229 lr : 0.9135172474836407\n",
      "epoch : 0 [4645/21279] Train loss: 0.30977,Valid loss: 0.40841, time : 12.517183065414429 lr : 0.9135172474836407\n",
      "epoch : 0 [4646/21279] Train loss: 0.29190,Valid loss: 0.46125, time : 12.087906122207642 lr : 0.9135172474836407\n",
      "epoch : 0 [4647/21279] Train loss: 0.31589,Valid loss: 0.43038, time : 11.15375280380249 lr : 0.9135172474836407\n",
      "epoch : 0 [4648/21279] Train loss: 0.33550,Valid loss: 0.44537, time : 11.399609327316284 lr : 0.9135172474836407\n",
      "epoch : 0 [4649/21279] Train loss: 0.30279,Valid loss: 0.43174, time : 11.568301916122437 lr : 0.9135172474836407\n",
      "epoch : 0 [4650/21279] Train loss: 0.30705,Valid loss: 0.71934, time : 11.985061883926392 lr : 0.9135172474836407\n",
      "epoch : 0 [4651/21279] Train loss: 0.30840,Valid loss: 0.43714, time : 11.229865789413452 lr : 0.9135172474836407\n",
      "epoch : 0 [4652/21279] Train loss: 0.31586,Valid loss: 0.43238, time : 11.238479614257812 lr : 0.9135172474836407\n",
      "epoch : 0 [4653/21279] Train loss: 0.30844,Valid loss: 0.55647, time : 11.119205713272095 lr : 0.9135172474836407\n",
      "epoch : 0 [4654/21279] Train loss: 0.30261,Valid loss: 0.42911, time : 11.27823281288147 lr : 0.9135172474836407\n",
      "epoch : 0 [4655/21279] Train loss: 0.29202,Valid loss: 0.45208, time : 11.842598676681519 lr : 0.9135172474836407\n",
      "epoch : 0 [4656/21279] Train loss: 0.32309,Valid loss: 0.43697, time : 12.520771503448486 lr : 0.9135172474836407\n",
      "epoch : 0 [4657/21279] Train loss: 0.29240,Valid loss: 0.46269, time : 12.282147407531738 lr : 0.9135172474836407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [4658/21279] Train loss: 0.30057,Valid loss: 0.43472, time : 16.514805555343628 lr : 0.9135172474836407\n",
      "epoch : 0 [4659/21279] Train loss: 0.30898,Valid loss: 0.41536, time : 12.350493431091309 lr : 0.9135172474836407\n",
      "epoch : 0 [4660/21279] Train loss: 0.30375,Valid loss: 0.41072, time : 12.574106216430664 lr : 0.9135172474836407\n",
      "epoch : 0 [4661/21279] Train loss: 0.28734,Valid loss: 0.44582, time : 12.242886066436768 lr : 0.9135172474836407\n",
      "epoch : 0 [4662/21279] Train loss: 0.30703,Valid loss: 0.42922, time : 12.603748798370361 lr : 0.9135172474836407\n",
      "epoch : 0 [4663/21279] Train loss: 0.29602,Valid loss: 0.40906, time : 12.530096769332886 lr : 0.9135172474836407\n",
      "epoch : 0 [4664/21279] Train loss: 0.32379,Valid loss: 0.44156, time : 12.537536382675171 lr : 0.9135172474836407\n",
      "epoch : 0 [4665/21279] Train loss: 0.28566,Valid loss: 0.67335, time : 12.892012119293213 lr : 0.9135172474836407\n",
      "epoch : 0 [4666/21279] Train loss: 0.28535,Valid loss: 0.45786, time : 12.614039897918701 lr : 0.9135172474836407\n",
      "epoch : 0 [4667/21279] Train loss: 0.30060,Valid loss: 0.42599, time : 12.87184453010559 lr : 0.9135172474836407\n",
      "epoch : 0 [4668/21279] Train loss: 0.28435,Valid loss: 0.44002, time : 12.605074167251587 lr : 0.9135172474836407\n",
      "epoch : 0 [4669/21279] Train loss: 0.31222,Valid loss: 0.42607, time : 12.71577262878418 lr : 0.9135172474836407\n",
      "epoch : 0 [4670/21279] Train loss: 0.28926,Valid loss: 0.44746, time : 12.8709557056427 lr : 0.9135172474836407\n",
      "epoch : 0 [4671/21279] Train loss: 0.29518,Valid loss: 0.42131, time : 14.690778970718384 lr : 0.9135172474836407\n",
      "epoch : 0 [4672/21279] Train loss: 0.29077,Valid loss: 0.60857, time : 12.930827617645264 lr : 0.9135172474836407\n",
      "epoch : 0 [4673/21279] Train loss: 0.30666,Valid loss: 0.41649, time : 12.709933280944824 lr : 0.9135172474836407\n",
      "epoch : 0 [4674/21279] Train loss: 0.30687,Valid loss: 0.43881, time : 12.752516269683838 lr : 0.9135172474836407\n",
      "epoch : 0 [4675/21279] Train loss: 0.29710,Valid loss: 0.41074, time : 12.625010967254639 lr : 0.9135172474836407\n",
      "epoch : 0 [4676/21279] Train loss: 0.32256,Valid loss: 0.46167, time : 12.518357515335083 lr : 0.9135172474836407\n",
      "epoch : 0 [4677/21279] Train loss: 0.31030,Valid loss: 0.42841, time : 12.614400863647461 lr : 0.9135172474836407\n",
      "epoch : 0 [4678/21279] Train loss: 0.29700,Valid loss: 0.44496, time : 11.682265520095825 lr : 0.9135172474836407\n",
      "epoch : 0 [4679/21279] Train loss: 0.30671,Valid loss: 0.43448, time : 11.862132787704468 lr : 0.9135172474836407\n",
      "epoch : 0 [4680/21279] Train loss: 0.31819,Valid loss: 0.42366, time : 11.75887942314148 lr : 0.9135172474836407\n",
      "epoch : 0 [4681/21279] Train loss: 0.29941,Valid loss: 0.42207, time : 11.723939657211304 lr : 0.9135172474836407\n",
      "epoch : 0 [4682/21279] Train loss: 0.29826,Valid loss: 0.53311, time : 11.556027889251709 lr : 0.9135172474836407\n",
      "epoch : 0 [4683/21279] Train loss: 0.29448,Valid loss: 0.40471, time : 12.15094780921936 lr : 0.9135172474836407\n",
      "epoch : 0 [4684/21279] Train loss: 0.27853,Valid loss: 0.46005, time : 12.057128190994263 lr : 0.9135172474836407\n",
      "epoch : 0 [4685/21279] Train loss: 0.29817,Valid loss: 0.42003, time : 12.283706665039062 lr : 0.9135172474836407\n",
      "epoch : 0 [4686/21279] Train loss: 0.30712,Valid loss: 0.41398, time : 14.991835594177246 lr : 0.9135172474836407\n",
      "epoch : 0 [4687/21279] Train loss: 0.28995,Valid loss: 0.55233, time : 12.791609764099121 lr : 0.9135172474836407\n",
      "epoch : 0 [4688/21279] Train loss: 0.29272,Valid loss: 0.40483, time : 12.593502759933472 lr : 0.9135172474836407\n",
      "epoch : 0 [4689/21279] Train loss: 0.29420,Valid loss: 0.42340, time : 13.147398948669434 lr : 0.9135172474836407\n",
      "epoch : 0 [4690/21279] Train loss: 0.28700,Valid loss: 0.43558, time : 12.54774284362793 lr : 0.9135172474836407\n",
      "epoch : 0 [4691/21279] Train loss: 0.30977,Valid loss: 0.45648, time : 13.130090475082397 lr : 0.9135172474836407\n",
      "epoch : 0 [4692/21279] Train loss: 0.30173,Valid loss: 0.46347, time : 12.866762161254883 lr : 0.9135172474836407\n",
      "epoch : 0 [4693/21279] Train loss: 0.31823,Valid loss: 0.43049, time : 13.113112211227417 lr : 0.9135172474836407\n",
      "epoch : 0 [4694/21279] Train loss: 0.29431,Valid loss: 0.50422, time : 12.180951356887817 lr : 0.9135172474836407\n",
      "epoch : 0 [4695/21279] Train loss: 0.31189,Valid loss: 0.39809, time : 12.176864862442017 lr : 0.9135172474836407\n",
      "epoch : 0 [4696/21279] Train loss: 0.31012,Valid loss: 0.45830, time : 12.393560647964478 lr : 0.9135172474836407\n",
      "epoch : 0 [4697/21279] Train loss: 0.31409,Valid loss: 0.41871, time : 12.592602014541626 lr : 0.9135172474836407\n",
      "epoch : 0 [4698/21279] Train loss: 0.29200,Valid loss: 0.42163, time : 13.696199178695679 lr : 0.9135172474836407\n",
      "epoch : 0 [4699/21279] Train loss: 0.29590,Valid loss: 0.39343, time : 12.371694564819336 lr : 0.9135172474836407\n",
      "epoch : 0 [4700/21279] Train loss: 0.28646,Valid loss: 0.62091, time : 12.421663522720337 lr : 0.9135172474836407\n",
      "epoch : 0 [4701/21279] Train loss: 0.31577,Valid loss: 0.41449, time : 12.634716272354126 lr : 0.9135172474836407\n",
      "epoch : 0 [4702/21279] Train loss: 0.29227,Valid loss: 0.40827, time : 12.357023477554321 lr : 0.9135172474836407\n",
      "epoch : 0 [4703/21279] Train loss: 0.29055,Valid loss: 0.42053, time : 12.3619863986969 lr : 0.9135172474836407\n",
      "epoch : 0 [4704/21279] Train loss: 0.29215,Valid loss: 0.43555, time : 12.307555437088013 lr : 0.9135172474836407\n",
      "epoch : 0 [4705/21279] Train loss: 0.28777,Valid loss: 0.38574, time : 12.666838884353638 lr : 0.9135172474836407\n",
      "epoch : 0 [4706/21279] Train loss: 0.29762,Valid loss: 0.42842, time : 12.773186683654785 lr : 0.9135172474836407\n",
      "epoch : 0 [4707/21279] Train loss: 0.28901,Valid loss: 0.41122, time : 12.908645391464233 lr : 0.9135172474836407\n",
      "epoch : 0 [4708/21279] Train loss: 0.29645,Valid loss: 0.40688, time : 12.498882293701172 lr : 0.9135172474836407\n",
      "epoch : 0 [4709/21279] Train loss: 0.28951,Valid loss: 0.45189, time : 12.715282917022705 lr : 0.9135172474836407\n",
      "epoch : 0 [4710/21279] Train loss: 0.29167,Valid loss: 0.40205, time : 12.633080005645752 lr : 0.9135172474836407\n",
      "epoch : 0 [4711/21279] Train loss: 0.29179,Valid loss: 0.42751, time : 12.81713056564331 lr : 0.9135172474836407\n",
      "epoch : 0 [4712/21279] Train loss: 0.28029,Valid loss: 0.41973, time : 13.613651990890503 lr : 0.9135172474836407\n",
      "epoch : 0 [4713/21279] Train loss: 0.32042,Valid loss: 0.66149, time : 12.562180757522583 lr : 0.9135172474836407\n",
      "epoch : 0 [4714/21279] Train loss: 0.31994,Valid loss: 0.53204, time : 12.911396741867065 lr : 0.9135172474836407\n",
      "epoch : 0 [4715/21279] Train loss: 0.30773,Valid loss: 0.42415, time : 12.343747615814209 lr : 0.9135172474836407\n",
      "epoch : 0 [4716/21279] Train loss: 0.29381,Valid loss: 0.61326, time : 12.895836353302002 lr : 0.9135172474836407\n",
      "epoch : 0 [4717/21279] Train loss: 0.28095,Valid loss: 0.42281, time : 12.135752201080322 lr : 0.9135172474836407\n",
      "epoch : 0 [4718/21279] Train loss: 0.30421,Valid loss: 0.44842, time : 12.744446039199829 lr : 0.9135172474836407\n",
      "epoch : 0 [4719/21279] Train loss: 0.30391,Valid loss: 0.42232, time : 12.79117465019226 lr : 0.9135172474836407\n",
      "epoch : 0 [4720/21279] Train loss: 0.28865,Valid loss: 0.38346, time : 12.903738021850586 lr : 0.9135172474836407\n",
      "epoch : 0 [4721/21279] Train loss: 0.30810,Valid loss: 0.44106, time : 12.009807109832764 lr : 0.9135172474836407\n",
      "epoch : 0 [4722/21279] Train loss: 0.28171,Valid loss: 0.41177, time : 12.559277296066284 lr : 0.9135172474836407\n",
      "epoch : 0 [4723/21279] Train loss: 0.29575,Valid loss: 0.39448, time : 12.425763607025146 lr : 0.9135172474836407\n",
      "epoch : 0 [4724/21279] Train loss: 0.28575,Valid loss: 0.39731, time : 17.088798999786377 lr : 0.9135172474836407\n",
      "epoch : 0 [4725/21279] Train loss: 0.30896,Valid loss: 0.46444, time : 12.95829176902771 lr : 0.9135172474836407\n",
      "epoch : 0 [4726/21279] Train loss: 0.30911,Valid loss: 0.44138, time : 12.332117557525635 lr : 0.9135172474836407\n",
      "epoch : 0 [4727/21279] Train loss: 0.30282,Valid loss: 0.48985, time : 12.07854700088501 lr : 0.9135172474836407\n",
      "epoch : 0 [4728/21279] Train loss: 0.32262,Valid loss: 0.91479, time : 12.4001944065094 lr : 0.9135172474836407\n",
      "epoch : 0 [4729/21279] Train loss: 0.74471,Valid loss: 1.50015, time : 12.811464309692383 lr : 0.9135172474836407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [4730/21279] Train loss: 1.03789,Valid loss: 2.44868, time : 12.152060508728027 lr : 0.9135172474836407\n",
      "epoch : 0 [4731/21279] Train loss: 0.58494,Valid loss: 0.96175, time : 12.69749402999878 lr : 0.9135172474836407\n",
      "epoch : 0 [4732/21279] Train loss: 0.51447,Valid loss: 1.28423, time : 12.268080711364746 lr : 0.9135172474836407\n",
      "epoch : 0 [4733/21279] Train loss: 0.52522,Valid loss: 2.06048, time : 12.004526376724243 lr : 0.9135172474836407\n",
      "epoch : 0 [4734/21279] Train loss: 1.00594,Valid loss: 2.97503, time : 12.450256824493408 lr : 0.9135172474836407\n",
      "epoch : 0 [4735/21279] Train loss: 0.72229,Valid loss: 1.18758, time : 12.081337928771973 lr : 0.9135172474836407\n",
      "epoch : 0 [4736/21279] Train loss: 0.44114,Valid loss: 0.57405, time : 12.47498869895935 lr : 0.9135172474836407\n",
      "epoch : 0 [4737/21279] Train loss: 0.34968,Valid loss: 1.11414, time : 12.2597177028656 lr : 0.9135172474836407\n",
      "epoch : 0 [4738/21279] Train loss: 0.47114,Valid loss: 0.72405, time : 12.556892156600952 lr : 0.9135172474836407\n",
      "epoch : 0 [4739/21279] Train loss: 0.40846,Valid loss: 0.82788, time : 12.527750015258789 lr : 0.9135172474836407\n",
      "epoch : 0 [4740/21279] Train loss: 0.48174,Valid loss: 0.97862, time : 14.066446781158447 lr : 0.9135172474836407\n",
      "epoch : 0 [4741/21279] Train loss: 0.39667,Valid loss: 0.68173, time : 13.124266624450684 lr : 0.9135172474836407\n",
      "epoch : 0 [4742/21279] Train loss: 0.35511,Valid loss: 0.54084, time : 13.15854549407959 lr : 0.9135172474836407\n",
      "epoch : 0 [4743/21279] Train loss: 0.34022,Valid loss: 0.49510, time : 13.18468189239502 lr : 0.9135172474836407\n",
      "epoch : 0 [4744/21279] Train loss: 0.32503,Valid loss: 0.41166, time : 13.140113353729248 lr : 0.9135172474836407\n",
      "epoch : 0 [4745/21279] Train loss: 0.31134,Valid loss: 0.47270, time : 13.10531497001648 lr : 0.9135172474836407\n",
      "epoch : 0 [4746/21279] Train loss: 0.30231,Valid loss: 0.42787, time : 12.979049921035767 lr : 0.9135172474836407\n",
      "epoch : 0 [4747/21279] Train loss: 0.31850,Valid loss: 0.44452, time : 13.268825054168701 lr : 0.9135172474836407\n",
      "epoch : 0 [4748/21279] Train loss: 0.29796,Valid loss: 0.38380, time : 13.082592964172363 lr : 0.9135172474836407\n",
      "epoch : 0 [4749/21279] Train loss: 0.31189,Valid loss: 0.41961, time : 13.342927932739258 lr : 0.9135172474836407\n",
      "epoch : 0 [4750/21279] Train loss: 0.31382,Valid loss: 0.52208, time : 13.22207498550415 lr : 0.9135172474836407\n",
      "epoch : 0 [4751/21279] Train loss: 0.28669,Valid loss: 0.42502, time : 12.991374969482422 lr : 0.9135172474836407\n",
      "epoch : 0 [4752/21279] Train loss: 0.29383,Valid loss: 0.54266, time : 14.663553714752197 lr : 0.9135172474836407\n",
      "epoch : 0 [4753/21279] Train loss: 0.29284,Valid loss: 0.56789, time : 13.326362371444702 lr : 0.9135172474836407\n",
      "epoch : 0 [4754/21279] Train loss: 0.30192,Valid loss: 0.41223, time : 13.04602313041687 lr : 0.9135172474836407\n",
      "epoch : 0 [4755/21279] Train loss: 0.27004,Valid loss: 0.38166, time : 12.792220115661621 lr : 0.9135172474836407\n",
      "epoch : 0 [4756/21279] Train loss: 0.29515,Valid loss: 0.37958, time : 12.625926733016968 lr : 0.9135172474836407\n",
      "epoch : 0 [4757/21279] Train loss: 0.27662,Valid loss: 0.39716, time : 12.550960779190063 lr : 0.9135172474836407\n",
      "epoch : 0 [4758/21279] Train loss: 0.29676,Valid loss: 0.41632, time : 12.780531167984009 lr : 0.9135172474836407\n",
      "epoch : 0 [4759/21279] Train loss: 0.28900,Valid loss: 0.37690, time : 12.999758005142212 lr : 0.9135172474836407\n",
      "epoch : 0 [4760/21279] Train loss: 0.29882,Valid loss: 0.41011, time : 13.378835678100586 lr : 0.9135172474836407\n",
      "epoch : 0 [4761/21279] Train loss: 0.31190,Valid loss: 0.55319, time : 13.026477813720703 lr : 0.9135172474836407\n",
      "epoch : 0 [4762/21279] Train loss: 0.28382,Valid loss: 0.58204, time : 12.884863138198853 lr : 0.9135172474836407\n",
      "epoch : 0 [4763/21279] Train loss: 0.28795,Valid loss: 0.38393, time : 12.450323820114136 lr : 0.9135172474836407\n",
      "epoch : 0 [4764/21279] Train loss: 0.29767,Valid loss: 0.37890, time : 12.750304222106934 lr : 0.9135172474836407\n",
      "epoch : 0 [4765/21279] Train loss: 0.29452,Valid loss: 0.42305, time : 12.762154579162598 lr : 0.9135172474836407\n",
      "epoch : 0 [4766/21279] Train loss: 0.30591,Valid loss: 0.37651, time : 12.389601230621338 lr : 0.9135172474836407\n",
      "epoch : 0 [4767/21279] Train loss: 0.28452,Valid loss: 0.39845, time : 12.722906351089478 lr : 0.9135172474836407\n",
      "epoch : 0 [4768/21279] Train loss: 0.30303,Valid loss: 0.43552, time : 14.172049045562744 lr : 0.9135172474836407\n",
      "epoch : 0 [4769/21279] Train loss: 0.29701,Valid loss: 0.49096, time : 12.480111360549927 lr : 0.9135172474836407\n",
      "epoch : 0 [4770/21279] Train loss: 0.28879,Valid loss: 0.58764, time : 12.471293210983276 lr : 0.9135172474836407\n",
      "epoch : 0 [4771/21279] Train loss: 0.32206,Valid loss: 0.42538, time : 12.675041675567627 lr : 0.9135172474836407\n",
      "epoch : 0 [4772/21279] Train loss: 0.28598,Valid loss: 0.40395, time : 12.484984874725342 lr : 0.9135172474836407\n",
      "epoch : 0 [4773/21279] Train loss: 0.28635,Valid loss: 0.36625, time : 12.947320938110352 lr : 0.9135172474836407\n",
      "epoch : 0 [4774/21279] Train loss: 0.29952,Valid loss: 0.40473, time : 12.775805950164795 lr : 0.9135172474836407\n",
      "epoch : 0 [4775/21279] Train loss: 0.29012,Valid loss: 0.40658, time : 12.858466863632202 lr : 0.9135172474836407\n",
      "epoch : 0 [4776/21279] Train loss: 0.30017,Valid loss: 0.41150, time : 12.957127809524536 lr : 0.9135172474836407\n",
      "epoch : 0 [4777/21279] Train loss: 0.28634,Valid loss: 0.40942, time : 13.087784767150879 lr : 0.9135172474836407\n",
      "epoch : 0 [4778/21279] Train loss: 0.29764,Valid loss: 0.39917, time : 12.943896055221558 lr : 0.9135172474836407\n",
      "epoch : 0 [4779/21279] Train loss: 0.28181,Valid loss: 0.38324, time : 12.935289859771729 lr : 0.9135172474836407\n",
      "epoch : 0 [4780/21279] Train loss: 0.28129,Valid loss: 0.41217, time : 12.734180688858032 lr : 0.9135172474836407\n",
      "epoch : 0 [4781/21279] Train loss: 0.28095,Valid loss: 0.38421, time : 15.091636896133423 lr : 0.9135172474836407\n",
      "epoch : 0 [4782/21279] Train loss: 0.26764,Valid loss: 0.55176, time : 12.583735942840576 lr : 0.9135172474836407\n",
      "epoch : 0 [4783/21279] Train loss: 0.28605,Valid loss: 0.65548, time : 12.733943700790405 lr : 0.9135172474836407\n",
      "epoch : 0 [4784/21279] Train loss: 0.28928,Valid loss: 0.63066, time : 12.784034013748169 lr : 0.9135172474836407\n",
      "epoch : 0 [4785/21279] Train loss: 0.29213,Valid loss: 0.38442, time : 12.403089046478271 lr : 0.9135172474836407\n",
      "epoch : 0 [4786/21279] Train loss: 0.28608,Valid loss: 0.38633, time : 12.480998754501343 lr : 0.9135172474836407\n",
      "epoch : 0 [4787/21279] Train loss: 0.28642,Valid loss: 0.40839, time : 12.5077383518219 lr : 0.9135172474836407\n",
      "epoch : 0 [4788/21279] Train loss: 0.27981,Valid loss: 0.37427, time : 12.63119912147522 lr : 0.9135172474836407\n",
      "epoch : 0 [4789/21279] Train loss: 0.28966,Valid loss: 0.39302, time : 12.754716873168945 lr : 0.9135172474836407\n",
      "epoch : 0 [4790/21279] Train loss: 0.30354,Valid loss: 0.36507, time : 12.24331521987915 lr : 0.9135172474836407\n",
      "epoch : 0 [4791/21279] Train loss: 0.28353,Valid loss: 0.37174, time : 12.429973840713501 lr : 0.9135172474836407\n",
      "epoch : 0 [4792/21279] Train loss: 0.28649,Valid loss: 0.37524, time : 12.714895248413086 lr : 0.9135172474836407\n",
      "epoch : 0 [4793/21279] Train loss: 0.28532,Valid loss: 0.37987, time : 12.722535848617554 lr : 0.9135172474836407\n",
      "epoch : 0 [4794/21279] Train loss: 0.29361,Valid loss: 0.57700, time : 12.377386808395386 lr : 0.9135172474836407\n",
      "epoch : 0 [4795/21279] Train loss: 0.26584,Valid loss: 0.37969, time : 12.453302145004272 lr : 0.9135172474836407\n",
      "epoch : 0 [4796/21279] Train loss: 0.27300,Valid loss: 0.68579, time : 13.464869022369385 lr : 0.9135172474836407\n",
      "epoch : 0 [4797/21279] Train loss: 0.28118,Valid loss: 0.36806, time : 12.085591554641724 lr : 0.9135172474836407\n",
      "epoch : 0 [4798/21279] Train loss: 0.27069,Valid loss: 0.40708, time : 12.821352243423462 lr : 0.9135172474836407\n",
      "epoch : 0 [4799/21279] Train loss: 0.27630,Valid loss: 0.35930, time : 12.692974090576172 lr : 0.9135172474836407\n",
      "epoch : 0 [4800/21279] Train loss: 0.27832,Valid loss: 0.50540, time : 12.305055618286133 lr : 0.9135172474836407\n",
      "epoch : 0 [4801/21279] Train loss: 0.28372,Valid loss: 0.39958, time : 11.723053216934204 lr : 0.9135172474836407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [4802/21279] Train loss: 0.27068,Valid loss: 0.41965, time : 12.19822883605957 lr : 0.9135172474836407\n",
      "epoch : 0 [4803/21279] Train loss: 0.28531,Valid loss: 0.78771, time : 12.235310554504395 lr : 0.9135172474836407\n",
      "epoch : 0 [4804/21279] Train loss: 0.28338,Valid loss: 0.63800, time : 12.325988531112671 lr : 0.9135172474836407\n",
      "epoch : 0 [4805/21279] Train loss: 0.30091,Valid loss: 0.53130, time : 12.32691478729248 lr : 0.9135172474836407\n",
      "epoch : 0 [4806/21279] Train loss: 0.28507,Valid loss: 0.86162, time : 12.506841897964478 lr : 0.9135172474836407\n",
      "epoch : 0 [4807/21279] Train loss: 0.30247,Valid loss: 0.63336, time : 12.106737613677979 lr : 0.9135172474836407\n",
      "epoch : 0 [4808/21279] Train loss: 0.29978,Valid loss: 0.38244, time : 14.037492036819458 lr : 0.9135172474836407\n",
      "epoch : 0 [4809/21279] Train loss: 0.28632,Valid loss: 0.38622, time : 12.436872959136963 lr : 0.9135172474836407\n",
      "epoch : 0 [4810/21279] Train loss: 0.27644,Valid loss: 0.39145, time : 11.784549236297607 lr : 0.9135172474836407\n",
      "epoch : 0 [4811/21279] Train loss: 0.28408,Valid loss: 0.41248, time : 12.052817821502686 lr : 0.9135172474836407\n",
      "epoch : 0 [4812/21279] Train loss: 0.27692,Valid loss: 0.60350, time : 11.721762657165527 lr : 0.9135172474836407\n",
      "epoch : 0 [4813/21279] Train loss: 0.28303,Valid loss: 0.71094, time : 12.065109014511108 lr : 0.9135172474836407\n",
      "epoch : 0 [4814/21279] Train loss: 0.27931,Valid loss: 0.60345, time : 12.306997299194336 lr : 0.9135172474836407\n",
      "epoch : 0 [4815/21279] Train loss: 0.28978,Valid loss: 0.40582, time : 11.782936573028564 lr : 0.9135172474836407\n",
      "epoch : 0 [4816/21279] Train loss: 0.28506,Valid loss: 0.70299, time : 12.168179035186768 lr : 0.9135172474836407\n",
      "epoch : 0 [4817/21279] Train loss: 0.28711,Valid loss: 0.39513, time : 12.158772230148315 lr : 0.9135172474836407\n",
      "epoch : 0 [4818/21279] Train loss: 0.28920,Valid loss: 0.37863, time : 12.272698879241943 lr : 0.9135172474836407\n",
      "epoch : 0 [4819/21279] Train loss: 0.28873,Valid loss: 0.39905, time : 12.589149475097656 lr : 0.9135172474836407\n",
      "epoch : 0 [4820/21279] Train loss: 0.27620,Valid loss: 0.38653, time : 12.526575326919556 lr : 0.9135172474836407\n",
      "epoch : 0 [4821/21279] Train loss: 0.28857,Valid loss: 0.40403, time : 12.965117931365967 lr : 0.9135172474836407\n",
      "epoch : 0 [4822/21279] Train loss: 0.28936,Valid loss: 0.38285, time : 22.709998846054077 lr : 0.9135172474836407\n",
      "epoch : 0 [4823/21279] Train loss: 0.27998,Valid loss: 0.39240, time : 11.924750804901123 lr : 0.9135172474836407\n",
      "epoch : 0 [4824/21279] Train loss: 0.27191,Valid loss: 0.37521, time : 12.385843753814697 lr : 0.9135172474836407\n",
      "epoch : 0 [4825/21279] Train loss: 0.28267,Valid loss: 1.51188, time : 12.58022427558899 lr : 0.9135172474836407\n",
      "epoch : 0 [4826/21279] Train loss: 1.32952,Valid loss: 0.95870, time : 12.498533725738525 lr : 0.9135172474836407\n",
      "epoch : 0 [4827/21279] Train loss: 0.36780,Valid loss: 0.81191, time : 12.771004676818848 lr : 0.9135172474836407\n",
      "epoch : 0 [4828/21279] Train loss: 0.34739,Valid loss: 0.47945, time : 12.918347835540771 lr : 0.9135172474836407\n",
      "epoch : 0 [4829/21279] Train loss: 0.31125,Valid loss: 0.59021, time : 11.644788026809692 lr : 0.9135172474836407\n",
      "epoch : 0 [4830/21279] Train loss: 0.32057,Valid loss: 0.52057, time : 11.753467321395874 lr : 0.9135172474836407\n",
      "epoch : 0 [4831/21279] Train loss: 0.30158,Valid loss: 0.43191, time : 12.678421258926392 lr : 0.9135172474836407\n",
      "epoch : 0 [4832/21279] Train loss: 0.27618,Valid loss: 0.43435, time : 12.155330657958984 lr : 0.9135172474836407\n",
      "epoch : 0 [4833/21279] Train loss: 0.29203,Valid loss: 0.62552, time : 11.869280576705933 lr : 0.9135172474836407\n",
      "epoch : 0 [4834/21279] Train loss: 0.26803,Valid loss: 0.46520, time : 16.87913203239441 lr : 0.9135172474836407\n",
      "epoch : 0 [4835/21279] Train loss: 0.30697,Valid loss: 0.39678, time : 11.50612497329712 lr : 0.9135172474836407\n",
      "epoch : 0 [4836/21279] Train loss: 0.29126,Valid loss: 0.39260, time : 11.835508108139038 lr : 0.9135172474836407\n",
      "epoch : 0 [4837/21279] Train loss: 0.27418,Valid loss: 0.42925, time : 11.861258268356323 lr : 0.9135172474836407\n",
      "epoch : 0 [4838/21279] Train loss: 0.27386,Valid loss: 0.38802, time : 12.68156623840332 lr : 0.9135172474836407\n",
      "epoch : 0 [4839/21279] Train loss: 0.28118,Valid loss: 0.40799, time : 12.200968980789185 lr : 0.9135172474836407\n",
      "epoch : 0 [4840/21279] Train loss: 0.29693,Valid loss: 0.82328, time : 12.11861777305603 lr : 0.9135172474836407\n",
      "epoch : 0 [4841/21279] Train loss: 0.46155,Valid loss: 5.42128, time : 11.857977390289307 lr : 0.9135172474836407\n",
      "epoch : 0 [4842/21279] Train loss: 0.66371,Valid loss: 1.16516, time : 12.261804819107056 lr : 0.9135172474836407\n",
      "epoch : 0 [4843/21279] Train loss: 0.44237,Valid loss: 3.66884, time : 12.663357973098755 lr : 0.9135172474836407\n",
      "epoch : 0 [4844/21279] Train loss: 0.37354,Valid loss: 0.59624, time : 12.553779363632202 lr : 0.9135172474836407\n",
      "epoch : 0 [4845/21279] Train loss: 0.31059,Valid loss: 0.46352, time : 12.23197603225708 lr : 0.9135172474836407\n",
      "epoch : 0 [4846/21279] Train loss: 0.31874,Valid loss: 0.46489, time : 12.339060306549072 lr : 0.9135172474836407\n",
      "epoch : 0 [4847/21279] Train loss: 0.31384,Valid loss: 0.48180, time : 12.043398380279541 lr : 0.9135172474836407\n",
      "epoch : 0 [4848/21279] Train loss: 0.28788,Valid loss: 0.44255, time : 12.212453842163086 lr : 0.9135172474836407\n",
      "epoch : 0 [4849/21279] Train loss: 0.29432,Valid loss: 0.42632, time : 12.225852966308594 lr : 0.9135172474836407\n",
      "epoch : 0 [4850/21279] Train loss: 0.29427,Valid loss: 0.39365, time : 18.57296323776245 lr : 0.9135172474836407\n",
      "epoch : 0 [4851/21279] Train loss: 0.28860,Valid loss: 0.38566, time : 12.268322229385376 lr : 0.9135172474836407\n",
      "epoch : 0 [4852/21279] Train loss: 0.27411,Valid loss: 0.39526, time : 12.366106986999512 lr : 0.9135172474836407\n",
      "epoch : 0 [4853/21279] Train loss: 0.26144,Valid loss: 0.38481, time : 12.260918855667114 lr : 0.9135172474836407\n",
      "epoch : 0 [4854/21279] Train loss: 0.29229,Valid loss: 0.39725, time : 11.827673196792603 lr : 0.9135172474836407\n",
      "epoch : 0 [4855/21279] Train loss: 0.29726,Valid loss: 0.39222, time : 12.76981234550476 lr : 0.9135172474836407\n",
      "epoch : 0 [4856/21279] Train loss: 0.30061,Valid loss: 0.41184, time : 12.34168815612793 lr : 0.9135172474836407\n",
      "epoch : 0 [4857/21279] Train loss: 0.28411,Valid loss: 0.38797, time : 12.367417097091675 lr : 0.9135172474836407\n",
      "epoch : 0 [4858/21279] Train loss: 0.29961,Valid loss: 0.40360, time : 11.79857325553894 lr : 0.9135172474836407\n",
      "epoch : 0 [4859/21279] Train loss: 0.28345,Valid loss: 0.40221, time : 12.241609811782837 lr : 0.9135172474836407\n",
      "epoch : 0 [4860/21279] Train loss: 0.27241,Valid loss: 0.38006, time : 12.462070226669312 lr : 0.9135172474836407\n",
      "epoch : 0 [4861/21279] Train loss: 0.28409,Valid loss: 0.41092, time : 11.809193134307861 lr : 0.9135172474836407\n",
      "epoch : 0 [4862/21279] Train loss: 0.27577,Valid loss: 0.89898, time : 14.262276411056519 lr : 0.9135172474836407\n",
      "epoch : 0 [4863/21279] Train loss: 0.28867,Valid loss: 0.39751, time : 11.843036890029907 lr : 0.9135172474836407\n",
      "epoch : 0 [4864/21279] Train loss: 0.27073,Valid loss: 0.40720, time : 12.087487936019897 lr : 0.9135172474836407\n",
      "epoch : 0 [4865/21279] Train loss: 0.29143,Valid loss: 0.37673, time : 11.548221588134766 lr : 0.9135172474836407\n",
      "epoch : 0 [4866/21279] Train loss: 0.28564,Valid loss: 0.38185, time : 12.256123065948486 lr : 0.9135172474836407\n",
      "epoch : 0 [4867/21279] Train loss: 0.27710,Valid loss: 0.38820, time : 12.377546787261963 lr : 0.9135172474836407\n",
      "epoch : 0 [4868/21279] Train loss: 0.27617,Valid loss: 0.41498, time : 11.853832244873047 lr : 0.9135172474836407\n",
      "epoch : 0 [4869/21279] Train loss: 0.27867,Valid loss: 0.39074, time : 11.706085443496704 lr : 0.9135172474836407\n",
      "epoch : 0 [4870/21279] Train loss: 0.28096,Valid loss: 0.38232, time : 11.376317501068115 lr : 0.9135172474836407\n",
      "epoch : 0 [4871/21279] Train loss: 0.27937,Valid loss: 0.37588, time : 11.965961456298828 lr : 0.9135172474836407\n",
      "epoch : 0 [4872/21279] Train loss: 0.25581,Valid loss: 0.37720, time : 12.052186727523804 lr : 0.9135172474836407\n",
      "epoch : 0 [4873/21279] Train loss: 0.27899,Valid loss: 0.39030, time : 12.782938718795776 lr : 0.9135172474836407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [4874/21279] Train loss: 0.26690,Valid loss: 0.38857, time : 11.497272253036499 lr : 0.9135172474836407\n",
      "epoch : 0 [4875/21279] Train loss: 0.27681,Valid loss: 0.38187, time : 12.152610063552856 lr : 0.9135172474836407\n",
      "epoch : 0 [4876/21279] Train loss: 0.26729,Valid loss: 0.44347, time : 11.862439155578613 lr : 0.9135172474836407\n",
      "epoch : 0 [4877/21279] Train loss: 0.30076,Valid loss: 0.39131, time : 12.196329116821289 lr : 0.9135172474836407\n",
      "epoch : 0 [4878/21279] Train loss: 0.27336,Valid loss: 0.38035, time : 14.02847409248352 lr : 0.9135172474836407\n",
      "epoch : 0 [4879/21279] Train loss: 0.27225,Valid loss: 0.40575, time : 12.207598209381104 lr : 0.9135172474836407\n",
      "epoch : 0 [4880/21279] Train loss: 0.26128,Valid loss: 0.49446, time : 12.427424430847168 lr : 0.9135172474836407\n",
      "epoch : 0 [4881/21279] Train loss: 0.27923,Valid loss: 0.37756, time : 12.829784154891968 lr : 0.9135172474836407\n",
      "epoch : 0 [4882/21279] Train loss: 0.27307,Valid loss: 0.37526, time : 12.486396312713623 lr : 0.9135172474836407\n",
      "epoch : 0 [4883/21279] Train loss: 0.26573,Valid loss: 0.51167, time : 12.611263036727905 lr : 0.9135172474836407\n",
      "epoch : 0 [4884/21279] Train loss: 0.28703,Valid loss: 0.38914, time : 12.607720851898193 lr : 0.9135172474836407\n",
      "epoch : 0 [4885/21279] Train loss: 0.27984,Valid loss: 0.39624, time : 12.624978303909302 lr : 0.9135172474836407\n",
      "epoch : 0 [4886/21279] Train loss: 0.27177,Valid loss: 0.59728, time : 12.274219274520874 lr : 0.9135172474836407\n",
      "epoch : 0 [4887/21279] Train loss: 0.32744,Valid loss: 0.51715, time : 11.59562873840332 lr : 0.9135172474836407\n",
      "epoch : 0 [4888/21279] Train loss: 0.40491,Valid loss: 1.41421, time : 12.136213541030884 lr : 0.9135172474836407\n",
      "epoch : 0 [4889/21279] Train loss: 0.59020,Valid loss: 0.71103, time : 12.14028024673462 lr : 0.9135172474836407\n",
      "epoch : 0 [4890/21279] Train loss: 0.48111,Valid loss: 0.81294, time : 12.160328388214111 lr : 0.9135172474836407\n",
      "epoch : 0 [4891/21279] Train loss: 0.45914,Valid loss: 0.63157, time : 14.408706426620483 lr : 0.9135172474836407\n",
      "epoch : 0 [4892/21279] Train loss: 0.32181,Valid loss: 0.68095, time : 12.642829179763794 lr : 0.9135172474836407\n",
      "epoch : 0 [4893/21279] Train loss: 0.32709,Valid loss: 0.42401, time : 11.854414224624634 lr : 0.9135172474836407\n",
      "epoch : 0 [4894/21279] Train loss: 0.29768,Valid loss: 0.46187, time : 11.69563364982605 lr : 0.9135172474836407\n",
      "epoch : 0 [4895/21279] Train loss: 0.31879,Valid loss: 0.41515, time : 11.842082023620605 lr : 0.9135172474836407\n",
      "epoch : 0 [4896/21279] Train loss: 0.28381,Valid loss: 0.44082, time : 11.391698598861694 lr : 0.9135172474836407\n",
      "epoch : 0 [4897/21279] Train loss: 0.28221,Valid loss: 0.38134, time : 11.538951396942139 lr : 0.9135172474836407\n",
      "epoch : 0 [4898/21279] Train loss: 0.28581,Valid loss: 0.37244, time : 12.146716356277466 lr : 0.9135172474836407\n",
      "epoch : 0 [4899/21279] Train loss: 0.27038,Valid loss: 0.38644, time : 11.639561891555786 lr : 0.9135172474836407\n",
      "epoch : 0 [4900/21279] Train loss: 0.26734,Valid loss: 0.36291, time : 11.860050201416016 lr : 0.9135172474836407\n",
      "epoch : 0 [4901/21279] Train loss: 0.27056,Valid loss: 0.37293, time : 11.857519626617432 lr : 0.9135172474836407\n",
      "epoch : 0 [4902/21279] Train loss: 0.27706,Valid loss: 0.37565, time : 11.972985982894897 lr : 0.9135172474836407\n",
      "epoch : 0 [4903/21279] Train loss: 0.25782,Valid loss: 0.37707, time : 12.312385320663452 lr : 0.9135172474836407\n",
      "epoch : 0 [4904/21279] Train loss: 0.27940,Valid loss: 0.36526, time : 12.713086605072021 lr : 0.9135172474836407\n",
      "epoch : 0 [4905/21279] Train loss: 0.25895,Valid loss: 0.38246, time : 12.487407922744751 lr : 0.9135172474836407\n",
      "epoch : 0 [4906/21279] Train loss: 0.25621,Valid loss: 0.36056, time : 13.828824996948242 lr : 0.9135172474836407\n",
      "epoch : 0 [4907/21279] Train loss: 0.26449,Valid loss: 0.35608, time : 12.472381591796875 lr : 0.9135172474836407\n",
      "epoch : 0 [4908/21279] Train loss: 0.27597,Valid loss: 0.36723, time : 12.735517978668213 lr : 0.9135172474836407\n",
      "epoch : 0 [4909/21279] Train loss: 0.25826,Valid loss: 0.55403, time : 12.887582778930664 lr : 0.9135172474836407\n",
      "epoch : 0 [4910/21279] Train loss: 0.27269,Valid loss: 0.35893, time : 12.603156566619873 lr : 0.9135172474836407\n",
      "epoch : 0 [4911/21279] Train loss: 0.26088,Valid loss: 0.37163, time : 12.229987382888794 lr : 0.9135172474836407\n",
      "epoch : 0 [4912/21279] Train loss: 0.25152,Valid loss: 0.37277, time : 12.709932565689087 lr : 0.9135172474836407\n",
      "epoch : 0 [4913/21279] Train loss: 0.25918,Valid loss: 0.38608, time : 12.577513217926025 lr : 0.9135172474836407\n",
      "epoch : 0 [4914/21279] Train loss: 0.26461,Valid loss: 0.39370, time : 11.86570429801941 lr : 0.9135172474836407\n",
      "epoch : 0 [4915/21279] Train loss: 0.26031,Valid loss: 0.37401, time : 12.486253023147583 lr : 0.9135172474836407\n",
      "epoch : 0 [4916/21279] Train loss: 0.27062,Valid loss: 0.45697, time : 13.089352130889893 lr : 0.9135172474836407\n",
      "epoch : 0 [4917/21279] Train loss: 0.27083,Valid loss: 0.38212, time : 12.97298789024353 lr : 0.9135172474836407\n",
      "epoch : 0 [4918/21279] Train loss: 0.28031,Valid loss: 0.41969, time : 14.321888208389282 lr : 0.9135172474836407\n",
      "epoch : 0 [4919/21279] Train loss: 0.27799,Valid loss: 0.37209, time : 12.11730408668518 lr : 0.9135172474836407\n",
      "epoch : 0 [4920/21279] Train loss: 0.28152,Valid loss: 0.37735, time : 13.034343481063843 lr : 0.9135172474836407\n",
      "epoch : 0 [4921/21279] Train loss: 0.25465,Valid loss: 0.39675, time : 11.944270610809326 lr : 0.9135172474836407\n",
      "epoch : 0 [4922/21279] Train loss: 0.25250,Valid loss: 0.39086, time : 12.344903945922852 lr : 0.9135172474836407\n",
      "epoch : 0 [4923/21279] Train loss: 0.27776,Valid loss: 0.36410, time : 12.599454164505005 lr : 0.9135172474836407\n",
      "epoch : 0 [4924/21279] Train loss: 0.27703,Valid loss: 0.39334, time : 11.740556716918945 lr : 0.9135172474836407\n",
      "epoch : 0 [4925/21279] Train loss: 0.26622,Valid loss: 0.37500, time : 12.144935607910156 lr : 0.9135172474836407\n",
      "epoch : 0 [4926/21279] Train loss: 0.27056,Valid loss: 0.37772, time : 12.00158143043518 lr : 0.9135172474836407\n",
      "epoch : 0 [4927/21279] Train loss: 0.26849,Valid loss: 0.61798, time : 12.376066446304321 lr : 0.9135172474836407\n",
      "epoch : 0 [4928/21279] Train loss: 0.29201,Valid loss: 0.37218, time : 12.275447845458984 lr : 0.9135172474836407\n",
      "epoch : 0 [4929/21279] Train loss: 0.28419,Valid loss: 0.38138, time : 11.580843687057495 lr : 0.9135172474836407\n",
      "epoch : 0 [4930/21279] Train loss: 0.26882,Valid loss: 0.36182, time : 11.342988014221191 lr : 0.9135172474836407\n",
      "epoch : 0 [4931/21279] Train loss: 0.27343,Valid loss: 0.37184, time : 11.628294706344604 lr : 0.9135172474836407\n",
      "epoch : 0 [4932/21279] Train loss: 0.26473,Valid loss: 0.36571, time : 13.279579639434814 lr : 0.9135172474836407\n",
      "epoch : 0 [4933/21279] Train loss: 0.25647,Valid loss: 0.35338, time : 11.717614889144897 lr : 0.9135172474836407\n",
      "epoch : 0 [4934/21279] Train loss: 0.28076,Valid loss: 0.36736, time : 12.276573657989502 lr : 0.9135172474836407\n",
      "epoch : 0 [4935/21279] Train loss: 0.26459,Valid loss: 0.68180, time : 11.591429471969604 lr : 0.9135172474836407\n",
      "epoch : 0 [4936/21279] Train loss: 0.37551,Valid loss: 1.77289, time : 12.245817184448242 lr : 0.9135172474836407\n",
      "epoch : 0 [4937/21279] Train loss: 0.34777,Valid loss: 0.58996, time : 11.882421970367432 lr : 0.9135172474836407\n",
      "epoch : 0 [4938/21279] Train loss: 0.30842,Valid loss: 0.42638, time : 12.131979942321777 lr : 0.9135172474836407\n",
      "epoch : 0 [4939/21279] Train loss: 0.28976,Valid loss: 0.53938, time : 12.7640962600708 lr : 0.9135172474836407\n",
      "epoch : 0 [4940/21279] Train loss: 0.29521,Valid loss: 0.52048, time : 12.40029764175415 lr : 0.9135172474836407\n",
      "epoch : 0 [4941/21279] Train loss: 0.29415,Valid loss: 0.39225, time : 12.543208837509155 lr : 0.9135172474836407\n",
      "epoch : 0 [4942/21279] Train loss: 0.26254,Valid loss: 0.38281, time : 12.351094484329224 lr : 0.9135172474836407\n",
      "epoch : 0 [4943/21279] Train loss: 0.29626,Valid loss: 0.37102, time : 12.65994930267334 lr : 0.9135172474836407\n",
      "epoch : 0 [4944/21279] Train loss: 0.27323,Valid loss: 0.36848, time : 14.386563777923584 lr : 0.9135172474836407\n",
      "epoch : 0 [4945/21279] Train loss: 0.26718,Valid loss: 0.36599, time : 11.769582509994507 lr : 0.9135172474836407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [4946/21279] Train loss: 0.26536,Valid loss: 0.35469, time : 12.406588792800903 lr : 0.9135172474836407\n",
      "epoch : 0 [4947/21279] Train loss: 0.29565,Valid loss: 0.37280, time : 12.218810558319092 lr : 0.9135172474836407\n",
      "epoch : 0 [4948/21279] Train loss: 0.27923,Valid loss: 0.39709, time : 12.049067974090576 lr : 0.9135172474836407\n",
      "epoch : 0 [4949/21279] Train loss: 0.26698,Valid loss: 0.39177, time : 12.025582790374756 lr : 0.9135172474836407\n",
      "epoch : 0 [4950/21279] Train loss: 0.27606,Valid loss: 0.40147, time : 12.045378923416138 lr : 0.9135172474836407\n",
      "epoch : 0 [4951/21279] Train loss: 0.27093,Valid loss: 0.37327, time : 12.381351470947266 lr : 0.9135172474836407\n",
      "epoch : 0 [4952/21279] Train loss: 0.28305,Valid loss: 0.38851, time : 13.08086085319519 lr : 0.9135172474836407\n",
      "epoch : 0 [4953/21279] Train loss: 0.26134,Valid loss: 0.39618, time : 12.425501346588135 lr : 0.9135172474836407\n",
      "epoch : 0 [4954/21279] Train loss: 0.25648,Valid loss: 0.38643, time : 12.624325037002563 lr : 0.9135172474836407\n",
      "epoch : 0 [4955/21279] Train loss: 0.25079,Valid loss: 0.38115, time : 12.781999826431274 lr : 0.9135172474836407\n",
      "epoch : 0 [4956/21279] Train loss: 0.25115,Valid loss: 0.53245, time : 12.89090609550476 lr : 0.9135172474836407\n",
      "epoch : 0 [4957/21279] Train loss: 0.24047,Valid loss: 0.35831, time : 12.93686318397522 lr : 0.9135172474836407\n",
      "epoch : 0 [4958/21279] Train loss: 0.26484,Valid loss: 0.37945, time : 12.934727907180786 lr : 0.9135172474836407\n",
      "epoch : 0 [4959/21279] Train loss: 0.25105,Valid loss: 0.52419, time : 12.778564691543579 lr : 0.9135172474836407\n",
      "epoch : 0 [4960/21279] Train loss: 0.25126,Valid loss: 0.36755, time : 15.20526385307312 lr : 0.9135172474836407\n",
      "epoch : 0 [4961/21279] Train loss: 0.26986,Valid loss: 0.37900, time : 12.161601543426514 lr : 0.9135172474836407\n",
      "epoch : 0 [4962/21279] Train loss: 0.28960,Valid loss: 0.51727, time : 12.179357290267944 lr : 0.9135172474836407\n",
      "epoch : 0 [4963/21279] Train loss: 0.26596,Valid loss: 0.52950, time : 11.962074279785156 lr : 0.9135172474836407\n",
      "epoch : 0 [4964/21279] Train loss: 0.26304,Valid loss: 0.37994, time : 11.644768714904785 lr : 0.9135172474836407\n",
      "epoch : 0 [4965/21279] Train loss: 0.25439,Valid loss: 0.36633, time : 11.789315462112427 lr : 0.9135172474836407\n",
      "epoch : 0 [4966/21279] Train loss: 0.26369,Valid loss: 0.36453, time : 12.402361392974854 lr : 0.9135172474836407\n",
      "epoch : 0 [4967/21279] Train loss: 0.26144,Valid loss: 0.35107, time : 12.490981817245483 lr : 0.9135172474836407\n",
      "epoch : 0 [4968/21279] Train loss: 0.27158,Valid loss: 0.37249, time : 12.743133068084717 lr : 0.9135172474836407\n",
      "epoch : 0 [4969/21279] Train loss: 0.26675,Valid loss: 0.36865, time : 12.90938138961792 lr : 0.9135172474836407\n",
      "epoch : 0 [4970/21279] Train loss: 0.25968,Valid loss: 0.35611, time : 12.234166860580444 lr : 0.9135172474836407\n",
      "epoch : 0 [4971/21279] Train loss: 0.26979,Valid loss: 0.55371, time : 12.684314966201782 lr : 0.9135172474836407\n",
      "epoch : 0 [4972/21279] Train loss: 0.25551,Valid loss: 0.35948, time : 12.505063772201538 lr : 0.9135172474836407\n",
      "epoch : 0 [4973/21279] Train loss: 0.26852,Valid loss: 0.38626, time : 12.644865036010742 lr : 0.9135172474836407\n",
      "epoch : 0 [4974/21279] Train loss: 0.25933,Valid loss: 1.39040, time : 12.881487846374512 lr : 0.9135172474836407\n",
      "epoch : 0 [4975/21279] Train loss: 0.30331,Valid loss: 0.67133, time : 13.177590608596802 lr : 0.9135172474836407\n",
      "epoch : 0 [4976/21279] Train loss: 0.28238,Valid loss: 0.85855, time : 14.647325992584229 lr : 0.9135172474836407\n",
      "epoch : 0 [4977/21279] Train loss: 0.36288,Valid loss: 0.47299, time : 12.633844375610352 lr : 0.9135172474836407\n",
      "epoch : 0 [4978/21279] Train loss: 0.30978,Valid loss: 0.38662, time : 12.103874206542969 lr : 0.9135172474836407\n",
      "epoch : 0 [4979/21279] Train loss: 0.28563,Valid loss: 0.37637, time : 12.484313488006592 lr : 0.9135172474836407\n",
      "epoch : 0 [4980/21279] Train loss: 0.26507,Valid loss: 0.36020, time : 12.522238731384277 lr : 0.9135172474836407\n",
      "epoch : 0 [4981/21279] Train loss: 0.26634,Valid loss: 0.35352, time : 12.546196937561035 lr : 0.9135172474836407\n",
      "epoch : 0 [4982/21279] Train loss: 0.27643,Valid loss: 0.46913, time : 12.762029647827148 lr : 0.9135172474836407\n",
      "epoch : 0 [4983/21279] Train loss: 0.25355,Valid loss: 0.34586, time : 12.612379312515259 lr : 0.9135172474836407\n",
      "epoch : 0 [4984/21279] Train loss: 0.26737,Valid loss: 0.43435, time : 12.403400182723999 lr : 0.9135172474836407\n",
      "epoch : 0 [4985/21279] Train loss: 0.28104,Valid loss: 0.35571, time : 12.758609294891357 lr : 0.9135172474836407\n",
      "epoch : 0 [4986/21279] Train loss: 0.26447,Valid loss: 0.33502, time : 12.85132098197937 lr : 0.9135172474836407\n",
      "epoch : 0 [4987/21279] Train loss: 0.26911,Valid loss: 0.35276, time : 12.035637855529785 lr : 0.9135172474836407\n",
      "epoch : 0 [4988/21279] Train loss: 0.25846,Valid loss: 0.34050, time : 14.606074810028076 lr : 0.9135172474836407\n",
      "epoch : 0 [4989/21279] Train loss: 0.28094,Valid loss: 0.36470, time : 12.352447748184204 lr : 0.9135172474836407\n",
      "epoch : 0 [4990/21279] Train loss: 0.27222,Valid loss: 0.44824, time : 12.21157193183899 lr : 0.9135172474836407\n",
      "epoch : 0 [4991/21279] Train loss: 0.28989,Valid loss: 0.44253, time : 12.286924123764038 lr : 0.9135172474836407\n",
      "epoch : 0 [4992/21279] Train loss: 0.26505,Valid loss: 0.35012, time : 12.412473678588867 lr : 0.9135172474836407\n",
      "epoch : 0 [4993/21279] Train loss: 0.25452,Valid loss: 0.35098, time : 12.005449295043945 lr : 0.9135172474836407\n",
      "epoch : 0 [4994/21279] Train loss: 0.24868,Valid loss: 0.36539, time : 11.87523365020752 lr : 0.9135172474836407\n",
      "epoch : 0 [4995/21279] Train loss: 0.27579,Valid loss: 0.38446, time : 11.716959238052368 lr : 0.9135172474836407\n",
      "epoch : 0 [4996/21279] Train loss: 0.24983,Valid loss: 0.37499, time : 11.733556509017944 lr : 0.9135172474836407\n",
      "epoch : 0 [4997/21279] Train loss: 0.26329,Valid loss: 0.37461, time : 11.479171752929688 lr : 0.9135172474836407\n",
      "epoch : 0 [4998/21279] Train loss: 0.26094,Valid loss: 0.49453, time : 11.495640993118286 lr : 0.9135172474836407\n",
      "epoch : 0 [4999/21279] Train loss: 0.34209,Valid loss: 0.48759, time : 12.002672910690308 lr : 0.9043820750088043\n",
      "epoch : 0 [5000/21279] Train loss: 0.27603,Valid loss: 0.39151, time : 11.748043298721313 lr : 0.9043820750088043\n",
      "epoch : 0 [5001/21279] Train loss: 0.28702,Valid loss: 0.39382, time : 12.167948722839355 lr : 0.9043820750088043\n",
      "epoch : 0 [5002/21279] Train loss: 0.25679,Valid loss: 0.39344, time : 13.668635129928589 lr : 0.9043820750088043\n",
      "epoch : 0 [5003/21279] Train loss: 0.26692,Valid loss: 0.35408, time : 12.4872305393219 lr : 0.9043820750088043\n",
      "epoch : 0 [5004/21279] Train loss: 0.27011,Valid loss: 0.35649, time : 11.436561346054077 lr : 0.9043820750088043\n",
      "epoch : 0 [5005/21279] Train loss: 0.26973,Valid loss: 0.35105, time : 11.765222072601318 lr : 0.9043820750088043\n",
      "epoch : 0 [5006/21279] Train loss: 0.26489,Valid loss: 0.34619, time : 12.155741214752197 lr : 0.9043820750088043\n",
      "epoch : 0 [5007/21279] Train loss: 0.25247,Valid loss: 0.34088, time : 12.142951011657715 lr : 0.9043820750088043\n",
      "epoch : 0 [5008/21279] Train loss: 0.26369,Valid loss: 0.35266, time : 11.774568796157837 lr : 0.9043820750088043\n",
      "epoch : 0 [5009/21279] Train loss: 0.26341,Valid loss: 0.35431, time : 12.208340644836426 lr : 0.9043820750088043\n",
      "epoch : 0 [5010/21279] Train loss: 0.27258,Valid loss: 0.35317, time : 12.17223596572876 lr : 0.9043820750088043\n",
      "epoch : 0 [5011/21279] Train loss: 0.26686,Valid loss: 0.38162, time : 12.196651220321655 lr : 0.9043820750088043\n",
      "epoch : 0 [5012/21279] Train loss: 0.25106,Valid loss: 0.49578, time : 12.337637901306152 lr : 0.9043820750088043\n",
      "epoch : 0 [5013/21279] Train loss: 0.25291,Valid loss: 0.35269, time : 12.376549243927002 lr : 0.9043820750088043\n",
      "epoch : 0 [5014/21279] Train loss: 0.26510,Valid loss: 0.91836, time : 14.52908444404602 lr : 0.9043820750088043\n",
      "epoch : 0 [5015/21279] Train loss: 0.33820,Valid loss: 0.68197, time : 12.463048696517944 lr : 0.9043820750088043\n",
      "epoch : 0 [5016/21279] Train loss: 0.34561,Valid loss: 0.80840, time : 12.354321002960205 lr : 0.9043820750088043\n",
      "epoch : 0 [5017/21279] Train loss: 0.30459,Valid loss: 0.71913, time : 12.671605825424194 lr : 0.9043820750088043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5018/21279] Train loss: 0.28076,Valid loss: 0.37252, time : 12.493096113204956 lr : 0.9043820750088043\n",
      "epoch : 0 [5019/21279] Train loss: 0.27256,Valid loss: 0.36575, time : 12.276081562042236 lr : 0.9043820750088043\n",
      "epoch : 0 [5020/21279] Train loss: 0.24803,Valid loss: 0.36493, time : 12.751763582229614 lr : 0.9043820750088043\n",
      "epoch : 0 [5021/21279] Train loss: 0.26816,Valid loss: 0.36086, time : 12.491014003753662 lr : 0.9043820750088043\n",
      "epoch : 0 [5022/21279] Train loss: 0.25731,Valid loss: 0.41014, time : 12.612837791442871 lr : 0.9043820750088043\n",
      "epoch : 0 [5023/21279] Train loss: 0.29831,Valid loss: 0.97740, time : 12.431851625442505 lr : 0.9043820750088043\n",
      "epoch : 0 [5024/21279] Train loss: 0.40087,Valid loss: 4.59002, time : 12.12025260925293 lr : 0.9043820750088043\n",
      "epoch : 0 [5025/21279] Train loss: 1.13917,Valid loss: 0.72446, time : 11.928860902786255 lr : 0.9043820750088043\n",
      "epoch : 0 [5026/21279] Train loss: 0.46607,Valid loss: 0.65310, time : 11.830943584442139 lr : 0.9043820750088043\n",
      "epoch : 0 [5027/21279] Train loss: 0.45479,Valid loss: 0.96868, time : 12.751184701919556 lr : 0.9043820750088043\n",
      "epoch : 0 [5028/21279] Train loss: 0.46298,Valid loss: 1.00325, time : 11.15325140953064 lr : 0.9043820750088043\n",
      "epoch : 0 [5029/21279] Train loss: 0.38155,Valid loss: 0.58524, time : 11.40264081954956 lr : 0.9043820750088043\n",
      "epoch : 0 [5030/21279] Train loss: 0.30552,Valid loss: 0.48114, time : 13.181739330291748 lr : 0.9043820750088043\n",
      "epoch : 0 [5031/21279] Train loss: 0.27744,Valid loss: 0.46290, time : 11.539421081542969 lr : 0.9043820750088043\n",
      "epoch : 0 [5032/21279] Train loss: 0.26068,Valid loss: 0.35707, time : 12.527106761932373 lr : 0.9043820750088043\n",
      "epoch : 0 [5033/21279] Train loss: 0.28014,Valid loss: 0.39398, time : 12.224135160446167 lr : 0.9043820750088043\n",
      "epoch : 0 [5034/21279] Train loss: 0.27566,Valid loss: 0.64233, time : 11.9397554397583 lr : 0.9043820750088043\n",
      "epoch : 0 [5035/21279] Train loss: 0.26386,Valid loss: 0.37938, time : 12.249428749084473 lr : 0.9043820750088043\n",
      "epoch : 0 [5036/21279] Train loss: 0.26899,Valid loss: 0.39088, time : 12.406168937683105 lr : 0.9043820750088043\n",
      "epoch : 0 [5037/21279] Train loss: 0.26864,Valid loss: 0.37858, time : 12.465030670166016 lr : 0.9043820750088043\n",
      "epoch : 0 [5038/21279] Train loss: 0.27007,Valid loss: 0.37285, time : 12.328261852264404 lr : 0.9043820750088043\n",
      "epoch : 0 [5039/21279] Train loss: 0.26674,Valid loss: 0.36759, time : 12.118554830551147 lr : 0.9043820750088043\n",
      "epoch : 0 [5040/21279] Train loss: 0.26106,Valid loss: 0.38994, time : 12.500625848770142 lr : 0.9043820750088043\n",
      "epoch : 0 [5041/21279] Train loss: 0.28647,Valid loss: 0.38620, time : 12.589505195617676 lr : 0.9043820750088043\n",
      "epoch : 0 [5042/21279] Train loss: 0.26331,Valid loss: 0.62210, time : 15.622928619384766 lr : 0.9043820750088043\n",
      "epoch : 0 [5043/21279] Train loss: 0.25420,Valid loss: 0.35436, time : 12.28343415260315 lr : 0.9043820750088043\n",
      "epoch : 0 [5044/21279] Train loss: 0.25279,Valid loss: 0.36426, time : 12.131700038909912 lr : 0.9043820750088043\n",
      "epoch : 0 [5045/21279] Train loss: 0.26131,Valid loss: 0.35517, time : 12.247911214828491 lr : 0.9043820750088043\n",
      "epoch : 0 [5046/21279] Train loss: 0.27654,Valid loss: 0.36703, time : 12.624805450439453 lr : 0.9043820750088043\n",
      "epoch : 0 [5047/21279] Train loss: 0.26738,Valid loss: 0.36453, time : 11.874518871307373 lr : 0.9043820750088043\n",
      "epoch : 0 [5048/21279] Train loss: 0.25869,Valid loss: 0.35916, time : 11.71226954460144 lr : 0.9043820750088043\n",
      "epoch : 0 [5049/21279] Train loss: 0.25752,Valid loss: 0.33894, time : 11.575360536575317 lr : 0.9043820750088043\n",
      "epoch : 0 [5050/21279] Train loss: 0.25895,Valid loss: 0.36472, time : 12.290262937545776 lr : 0.9043820750088043\n",
      "epoch : 0 [5051/21279] Train loss: 0.28597,Valid loss: 0.34559, time : 11.99808669090271 lr : 0.9043820750088043\n",
      "epoch : 0 [5052/21279] Train loss: 0.27629,Valid loss: 0.38238, time : 11.789677858352661 lr : 0.9043820750088043\n",
      "epoch : 0 [5053/21279] Train loss: 0.26082,Valid loss: 0.36347, time : 12.253260374069214 lr : 0.9043820750088043\n",
      "epoch : 0 [5054/21279] Train loss: 0.26524,Valid loss: 0.36139, time : 12.919098138809204 lr : 0.9043820750088043\n",
      "epoch : 0 [5055/21279] Train loss: 0.26339,Valid loss: 0.51801, time : 12.56781530380249 lr : 0.9043820750088043\n",
      "epoch : 0 [5056/21279] Train loss: 0.26022,Valid loss: 0.38198, time : 12.937845706939697 lr : 0.9043820750088043\n",
      "epoch : 0 [5057/21279] Train loss: 0.25609,Valid loss: 0.36981, time : 12.12446641921997 lr : 0.9043820750088043\n",
      "epoch : 0 [5058/21279] Train loss: 0.26178,Valid loss: 0.36786, time : 13.17069149017334 lr : 0.9043820750088043\n",
      "epoch : 0 [5059/21279] Train loss: 0.27349,Valid loss: 0.37903, time : 11.636591672897339 lr : 0.9043820750088043\n",
      "epoch : 0 [5060/21279] Train loss: 0.26815,Valid loss: 0.35728, time : 11.763777732849121 lr : 0.9043820750088043\n",
      "epoch : 0 [5061/21279] Train loss: 0.27059,Valid loss: 0.37697, time : 11.709792852401733 lr : 0.9043820750088043\n",
      "epoch : 0 [5062/21279] Train loss: 0.27040,Valid loss: 0.36111, time : 11.610895156860352 lr : 0.9043820750088043\n",
      "epoch : 0 [5063/21279] Train loss: 0.25534,Valid loss: 0.37366, time : 11.029006719589233 lr : 0.9043820750088043\n",
      "epoch : 0 [5064/21279] Train loss: 0.25213,Valid loss: 0.36996, time : 11.627727031707764 lr : 0.9043820750088043\n",
      "epoch : 0 [5065/21279] Train loss: 0.25332,Valid loss: 0.54592, time : 11.652486085891724 lr : 0.9043820750088043\n",
      "epoch : 0 [5066/21279] Train loss: 0.27621,Valid loss: 0.37518, time : 10.875204801559448 lr : 0.9043820750088043\n",
      "epoch : 0 [5067/21279] Train loss: 0.26573,Valid loss: 0.38319, time : 11.790343523025513 lr : 0.9043820750088043\n",
      "epoch : 0 [5068/21279] Train loss: 0.26156,Valid loss: 0.40889, time : 11.119792938232422 lr : 0.9043820750088043\n",
      "epoch : 0 [5069/21279] Train loss: 0.28145,Valid loss: 0.38354, time : 11.6849524974823 lr : 0.9043820750088043\n",
      "epoch : 0 [5070/21279] Train loss: 0.26396,Valid loss: 0.38559, time : 11.63844084739685 lr : 0.9043820750088043\n",
      "epoch : 0 [5071/21279] Train loss: 0.25991,Valid loss: 0.35432, time : 13.592678308486938 lr : 0.9043820750088043\n",
      "epoch : 0 [5072/21279] Train loss: 0.26533,Valid loss: 0.37393, time : 12.076061010360718 lr : 0.9043820750088043\n",
      "epoch : 0 [5073/21279] Train loss: 0.24642,Valid loss: 0.34022, time : 12.468250751495361 lr : 0.9043820750088043\n",
      "epoch : 0 [5074/21279] Train loss: 0.25035,Valid loss: 0.35734, time : 12.715945482254028 lr : 0.9043820750088043\n",
      "epoch : 0 [5075/21279] Train loss: 0.25486,Valid loss: 0.35875, time : 11.787297248840332 lr : 0.9043820750088043\n",
      "epoch : 0 [5076/21279] Train loss: 0.23083,Valid loss: 0.35999, time : 11.846935033798218 lr : 0.9043820750088043\n",
      "epoch : 0 [5077/21279] Train loss: 0.26377,Valid loss: 0.35516, time : 12.00542426109314 lr : 0.9043820750088043\n",
      "epoch : 0 [5078/21279] Train loss: 0.26388,Valid loss: 0.34820, time : 12.197441101074219 lr : 0.9043820750088043\n",
      "epoch : 0 [5079/21279] Train loss: 0.25670,Valid loss: 0.35563, time : 12.000129699707031 lr : 0.9043820750088043\n",
      "epoch : 0 [5080/21279] Train loss: 0.25742,Valid loss: 0.34801, time : 12.665719032287598 lr : 0.9043820750088043\n",
      "epoch : 0 [5081/21279] Train loss: 0.25006,Valid loss: 0.36100, time : 12.180837869644165 lr : 0.9043820750088043\n",
      "epoch : 0 [5082/21279] Train loss: 0.25451,Valid loss: 0.36148, time : 12.820303440093994 lr : 0.9043820750088043\n",
      "epoch : 0 [5083/21279] Train loss: 0.25404,Valid loss: 0.35961, time : 13.045610666275024 lr : 0.9043820750088043\n",
      "epoch : 0 [5084/21279] Train loss: 0.26158,Valid loss: 0.38650, time : 12.595756530761719 lr : 0.9043820750088043\n",
      "epoch : 0 [5085/21279] Train loss: 0.24806,Valid loss: 0.59321, time : 12.75651502609253 lr : 0.9043820750088043\n",
      "epoch : 0 [5086/21279] Train loss: 0.26623,Valid loss: 0.37535, time : 13.9245023727417 lr : 0.9043820750088043\n",
      "epoch : 0 [5087/21279] Train loss: 0.23556,Valid loss: 0.36022, time : 12.682770729064941 lr : 0.9043820750088043\n",
      "epoch : 0 [5088/21279] Train loss: 0.26132,Valid loss: 0.37015, time : 12.787397146224976 lr : 0.9043820750088043\n",
      "epoch : 0 [5089/21279] Train loss: 0.26236,Valid loss: 0.67843, time : 11.721592426300049 lr : 0.9043820750088043\n",
      "epoch : 0 [5090/21279] Train loss: 0.26892,Valid loss: 0.37294, time : 11.851591348648071 lr : 0.9043820750088043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5091/21279] Train loss: 0.25822,Valid loss: 0.34497, time : 11.926701545715332 lr : 0.9043820750088043\n",
      "epoch : 0 [5092/21279] Train loss: 0.26731,Valid loss: 0.35922, time : 11.747545719146729 lr : 0.9043820750088043\n",
      "epoch : 0 [5093/21279] Train loss: 0.25916,Valid loss: 0.34920, time : 12.55351996421814 lr : 0.9043820750088043\n",
      "epoch : 0 [5094/21279] Train loss: 0.26152,Valid loss: 0.34827, time : 12.433408737182617 lr : 0.9043820750088043\n",
      "epoch : 0 [5095/21279] Train loss: 0.23407,Valid loss: 0.35815, time : 11.6055428981781 lr : 0.9043820750088043\n",
      "epoch : 0 [5096/21279] Train loss: 0.24401,Valid loss: 0.35619, time : 11.828759908676147 lr : 0.9043820750088043\n",
      "epoch : 0 [5097/21279] Train loss: 0.26580,Valid loss: 0.36557, time : 12.048454523086548 lr : 0.9043820750088043\n",
      "epoch : 0 [5098/21279] Train loss: 0.26219,Valid loss: 0.34649, time : 13.157980918884277 lr : 0.9043820750088043\n",
      "epoch : 0 [5099/21279] Train loss: 0.25431,Valid loss: 0.34672, time : 12.086944103240967 lr : 0.9043820750088043\n",
      "epoch : 0 [5100/21279] Train loss: 0.25894,Valid loss: 0.36377, time : 11.192127227783203 lr : 0.9043820750088043\n",
      "epoch : 0 [5101/21279] Train loss: 0.26302,Valid loss: 0.33660, time : 11.656198501586914 lr : 0.9043820750088043\n",
      "epoch : 0 [5102/21279] Train loss: 0.22730,Valid loss: 0.37019, time : 12.245146036148071 lr : 0.9043820750088043\n",
      "epoch : 0 [5103/21279] Train loss: 0.23543,Valid loss: 0.36200, time : 12.366006851196289 lr : 0.9043820750088043\n",
      "epoch : 0 [5104/21279] Train loss: 0.25603,Valid loss: 0.36208, time : 12.077672481536865 lr : 0.9043820750088043\n",
      "epoch : 0 [5105/21279] Train loss: 0.24574,Valid loss: 0.35203, time : 12.066866397857666 lr : 0.9043820750088043\n",
      "epoch : 0 [5106/21279] Train loss: 0.23402,Valid loss: 0.33778, time : 11.9304780960083 lr : 0.9043820750088043\n",
      "epoch : 0 [5107/21279] Train loss: 0.25959,Valid loss: 0.35792, time : 12.033978939056396 lr : 0.9043820750088043\n",
      "epoch : 0 [5108/21279] Train loss: 0.26625,Valid loss: 0.38495, time : 12.451924324035645 lr : 0.9043820750088043\n",
      "epoch : 0 [5109/21279] Train loss: 0.27612,Valid loss: 0.49866, time : 12.177988290786743 lr : 0.9043820750088043\n",
      "epoch : 0 [5110/21279] Train loss: 0.25965,Valid loss: 0.35529, time : 11.907496690750122 lr : 0.9043820750088043\n",
      "epoch : 0 [5111/21279] Train loss: 0.24584,Valid loss: 0.35557, time : 12.870100498199463 lr : 0.9043820750088043\n",
      "epoch : 0 [5112/21279] Train loss: 0.24097,Valid loss: 0.34734, time : 14.776927947998047 lr : 0.9043820750088043\n",
      "epoch : 0 [5113/21279] Train loss: 0.25151,Valid loss: 0.36185, time : 13.178367137908936 lr : 0.9043820750088043\n",
      "epoch : 0 [5114/21279] Train loss: 0.23154,Valid loss: 0.32956, time : 12.290982007980347 lr : 0.9043820750088043\n",
      "epoch : 0 [5115/21279] Train loss: 0.24097,Valid loss: 0.38172, time : 12.412185907363892 lr : 0.9043820750088043\n",
      "epoch : 0 [5116/21279] Train loss: 0.26282,Valid loss: 0.32839, time : 12.320367336273193 lr : 0.9043820750088043\n",
      "epoch : 0 [5117/21279] Train loss: 0.25793,Valid loss: 0.34443, time : 12.762000560760498 lr : 0.9043820750088043\n",
      "epoch : 0 [5118/21279] Train loss: 0.26651,Valid loss: 0.32151, time : 11.934969425201416 lr : 0.9043820750088043\n",
      "epoch : 0 [5119/21279] Train loss: 0.25189,Valid loss: 0.35739, time : 12.113360404968262 lr : 0.9043820750088043\n",
      "epoch : 0 [5120/21279] Train loss: 0.24532,Valid loss: 0.34610, time : 12.903551578521729 lr : 0.9043820750088043\n",
      "epoch : 0 [5121/21279] Train loss: 0.23566,Valid loss: 0.32723, time : 12.112850189208984 lr : 0.9043820750088043\n",
      "epoch : 0 [5122/21279] Train loss: 0.24686,Valid loss: 0.36553, time : 12.029911041259766 lr : 0.9043820750088043\n",
      "epoch : 0 [5123/21279] Train loss: 0.26051,Valid loss: 0.34239, time : 11.984174013137817 lr : 0.9043820750088043\n",
      "epoch : 0 [5124/21279] Train loss: 0.24370,Valid loss: 0.32720, time : 13.448135137557983 lr : 0.9043820750088043\n",
      "epoch : 0 [5125/21279] Train loss: 0.25637,Valid loss: 0.39241, time : 11.852461338043213 lr : 0.9043820750088043\n",
      "epoch : 0 [5126/21279] Train loss: 0.26124,Valid loss: 0.34134, time : 12.052297353744507 lr : 0.9043820750088043\n",
      "epoch : 0 [5127/21279] Train loss: 0.23694,Valid loss: 0.32413, time : 11.603744983673096 lr : 0.9043820750088043\n",
      "epoch : 0 [5128/21279] Train loss: 0.23864,Valid loss: 0.32589, time : 11.93380093574524 lr : 0.9043820750088043\n",
      "epoch : 0 [5129/21279] Train loss: 0.26078,Valid loss: 0.33145, time : 12.1112220287323 lr : 0.9043820750088043\n",
      "epoch : 0 [5130/21279] Train loss: 0.24379,Valid loss: 0.33336, time : 11.911197900772095 lr : 0.9043820750088043\n",
      "epoch : 0 [5131/21279] Train loss: 0.25029,Valid loss: 0.32243, time : 12.488337278366089 lr : 0.9043820750088043\n",
      "epoch : 0 [5132/21279] Train loss: 0.25460,Valid loss: 0.65561, time : 12.802537441253662 lr : 0.9043820750088043\n",
      "epoch : 0 [5133/21279] Train loss: 0.30078,Valid loss: 0.90651, time : 12.23836064338684 lr : 0.9043820750088043\n",
      "epoch : 0 [5134/21279] Train loss: 0.30379,Valid loss: 0.50738, time : 12.201654434204102 lr : 0.9043820750088043\n",
      "epoch : 0 [5135/21279] Train loss: 0.25255,Valid loss: 0.49546, time : 11.828366041183472 lr : 0.9043820750088043\n",
      "epoch : 0 [5136/21279] Train loss: 0.26990,Valid loss: 0.34540, time : 12.45975399017334 lr : 0.9043820750088043\n",
      "epoch : 0 [5137/21279] Train loss: 0.25414,Valid loss: 0.35354, time : 12.08864974975586 lr : 0.9043820750088043\n",
      "epoch : 0 [5138/21279] Train loss: 0.25568,Valid loss: 0.36863, time : 11.98052978515625 lr : 0.9043820750088043\n",
      "epoch : 0 [5139/21279] Train loss: 0.26549,Valid loss: 0.48468, time : 12.494561195373535 lr : 0.9043820750088043\n",
      "epoch : 0 [5140/21279] Train loss: 0.24277,Valid loss: 0.35349, time : 14.19745683670044 lr : 0.9043820750088043\n",
      "epoch : 0 [5141/21279] Train loss: 0.26275,Valid loss: 0.34145, time : 11.938268661499023 lr : 0.9043820750088043\n",
      "epoch : 0 [5142/21279] Train loss: 0.24889,Valid loss: 0.33542, time : 12.687392950057983 lr : 0.9043820750088043\n",
      "epoch : 0 [5143/21279] Train loss: 0.26063,Valid loss: 0.36005, time : 12.812721252441406 lr : 0.9043820750088043\n",
      "epoch : 0 [5144/21279] Train loss: 0.25979,Valid loss: 0.35523, time : 13.338350534439087 lr : 0.9043820750088043\n",
      "epoch : 0 [5145/21279] Train loss: 0.24688,Valid loss: 0.35917, time : 12.995263576507568 lr : 0.9043820750088043\n",
      "epoch : 0 [5146/21279] Train loss: 0.25132,Valid loss: 0.34423, time : 12.575269222259521 lr : 0.9043820750088043\n",
      "epoch : 0 [5147/21279] Train loss: 0.24352,Valid loss: 0.34897, time : 12.622140169143677 lr : 0.9043820750088043\n",
      "epoch : 0 [5148/21279] Train loss: 0.27347,Valid loss: 0.34911, time : 13.035205602645874 lr : 0.9043820750088043\n",
      "epoch : 0 [5149/21279] Train loss: 0.24585,Valid loss: 0.37486, time : 12.8532395362854 lr : 0.9043820750088043\n",
      "epoch : 0 [5150/21279] Train loss: 0.25760,Valid loss: 0.34993, time : 12.214639902114868 lr : 0.9043820750088043\n",
      "epoch : 0 [5151/21279] Train loss: 0.26481,Valid loss: 0.35313, time : 12.45508074760437 lr : 0.9043820750088043\n",
      "epoch : 0 [5152/21279] Train loss: 0.25061,Valid loss: 0.33537, time : 13.913954496383667 lr : 0.9043820750088043\n",
      "epoch : 0 [5153/21279] Train loss: 0.24702,Valid loss: 0.34064, time : 11.824007511138916 lr : 0.9043820750088043\n",
      "epoch : 0 [5154/21279] Train loss: 0.24779,Valid loss: 0.93452, time : 11.418312549591064 lr : 0.9043820750088043\n",
      "epoch : 0 [5155/21279] Train loss: 0.27728,Valid loss: 0.36939, time : 11.778766393661499 lr : 0.9043820750088043\n",
      "epoch : 0 [5156/21279] Train loss: 0.25473,Valid loss: 0.47523, time : 11.953937530517578 lr : 0.9043820750088043\n",
      "epoch : 0 [5157/21279] Train loss: 0.25686,Valid loss: 0.35331, time : 11.51935338973999 lr : 0.9043820750088043\n",
      "epoch : 0 [5158/21279] Train loss: 0.24807,Valid loss: 0.33287, time : 11.998647689819336 lr : 0.9043820750088043\n",
      "epoch : 0 [5159/21279] Train loss: 0.24524,Valid loss: 0.32439, time : 11.539282321929932 lr : 0.9043820750088043\n",
      "epoch : 0 [5160/21279] Train loss: 0.25155,Valid loss: 0.34252, time : 11.696296215057373 lr : 0.9043820750088043\n",
      "epoch : 0 [5161/21279] Train loss: 0.23642,Valid loss: 0.32794, time : 11.931643962860107 lr : 0.9043820750088043\n",
      "epoch : 0 [5162/21279] Train loss: 0.27177,Valid loss: 0.37722, time : 11.694896936416626 lr : 0.9043820750088043\n",
      "epoch : 0 [5163/21279] Train loss: 0.25234,Valid loss: 0.51136, time : 11.974305152893066 lr : 0.9043820750088043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5164/21279] Train loss: 0.26986,Valid loss: 0.51049, time : 14.709912776947021 lr : 0.9043820750088043\n",
      "epoch : 0 [5165/21279] Train loss: 0.25946,Valid loss: 0.62576, time : 12.247596740722656 lr : 0.9043820750088043\n",
      "epoch : 0 [5166/21279] Train loss: 0.25293,Valid loss: 0.34835, time : 11.618419885635376 lr : 0.9043820750088043\n",
      "epoch : 0 [5167/21279] Train loss: 0.24879,Valid loss: 0.49972, time : 12.25499939918518 lr : 0.9043820750088043\n",
      "epoch : 0 [5168/21279] Train loss: 0.24588,Valid loss: 0.36825, time : 11.574268579483032 lr : 0.9043820750088043\n",
      "epoch : 0 [5169/21279] Train loss: 0.26261,Valid loss: 0.50563, time : 12.34014344215393 lr : 0.9043820750088043\n",
      "epoch : 0 [5170/21279] Train loss: 0.26699,Valid loss: 0.60108, time : 12.069054126739502 lr : 0.9043820750088043\n",
      "epoch : 0 [5171/21279] Train loss: 0.26127,Valid loss: 0.49535, time : 12.089983463287354 lr : 0.9043820750088043\n",
      "epoch : 0 [5172/21279] Train loss: 0.27126,Valid loss: 0.50922, time : 12.17328953742981 lr : 0.9043820750088043\n",
      "epoch : 0 [5173/21279] Train loss: 0.23843,Valid loss: 0.48273, time : 12.975100994110107 lr : 0.9043820750088043\n",
      "epoch : 0 [5174/21279] Train loss: 0.25169,Valid loss: 0.50230, time : 12.91135549545288 lr : 0.9043820750088043\n",
      "epoch : 0 [5175/21279] Train loss: 0.25651,Valid loss: 0.49536, time : 12.385599374771118 lr : 0.9043820750088043\n",
      "epoch : 0 [5176/21279] Train loss: 0.26187,Valid loss: 0.48624, time : 11.7765953540802 lr : 0.9043820750088043\n",
      "epoch : 0 [5177/21279] Train loss: 0.24255,Valid loss: 0.48230, time : 12.41157078742981 lr : 0.9043820750088043\n",
      "epoch : 0 [5178/21279] Train loss: 0.23832,Valid loss: 0.48005, time : 12.698951959609985 lr : 0.9043820750088043\n",
      "epoch : 0 [5179/21279] Train loss: 0.24954,Valid loss: 0.49554, time : 12.4401535987854 lr : 0.9043820750088043\n",
      "epoch : 0 [5180/21279] Train loss: 0.24838,Valid loss: 0.58588, time : 13.804037094116211 lr : 0.9043820750088043\n",
      "epoch : 0 [5181/21279] Train loss: 0.36884,Valid loss: 2.31026, time : 11.702110528945923 lr : 0.9043820750088043\n",
      "epoch : 0 [5182/21279] Train loss: 1.13881,Valid loss: 0.66653, time : 12.144014120101929 lr : 0.9043820750088043\n",
      "epoch : 0 [5183/21279] Train loss: 0.33909,Valid loss: 0.76248, time : 11.831524133682251 lr : 0.9043820750088043\n",
      "epoch : 0 [5184/21279] Train loss: 0.31063,Valid loss: 0.55711, time : 12.241081953048706 lr : 0.9043820750088043\n",
      "epoch : 0 [5185/21279] Train loss: 0.28202,Valid loss: 1.02940, time : 12.011675119400024 lr : 0.9043820750088043\n",
      "epoch : 0 [5186/21279] Train loss: 0.27689,Valid loss: 0.36699, time : 11.856402397155762 lr : 0.9043820750088043\n",
      "epoch : 0 [5187/21279] Train loss: 0.27381,Valid loss: 0.41109, time : 11.685540437698364 lr : 0.9043820750088043\n",
      "epoch : 0 [5188/21279] Train loss: 0.26460,Valid loss: 0.53454, time : 11.635150671005249 lr : 0.9043820750088043\n",
      "epoch : 0 [5189/21279] Train loss: 0.26666,Valid loss: 0.54120, time : 11.807941198348999 lr : 0.9043820750088043\n",
      "epoch : 0 [5190/21279] Train loss: 0.26289,Valid loss: 0.82164, time : 12.125478744506836 lr : 0.9043820750088043\n",
      "epoch : 0 [5191/21279] Train loss: 0.26571,Valid loss: 0.49413, time : 12.56222653388977 lr : 0.9043820750088043\n",
      "epoch : 0 [5192/21279] Train loss: 0.25877,Valid loss: 0.48308, time : 12.663810729980469 lr : 0.9043820750088043\n",
      "epoch : 0 [5193/21279] Train loss: 0.26151,Valid loss: 0.50069, time : 14.48797869682312 lr : 0.9043820750088043\n",
      "epoch : 0 [5194/21279] Train loss: 0.24262,Valid loss: 0.33154, time : 12.233083009719849 lr : 0.9043820750088043\n",
      "epoch : 0 [5195/21279] Train loss: 0.25520,Valid loss: 0.51341, time : 12.784630060195923 lr : 0.9043820750088043\n",
      "epoch : 0 [5196/21279] Train loss: 0.26302,Valid loss: 0.80588, time : 11.657554388046265 lr : 0.9043820750088043\n",
      "epoch : 0 [5197/21279] Train loss: 0.27947,Valid loss: 0.48748, time : 12.18416953086853 lr : 0.9043820750088043\n",
      "epoch : 0 [5198/21279] Train loss: 0.25246,Valid loss: 0.48430, time : 12.602989196777344 lr : 0.9043820750088043\n",
      "epoch : 0 [5199/21279] Train loss: 0.25058,Valid loss: 0.49803, time : 12.957464218139648 lr : 0.9043820750088043\n",
      "epoch : 0 [5200/21279] Train loss: 0.25204,Valid loss: 0.74050, time : 12.947833776473999 lr : 0.9043820750088043\n",
      "epoch : 0 [5201/21279] Train loss: 0.23630,Valid loss: 1.05111, time : 12.16265320777893 lr : 0.9043820750088043\n",
      "epoch : 0 [5202/21279] Train loss: 0.34630,Valid loss: 1.30135, time : 12.27581000328064 lr : 0.9043820750088043\n",
      "epoch : 0 [5203/21279] Train loss: 0.29982,Valid loss: 0.57197, time : 11.97055721282959 lr : 0.9043820750088043\n",
      "epoch : 0 [5204/21279] Train loss: 0.29533,Valid loss: 0.35193, time : 12.449164152145386 lr : 0.9043820750088043\n",
      "epoch : 0 [5205/21279] Train loss: 0.24979,Valid loss: 0.37532, time : 11.680940389633179 lr : 0.9043820750088043\n",
      "epoch : 0 [5206/21279] Train loss: 0.29283,Valid loss: 0.34413, time : 11.755200862884521 lr : 0.9043820750088043\n",
      "epoch : 0 [5207/21279] Train loss: 0.26652,Valid loss: 0.49440, time : 11.98100757598877 lr : 0.9043820750088043\n",
      "epoch : 0 [5208/21279] Train loss: 0.25827,Valid loss: 0.57311, time : 15.596367120742798 lr : 0.9043820750088043\n",
      "epoch : 0 [5209/21279] Train loss: 0.26112,Valid loss: 0.35433, time : 12.943004131317139 lr : 0.9043820750088043\n",
      "epoch : 0 [5210/21279] Train loss: 0.23294,Valid loss: 0.57629, time : 12.834888458251953 lr : 0.9043820750088043\n",
      "epoch : 0 [5211/21279] Train loss: 0.25052,Valid loss: 0.59784, time : 13.080599308013916 lr : 0.9043820750088043\n",
      "epoch : 0 [5212/21279] Train loss: 0.24709,Valid loss: 0.57096, time : 12.903515100479126 lr : 0.9043820750088043\n",
      "epoch : 0 [5213/21279] Train loss: 0.26738,Valid loss: 0.59946, time : 12.730293989181519 lr : 0.9043820750088043\n",
      "epoch : 0 [5214/21279] Train loss: 0.26169,Valid loss: 0.38263, time : 12.906214237213135 lr : 0.9043820750088043\n",
      "epoch : 0 [5215/21279] Train loss: 0.24749,Valid loss: 0.34288, time : 12.969995737075806 lr : 0.9043820750088043\n",
      "epoch : 0 [5216/21279] Train loss: 0.24035,Valid loss: 0.58315, time : 12.694446325302124 lr : 0.9043820750088043\n",
      "epoch : 0 [5217/21279] Train loss: 0.23651,Valid loss: 0.47120, time : 12.898039102554321 lr : 0.9043820750088043\n",
      "epoch : 0 [5218/21279] Train loss: 0.25611,Valid loss: 0.34631, time : 12.890790939331055 lr : 0.9043820750088043\n",
      "epoch : 0 [5219/21279] Train loss: 0.26254,Valid loss: 0.32503, time : 12.852961540222168 lr : 0.9043820750088043\n",
      "epoch : 0 [5220/21279] Train loss: 0.24825,Valid loss: 0.34086, time : 14.572297811508179 lr : 0.9043820750088043\n",
      "epoch : 0 [5221/21279] Train loss: 0.23879,Valid loss: 0.33713, time : 12.033857345581055 lr : 0.9043820750088043\n",
      "epoch : 0 [5222/21279] Train loss: 0.25110,Valid loss: 0.35539, time : 12.654674291610718 lr : 0.9043820750088043\n",
      "epoch : 0 [5223/21279] Train loss: 0.23851,Valid loss: 0.57660, time : 12.65098261833191 lr : 0.9043820750088043\n",
      "epoch : 0 [5224/21279] Train loss: 0.34768,Valid loss: 0.76687, time : 12.84558367729187 lr : 0.9043820750088043\n",
      "epoch : 0 [5225/21279] Train loss: 0.30396,Valid loss: 3.48622, time : 12.444177150726318 lr : 0.9043820750088043\n",
      "epoch : 0 [5226/21279] Train loss: 1.34410,Valid loss: 1.72497, time : 12.403547525405884 lr : 0.9043820750088043\n",
      "epoch : 0 [5227/21279] Train loss: 0.37513,Valid loss: 0.62337, time : 12.776331186294556 lr : 0.9043820750088043\n",
      "epoch : 0 [5228/21279] Train loss: 0.31392,Valid loss: 0.51241, time : 12.674651145935059 lr : 0.9043820750088043\n",
      "epoch : 0 [5229/21279] Train loss: 0.28867,Valid loss: 0.65446, time : 12.693245649337769 lr : 0.9043820750088043\n",
      "epoch : 0 [5230/21279] Train loss: 0.25887,Valid loss: 0.49188, time : 12.91605830192566 lr : 0.9043820750088043\n",
      "epoch : 0 [5231/21279] Train loss: 0.26303,Valid loss: 0.34901, time : 12.950562000274658 lr : 0.9043820750088043\n",
      "epoch : 0 [5232/21279] Train loss: 0.25078,Valid loss: 0.34719, time : 12.97554874420166 lr : 0.9043820750088043\n",
      "epoch : 0 [5233/21279] Train loss: 0.23737,Valid loss: 1.12451, time : 12.630339622497559 lr : 0.9043820750088043\n",
      "epoch : 0 [5234/21279] Train loss: 0.27676,Valid loss: 1.50654, time : 21.013155460357666 lr : 0.9043820750088043\n",
      "epoch : 0 [5235/21279] Train loss: 0.36932,Valid loss: 0.55121, time : 13.479381322860718 lr : 0.9043820750088043\n",
      "epoch : 0 [5236/21279] Train loss: 0.31051,Valid loss: 0.64444, time : 13.25516128540039 lr : 0.9043820750088043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5237/21279] Train loss: 0.28459,Valid loss: 0.59963, time : 12.646450757980347 lr : 0.9043820750088043\n",
      "epoch : 0 [5238/21279] Train loss: 0.24415,Valid loss: 0.31661, time : 13.341537475585938 lr : 0.9043820750088043\n",
      "epoch : 0 [5239/21279] Train loss: 0.25331,Valid loss: 0.47864, time : 12.64839482307434 lr : 0.9043820750088043\n",
      "epoch : 0 [5240/21279] Train loss: 0.26378,Valid loss: 1.10206, time : 13.05915117263794 lr : 0.9043820750088043\n",
      "epoch : 0 [5241/21279] Train loss: 0.27445,Valid loss: 0.33794, time : 12.950210809707642 lr : 0.9043820750088043\n",
      "epoch : 0 [5242/21279] Train loss: 0.25359,Valid loss: 0.71388, time : 12.870055198669434 lr : 0.9043820750088043\n",
      "epoch : 0 [5243/21279] Train loss: 0.25691,Valid loss: 0.33869, time : 12.416577816009521 lr : 0.9043820750088043\n",
      "epoch : 0 [5244/21279] Train loss: 0.24863,Valid loss: 0.33336, time : 12.646918535232544 lr : 0.9043820750088043\n",
      "epoch : 0 [5245/21279] Train loss: 0.24921,Valid loss: 0.31448, time : 12.540914297103882 lr : 0.9043820750088043\n",
      "epoch : 0 [5246/21279] Train loss: 0.26046,Valid loss: 0.32363, time : 20.145108222961426 lr : 0.9043820750088043\n",
      "epoch : 0 [5247/21279] Train loss: 0.24779,Valid loss: 0.32332, time : 12.482467412948608 lr : 0.9043820750088043\n",
      "epoch : 0 [5248/21279] Train loss: 0.25235,Valid loss: 0.76290, time : 11.802066802978516 lr : 0.9043820750088043\n",
      "epoch : 0 [5249/21279] Train loss: 0.29128,Valid loss: 0.35528, time : 11.8630952835083 lr : 0.9043820750088043\n",
      "epoch : 0 [5250/21279] Train loss: 0.26381,Valid loss: 0.32858, time : 11.878397941589355 lr : 0.9043820750088043\n",
      "epoch : 0 [5251/21279] Train loss: 0.24016,Valid loss: 0.39552, time : 11.760393142700195 lr : 0.9043820750088043\n",
      "epoch : 0 [5252/21279] Train loss: 0.25163,Valid loss: 0.51260, time : 11.43810772895813 lr : 0.9043820750088043\n",
      "epoch : 0 [5253/21279] Train loss: 0.28163,Valid loss: 0.52415, time : 11.24792742729187 lr : 0.9043820750088043\n",
      "epoch : 0 [5254/21279] Train loss: 0.24948,Valid loss: 0.31204, time : 11.877020359039307 lr : 0.9043820750088043\n",
      "epoch : 0 [5255/21279] Train loss: 0.23652,Valid loss: 0.51358, time : 12.139805555343628 lr : 0.9043820750088043\n",
      "epoch : 0 [5256/21279] Train loss: 0.26267,Valid loss: 0.50004, time : 12.979880332946777 lr : 0.9043820750088043\n",
      "epoch : 0 [5257/21279] Train loss: 0.25297,Valid loss: 0.48076, time : 12.1154305934906 lr : 0.9043820750088043\n",
      "epoch : 0 [5258/21279] Train loss: 0.27484,Valid loss: 0.48300, time : 11.925853967666626 lr : 0.9043820750088043\n",
      "epoch : 0 [5259/21279] Train loss: 0.25275,Valid loss: 0.32178, time : 12.140719175338745 lr : 0.9043820750088043\n",
      "epoch : 0 [5260/21279] Train loss: 0.24345,Valid loss: 0.34762, time : 12.345082759857178 lr : 0.9043820750088043\n",
      "epoch : 0 [5261/21279] Train loss: 0.23763,Valid loss: 0.48391, time : 11.849223136901855 lr : 0.9043820750088043\n",
      "epoch : 0 [5262/21279] Train loss: 0.26582,Valid loss: 0.33761, time : 14.959277153015137 lr : 0.9043820750088043\n",
      "epoch : 0 [5263/21279] Train loss: 0.24359,Valid loss: 0.33478, time : 12.237745761871338 lr : 0.9043820750088043\n",
      "epoch : 0 [5264/21279] Train loss: 0.24941,Valid loss: 0.34830, time : 11.524169683456421 lr : 0.9043820750088043\n",
      "epoch : 0 [5265/21279] Train loss: 0.26947,Valid loss: 0.49500, time : 12.82957148551941 lr : 0.9043820750088043\n",
      "epoch : 0 [5266/21279] Train loss: 0.25295,Valid loss: 0.44691, time : 11.727414608001709 lr : 0.9043820750088043\n",
      "epoch : 0 [5267/21279] Train loss: 0.25613,Valid loss: 0.36203, time : 12.952220916748047 lr : 0.9043820750088043\n",
      "epoch : 0 [5268/21279] Train loss: 0.24290,Valid loss: 0.42217, time : 12.239129304885864 lr : 0.9043820750088043\n",
      "epoch : 0 [5269/21279] Train loss: 0.24767,Valid loss: 0.36826, time : 12.583200693130493 lr : 0.9043820750088043\n",
      "epoch : 0 [5270/21279] Train loss: 0.25770,Valid loss: 0.34858, time : 12.199266195297241 lr : 0.9043820750088043\n",
      "epoch : 0 [5271/21279] Train loss: 0.25946,Valid loss: 0.33581, time : 12.71171259880066 lr : 0.9043820750088043\n",
      "epoch : 0 [5272/21279] Train loss: 0.24458,Valid loss: 0.34272, time : 12.436298131942749 lr : 0.9043820750088043\n",
      "epoch : 0 [5273/21279] Train loss: 0.24369,Valid loss: 0.35550, time : 12.575148105621338 lr : 0.9043820750088043\n",
      "epoch : 0 [5274/21279] Train loss: 0.23981,Valid loss: 0.32303, time : 14.170721530914307 lr : 0.9043820750088043\n",
      "epoch : 0 [5275/21279] Train loss: 0.23693,Valid loss: 0.33043, time : 12.575366735458374 lr : 0.9043820750088043\n",
      "epoch : 0 [5276/21279] Train loss: 0.24210,Valid loss: 0.32788, time : 11.804437398910522 lr : 0.9043820750088043\n",
      "epoch : 0 [5277/21279] Train loss: 0.24167,Valid loss: 0.31578, time : 12.684999465942383 lr : 0.9043820750088043\n",
      "epoch : 0 [5278/21279] Train loss: 0.23944,Valid loss: 0.31448, time : 12.206578493118286 lr : 0.9043820750088043\n",
      "epoch : 0 [5279/21279] Train loss: 0.23375,Valid loss: 0.31999, time : 12.527652025222778 lr : 0.9043820750088043\n",
      "epoch : 0 [5280/21279] Train loss: 0.25744,Valid loss: 0.34797, time : 12.40477967262268 lr : 0.9043820750088043\n",
      "epoch : 0 [5281/21279] Train loss: 0.23732,Valid loss: 0.32879, time : 12.41637897491455 lr : 0.9043820750088043\n",
      "epoch : 0 [5282/21279] Train loss: 0.23884,Valid loss: 0.31440, time : 11.947143316268921 lr : 0.9043820750088043\n",
      "epoch : 0 [5283/21279] Train loss: 0.24485,Valid loss: 0.43478, time : 11.7559974193573 lr : 0.9043820750088043\n",
      "epoch : 0 [5284/21279] Train loss: 0.23720,Valid loss: 0.54548, time : 11.730307579040527 lr : 0.9043820750088043\n",
      "epoch : 0 [5285/21279] Train loss: 0.23561,Valid loss: 0.48814, time : 11.882884740829468 lr : 0.9043820750088043\n",
      "epoch : 0 [5286/21279] Train loss: 0.26695,Valid loss: 0.47490, time : 11.728040933609009 lr : 0.9043820750088043\n",
      "epoch : 0 [5287/21279] Train loss: 0.24101,Valid loss: 0.32806, time : 12.475059747695923 lr : 0.9043820750088043\n",
      "epoch : 0 [5288/21279] Train loss: 0.24929,Valid loss: 0.70677, time : 12.302994728088379 lr : 0.9043820750088043\n",
      "epoch : 0 [5289/21279] Train loss: 0.24162,Valid loss: 0.31834, time : 12.231401205062866 lr : 0.9043820750088043\n",
      "epoch : 0 [5290/21279] Train loss: 0.23268,Valid loss: 0.55339, time : 13.496697187423706 lr : 0.9043820750088043\n",
      "epoch : 0 [5291/21279] Train loss: 0.23290,Valid loss: 0.31019, time : 11.970374822616577 lr : 0.9043820750088043\n",
      "epoch : 0 [5292/21279] Train loss: 0.23884,Valid loss: 0.29858, time : 11.93044400215149 lr : 0.9043820750088043\n",
      "epoch : 0 [5293/21279] Train loss: 0.24773,Valid loss: 0.30631, time : 11.884921312332153 lr : 0.9043820750088043\n",
      "epoch : 0 [5294/21279] Train loss: 0.23503,Valid loss: 0.29934, time : 12.072437763214111 lr : 0.9043820750088043\n",
      "epoch : 0 [5295/21279] Train loss: 0.23426,Valid loss: 0.29127, time : 11.86130404472351 lr : 0.9043820750088043\n",
      "epoch : 0 [5296/21279] Train loss: 0.23625,Valid loss: 0.31935, time : 12.161152362823486 lr : 0.9043820750088043\n",
      "epoch : 0 [5297/21279] Train loss: 0.22143,Valid loss: 0.29773, time : 11.777654647827148 lr : 0.9043820750088043\n",
      "epoch : 0 [5298/21279] Train loss: 0.23525,Valid loss: 0.31263, time : 12.027964115142822 lr : 0.9043820750088043\n",
      "epoch : 0 [5299/21279] Train loss: 0.23237,Valid loss: 0.45232, time : 11.983541488647461 lr : 0.9043820750088043\n",
      "epoch : 0 [5300/21279] Train loss: 0.25290,Valid loss: 0.47501, time : 12.437196731567383 lr : 0.9043820750088043\n",
      "epoch : 0 [5301/21279] Train loss: 0.24702,Valid loss: 0.31096, time : 12.02835202217102 lr : 0.9043820750088043\n",
      "epoch : 0 [5302/21279] Train loss: 0.22660,Valid loss: 0.30895, time : 12.027273178100586 lr : 0.9043820750088043\n",
      "epoch : 0 [5303/21279] Train loss: 0.25061,Valid loss: 0.47806, time : 14.366228818893433 lr : 0.9043820750088043\n",
      "epoch : 0 [5304/21279] Train loss: 0.23779,Valid loss: 0.32114, time : 12.10816216468811 lr : 0.9043820750088043\n",
      "epoch : 0 [5305/21279] Train loss: 0.22589,Valid loss: 0.33547, time : 11.883240222930908 lr : 0.9043820750088043\n",
      "epoch : 0 [5306/21279] Train loss: 0.23639,Valid loss: 0.32697, time : 11.058781385421753 lr : 0.9043820750088043\n",
      "epoch : 0 [5307/21279] Train loss: 0.24405,Valid loss: 0.32991, time : 11.703392028808594 lr : 0.9043820750088043\n",
      "epoch : 0 [5308/21279] Train loss: 0.24355,Valid loss: 0.33650, time : 11.326209306716919 lr : 0.9043820750088043\n",
      "epoch : 0 [5309/21279] Train loss: 0.28353,Valid loss: 0.38838, time : 12.274955749511719 lr : 0.9043820750088043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5310/21279] Train loss: 0.30238,Valid loss: 0.58339, time : 11.024847030639648 lr : 0.9043820750088043\n",
      "epoch : 0 [5311/21279] Train loss: 0.28622,Valid loss: 0.39677, time : 11.909515380859375 lr : 0.9043820750088043\n",
      "epoch : 0 [5312/21279] Train loss: 0.24095,Valid loss: 0.39583, time : 12.46169924736023 lr : 0.9043820750088043\n",
      "epoch : 0 [5313/21279] Train loss: 0.25741,Valid loss: 0.35534, time : 11.840412855148315 lr : 0.9043820750088043\n",
      "epoch : 0 [5314/21279] Train loss: 0.24972,Valid loss: 0.33745, time : 11.735843181610107 lr : 0.9043820750088043\n",
      "epoch : 0 [5315/21279] Train loss: 0.23655,Valid loss: 0.32086, time : 12.269699811935425 lr : 0.9043820750088043\n",
      "epoch : 0 [5316/21279] Train loss: 0.22073,Valid loss: 0.34433, time : 12.187319040298462 lr : 0.9043820750088043\n",
      "epoch : 0 [5317/21279] Train loss: 0.23720,Valid loss: 0.33764, time : 12.234829902648926 lr : 0.9043820750088043\n",
      "epoch : 0 [5318/21279] Train loss: 0.23009,Valid loss: 0.32609, time : 15.494567394256592 lr : 0.9043820750088043\n",
      "epoch : 0 [5319/21279] Train loss: 0.23487,Valid loss: 0.46025, time : 12.868342638015747 lr : 0.9043820750088043\n",
      "epoch : 0 [5320/21279] Train loss: 0.23008,Valid loss: 0.34920, time : 12.995245933532715 lr : 0.9043820750088043\n",
      "epoch : 0 [5321/21279] Train loss: 0.24935,Valid loss: 0.31706, time : 12.741380214691162 lr : 0.9043820750088043\n",
      "epoch : 0 [5322/21279] Train loss: 0.23632,Valid loss: 0.32730, time : 12.365000009536743 lr : 0.9043820750088043\n",
      "epoch : 0 [5323/21279] Train loss: 0.24783,Valid loss: 0.29881, time : 12.67542815208435 lr : 0.9043820750088043\n",
      "epoch : 0 [5324/21279] Train loss: 0.23503,Valid loss: 0.30781, time : 12.906400442123413 lr : 0.9043820750088043\n",
      "epoch : 0 [5325/21279] Train loss: 0.21329,Valid loss: 0.29972, time : 12.636066913604736 lr : 0.9043820750088043\n",
      "epoch : 0 [5326/21279] Train loss: 0.23164,Valid loss: 0.30205, time : 12.501972675323486 lr : 0.9043820750088043\n",
      "epoch : 0 [5327/21279] Train loss: 0.23136,Valid loss: 0.30186, time : 12.910167932510376 lr : 0.9043820750088043\n",
      "epoch : 0 [5328/21279] Train loss: 0.22796,Valid loss: 0.33153, time : 12.676559448242188 lr : 0.9043820750088043\n",
      "epoch : 0 [5329/21279] Train loss: 0.24582,Valid loss: 0.32494, time : 12.15865159034729 lr : 0.9043820750088043\n",
      "epoch : 0 [5330/21279] Train loss: 0.26209,Valid loss: 0.31721, time : 13.908753395080566 lr : 0.9043820750088043\n",
      "epoch : 0 [5331/21279] Train loss: 0.26051,Valid loss: 0.32916, time : 13.160377502441406 lr : 0.9043820750088043\n",
      "epoch : 0 [5332/21279] Train loss: 0.26106,Valid loss: 0.36141, time : 12.27568507194519 lr : 0.9043820750088043\n",
      "epoch : 0 [5333/21279] Train loss: 0.25245,Valid loss: 0.48117, time : 12.617130041122437 lr : 0.9043820750088043\n",
      "epoch : 0 [5334/21279] Train loss: 0.25259,Valid loss: 0.36276, time : 12.205923795700073 lr : 0.9043820750088043\n",
      "epoch : 0 [5335/21279] Train loss: 0.24132,Valid loss: 0.31987, time : 12.6614511013031 lr : 0.9043820750088043\n",
      "epoch : 0 [5336/21279] Train loss: 0.23161,Valid loss: 0.33491, time : 13.029591083526611 lr : 0.9043820750088043\n",
      "epoch : 0 [5337/21279] Train loss: 0.24259,Valid loss: 0.30222, time : 12.784446954727173 lr : 0.9043820750088043\n",
      "epoch : 0 [5338/21279] Train loss: 0.23222,Valid loss: 0.34676, time : 12.468325853347778 lr : 0.9043820750088043\n",
      "epoch : 0 [5339/21279] Train loss: 0.23198,Valid loss: 0.32483, time : 13.107769250869751 lr : 0.9043820750088043\n",
      "epoch : 0 [5340/21279] Train loss: 0.22260,Valid loss: 0.31720, time : 12.283538818359375 lr : 0.9043820750088043\n",
      "epoch : 0 [5341/21279] Train loss: 0.23816,Valid loss: 0.31336, time : 12.369582176208496 lr : 0.9043820750088043\n",
      "epoch : 0 [5342/21279] Train loss: 0.23191,Valid loss: 0.32595, time : 12.463672399520874 lr : 0.9043820750088043\n",
      "epoch : 0 [5343/21279] Train loss: 0.21990,Valid loss: 0.32184, time : 12.033315658569336 lr : 0.9043820750088043\n",
      "epoch : 0 [5344/21279] Train loss: 0.27964,Valid loss: 0.46656, time : 18.632225036621094 lr : 0.9043820750088043\n",
      "epoch : 0 [5345/21279] Train loss: 0.42594,Valid loss: 0.97164, time : 12.34169626235962 lr : 0.9043820750088043\n",
      "epoch : 0 [5346/21279] Train loss: 0.51579,Valid loss: 1.02587, time : 12.96695065498352 lr : 0.9043820750088043\n",
      "epoch : 0 [5347/21279] Train loss: 0.60265,Valid loss: 0.75932, time : 13.081400871276855 lr : 0.9043820750088043\n",
      "epoch : 0 [5348/21279] Train loss: 0.40683,Valid loss: 1.32335, time : 12.779757499694824 lr : 0.9043820750088043\n",
      "epoch : 0 [5349/21279] Train loss: 0.44943,Valid loss: 1.64234, time : 12.81251859664917 lr : 0.9043820750088043\n",
      "epoch : 0 [5350/21279] Train loss: 0.35110,Valid loss: 0.72925, time : 12.91684865951538 lr : 0.9043820750088043\n",
      "epoch : 0 [5351/21279] Train loss: 0.38227,Valid loss: 1.57327, time : 12.493543148040771 lr : 0.9043820750088043\n",
      "epoch : 0 [5352/21279] Train loss: 0.62489,Valid loss: 1.39904, time : 12.8098726272583 lr : 0.9043820750088043\n",
      "epoch : 0 [5353/21279] Train loss: 0.61986,Valid loss: 1.30350, time : 12.77260708808899 lr : 0.9043820750088043\n",
      "epoch : 0 [5354/21279] Train loss: 0.40141,Valid loss: 0.60692, time : 12.477497816085815 lr : 0.9043820750088043\n",
      "epoch : 0 [5355/21279] Train loss: 0.29532,Valid loss: 0.63969, time : 12.632728576660156 lr : 0.9043820750088043\n",
      "epoch : 0 [5356/21279] Train loss: 0.30452,Valid loss: 0.51793, time : 12.742748260498047 lr : 0.9043820750088043\n",
      "epoch : 0 [5357/21279] Train loss: 0.27899,Valid loss: 0.49522, time : 12.368068933486938 lr : 0.9043820750088043\n",
      "epoch : 0 [5358/21279] Train loss: 0.29050,Valid loss: 0.35396, time : 12.962881803512573 lr : 0.9043820750088043\n",
      "epoch : 0 [5359/21279] Train loss: 0.28926,Valid loss: 0.34039, time : 12.378963708877563 lr : 0.9043820750088043\n",
      "epoch : 0 [5360/21279] Train loss: 0.23837,Valid loss: 0.33356, time : 16.891342163085938 lr : 0.9043820750088043\n",
      "epoch : 0 [5361/21279] Train loss: 0.25318,Valid loss: 0.32545, time : 13.053402662277222 lr : 0.9043820750088043\n",
      "epoch : 0 [5362/21279] Train loss: 0.26554,Valid loss: 0.32508, time : 12.970033407211304 lr : 0.9043820750088043\n",
      "epoch : 0 [5363/21279] Train loss: 0.25533,Valid loss: 0.51699, time : 12.94073224067688 lr : 0.9043820750088043\n",
      "epoch : 0 [5364/21279] Train loss: 0.24137,Valid loss: 0.28732, time : 13.056133031845093 lr : 0.9043820750088043\n",
      "epoch : 0 [5365/21279] Train loss: 0.23963,Valid loss: 0.73986, time : 12.927798748016357 lr : 0.9043820750088043\n",
      "epoch : 0 [5366/21279] Train loss: 0.43426,Valid loss: 0.61099, time : 13.047261953353882 lr : 0.9043820750088043\n",
      "epoch : 0 [5367/21279] Train loss: 0.31022,Valid loss: 0.35303, time : 12.904781818389893 lr : 0.9043820750088043\n",
      "epoch : 0 [5368/21279] Train loss: 0.26661,Valid loss: 1.42318, time : 12.85337495803833 lr : 0.9043820750088043\n",
      "epoch : 0 [5369/21279] Train loss: 0.34785,Valid loss: 0.75293, time : 12.308670043945312 lr : 0.9043820750088043\n",
      "epoch : 0 [5370/21279] Train loss: 0.36185,Valid loss: 2.05378, time : 12.805621862411499 lr : 0.9043820750088043\n",
      "epoch : 0 [5371/21279] Train loss: 0.32584,Valid loss: 0.80260, time : 12.973264217376709 lr : 0.9043820750088043\n",
      "epoch : 0 [5372/21279] Train loss: 0.29137,Valid loss: 0.40903, time : 13.363362789154053 lr : 0.9043820750088043\n",
      "epoch : 0 [5373/21279] Train loss: 0.24906,Valid loss: 0.47726, time : 15.630971193313599 lr : 0.9043820750088043\n",
      "epoch : 0 [5374/21279] Train loss: 0.25022,Valid loss: 0.62877, time : 12.990943670272827 lr : 0.9043820750088043\n",
      "epoch : 0 [5375/21279] Train loss: 0.26982,Valid loss: 0.61201, time : 12.698533058166504 lr : 0.9043820750088043\n",
      "epoch : 0 [5376/21279] Train loss: 0.26221,Valid loss: 0.46762, time : 12.67108964920044 lr : 0.9043820750088043\n",
      "epoch : 0 [5377/21279] Train loss: 0.25340,Valid loss: 0.88249, time : 12.777639389038086 lr : 0.9043820750088043\n",
      "epoch : 0 [5378/21279] Train loss: 0.24866,Valid loss: 0.75370, time : 12.617884159088135 lr : 0.9043820750088043\n",
      "epoch : 0 [5379/21279] Train loss: 0.26009,Valid loss: 0.47884, time : 13.070206880569458 lr : 0.9043820750088043\n",
      "epoch : 0 [5380/21279] Train loss: 0.25871,Valid loss: 0.60191, time : 12.520225524902344 lr : 0.9043820750088043\n",
      "epoch : 0 [5381/21279] Train loss: 0.23860,Valid loss: 0.45662, time : 13.06807541847229 lr : 0.9043820750088043\n",
      "epoch : 0 [5382/21279] Train loss: 0.24722,Valid loss: 0.48915, time : 12.757658958435059 lr : 0.9043820750088043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5383/21279] Train loss: 0.24294,Valid loss: 0.61969, time : 13.361079454421997 lr : 0.9043820750088043\n",
      "epoch : 0 [5384/21279] Train loss: 0.24670,Valid loss: 0.60902, time : 13.059024572372437 lr : 0.9043820750088043\n",
      "epoch : 0 [5385/21279] Train loss: 0.24698,Valid loss: 0.48567, time : 12.490860223770142 lr : 0.9043820750088043\n",
      "epoch : 0 [5386/21279] Train loss: 0.23870,Valid loss: 0.32283, time : 12.59480333328247 lr : 0.9043820750088043\n",
      "epoch : 0 [5387/21279] Train loss: 0.24335,Valid loss: 0.45036, time : 11.97079062461853 lr : 0.9043820750088043\n",
      "epoch : 0 [5388/21279] Train loss: 0.22016,Valid loss: 0.46321, time : 14.307236671447754 lr : 0.9043820750088043\n",
      "epoch : 0 [5389/21279] Train loss: 0.23296,Valid loss: 0.46202, time : 11.871758937835693 lr : 0.9043820750088043\n",
      "epoch : 0 [5390/21279] Train loss: 0.24720,Valid loss: 0.53313, time : 12.107011795043945 lr : 0.9043820750088043\n",
      "epoch : 0 [5391/21279] Train loss: 0.24244,Valid loss: 0.47319, time : 12.362403392791748 lr : 0.9043820750088043\n",
      "epoch : 0 [5392/21279] Train loss: 0.23636,Valid loss: 0.47007, time : 12.156376361846924 lr : 0.9043820750088043\n",
      "epoch : 0 [5393/21279] Train loss: 0.22402,Valid loss: 0.46434, time : 12.136034488677979 lr : 0.9043820750088043\n",
      "epoch : 0 [5394/21279] Train loss: 0.24444,Valid loss: 0.45434, time : 12.016834497451782 lr : 0.9043820750088043\n",
      "epoch : 0 [5395/21279] Train loss: 0.21699,Valid loss: 0.30955, time : 12.259279489517212 lr : 0.9043820750088043\n",
      "epoch : 0 [5396/21279] Train loss: 0.23617,Valid loss: 0.30675, time : 12.803871870040894 lr : 0.9043820750088043\n",
      "epoch : 0 [5397/21279] Train loss: 0.23273,Valid loss: 0.32624, time : 12.686150789260864 lr : 0.9043820750088043\n",
      "epoch : 0 [5398/21279] Train loss: 0.22117,Valid loss: 0.31570, time : 12.846422672271729 lr : 0.9043820750088043\n",
      "epoch : 0 [5399/21279] Train loss: 0.22844,Valid loss: 0.32694, time : 12.470234394073486 lr : 0.9043820750088043\n",
      "epoch : 0 [5400/21279] Train loss: 0.22430,Valid loss: 0.45308, time : 14.38472318649292 lr : 0.9043820750088043\n",
      "epoch : 0 [5401/21279] Train loss: 0.22743,Valid loss: 0.30922, time : 12.71177864074707 lr : 0.9043820750088043\n",
      "epoch : 0 [5402/21279] Train loss: 0.24665,Valid loss: 0.32958, time : 12.551878690719604 lr : 0.9043820750088043\n",
      "epoch : 0 [5403/21279] Train loss: 0.24173,Valid loss: 0.45835, time : 12.63740062713623 lr : 0.9043820750088043\n",
      "epoch : 0 [5404/21279] Train loss: 0.23878,Valid loss: 0.31999, time : 12.585036039352417 lr : 0.9043820750088043\n",
      "epoch : 0 [5405/21279] Train loss: 0.25759,Valid loss: 0.29813, time : 12.580188989639282 lr : 0.9043820750088043\n",
      "epoch : 0 [5406/21279] Train loss: 0.21643,Valid loss: 0.44537, time : 12.678227424621582 lr : 0.9043820750088043\n",
      "epoch : 0 [5407/21279] Train loss: 0.23617,Valid loss: 0.45832, time : 12.705613613128662 lr : 0.9043820750088043\n",
      "epoch : 0 [5408/21279] Train loss: 0.23326,Valid loss: 0.29080, time : 12.589911937713623 lr : 0.9043820750088043\n",
      "epoch : 0 [5409/21279] Train loss: 0.23685,Valid loss: 0.44366, time : 12.702425956726074 lr : 0.9043820750088043\n",
      "epoch : 0 [5410/21279] Train loss: 0.24435,Valid loss: 0.28272, time : 12.510728359222412 lr : 0.9043820750088043\n",
      "epoch : 0 [5411/21279] Train loss: 0.23130,Valid loss: 0.28845, time : 12.399165868759155 lr : 0.9043820750088043\n",
      "epoch : 0 [5412/21279] Train loss: 0.23295,Valid loss: 0.29420, time : 12.092513084411621 lr : 0.9043820750088043\n",
      "epoch : 0 [5413/21279] Train loss: 0.22497,Valid loss: 0.30145, time : 12.422881603240967 lr : 0.9043820750088043\n",
      "epoch : 0 [5414/21279] Train loss: 0.23511,Valid loss: 0.29817, time : 16.217023134231567 lr : 0.9043820750088043\n",
      "epoch : 0 [5415/21279] Train loss: 0.21787,Valid loss: 0.32377, time : 12.238675832748413 lr : 0.9043820750088043\n",
      "epoch : 0 [5416/21279] Train loss: 0.23437,Valid loss: 1.09238, time : 12.794111967086792 lr : 0.9043820750088043\n",
      "epoch : 0 [5417/21279] Train loss: 0.28929,Valid loss: 0.75578, time : 12.628649711608887 lr : 0.9043820750088043\n",
      "epoch : 0 [5418/21279] Train loss: 0.27894,Valid loss: 0.44986, time : 12.358166456222534 lr : 0.9043820750088043\n",
      "epoch : 0 [5419/21279] Train loss: 0.24300,Valid loss: 0.30785, time : 12.488390684127808 lr : 0.9043820750088043\n",
      "epoch : 0 [5420/21279] Train loss: 0.23581,Valid loss: 0.30880, time : 12.77661919593811 lr : 0.9043820750088043\n",
      "epoch : 0 [5421/21279] Train loss: 0.23540,Valid loss: 0.60231, time : 12.83252477645874 lr : 0.9043820750088043\n",
      "epoch : 0 [5422/21279] Train loss: 0.23834,Valid loss: 0.32046, time : 12.594089031219482 lr : 0.9043820750088043\n",
      "epoch : 0 [5423/21279] Train loss: 0.22275,Valid loss: 0.30548, time : 12.817085266113281 lr : 0.9043820750088043\n",
      "epoch : 0 [5424/21279] Train loss: 0.23128,Valid loss: 0.30826, time : 12.281085729598999 lr : 0.9043820750088043\n",
      "epoch : 0 [5425/21279] Train loss: 0.23778,Valid loss: 0.30726, time : 12.63682222366333 lr : 0.9043820750088043\n",
      "epoch : 0 [5426/21279] Train loss: 0.24149,Valid loss: 0.32915, time : 15.007420539855957 lr : 0.9043820750088043\n",
      "epoch : 0 [5427/21279] Train loss: 0.21663,Valid loss: 0.30692, time : 12.99908995628357 lr : 0.9043820750088043\n",
      "epoch : 0 [5428/21279] Train loss: 0.21491,Valid loss: 0.62094, time : 12.155167579650879 lr : 0.9043820750088043\n",
      "epoch : 0 [5429/21279] Train loss: 0.28346,Valid loss: 0.96505, time : 12.768481969833374 lr : 0.9043820750088043\n",
      "epoch : 0 [5430/21279] Train loss: 0.48185,Valid loss: 6.21545, time : 12.668377876281738 lr : 0.9043820750088043\n",
      "epoch : 0 [5431/21279] Train loss: 0.50658,Valid loss: 1.50579, time : 12.72386646270752 lr : 0.9043820750088043\n",
      "epoch : 0 [5432/21279] Train loss: 0.48578,Valid loss: 1.04743, time : 12.968993425369263 lr : 0.9043820750088043\n",
      "epoch : 0 [5433/21279] Train loss: 0.30698,Valid loss: 0.83495, time : 13.379794836044312 lr : 0.9043820750088043\n",
      "epoch : 0 [5434/21279] Train loss: 0.27338,Valid loss: 0.52424, time : 13.136238098144531 lr : 0.9043820750088043\n",
      "epoch : 0 [5435/21279] Train loss: 0.27136,Valid loss: 0.63395, time : 13.192105531692505 lr : 0.9043820750088043\n",
      "epoch : 0 [5436/21279] Train loss: 0.26243,Valid loss: 0.34342, time : 13.343243837356567 lr : 0.9043820750088043\n",
      "epoch : 0 [5437/21279] Train loss: 0.26685,Valid loss: 0.33940, time : 13.230597972869873 lr : 0.9043820750088043\n",
      "epoch : 0 [5438/21279] Train loss: 0.22660,Valid loss: 0.47539, time : 12.700814485549927 lr : 0.9043820750088043\n",
      "epoch : 0 [5439/21279] Train loss: 0.24563,Valid loss: 0.46072, time : 12.904187440872192 lr : 0.9043820750088043\n",
      "epoch : 0 [5440/21279] Train loss: 0.23272,Valid loss: 0.46799, time : 13.192734718322754 lr : 0.9043820750088043\n",
      "epoch : 0 [5441/21279] Train loss: 0.24325,Valid loss: 0.45846, time : 13.176624774932861 lr : 0.9043820750088043\n",
      "epoch : 0 [5442/21279] Train loss: 0.23254,Valid loss: 0.31593, time : 15.241864919662476 lr : 0.9043820750088043\n",
      "epoch : 0 [5443/21279] Train loss: 0.24059,Valid loss: 0.48404, time : 12.933446645736694 lr : 0.9043820750088043\n",
      "epoch : 0 [5444/21279] Train loss: 0.22095,Valid loss: 0.30239, time : 13.016483068466187 lr : 0.9043820750088043\n",
      "epoch : 0 [5445/21279] Train loss: 0.23244,Valid loss: 0.66766, time : 13.121864080429077 lr : 0.9043820750088043\n",
      "epoch : 0 [5446/21279] Train loss: 0.26168,Valid loss: 0.31666, time : 13.077700853347778 lr : 0.9043820750088043\n",
      "epoch : 0 [5447/21279] Train loss: 0.24796,Valid loss: 0.31838, time : 12.829588651657104 lr : 0.9043820750088043\n",
      "epoch : 0 [5448/21279] Train loss: 0.23236,Valid loss: 0.31465, time : 12.333336114883423 lr : 0.9043820750088043\n",
      "epoch : 0 [5449/21279] Train loss: 0.24321,Valid loss: 0.31723, time : 12.47178602218628 lr : 0.9043820750088043\n",
      "epoch : 0 [5450/21279] Train loss: 0.23311,Valid loss: 0.29298, time : 11.869874477386475 lr : 0.9043820750088043\n",
      "epoch : 0 [5451/21279] Train loss: 0.22098,Valid loss: 0.42337, time : 12.266833543777466 lr : 0.9043820750088043\n",
      "epoch : 0 [5452/21279] Train loss: 0.22187,Valid loss: 0.41906, time : 12.080041646957397 lr : 0.9043820750088043\n",
      "epoch : 0 [5453/21279] Train loss: 0.23357,Valid loss: 0.28678, time : 12.180110931396484 lr : 0.9043820750088043\n",
      "epoch : 0 [5454/21279] Train loss: 0.23145,Valid loss: 0.44558, time : 15.31105661392212 lr : 0.9043820750088043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5455/21279] Train loss: 0.22498,Valid loss: 0.44875, time : 12.21569013595581 lr : 0.9043820750088043\n",
      "epoch : 0 [5456/21279] Train loss: 0.24799,Valid loss: 0.31804, time : 11.904781103134155 lr : 0.9043820750088043\n",
      "epoch : 0 [5457/21279] Train loss: 0.24130,Valid loss: 0.31637, time : 12.043524980545044 lr : 0.9043820750088043\n",
      "epoch : 0 [5458/21279] Train loss: 0.22953,Valid loss: 0.30702, time : 12.21846055984497 lr : 0.9043820750088043\n",
      "epoch : 0 [5459/21279] Train loss: 0.22487,Valid loss: 0.31091, time : 12.50338339805603 lr : 0.9043820750088043\n",
      "epoch : 0 [5460/21279] Train loss: 0.22035,Valid loss: 0.30724, time : 12.296929597854614 lr : 0.9043820750088043\n",
      "epoch : 0 [5461/21279] Train loss: 0.24632,Valid loss: 0.45185, time : 12.49800729751587 lr : 0.9043820750088043\n",
      "epoch : 0 [5462/21279] Train loss: 0.21594,Valid loss: 0.30802, time : 12.329179286956787 lr : 0.9043820750088043\n",
      "epoch : 0 [5463/21279] Train loss: 0.21640,Valid loss: 0.29221, time : 12.368950366973877 lr : 0.9043820750088043\n",
      "epoch : 0 [5464/21279] Train loss: 0.21692,Valid loss: 0.29788, time : 12.790351152420044 lr : 0.9043820750088043\n",
      "epoch : 0 [5465/21279] Train loss: 0.24499,Valid loss: 0.29825, time : 12.854262828826904 lr : 0.9043820750088043\n",
      "epoch : 0 [5466/21279] Train loss: 0.23602,Valid loss: 0.30103, time : 12.781222105026245 lr : 0.9043820750088043\n",
      "epoch : 0 [5467/21279] Train loss: 0.23289,Valid loss: 0.28985, time : 12.496268033981323 lr : 0.9043820750088043\n",
      "epoch : 0 [5468/21279] Train loss: 0.22027,Valid loss: 0.29371, time : 12.60766315460205 lr : 0.9043820750088043\n",
      "epoch : 0 [5469/21279] Train loss: 0.22098,Valid loss: 0.29995, time : 12.578513383865356 lr : 0.9043820750088043\n",
      "epoch : 0 [5470/21279] Train loss: 0.21862,Valid loss: 0.29249, time : 14.699690341949463 lr : 0.9043820750088043\n",
      "epoch : 0 [5471/21279] Train loss: 0.23519,Valid loss: 0.30530, time : 12.494803667068481 lr : 0.9043820750088043\n",
      "epoch : 0 [5472/21279] Train loss: 0.22739,Valid loss: 0.29806, time : 12.72171950340271 lr : 0.9043820750088043\n",
      "epoch : 0 [5473/21279] Train loss: 0.22610,Valid loss: 0.30581, time : 12.776408195495605 lr : 0.9043820750088043\n",
      "epoch : 0 [5474/21279] Train loss: 0.22206,Valid loss: 0.30134, time : 13.05456018447876 lr : 0.9043820750088043\n",
      "epoch : 0 [5475/21279] Train loss: 0.23952,Valid loss: 0.31310, time : 11.985412359237671 lr : 0.9043820750088043\n",
      "epoch : 0 [5476/21279] Train loss: 0.22510,Valid loss: 0.32270, time : 12.560879230499268 lr : 0.9043820750088043\n",
      "epoch : 0 [5477/21279] Train loss: 0.23221,Valid loss: 0.29528, time : 11.851367950439453 lr : 0.9043820750088043\n",
      "epoch : 0 [5478/21279] Train loss: 0.22495,Valid loss: 0.29470, time : 12.335539817810059 lr : 0.9043820750088043\n",
      "epoch : 0 [5479/21279] Train loss: 0.23806,Valid loss: 0.30550, time : 12.708568334579468 lr : 0.9043820750088043\n",
      "epoch : 0 [5480/21279] Train loss: 0.21272,Valid loss: 0.28779, time : 12.378926992416382 lr : 0.9043820750088043\n",
      "epoch : 0 [5481/21279] Train loss: 0.22005,Valid loss: 0.56672, time : 12.416572570800781 lr : 0.9043820750088043\n",
      "epoch : 0 [5482/21279] Train loss: 0.27368,Valid loss: 0.89011, time : 11.912665843963623 lr : 0.9043820750088043\n",
      "epoch : 0 [5483/21279] Train loss: 0.31650,Valid loss: 0.59359, time : 14.038474798202515 lr : 0.9043820750088043\n",
      "epoch : 0 [5484/21279] Train loss: 0.26413,Valid loss: 0.55962, time : 12.237578868865967 lr : 0.9043820750088043\n",
      "epoch : 0 [5485/21279] Train loss: 0.25236,Valid loss: 0.32873, time : 12.657098531723022 lr : 0.9043820750088043\n",
      "epoch : 0 [5486/21279] Train loss: 0.23519,Valid loss: 0.31425, time : 12.739744901657104 lr : 0.9043820750088043\n",
      "epoch : 0 [5487/21279] Train loss: 0.22963,Valid loss: 0.30602, time : 12.717210054397583 lr : 0.9043820750088043\n",
      "epoch : 0 [5488/21279] Train loss: 0.22583,Valid loss: 0.31842, time : 12.926917552947998 lr : 0.9043820750088043\n",
      "epoch : 0 [5489/21279] Train loss: 0.21799,Valid loss: 0.30907, time : 12.20900583267212 lr : 0.9043820750088043\n",
      "epoch : 0 [5490/21279] Train loss: 0.22320,Valid loss: 0.29744, time : 12.427653789520264 lr : 0.9043820750088043\n",
      "epoch : 0 [5491/21279] Train loss: 0.22510,Valid loss: 0.31788, time : 12.863339900970459 lr : 0.9043820750088043\n",
      "epoch : 0 [5492/21279] Train loss: 0.21754,Valid loss: 0.30354, time : 12.836810827255249 lr : 0.9043820750088043\n",
      "epoch : 0 [5493/21279] Train loss: 0.24235,Valid loss: 0.31677, time : 12.527176856994629 lr : 0.9043820750088043\n",
      "epoch : 0 [5494/21279] Train loss: 0.22886,Valid loss: 0.47596, time : 12.889204978942871 lr : 0.9043820750088043\n",
      "epoch : 0 [5495/21279] Train loss: 0.26046,Valid loss: 0.33494, time : 12.71770977973938 lr : 0.9043820750088043\n",
      "epoch : 0 [5496/21279] Train loss: 0.25429,Valid loss: 0.32182, time : 12.77181339263916 lr : 0.9043820750088043\n",
      "epoch : 0 [5497/21279] Train loss: 0.23698,Valid loss: 0.34790, time : 12.322922468185425 lr : 0.9043820750088043\n",
      "epoch : 0 [5498/21279] Train loss: 0.22861,Valid loss: 0.32388, time : 14.21000051498413 lr : 0.9043820750088043\n",
      "epoch : 0 [5499/21279] Train loss: 0.21951,Valid loss: 0.45887, time : 12.981568813323975 lr : 0.8953382542587163\n",
      "epoch : 0 [5500/21279] Train loss: 0.25155,Valid loss: 0.33283, time : 12.85381031036377 lr : 0.8953382542587163\n",
      "epoch : 0 [5501/21279] Train loss: 0.23888,Valid loss: 0.34505, time : 13.100685596466064 lr : 0.8953382542587163\n",
      "epoch : 0 [5502/21279] Train loss: 0.23707,Valid loss: 0.32875, time : 12.716617345809937 lr : 0.8953382542587163\n",
      "epoch : 0 [5503/21279] Train loss: 0.21372,Valid loss: 0.31996, time : 12.552462100982666 lr : 0.8953382542587163\n",
      "epoch : 0 [5504/21279] Train loss: 0.21041,Valid loss: 0.30502, time : 12.64084243774414 lr : 0.8953382542587163\n",
      "epoch : 0 [5505/21279] Train loss: 0.21565,Valid loss: 0.32695, time : 12.403616428375244 lr : 0.8953382542587163\n",
      "epoch : 0 [5506/21279] Train loss: 0.22452,Valid loss: 0.32459, time : 12.40215539932251 lr : 0.8953382542587163\n",
      "epoch : 0 [5507/21279] Train loss: 0.23946,Valid loss: 0.48642, time : 12.53679895401001 lr : 0.8953382542587163\n",
      "epoch : 0 [5508/21279] Train loss: 0.23554,Valid loss: 0.32446, time : 12.596806526184082 lr : 0.8953382542587163\n",
      "epoch : 0 [5509/21279] Train loss: 0.23188,Valid loss: 0.34725, time : 12.678674936294556 lr : 0.8953382542587163\n",
      "epoch : 0 [5510/21279] Train loss: 0.21841,Valid loss: 0.29277, time : 15.04110312461853 lr : 0.8953382542587163\n",
      "epoch : 0 [5511/21279] Train loss: 0.21120,Valid loss: 0.30585, time : 12.940821647644043 lr : 0.8953382542587163\n",
      "epoch : 0 [5512/21279] Train loss: 0.22226,Valid loss: 0.29168, time : 12.633661031723022 lr : 0.8953382542587163\n",
      "epoch : 0 [5513/21279] Train loss: 0.23687,Valid loss: 0.30812, time : 12.976118803024292 lr : 0.8953382542587163\n",
      "epoch : 0 [5514/21279] Train loss: 0.22248,Valid loss: 0.30558, time : 13.010395526885986 lr : 0.8953382542587163\n",
      "epoch : 0 [5515/21279] Train loss: 0.25102,Valid loss: 0.30974, time : 13.386706829071045 lr : 0.8953382542587163\n",
      "epoch : 0 [5516/21279] Train loss: 0.21586,Valid loss: 0.30784, time : 12.805888652801514 lr : 0.8953382542587163\n",
      "epoch : 0 [5517/21279] Train loss: 0.23523,Valid loss: 0.32530, time : 12.759896993637085 lr : 0.8953382542587163\n",
      "epoch : 0 [5518/21279] Train loss: 0.22740,Valid loss: 0.28224, time : 12.415300369262695 lr : 0.8953382542587163\n",
      "epoch : 0 [5519/21279] Train loss: 0.21743,Valid loss: 0.30055, time : 12.30819582939148 lr : 0.8953382542587163\n",
      "epoch : 0 [5520/21279] Train loss: 0.21708,Valid loss: 0.29265, time : 12.623849630355835 lr : 0.8953382542587163\n",
      "epoch : 0 [5521/21279] Train loss: 0.22603,Valid loss: 0.29926, time : 12.602757692337036 lr : 0.8953382542587163\n",
      "epoch : 0 [5522/21279] Train loss: 0.21617,Valid loss: 0.31085, time : 12.558669090270996 lr : 0.8953382542587163\n",
      "epoch : 0 [5523/21279] Train loss: 0.21358,Valid loss: 0.28850, time : 12.654794454574585 lr : 0.8953382542587163\n",
      "epoch : 0 [5524/21279] Train loss: 0.22565,Valid loss: 0.29365, time : 16.31221294403076 lr : 0.8953382542587163\n",
      "epoch : 0 [5525/21279] Train loss: 0.21056,Valid loss: 0.32049, time : 12.288833141326904 lr : 0.8953382542587163\n",
      "epoch : 0 [5526/21279] Train loss: 0.22469,Valid loss: 0.29806, time : 12.84569263458252 lr : 0.8953382542587163\n",
      "epoch : 0 [5527/21279] Train loss: 0.19886,Valid loss: 0.59054, time : 13.053375005722046 lr : 0.8953382542587163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5528/21279] Train loss: 0.21877,Valid loss: 0.33296, time : 12.450769662857056 lr : 0.8953382542587163\n",
      "epoch : 0 [5529/21279] Train loss: 0.23103,Valid loss: 0.33403, time : 13.085484266281128 lr : 0.8953382542587163\n",
      "epoch : 0 [5530/21279] Train loss: 0.20810,Valid loss: 0.30895, time : 12.460151433944702 lr : 0.8953382542587163\n",
      "epoch : 0 [5531/21279] Train loss: 0.21889,Valid loss: 0.29418, time : 12.536157369613647 lr : 0.8953382542587163\n",
      "epoch : 0 [5532/21279] Train loss: 0.21610,Valid loss: 0.32263, time : 12.716541290283203 lr : 0.8953382542587163\n",
      "epoch : 0 [5533/21279] Train loss: 0.22300,Valid loss: 0.55137, time : 12.757593154907227 lr : 0.8953382542587163\n",
      "epoch : 0 [5534/21279] Train loss: 0.24147,Valid loss: 0.44479, time : 12.7045259475708 lr : 0.8953382542587163\n",
      "epoch : 0 [5535/21279] Train loss: 0.22148,Valid loss: 0.29127, time : 12.658130168914795 lr : 0.8953382542587163\n",
      "epoch : 0 [5536/21279] Train loss: 0.21058,Valid loss: 0.31821, time : 16.87203359603882 lr : 0.8953382542587163\n",
      "epoch : 0 [5537/21279] Train loss: 0.21863,Valid loss: 0.30238, time : 13.379560708999634 lr : 0.8953382542587163\n",
      "epoch : 0 [5538/21279] Train loss: 0.22447,Valid loss: 0.45879, time : 13.276859045028687 lr : 0.8953382542587163\n",
      "epoch : 0 [5539/21279] Train loss: 0.20782,Valid loss: 0.30544, time : 12.555726528167725 lr : 0.8953382542587163\n",
      "epoch : 0 [5540/21279] Train loss: 0.23808,Valid loss: 0.31258, time : 12.954149007797241 lr : 0.8953382542587163\n",
      "epoch : 0 [5541/21279] Train loss: 0.20718,Valid loss: 0.30577, time : 12.891679286956787 lr : 0.8953382542587163\n",
      "epoch : 0 [5542/21279] Train loss: 0.20833,Valid loss: 0.30630, time : 12.395140409469604 lr : 0.8953382542587163\n",
      "epoch : 0 [5543/21279] Train loss: 0.23383,Valid loss: 0.29916, time : 12.560352087020874 lr : 0.8953382542587163\n",
      "epoch : 0 [5544/21279] Train loss: 0.22522,Valid loss: 0.31195, time : 12.571218490600586 lr : 0.8953382542587163\n",
      "epoch : 0 [5545/21279] Train loss: 0.22226,Valid loss: 0.30346, time : 12.898823261260986 lr : 0.8953382542587163\n",
      "epoch : 0 [5546/21279] Train loss: 0.20923,Valid loss: 0.30127, time : 12.011184453964233 lr : 0.8953382542587163\n",
      "epoch : 0 [5547/21279] Train loss: 0.22129,Valid loss: 0.29279, time : 12.110671520233154 lr : 0.8953382542587163\n",
      "epoch : 0 [5548/21279] Train loss: 0.23244,Valid loss: 1.32047, time : 13.930708169937134 lr : 0.8953382542587163\n",
      "epoch : 0 [5549/21279] Train loss: 0.27416,Valid loss: 0.92866, time : 12.42136812210083 lr : 0.8953382542587163\n",
      "epoch : 0 [5550/21279] Train loss: 0.33464,Valid loss: 0.94909, time : 12.168662071228027 lr : 0.8953382542587163\n",
      "epoch : 0 [5551/21279] Train loss: 0.56300,Valid loss: 0.91169, time : 12.257085800170898 lr : 0.8953382542587163\n",
      "epoch : 0 [5552/21279] Train loss: 0.49311,Valid loss: 0.50458, time : 12.288996934890747 lr : 0.8953382542587163\n",
      "epoch : 0 [5553/21279] Train loss: 0.30343,Valid loss: 0.51861, time : 12.731807231903076 lr : 0.8953382542587163\n",
      "epoch : 0 [5554/21279] Train loss: 0.26456,Valid loss: 0.31114, time : 12.904867172241211 lr : 0.8953382542587163\n",
      "epoch : 0 [5555/21279] Train loss: 0.24107,Valid loss: 0.30198, time : 12.391337633132935 lr : 0.8953382542587163\n",
      "epoch : 0 [5556/21279] Train loss: 0.22436,Valid loss: 0.30855, time : 12.777248859405518 lr : 0.8953382542587163\n",
      "epoch : 0 [5557/21279] Train loss: 0.23336,Valid loss: 0.29089, time : 12.797313690185547 lr : 0.8953382542587163\n",
      "epoch : 0 [5558/21279] Train loss: 0.23319,Valid loss: 0.29483, time : 13.125218868255615 lr : 0.8953382542587163\n",
      "epoch : 0 [5559/21279] Train loss: 0.22006,Valid loss: 0.28303, time : 13.005321502685547 lr : 0.8953382542587163\n",
      "epoch : 0 [5560/21279] Train loss: 0.23151,Valid loss: 0.27920, time : 12.89432954788208 lr : 0.8953382542587163\n",
      "epoch : 0 [5561/21279] Train loss: 0.22192,Valid loss: 0.29498, time : 13.007652282714844 lr : 0.8953382542587163\n",
      "epoch : 0 [5562/21279] Train loss: 0.23513,Valid loss: 0.29922, time : 12.600650548934937 lr : 0.8953382542587163\n",
      "epoch : 0 [5563/21279] Train loss: 0.22164,Valid loss: 0.29935, time : 12.392662048339844 lr : 0.8953382542587163\n",
      "epoch : 0 [5564/21279] Train loss: 0.22891,Valid loss: 0.29575, time : 16.947210550308228 lr : 0.8953382542587163\n",
      "epoch : 0 [5565/21279] Train loss: 0.22955,Valid loss: 0.30520, time : 12.454484939575195 lr : 0.8953382542587163\n",
      "epoch : 0 [5566/21279] Train loss: 0.22209,Valid loss: 0.28731, time : 12.045103788375854 lr : 0.8953382542587163\n",
      "epoch : 0 [5567/21279] Train loss: 0.22107,Valid loss: 0.28538, time : 11.974411010742188 lr : 0.8953382542587163\n",
      "epoch : 0 [5568/21279] Train loss: 0.21035,Valid loss: 0.30968, time : 11.744827032089233 lr : 0.8953382542587163\n",
      "epoch : 0 [5569/21279] Train loss: 0.22603,Valid loss: 0.28737, time : 12.14091682434082 lr : 0.8953382542587163\n",
      "epoch : 0 [5570/21279] Train loss: 0.21583,Valid loss: 0.27758, time : 11.5038743019104 lr : 0.8953382542587163\n",
      "epoch : 0 [5571/21279] Train loss: 0.21204,Valid loss: 0.27567, time : 11.806115865707397 lr : 0.8953382542587163\n",
      "epoch : 0 [5572/21279] Train loss: 0.21048,Valid loss: 0.28252, time : 11.898506164550781 lr : 0.8953382542587163\n",
      "epoch : 0 [5573/21279] Train loss: 0.22085,Valid loss: 0.27346, time : 11.611220121383667 lr : 0.8953382542587163\n",
      "epoch : 0 [5574/21279] Train loss: 0.23154,Valid loss: 0.28456, time : 12.662949323654175 lr : 0.8953382542587163\n",
      "epoch : 0 [5575/21279] Train loss: 0.21681,Valid loss: 0.29635, time : 12.844107627868652 lr : 0.8953382542587163\n",
      "epoch : 0 [5576/21279] Train loss: 0.20588,Valid loss: 0.30780, time : 15.115540981292725 lr : 0.8953382542587163\n",
      "epoch : 0 [5577/21279] Train loss: 0.23082,Valid loss: 0.29046, time : 12.802985191345215 lr : 0.8953382542587163\n",
      "epoch : 0 [5578/21279] Train loss: 0.22251,Valid loss: 0.27596, time : 12.197840690612793 lr : 0.8953382542587163\n",
      "epoch : 0 [5579/21279] Train loss: 0.23551,Valid loss: 0.28612, time : 12.410884857177734 lr : 0.8953382542587163\n",
      "epoch : 0 [5580/21279] Train loss: 0.22138,Valid loss: 0.29618, time : 12.589595317840576 lr : 0.8953382542587163\n",
      "epoch : 0 [5581/21279] Train loss: 0.21436,Valid loss: 0.28539, time : 12.339224576950073 lr : 0.8953382542587163\n",
      "epoch : 0 [5582/21279] Train loss: 0.21568,Valid loss: 0.81896, time : 12.357950448989868 lr : 0.8953382542587163\n",
      "epoch : 0 [5583/21279] Train loss: 0.23178,Valid loss: 1.16681, time : 12.638002634048462 lr : 0.8953382542587163\n",
      "epoch : 0 [5584/21279] Train loss: 0.24147,Valid loss: 0.32450, time : 12.820086479187012 lr : 0.8953382542587163\n",
      "epoch : 0 [5585/21279] Train loss: 0.22289,Valid loss: 0.32451, time : 12.843566656112671 lr : 0.8953382542587163\n",
      "epoch : 0 [5586/21279] Train loss: 0.22796,Valid loss: 0.44110, time : 12.384622812271118 lr : 0.8953382542587163\n",
      "epoch : 0 [5587/21279] Train loss: 0.21226,Valid loss: 0.33338, time : 12.64323091506958 lr : 0.8953382542587163\n",
      "epoch : 0 [5588/21279] Train loss: 0.23336,Valid loss: 0.33511, time : 12.080123662948608 lr : 0.8953382542587163\n",
      "epoch : 0 [5589/21279] Train loss: 0.22048,Valid loss: 0.30936, time : 12.568769931793213 lr : 0.8953382542587163\n",
      "epoch : 0 [5590/21279] Train loss: 0.20493,Valid loss: 0.29842, time : 11.84098482131958 lr : 0.8953382542587163\n",
      "epoch : 0 [5591/21279] Train loss: 0.22183,Valid loss: 0.29077, time : 12.299020290374756 lr : 0.8953382542587163\n",
      "epoch : 0 [5592/21279] Train loss: 0.20472,Valid loss: 0.29352, time : 15.670387983322144 lr : 0.8953382542587163\n",
      "epoch : 0 [5593/21279] Train loss: 0.22272,Valid loss: 0.29228, time : 12.462620973587036 lr : 0.8953382542587163\n",
      "epoch : 0 [5594/21279] Train loss: 0.21720,Valid loss: 0.28686, time : 12.420988321304321 lr : 0.8953382542587163\n",
      "epoch : 0 [5595/21279] Train loss: 0.20895,Valid loss: 0.28533, time : 12.257173538208008 lr : 0.8953382542587163\n",
      "epoch : 0 [5596/21279] Train loss: 0.20728,Valid loss: 0.29008, time : 12.315270185470581 lr : 0.8953382542587163\n",
      "epoch : 0 [5597/21279] Train loss: 0.21966,Valid loss: 0.29276, time : 12.741233348846436 lr : 0.8953382542587163\n",
      "epoch : 0 [5598/21279] Train loss: 0.23507,Valid loss: 0.29671, time : 12.604530811309814 lr : 0.8953382542587163\n",
      "epoch : 0 [5599/21279] Train loss: 0.21263,Valid loss: 0.29801, time : 11.994786977767944 lr : 0.8953382542587163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5600/21279] Train loss: 0.24261,Valid loss: 0.42988, time : 12.160428524017334 lr : 0.8953382542587163\n",
      "epoch : 0 [5601/21279] Train loss: 0.23613,Valid loss: 0.30278, time : 12.229682445526123 lr : 0.8953382542587163\n",
      "epoch : 0 [5602/21279] Train loss: 0.21441,Valid loss: 0.28970, time : 11.63080620765686 lr : 0.8953382542587163\n",
      "epoch : 0 [5603/21279] Train loss: 0.20002,Valid loss: 0.27773, time : 12.504825115203857 lr : 0.8953382542587163\n",
      "epoch : 0 [5604/21279] Train loss: 0.21764,Valid loss: 0.27639, time : 11.7261483669281 lr : 0.8953382542587163\n",
      "epoch : 0 [5605/21279] Train loss: 0.22615,Valid loss: 0.28622, time : 14.312845945358276 lr : 0.8953382542587163\n",
      "epoch : 0 [5606/21279] Train loss: 0.22179,Valid loss: 0.29388, time : 12.036719799041748 lr : 0.8953382542587163\n",
      "epoch : 0 [5607/21279] Train loss: 0.21163,Valid loss: 0.82036, time : 12.271899700164795 lr : 0.8953382542587163\n",
      "epoch : 0 [5608/21279] Train loss: 0.20784,Valid loss: 0.48038, time : 12.347226858139038 lr : 0.8953382542587163\n",
      "epoch : 0 [5609/21279] Train loss: 0.22118,Valid loss: 0.33142, time : 12.52013349533081 lr : 0.8953382542587163\n",
      "epoch : 0 [5610/21279] Train loss: 0.22285,Valid loss: 0.28738, time : 11.790221929550171 lr : 0.8953382542587163\n",
      "epoch : 0 [5611/21279] Train loss: 0.21612,Valid loss: 0.28808, time : 12.504172325134277 lr : 0.8953382542587163\n",
      "epoch : 0 [5612/21279] Train loss: 0.23583,Valid loss: 0.27861, time : 12.999390125274658 lr : 0.8953382542587163\n",
      "epoch : 0 [5613/21279] Train loss: 0.22359,Valid loss: 0.31156, time : 12.617863416671753 lr : 0.8953382542587163\n",
      "epoch : 0 [5614/21279] Train loss: 0.21466,Valid loss: 0.29063, time : 12.965486764907837 lr : 0.8953382542587163\n",
      "epoch : 0 [5615/21279] Train loss: 0.23161,Valid loss: 0.32726, time : 12.974349737167358 lr : 0.8953382542587163\n",
      "epoch : 0 [5616/21279] Train loss: 0.32370,Valid loss: 0.52035, time : 12.91015625 lr : 0.8953382542587163\n",
      "epoch : 0 [5617/21279] Train loss: 0.25625,Valid loss: 0.57869, time : 11.783148050308228 lr : 0.8953382542587163\n",
      "epoch : 0 [5618/21279] Train loss: 0.26379,Valid loss: 0.39444, time : 12.193223237991333 lr : 0.8953382542587163\n",
      "epoch : 0 [5619/21279] Train loss: 0.28689,Valid loss: 0.42662, time : 12.666108131408691 lr : 0.8953382542587163\n",
      "epoch : 0 [5620/21279] Train loss: 0.28406,Valid loss: 0.37261, time : 15.562483787536621 lr : 0.8953382542587163\n",
      "epoch : 0 [5621/21279] Train loss: 0.22673,Valid loss: 0.32826, time : 13.271917581558228 lr : 0.8953382542587163\n",
      "epoch : 0 [5622/21279] Train loss: 0.22436,Valid loss: 0.29256, time : 13.2655611038208 lr : 0.8953382542587163\n",
      "epoch : 0 [5623/21279] Train loss: 0.22341,Valid loss: 0.30298, time : 12.85195279121399 lr : 0.8953382542587163\n",
      "epoch : 0 [5624/21279] Train loss: 0.22254,Valid loss: 0.29597, time : 12.814863920211792 lr : 0.8953382542587163\n",
      "epoch : 0 [5625/21279] Train loss: 0.22094,Valid loss: 0.30065, time : 12.423551082611084 lr : 0.8953382542587163\n",
      "epoch : 0 [5626/21279] Train loss: 0.22134,Valid loss: 0.29418, time : 13.14135193824768 lr : 0.8953382542587163\n",
      "epoch : 0 [5627/21279] Train loss: 0.20729,Valid loss: 0.28617, time : 13.15579104423523 lr : 0.8953382542587163\n",
      "epoch : 0 [5628/21279] Train loss: 0.21299,Valid loss: 0.30929, time : 12.687660217285156 lr : 0.8953382542587163\n",
      "epoch : 0 [5629/21279] Train loss: 0.22289,Valid loss: 0.27534, time : 13.172987461090088 lr : 0.8953382542587163\n",
      "epoch : 0 [5630/21279] Train loss: 0.22101,Valid loss: 0.33936, time : 12.905681371688843 lr : 0.8953382542587163\n",
      "epoch : 0 [5631/21279] Train loss: 0.21896,Valid loss: 0.29510, time : 12.568657398223877 lr : 0.8953382542587163\n",
      "epoch : 0 [5632/21279] Train loss: 0.23117,Valid loss: 0.29596, time : 14.407837867736816 lr : 0.8953382542587163\n",
      "epoch : 0 [5633/21279] Train loss: 0.24127,Valid loss: 0.28533, time : 12.631771087646484 lr : 0.8953382542587163\n",
      "epoch : 0 [5634/21279] Train loss: 0.20792,Valid loss: 0.30149, time : 13.067458868026733 lr : 0.8953382542587163\n",
      "epoch : 0 [5635/21279] Train loss: 0.21145,Valid loss: 0.27361, time : 13.430161476135254 lr : 0.8953382542587163\n",
      "epoch : 0 [5636/21279] Train loss: 0.21141,Valid loss: 0.29281, time : 13.356761693954468 lr : 0.8953382542587163\n",
      "epoch : 0 [5637/21279] Train loss: 0.20870,Valid loss: 0.28536, time : 13.394396781921387 lr : 0.8953382542587163\n",
      "epoch : 0 [5638/21279] Train loss: 0.19151,Valid loss: 0.28439, time : 13.326013803482056 lr : 0.8953382542587163\n",
      "epoch : 0 [5639/21279] Train loss: 0.22140,Valid loss: 0.28159, time : 13.487757205963135 lr : 0.8953382542587163\n",
      "epoch : 0 [5640/21279] Train loss: 0.21736,Valid loss: 0.27276, time : 13.194509983062744 lr : 0.8953382542587163\n",
      "epoch : 0 [5641/21279] Train loss: 0.21486,Valid loss: 0.30590, time : 13.397706031799316 lr : 0.8953382542587163\n",
      "epoch : 0 [5642/21279] Train loss: 0.20758,Valid loss: 0.27383, time : 12.017660856246948 lr : 0.8953382542587163\n",
      "epoch : 0 [5643/21279] Train loss: 0.21658,Valid loss: 0.28588, time : 12.464441061019897 lr : 0.8953382542587163\n",
      "epoch : 0 [5644/21279] Train loss: 0.21819,Valid loss: 0.28251, time : 12.671519994735718 lr : 0.8953382542587163\n",
      "epoch : 0 [5645/21279] Train loss: 0.19711,Valid loss: 0.27636, time : 13.28343939781189 lr : 0.8953382542587163\n",
      "epoch : 0 [5646/21279] Train loss: 0.21611,Valid loss: 0.28622, time : 14.790966033935547 lr : 0.8953382542587163\n",
      "epoch : 0 [5647/21279] Train loss: 0.21693,Valid loss: 0.28056, time : 13.361610889434814 lr : 0.8953382542587163\n",
      "epoch : 0 [5648/21279] Train loss: 0.22143,Valid loss: 0.31182, time : 12.988411664962769 lr : 0.8953382542587163\n",
      "epoch : 0 [5649/21279] Train loss: 0.20186,Valid loss: 0.29929, time : 13.108351707458496 lr : 0.8953382542587163\n",
      "epoch : 0 [5650/21279] Train loss: 0.20914,Valid loss: 0.30730, time : 12.840346574783325 lr : 0.8953382542587163\n",
      "epoch : 0 [5651/21279] Train loss: 0.20913,Valid loss: 0.29124, time : 13.019231796264648 lr : 0.8953382542587163\n",
      "epoch : 0 [5652/21279] Train loss: 0.20785,Valid loss: 0.28972, time : 12.212083101272583 lr : 0.8953382542587163\n",
      "epoch : 0 [5653/21279] Train loss: 0.20527,Valid loss: 0.29215, time : 12.787206649780273 lr : 0.8953382542587163\n",
      "epoch : 0 [5654/21279] Train loss: 0.20719,Valid loss: 0.28396, time : 12.224323034286499 lr : 0.8953382542587163\n",
      "epoch : 0 [5655/21279] Train loss: 0.21179,Valid loss: 0.29024, time : 12.893143892288208 lr : 0.8953382542587163\n",
      "epoch : 0 [5656/21279] Train loss: 0.19969,Valid loss: 0.28398, time : 12.20192837715149 lr : 0.8953382542587163\n",
      "epoch : 0 [5657/21279] Train loss: 0.20794,Valid loss: 0.27196, time : 12.4157235622406 lr : 0.8953382542587163\n",
      "epoch : 0 [5658/21279] Train loss: 0.20132,Valid loss: 0.27592, time : 19.215654850006104 lr : 0.8953382542587163\n",
      "epoch : 0 [5659/21279] Train loss: 0.23344,Valid loss: 0.28855, time : 12.47316575050354 lr : 0.8953382542587163\n",
      "epoch : 0 [5660/21279] Train loss: 0.22729,Valid loss: 0.29103, time : 12.573854207992554 lr : 0.8953382542587163\n",
      "epoch : 0 [5661/21279] Train loss: 0.19877,Valid loss: 0.28376, time : 12.598830938339233 lr : 0.8953382542587163\n",
      "epoch : 0 [5662/21279] Train loss: 0.20685,Valid loss: 0.28006, time : 11.530436277389526 lr : 0.8953382542587163\n",
      "epoch : 0 [5663/21279] Train loss: 0.21277,Valid loss: 0.30554, time : 11.477519512176514 lr : 0.8953382542587163\n",
      "epoch : 0 [5664/21279] Train loss: 0.22419,Valid loss: 0.31433, time : 12.298774719238281 lr : 0.8953382542587163\n",
      "epoch : 0 [5665/21279] Train loss: 0.20745,Valid loss: 0.28455, time : 12.527938604354858 lr : 0.8953382542587163\n",
      "epoch : 0 [5666/21279] Train loss: 0.20865,Valid loss: 0.27361, time : 12.636725187301636 lr : 0.8953382542587163\n",
      "epoch : 0 [5667/21279] Train loss: 0.20951,Valid loss: 0.27294, time : 12.86949348449707 lr : 0.8953382542587163\n",
      "epoch : 0 [5668/21279] Train loss: 0.20680,Valid loss: 0.26695, time : 12.281652212142944 lr : 0.8953382542587163\n",
      "epoch : 0 [5669/21279] Train loss: 0.20050,Valid loss: 0.28946, time : 12.691788673400879 lr : 0.8953382542587163\n",
      "epoch : 0 [5670/21279] Train loss: 0.19993,Valid loss: 0.29184, time : 12.85723090171814 lr : 0.8953382542587163\n",
      "epoch : 0 [5671/21279] Train loss: 0.20480,Valid loss: 0.28095, time : 12.937316656112671 lr : 0.8953382542587163\n",
      "epoch : 0 [5672/21279] Train loss: 0.20915,Valid loss: 0.27799, time : 12.338057041168213 lr : 0.8953382542587163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5673/21279] Train loss: 0.22205,Valid loss: 0.28608, time : 12.170054912567139 lr : 0.8953382542587163\n",
      "epoch : 0 [5674/21279] Train loss: 0.20647,Valid loss: 0.27604, time : 13.699732780456543 lr : 0.8953382542587163\n",
      "epoch : 0 [5675/21279] Train loss: 0.22306,Valid loss: 0.31096, time : 12.726357221603394 lr : 0.8953382542587163\n",
      "epoch : 0 [5676/21279] Train loss: 0.20738,Valid loss: 0.28744, time : 12.30353045463562 lr : 0.8953382542587163\n",
      "epoch : 0 [5677/21279] Train loss: 0.21255,Valid loss: 0.28683, time : 12.429491758346558 lr : 0.8953382542587163\n",
      "epoch : 0 [5678/21279] Train loss: 0.21070,Valid loss: 0.31239, time : 12.474599361419678 lr : 0.8953382542587163\n",
      "epoch : 0 [5679/21279] Train loss: 0.21493,Valid loss: 0.33248, time : 12.247869491577148 lr : 0.8953382542587163\n",
      "epoch : 0 [5680/21279] Train loss: 0.22456,Valid loss: 0.29835, time : 12.07025694847107 lr : 0.8953382542587163\n",
      "epoch : 0 [5681/21279] Train loss: 0.22435,Valid loss: 0.29926, time : 12.48981523513794 lr : 0.8953382542587163\n",
      "epoch : 0 [5682/21279] Train loss: 0.21001,Valid loss: 0.30859, time : 12.557193040847778 lr : 0.8953382542587163\n",
      "epoch : 0 [5683/21279] Train loss: 0.23307,Valid loss: 0.30510, time : 12.341527700424194 lr : 0.8953382542587163\n",
      "epoch : 0 [5684/21279] Train loss: 0.20570,Valid loss: 0.28800, time : 11.716211795806885 lr : 0.8953382542587163\n",
      "epoch : 0 [5685/21279] Train loss: 0.21431,Valid loss: 0.28636, time : 12.153677463531494 lr : 0.8953382542587163\n",
      "epoch : 0 [5686/21279] Train loss: 0.22154,Valid loss: 0.27716, time : 13.811413764953613 lr : 0.8953382542587163\n",
      "epoch : 0 [5687/21279] Train loss: 0.21195,Valid loss: 0.28312, time : 12.140692234039307 lr : 0.8953382542587163\n",
      "epoch : 0 [5688/21279] Train loss: 0.20237,Valid loss: 0.28085, time : 12.682031631469727 lr : 0.8953382542587163\n",
      "epoch : 0 [5689/21279] Train loss: 0.22035,Valid loss: 0.27308, time : 12.691007614135742 lr : 0.8953382542587163\n",
      "epoch : 0 [5690/21279] Train loss: 0.22768,Valid loss: 0.46809, time : 12.711902379989624 lr : 0.8953382542587163\n",
      "epoch : 0 [5691/21279] Train loss: 0.23466,Valid loss: 0.33284, time : 12.080057859420776 lr : 0.8953382542587163\n",
      "epoch : 0 [5692/21279] Train loss: 0.26804,Valid loss: 0.96082, time : 12.512524127960205 lr : 0.8953382542587163\n",
      "epoch : 0 [5693/21279] Train loss: 0.47869,Valid loss: 0.44658, time : 12.515809297561646 lr : 0.8953382542587163\n",
      "epoch : 0 [5694/21279] Train loss: 0.33914,Valid loss: 0.48264, time : 12.19795846939087 lr : 0.8953382542587163\n",
      "epoch : 0 [5695/21279] Train loss: 0.31089,Valid loss: 0.76205, time : 11.969128370285034 lr : 0.8953382542587163\n",
      "epoch : 0 [5696/21279] Train loss: 0.26595,Valid loss: 0.33209, time : 12.67634654045105 lr : 0.8953382542587163\n",
      "epoch : 0 [5697/21279] Train loss: 0.22383,Valid loss: 0.32612, time : 12.60583209991455 lr : 0.8953382542587163\n",
      "epoch : 0 [5698/21279] Train loss: 0.23688,Valid loss: 1.34589, time : 11.658752202987671 lr : 0.8953382542587163\n",
      "epoch : 0 [5699/21279] Train loss: 0.56144,Valid loss: 3.45565, time : 12.475687265396118 lr : 0.8953382542587163\n",
      "epoch : 0 [5700/21279] Train loss: 0.40473,Valid loss: 1.10318, time : 12.58036208152771 lr : 0.8953382542587163\n",
      "epoch : 0 [5701/21279] Train loss: 0.31440,Valid loss: 0.75157, time : 12.006594181060791 lr : 0.8953382542587163\n",
      "epoch : 0 [5702/21279] Train loss: 0.26121,Valid loss: 0.71441, time : 13.53023886680603 lr : 0.8953382542587163\n",
      "epoch : 0 [5703/21279] Train loss: 0.24039,Valid loss: 0.31718, time : 11.953142642974854 lr : 0.8953382542587163\n",
      "epoch : 0 [5704/21279] Train loss: 0.23071,Valid loss: 0.32472, time : 12.102180480957031 lr : 0.8953382542587163\n",
      "epoch : 0 [5705/21279] Train loss: 0.22625,Valid loss: 0.31531, time : 12.383407592773438 lr : 0.8953382542587163\n",
      "epoch : 0 [5706/21279] Train loss: 0.22780,Valid loss: 0.29664, time : 11.909764289855957 lr : 0.8953382542587163\n",
      "epoch : 0 [5707/21279] Train loss: 0.21320,Valid loss: 0.29983, time : 12.049250602722168 lr : 0.8953382542587163\n",
      "epoch : 0 [5708/21279] Train loss: 0.22266,Valid loss: 0.30867, time : 11.919633388519287 lr : 0.8953382542587163\n",
      "epoch : 0 [5709/21279] Train loss: 0.21328,Valid loss: 0.28654, time : 12.501632690429688 lr : 0.8953382542587163\n",
      "epoch : 0 [5710/21279] Train loss: 0.22562,Valid loss: 0.28544, time : 11.552171230316162 lr : 0.8953382542587163\n",
      "epoch : 0 [5711/21279] Train loss: 0.21997,Valid loss: 0.27709, time : 11.866771697998047 lr : 0.8953382542587163\n",
      "epoch : 0 [5712/21279] Train loss: 0.19445,Valid loss: 0.28903, time : 11.563980340957642 lr : 0.8953382542587163\n",
      "epoch : 0 [5713/21279] Train loss: 0.21134,Valid loss: 0.26763, time : 12.291417121887207 lr : 0.8953382542587163\n",
      "epoch : 0 [5714/21279] Train loss: 0.20645,Valid loss: 0.36710, time : 12.568462610244751 lr : 0.8953382542587163\n",
      "epoch : 0 [5715/21279] Train loss: 0.27530,Valid loss: 0.47343, time : 14.755034923553467 lr : 0.8953382542587163\n",
      "epoch : 0 [5716/21279] Train loss: 0.23215,Valid loss: 0.30278, time : 12.84177541732788 lr : 0.8953382542587163\n",
      "epoch : 0 [5717/21279] Train loss: 0.21062,Valid loss: 0.27524, time : 12.529829740524292 lr : 0.8953382542587163\n",
      "epoch : 0 [5718/21279] Train loss: 0.20826,Valid loss: 0.30635, time : 12.605268716812134 lr : 0.8953382542587163\n",
      "epoch : 0 [5719/21279] Train loss: 0.21311,Valid loss: 0.27954, time : 12.987775564193726 lr : 0.8953382542587163\n",
      "epoch : 0 [5720/21279] Train loss: 0.21342,Valid loss: 0.28738, time : 13.015211343765259 lr : 0.8953382542587163\n",
      "epoch : 0 [5721/21279] Train loss: 0.20912,Valid loss: 0.41713, time : 13.2640061378479 lr : 0.8953382542587163\n",
      "epoch : 0 [5722/21279] Train loss: 0.20827,Valid loss: 0.27641, time : 12.68547797203064 lr : 0.8953382542587163\n",
      "epoch : 0 [5723/21279] Train loss: 0.21390,Valid loss: 0.48537, time : 12.646658897399902 lr : 0.8953382542587163\n",
      "epoch : 0 [5724/21279] Train loss: 0.21857,Valid loss: 0.29549, time : 12.408430814743042 lr : 0.8953382542587163\n",
      "epoch : 0 [5725/21279] Train loss: 0.23293,Valid loss: 0.26838, time : 12.70297360420227 lr : 0.8953382542587163\n",
      "epoch : 0 [5726/21279] Train loss: 0.22272,Valid loss: 0.28953, time : 12.109074115753174 lr : 0.8953382542587163\n",
      "epoch : 0 [5727/21279] Train loss: 0.22025,Valid loss: 0.51295, time : 12.015204429626465 lr : 0.8953382542587163\n",
      "epoch : 0 [5728/21279] Train loss: 0.20235,Valid loss: 0.41130, time : 12.324174880981445 lr : 0.8953382542587163\n",
      "epoch : 0 [5729/21279] Train loss: 0.23320,Valid loss: 0.27961, time : 12.371879577636719 lr : 0.8953382542587163\n",
      "epoch : 0 [5730/21279] Train loss: 0.21201,Valid loss: 0.41556, time : 15.589897871017456 lr : 0.8953382542587163\n",
      "epoch : 0 [5731/21279] Train loss: 0.20731,Valid loss: 0.27803, time : 12.116333723068237 lr : 0.8953382542587163\n",
      "epoch : 0 [5732/21279] Train loss: 0.19789,Valid loss: 0.27894, time : 12.107443571090698 lr : 0.8953382542587163\n",
      "epoch : 0 [5733/21279] Train loss: 0.19992,Valid loss: 0.29788, time : 12.75919795036316 lr : 0.8953382542587163\n",
      "epoch : 0 [5734/21279] Train loss: 0.20931,Valid loss: 0.43004, time : 12.443598747253418 lr : 0.8953382542587163\n",
      "epoch : 0 [5735/21279] Train loss: 0.22318,Valid loss: 0.58249, time : 12.863738536834717 lr : 0.8953382542587163\n",
      "epoch : 0 [5736/21279] Train loss: 0.22496,Valid loss: 0.27997, time : 12.490500450134277 lr : 0.8953382542587163\n",
      "epoch : 0 [5737/21279] Train loss: 0.22484,Valid loss: 0.42865, time : 12.201829195022583 lr : 0.8953382542587163\n",
      "epoch : 0 [5738/21279] Train loss: 0.22420,Valid loss: 0.29891, time : 11.848744630813599 lr : 0.8953382542587163\n",
      "epoch : 0 [5739/21279] Train loss: 0.21138,Valid loss: 0.27722, time : 12.957659482955933 lr : 0.8953382542587163\n",
      "epoch : 0 [5740/21279] Train loss: 0.20617,Valid loss: 0.34927, time : 12.685266971588135 lr : 0.8953382542587163\n",
      "epoch : 0 [5741/21279] Train loss: 0.22540,Valid loss: 0.27976, time : 13.091872692108154 lr : 0.8953382542587163\n",
      "epoch : 0 [5742/21279] Train loss: 0.22307,Valid loss: 0.26740, time : 14.573792934417725 lr : 0.8953382542587163\n",
      "epoch : 0 [5743/21279] Train loss: 0.20723,Valid loss: 0.27885, time : 12.358007907867432 lr : 0.8953382542587163\n",
      "epoch : 0 [5744/21279] Train loss: 0.22243,Valid loss: 0.28144, time : 12.305873155593872 lr : 0.8953382542587163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5745/21279] Train loss: 0.20042,Valid loss: 0.26565, time : 12.812299489974976 lr : 0.8953382542587163\n",
      "epoch : 0 [5746/21279] Train loss: 0.21109,Valid loss: 0.28404, time : 12.632340908050537 lr : 0.8953382542587163\n",
      "epoch : 0 [5747/21279] Train loss: 0.21360,Valid loss: 0.30092, time : 12.77607536315918 lr : 0.8953382542587163\n",
      "epoch : 0 [5748/21279] Train loss: 0.20780,Valid loss: 0.27961, time : 12.706265687942505 lr : 0.8953382542587163\n",
      "epoch : 0 [5749/21279] Train loss: 0.19618,Valid loss: 0.50700, time : 12.10851788520813 lr : 0.8953382542587163\n",
      "epoch : 0 [5750/21279] Train loss: 0.20924,Valid loss: 0.26229, time : 12.66460919380188 lr : 0.8953382542587163\n",
      "epoch : 0 [5751/21279] Train loss: 0.20023,Valid loss: 0.28819, time : 12.356524467468262 lr : 0.8953382542587163\n",
      "epoch : 0 [5752/21279] Train loss: 0.21915,Valid loss: 0.27375, time : 12.457216262817383 lr : 0.8953382542587163\n",
      "epoch : 0 [5753/21279] Train loss: 0.21611,Valid loss: 0.26849, time : 12.350821018218994 lr : 0.8953382542587163\n",
      "epoch : 0 [5754/21279] Train loss: 0.22253,Valid loss: 0.30522, time : 12.560221910476685 lr : 0.8953382542587163\n",
      "epoch : 0 [5755/21279] Train loss: 0.20139,Valid loss: 0.27630, time : 12.943977355957031 lr : 0.8953382542587163\n",
      "epoch : 0 [5756/21279] Train loss: 0.20956,Valid loss: 0.26637, time : 14.688064336776733 lr : 0.8953382542587163\n",
      "epoch : 0 [5757/21279] Train loss: 0.19031,Valid loss: 0.27758, time : 12.671053647994995 lr : 0.8953382542587163\n",
      "epoch : 0 [5758/21279] Train loss: 0.19591,Valid loss: 0.27226, time : 12.403073072433472 lr : 0.8953382542587163\n",
      "epoch : 0 [5759/21279] Train loss: 0.19669,Valid loss: 0.27569, time : 12.300007581710815 lr : 0.8953382542587163\n",
      "epoch : 0 [5760/21279] Train loss: 0.22562,Valid loss: 0.26765, time : 13.045498847961426 lr : 0.8953382542587163\n",
      "epoch : 0 [5761/21279] Train loss: 0.22302,Valid loss: 0.26428, time : 13.086040258407593 lr : 0.8953382542587163\n",
      "epoch : 0 [5762/21279] Train loss: 0.20630,Valid loss: 0.26524, time : 12.327564239501953 lr : 0.8953382542587163\n",
      "epoch : 0 [5763/21279] Train loss: 0.20053,Valid loss: 0.27000, time : 12.173083066940308 lr : 0.8953382542587163\n",
      "epoch : 0 [5764/21279] Train loss: 0.20380,Valid loss: 0.42364, time : 12.165794372558594 lr : 0.8953382542587163\n",
      "epoch : 0 [5765/21279] Train loss: 0.20791,Valid loss: 0.26676, time : 12.039989709854126 lr : 0.8953382542587163\n",
      "epoch : 0 [5766/21279] Train loss: 0.21160,Valid loss: 0.27582, time : 11.791340827941895 lr : 0.8953382542587163\n",
      "epoch : 0 [5767/21279] Train loss: 0.20794,Valid loss: 0.26645, time : 11.803672790527344 lr : 0.8953382542587163\n",
      "epoch : 0 [5768/21279] Train loss: 0.19103,Valid loss: 0.26011, time : 15.127157211303711 lr : 0.8953382542587163\n",
      "epoch : 0 [5769/21279] Train loss: 0.20573,Valid loss: 0.26009, time : 12.314008474349976 lr : 0.8953382542587163\n",
      "epoch : 0 [5770/21279] Train loss: 0.20817,Valid loss: 0.42471, time : 12.213661193847656 lr : 0.8953382542587163\n",
      "epoch : 0 [5771/21279] Train loss: 0.28919,Valid loss: 0.64140, time : 12.299144744873047 lr : 0.8953382542587163\n",
      "epoch : 0 [5772/21279] Train loss: 0.23773,Valid loss: 0.31218, time : 12.52055835723877 lr : 0.8953382542587163\n",
      "epoch : 0 [5773/21279] Train loss: 0.22678,Valid loss: 0.32410, time : 12.159343242645264 lr : 0.8953382542587163\n",
      "epoch : 0 [5774/21279] Train loss: 0.21049,Valid loss: 0.30952, time : 12.730560302734375 lr : 0.8953382542587163\n",
      "epoch : 0 [5775/21279] Train loss: 0.21194,Valid loss: 0.30622, time : 12.101565837860107 lr : 0.8953382542587163\n",
      "epoch : 0 [5776/21279] Train loss: 0.21881,Valid loss: 0.29274, time : 12.233354806900024 lr : 0.8953382542587163\n",
      "epoch : 0 [5777/21279] Train loss: 0.20869,Valid loss: 0.31720, time : 12.357946157455444 lr : 0.8953382542587163\n",
      "epoch : 0 [5778/21279] Train loss: 0.21139,Valid loss: 0.27016, time : 12.276138067245483 lr : 0.8953382542587163\n",
      "epoch : 0 [5779/21279] Train loss: 0.19826,Valid loss: 0.27017, time : 11.978580236434937 lr : 0.8953382542587163\n",
      "epoch : 0 [5780/21279] Train loss: 0.19295,Valid loss: 0.26090, time : 12.086916446685791 lr : 0.8953382542587163\n",
      "epoch : 0 [5781/21279] Train loss: 0.21178,Valid loss: 0.27737, time : 12.559814929962158 lr : 0.8953382542587163\n",
      "epoch : 0 [5782/21279] Train loss: 0.19822,Valid loss: 0.28064, time : 12.729821920394897 lr : 0.8953382542587163\n",
      "epoch : 0 [5783/21279] Train loss: 0.20827,Valid loss: 0.26075, time : 11.9879629611969 lr : 0.8953382542587163\n",
      "epoch : 0 [5784/21279] Train loss: 0.21232,Valid loss: 0.26515, time : 15.968059062957764 lr : 0.8953382542587163\n",
      "epoch : 0 [5785/21279] Train loss: 0.20606,Valid loss: 0.27011, time : 13.096036434173584 lr : 0.8953382542587163\n",
      "epoch : 0 [5786/21279] Train loss: 0.19614,Valid loss: 0.27064, time : 11.968165636062622 lr : 0.8953382542587163\n",
      "epoch : 0 [5787/21279] Train loss: 0.19262,Valid loss: 0.27940, time : 12.50072455406189 lr : 0.8953382542587163\n",
      "epoch : 0 [5788/21279] Train loss: 0.22028,Valid loss: 0.28546, time : 12.458239793777466 lr : 0.8953382542587163\n",
      "epoch : 0 [5789/21279] Train loss: 0.20707,Valid loss: 0.27729, time : 12.743337869644165 lr : 0.8953382542587163\n",
      "epoch : 0 [5790/21279] Train loss: 0.20641,Valid loss: 0.27419, time : 12.252606868743896 lr : 0.8953382542587163\n",
      "epoch : 0 [5791/21279] Train loss: 0.20130,Valid loss: 0.27061, time : 11.795360326766968 lr : 0.8953382542587163\n",
      "epoch : 0 [5792/21279] Train loss: 0.20345,Valid loss: 0.27515, time : 12.393248796463013 lr : 0.8953382542587163\n",
      "epoch : 0 [5793/21279] Train loss: 0.21146,Valid loss: 0.29919, time : 12.616071224212646 lr : 0.8953382542587163\n",
      "epoch : 0 [5794/21279] Train loss: 0.21002,Valid loss: 0.28229, time : 12.097894668579102 lr : 0.8953382542587163\n",
      "epoch : 0 [5795/21279] Train loss: 0.20307,Valid loss: 0.28320, time : 12.594120502471924 lr : 0.8953382542587163\n",
      "epoch : 0 [5796/21279] Train loss: 0.21298,Valid loss: 0.27739, time : 22.955470323562622 lr : 0.8953382542587163\n",
      "epoch : 0 [5797/21279] Train loss: 0.20785,Valid loss: 0.28359, time : 12.348328590393066 lr : 0.8953382542587163\n",
      "epoch : 0 [5798/21279] Train loss: 0.20764,Valid loss: 0.25985, time : 12.473741292953491 lr : 0.8953382542587163\n",
      "epoch : 0 [5799/21279] Train loss: 0.18972,Valid loss: 0.29823, time : 12.427248239517212 lr : 0.8953382542587163\n",
      "epoch : 0 [5800/21279] Train loss: 0.20700,Valid loss: 0.25926, time : 12.686272859573364 lr : 0.8953382542587163\n",
      "epoch : 0 [5801/21279] Train loss: 0.20526,Valid loss: 0.26660, time : 11.84916639328003 lr : 0.8953382542587163\n",
      "epoch : 0 [5802/21279] Train loss: 0.20771,Valid loss: 0.27978, time : 12.403923511505127 lr : 0.8953382542587163\n",
      "epoch : 0 [5803/21279] Train loss: 0.21189,Valid loss: 0.27275, time : 11.676215648651123 lr : 0.8953382542587163\n",
      "epoch : 0 [5804/21279] Train loss: 0.19205,Valid loss: 0.26263, time : 12.550857543945312 lr : 0.8953382542587163\n",
      "epoch : 0 [5805/21279] Train loss: 0.19195,Valid loss: 0.27548, time : 11.914646625518799 lr : 0.8953382542587163\n",
      "epoch : 0 [5806/21279] Train loss: 0.20272,Valid loss: 0.28365, time : 12.529722452163696 lr : 0.8953382542587163\n",
      "epoch : 0 [5807/21279] Train loss: 0.20265,Valid loss: 0.27950, time : 11.93055009841919 lr : 0.8953382542587163\n",
      "epoch : 0 [5808/21279] Train loss: 0.20357,Valid loss: 0.25507, time : 12.818440914154053 lr : 0.8953382542587163\n",
      "epoch : 0 [5809/21279] Train loss: 0.21301,Valid loss: 0.80335, time : 12.708341598510742 lr : 0.8953382542587163\n",
      "epoch : 0 [5810/21279] Train loss: 0.26479,Valid loss: 0.98051, time : 12.990521907806396 lr : 0.8953382542587163\n",
      "epoch : 0 [5811/21279] Train loss: 0.38019,Valid loss: 1.42700, time : 12.699480295181274 lr : 0.8953382542587163\n",
      "epoch : 0 [5812/21279] Train loss: 0.43298,Valid loss: 0.71782, time : 14.066417694091797 lr : 0.8953382542587163\n",
      "epoch : 0 [5813/21279] Train loss: 0.27101,Valid loss: 0.57685, time : 12.290780544281006 lr : 0.8953382542587163\n",
      "epoch : 0 [5814/21279] Train loss: 0.23311,Valid loss: 0.31307, time : 12.480072259902954 lr : 0.8953382542587163\n",
      "epoch : 0 [5815/21279] Train loss: 0.21689,Valid loss: 0.27882, time : 11.994850635528564 lr : 0.8953382542587163\n",
      "epoch : 0 [5816/21279] Train loss: 0.20738,Valid loss: 0.28873, time : 12.15502643585205 lr : 0.8953382542587163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5817/21279] Train loss: 0.20457,Valid loss: 0.27608, time : 12.268569707870483 lr : 0.8953382542587163\n",
      "epoch : 0 [5818/21279] Train loss: 0.19058,Valid loss: 0.29013, time : 12.626589059829712 lr : 0.8953382542587163\n",
      "epoch : 0 [5819/21279] Train loss: 0.20909,Valid loss: 0.30437, time : 12.7677743434906 lr : 0.8953382542587163\n",
      "epoch : 0 [5820/21279] Train loss: 0.21906,Valid loss: 0.44539, time : 12.74200701713562 lr : 0.8953382542587163\n",
      "epoch : 0 [5821/21279] Train loss: 0.22806,Valid loss: 0.29947, time : 12.152782440185547 lr : 0.8953382542587163\n",
      "epoch : 0 [5822/21279] Train loss: 0.21881,Valid loss: 0.28120, time : 12.520474433898926 lr : 0.8953382542587163\n",
      "epoch : 0 [5823/21279] Train loss: 0.21229,Valid loss: 0.26289, time : 11.902531623840332 lr : 0.8953382542587163\n",
      "epoch : 0 [5824/21279] Train loss: 0.20370,Valid loss: 0.27121, time : 12.136374235153198 lr : 0.8953382542587163\n",
      "epoch : 0 [5825/21279] Train loss: 0.19395,Valid loss: 0.25957, time : 13.79031252861023 lr : 0.8953382542587163\n",
      "epoch : 0 [5826/21279] Train loss: 0.18517,Valid loss: 0.25981, time : 12.542163372039795 lr : 0.8953382542587163\n",
      "epoch : 0 [5827/21279] Train loss: 0.19966,Valid loss: 0.25572, time : 12.875786542892456 lr : 0.8953382542587163\n",
      "epoch : 0 [5828/21279] Train loss: 0.21094,Valid loss: 0.26920, time : 12.157150030136108 lr : 0.8953382542587163\n",
      "epoch : 0 [5829/21279] Train loss: 0.21175,Valid loss: 0.25042, time : 12.387198686599731 lr : 0.8953382542587163\n",
      "epoch : 0 [5830/21279] Train loss: 0.20249,Valid loss: 0.25094, time : 12.282519817352295 lr : 0.8953382542587163\n",
      "epoch : 0 [5831/21279] Train loss: 0.21399,Valid loss: 0.26290, time : 12.550219535827637 lr : 0.8953382542587163\n",
      "epoch : 0 [5832/21279] Train loss: 0.21079,Valid loss: 0.26860, time : 12.606902599334717 lr : 0.8953382542587163\n",
      "epoch : 0 [5833/21279] Train loss: 0.19997,Valid loss: 0.26449, time : 12.58141803741455 lr : 0.8953382542587163\n",
      "epoch : 0 [5834/21279] Train loss: 0.18510,Valid loss: 0.26870, time : 12.983800411224365 lr : 0.8953382542587163\n",
      "epoch : 0 [5835/21279] Train loss: 0.20821,Valid loss: 0.29303, time : 12.624590635299683 lr : 0.8953382542587163\n",
      "epoch : 0 [5836/21279] Train loss: 0.19038,Valid loss: 0.26831, time : 12.905960083007812 lr : 0.8953382542587163\n",
      "epoch : 0 [5837/21279] Train loss: 0.19751,Valid loss: 0.25942, time : 12.78723430633545 lr : 0.8953382542587163\n",
      "epoch : 0 [5838/21279] Train loss: 0.20676,Valid loss: 0.25432, time : 12.794361591339111 lr : 0.8953382542587163\n",
      "epoch : 0 [5839/21279] Train loss: 0.19031,Valid loss: 0.25307, time : 12.587139368057251 lr : 0.8953382542587163\n",
      "epoch : 0 [5840/21279] Train loss: 0.20861,Valid loss: 0.25721, time : 14.338314771652222 lr : 0.8953382542587163\n",
      "epoch : 0 [5841/21279] Train loss: 0.20145,Valid loss: 0.25739, time : 12.473277568817139 lr : 0.8953382542587163\n",
      "epoch : 0 [5842/21279] Train loss: 0.20059,Valid loss: 0.26744, time : 12.123228073120117 lr : 0.8953382542587163\n",
      "epoch : 0 [5843/21279] Train loss: 0.20357,Valid loss: 0.26087, time : 12.283231496810913 lr : 0.8953382542587163\n",
      "epoch : 0 [5844/21279] Train loss: 0.21567,Valid loss: 0.27304, time : 12.213690280914307 lr : 0.8953382542587163\n",
      "epoch : 0 [5845/21279] Train loss: 0.20053,Valid loss: 0.25725, time : 12.396095991134644 lr : 0.8953382542587163\n",
      "epoch : 0 [5846/21279] Train loss: 0.21903,Valid loss: 0.25600, time : 12.649266958236694 lr : 0.8953382542587163\n",
      "epoch : 0 [5847/21279] Train loss: 0.19685,Valid loss: 0.25189, time : 12.992030620574951 lr : 0.8953382542587163\n",
      "epoch : 0 [5848/21279] Train loss: 0.20671,Valid loss: 0.25901, time : 12.585153341293335 lr : 0.8953382542587163\n",
      "epoch : 0 [5849/21279] Train loss: 0.20950,Valid loss: 0.26541, time : 12.590571641921997 lr : 0.8953382542587163\n",
      "epoch : 0 [5850/21279] Train loss: 0.19917,Valid loss: 0.24780, time : 12.675074100494385 lr : 0.8953382542587163\n",
      "epoch : 0 [5851/21279] Train loss: 0.20636,Valid loss: 0.26042, time : 12.198033571243286 lr : 0.8953382542587163\n",
      "epoch : 0 [5852/21279] Train loss: 0.20335,Valid loss: 0.31696, time : 15.026775598526001 lr : 0.8953382542587163\n",
      "epoch : 0 [5853/21279] Train loss: 0.22222,Valid loss: 0.25963, time : 12.403518199920654 lr : 0.8953382542587163\n",
      "epoch : 0 [5854/21279] Train loss: 0.20282,Valid loss: 0.26938, time : 12.148065567016602 lr : 0.8953382542587163\n",
      "epoch : 0 [5855/21279] Train loss: 0.20017,Valid loss: 0.26676, time : 12.290698289871216 lr : 0.8953382542587163\n",
      "epoch : 0 [5856/21279] Train loss: 0.21515,Valid loss: 0.27045, time : 12.522623300552368 lr : 0.8953382542587163\n",
      "epoch : 0 [5857/21279] Train loss: 0.22528,Valid loss: 0.26817, time : 12.567976951599121 lr : 0.8953382542587163\n",
      "epoch : 0 [5858/21279] Train loss: 0.23321,Valid loss: 0.28333, time : 12.681187152862549 lr : 0.8953382542587163\n",
      "epoch : 0 [5859/21279] Train loss: 0.19310,Valid loss: 0.25860, time : 12.964399576187134 lr : 0.8953382542587163\n",
      "epoch : 0 [5860/21279] Train loss: 0.20079,Valid loss: 0.25407, time : 13.062767505645752 lr : 0.8953382542587163\n",
      "epoch : 0 [5861/21279] Train loss: 0.20481,Valid loss: 0.27678, time : 12.675707817077637 lr : 0.8953382542587163\n",
      "epoch : 0 [5862/21279] Train loss: 0.22379,Valid loss: 0.25919, time : 12.953750610351562 lr : 0.8953382542587163\n",
      "epoch : 0 [5863/21279] Train loss: 0.19843,Valid loss: 0.28437, time : 11.876751184463501 lr : 0.8953382542587163\n",
      "epoch : 0 [5864/21279] Train loss: 0.20975,Valid loss: 0.26880, time : 12.358126640319824 lr : 0.8953382542587163\n",
      "epoch : 0 [5865/21279] Train loss: 0.18310,Valid loss: 0.25516, time : 12.435013055801392 lr : 0.8953382542587163\n",
      "epoch : 0 [5866/21279] Train loss: 0.19706,Valid loss: 0.49463, time : 14.523842573165894 lr : 0.8953382542587163\n",
      "epoch : 0 [5867/21279] Train loss: 0.20570,Valid loss: 0.25672, time : 12.83562970161438 lr : 0.8953382542587163\n",
      "epoch : 0 [5868/21279] Train loss: 0.20119,Valid loss: 0.26529, time : 13.105957746505737 lr : 0.8953382542587163\n",
      "epoch : 0 [5869/21279] Train loss: 0.19506,Valid loss: 0.24568, time : 12.690021753311157 lr : 0.8953382542587163\n",
      "epoch : 0 [5870/21279] Train loss: 0.19748,Valid loss: 0.25339, time : 12.511760711669922 lr : 0.8953382542587163\n",
      "epoch : 0 [5871/21279] Train loss: 0.20540,Valid loss: 0.26418, time : 12.922191619873047 lr : 0.8953382542587163\n",
      "epoch : 0 [5872/21279] Train loss: 0.19166,Valid loss: 0.27736, time : 12.354990243911743 lr : 0.8953382542587163\n",
      "epoch : 0 [5873/21279] Train loss: 0.19860,Valid loss: 0.26457, time : 12.4347505569458 lr : 0.8953382542587163\n",
      "epoch : 0 [5874/21279] Train loss: 0.20038,Valid loss: 0.24795, time : 12.777985572814941 lr : 0.8953382542587163\n",
      "epoch : 0 [5875/21279] Train loss: 0.21457,Valid loss: 0.26551, time : 12.607469081878662 lr : 0.8953382542587163\n",
      "epoch : 0 [5876/21279] Train loss: 0.20668,Valid loss: 0.26432, time : 12.415661811828613 lr : 0.8953382542587163\n",
      "epoch : 0 [5877/21279] Train loss: 0.20413,Valid loss: 0.25372, time : 12.413476467132568 lr : 0.8953382542587163\n",
      "epoch : 0 [5878/21279] Train loss: 0.19000,Valid loss: 0.41152, time : 14.160855531692505 lr : 0.8953382542587163\n",
      "epoch : 0 [5879/21279] Train loss: 0.19373,Valid loss: 0.26095, time : 12.438902139663696 lr : 0.8953382542587163\n",
      "epoch : 0 [5880/21279] Train loss: 0.19103,Valid loss: 0.41454, time : 12.83224868774414 lr : 0.8953382542587163\n",
      "epoch : 0 [5881/21279] Train loss: 0.21253,Valid loss: 0.33090, time : 12.484681367874146 lr : 0.8953382542587163\n",
      "epoch : 0 [5882/21279] Train loss: 0.19528,Valid loss: 0.30463, time : 12.491398572921753 lr : 0.8953382542587163\n",
      "epoch : 0 [5883/21279] Train loss: 0.21377,Valid loss: 0.28903, time : 12.385863304138184 lr : 0.8953382542587163\n",
      "epoch : 0 [5884/21279] Train loss: 0.21245,Valid loss: 0.26063, time : 12.89388108253479 lr : 0.8953382542587163\n",
      "epoch : 0 [5885/21279] Train loss: 0.19857,Valid loss: 0.24952, time : 12.618199110031128 lr : 0.8953382542587163\n",
      "epoch : 0 [5886/21279] Train loss: 0.21015,Valid loss: 0.28526, time : 12.358773946762085 lr : 0.8953382542587163\n",
      "epoch : 0 [5887/21279] Train loss: 0.19523,Valid loss: 0.28388, time : 12.792314052581787 lr : 0.8953382542587163\n",
      "epoch : 0 [5888/21279] Train loss: 0.19000,Valid loss: 0.41574, time : 12.98040509223938 lr : 0.8953382542587163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5889/21279] Train loss: 0.20391,Valid loss: 0.40911, time : 12.89437484741211 lr : 0.8953382542587163\n",
      "epoch : 0 [5890/21279] Train loss: 0.20539,Valid loss: 0.38606, time : 12.614549160003662 lr : 0.8953382542587163\n",
      "epoch : 0 [5891/21279] Train loss: 0.18838,Valid loss: 0.27212, time : 12.497590780258179 lr : 0.8953382542587163\n",
      "epoch : 0 [5892/21279] Train loss: 0.20392,Valid loss: 0.39152, time : 12.578194856643677 lr : 0.8953382542587163\n",
      "epoch : 0 [5893/21279] Train loss: 0.18276,Valid loss: 0.40823, time : 12.042886972427368 lr : 0.8953382542587163\n",
      "epoch : 0 [5894/21279] Train loss: 0.20000,Valid loss: 0.25349, time : 14.587239980697632 lr : 0.8953382542587163\n",
      "epoch : 0 [5895/21279] Train loss: 0.19594,Valid loss: 0.24752, time : 11.964415550231934 lr : 0.8953382542587163\n",
      "epoch : 0 [5896/21279] Train loss: 0.18982,Valid loss: 0.26685, time : 12.658157348632812 lr : 0.8953382542587163\n",
      "epoch : 0 [5897/21279] Train loss: 0.19930,Valid loss: 0.26629, time : 12.615726947784424 lr : 0.8953382542587163\n",
      "epoch : 0 [5898/21279] Train loss: 0.19054,Valid loss: 0.25473, time : 13.01133918762207 lr : 0.8953382542587163\n",
      "epoch : 0 [5899/21279] Train loss: 0.20374,Valid loss: 0.26780, time : 12.776546478271484 lr : 0.8953382542587163\n",
      "epoch : 0 [5900/21279] Train loss: 0.19014,Valid loss: 0.24297, time : 12.924705743789673 lr : 0.8953382542587163\n",
      "epoch : 0 [5901/21279] Train loss: 0.18666,Valid loss: 0.41808, time : 13.08286452293396 lr : 0.8953382542587163\n",
      "epoch : 0 [5902/21279] Train loss: 0.20296,Valid loss: 0.44178, time : 13.09212589263916 lr : 0.8953382542587163\n",
      "epoch : 0 [5903/21279] Train loss: 0.21588,Valid loss: 0.43097, time : 13.285036325454712 lr : 0.8953382542587163\n",
      "epoch : 0 [5904/21279] Train loss: 0.21085,Valid loss: 0.39499, time : 13.131330251693726 lr : 0.8953382542587163\n",
      "epoch : 0 [5905/21279] Train loss: 0.20503,Valid loss: 0.28614, time : 13.261569738388062 lr : 0.8953382542587163\n",
      "epoch : 0 [5906/21279] Train loss: 0.19821,Valid loss: 0.24626, time : 19.560608386993408 lr : 0.8953382542587163\n",
      "epoch : 0 [5907/21279] Train loss: 0.20557,Valid loss: 0.25584, time : 13.129957675933838 lr : 0.8953382542587163\n",
      "epoch : 0 [5908/21279] Train loss: 0.19267,Valid loss: 0.25182, time : 11.990125179290771 lr : 0.8953382542587163\n",
      "epoch : 0 [5909/21279] Train loss: 0.20204,Valid loss: 0.25717, time : 12.315771341323853 lr : 0.8953382542587163\n",
      "epoch : 0 [5910/21279] Train loss: 0.20831,Valid loss: 0.26224, time : 12.710758924484253 lr : 0.8953382542587163\n",
      "epoch : 0 [5911/21279] Train loss: 0.19959,Valid loss: 0.24377, time : 12.66929841041565 lr : 0.8953382542587163\n",
      "epoch : 0 [5912/21279] Train loss: 0.17922,Valid loss: 0.25335, time : 12.567020893096924 lr : 0.8953382542587163\n",
      "epoch : 0 [5913/21279] Train loss: 0.20248,Valid loss: 0.25072, time : 12.11736273765564 lr : 0.8953382542587163\n",
      "epoch : 0 [5914/21279] Train loss: 0.19864,Valid loss: 0.24401, time : 12.257476329803467 lr : 0.8953382542587163\n",
      "epoch : 0 [5915/21279] Train loss: 0.19549,Valid loss: 0.26914, time : 12.283218383789062 lr : 0.8953382542587163\n",
      "epoch : 0 [5916/21279] Train loss: 0.20432,Valid loss: 1.14402, time : 12.710769176483154 lr : 0.8953382542587163\n",
      "epoch : 0 [5917/21279] Train loss: 0.26916,Valid loss: 0.43172, time : 12.951597452163696 lr : 0.8953382542587163\n",
      "epoch : 0 [5918/21279] Train loss: 0.25377,Valid loss: 0.44257, time : 13.23139500617981 lr : 0.8953382542587163\n",
      "epoch : 0 [5919/21279] Train loss: 0.24617,Valid loss: 0.93302, time : 13.078855037689209 lr : 0.8953382542587163\n",
      "epoch : 0 [5920/21279] Train loss: 0.25302,Valid loss: 0.45502, time : 12.67342472076416 lr : 0.8953382542587163\n",
      "epoch : 0 [5921/21279] Train loss: 0.20819,Valid loss: 0.29193, time : 13.02320146560669 lr : 0.8953382542587163\n",
      "epoch : 0 [5922/21279] Train loss: 0.21192,Valid loss: 0.28850, time : 14.657790422439575 lr : 0.8953382542587163\n",
      "epoch : 0 [5923/21279] Train loss: 0.22507,Valid loss: 0.26777, time : 12.949330568313599 lr : 0.8953382542587163\n",
      "epoch : 0 [5924/21279] Train loss: 0.22292,Valid loss: 0.26303, time : 13.127584218978882 lr : 0.8953382542587163\n",
      "epoch : 0 [5925/21279] Train loss: 0.19094,Valid loss: 0.23879, time : 12.976505994796753 lr : 0.8953382542587163\n",
      "epoch : 0 [5926/21279] Train loss: 0.19324,Valid loss: 0.27474, time : 12.957596063613892 lr : 0.8953382542587163\n",
      "epoch : 0 [5927/21279] Train loss: 0.19568,Valid loss: 0.23913, time : 12.687148809432983 lr : 0.8953382542587163\n",
      "epoch : 0 [5928/21279] Train loss: 0.18640,Valid loss: 0.27555, time : 12.804943799972534 lr : 0.8953382542587163\n",
      "epoch : 0 [5929/21279] Train loss: 0.19139,Valid loss: 0.24551, time : 12.801963329315186 lr : 0.8953382542587163\n",
      "epoch : 0 [5930/21279] Train loss: 0.19746,Valid loss: 0.26284, time : 12.578914403915405 lr : 0.8953382542587163\n",
      "epoch : 0 [5931/21279] Train loss: 0.20126,Valid loss: 0.25538, time : 11.704751014709473 lr : 0.8953382542587163\n",
      "epoch : 0 [5932/21279] Train loss: 0.19428,Valid loss: 0.26272, time : 12.175837993621826 lr : 0.8953382542587163\n",
      "epoch : 0 [5933/21279] Train loss: 0.19795,Valid loss: 0.25199, time : 11.77144479751587 lr : 0.8953382542587163\n",
      "epoch : 0 [5934/21279] Train loss: 0.19801,Valid loss: 0.24235, time : 11.71579885482788 lr : 0.8953382542587163\n",
      "epoch : 0 [5935/21279] Train loss: 0.18867,Valid loss: 0.51700, time : 13.94709825515747 lr : 0.8953382542587163\n",
      "epoch : 0 [5936/21279] Train loss: 0.21262,Valid loss: 0.26231, time : 11.992765426635742 lr : 0.8953382542587163\n",
      "epoch : 0 [5937/21279] Train loss: 0.25029,Valid loss: 1.40444, time : 12.16605019569397 lr : 0.8953382542587163\n",
      "epoch : 0 [5938/21279] Train loss: 0.42340,Valid loss: 1.49269, time : 12.479413270950317 lr : 0.8953382542587163\n",
      "epoch : 0 [5939/21279] Train loss: 0.77726,Valid loss: 0.80017, time : 12.349229097366333 lr : 0.8953382542587163\n",
      "epoch : 0 [5940/21279] Train loss: 0.30528,Valid loss: 0.69482, time : 12.746392488479614 lr : 0.8953382542587163\n",
      "epoch : 0 [5941/21279] Train loss: 0.25465,Valid loss: 0.32570, time : 12.659029722213745 lr : 0.8953382542587163\n",
      "epoch : 0 [5942/21279] Train loss: 0.22003,Valid loss: 0.27682, time : 12.50162672996521 lr : 0.8953382542587163\n",
      "epoch : 0 [5943/21279] Train loss: 0.21794,Valid loss: 0.29227, time : 12.764047622680664 lr : 0.8953382542587163\n",
      "epoch : 0 [5944/21279] Train loss: 0.20143,Valid loss: 0.25681, time : 12.799164533615112 lr : 0.8953382542587163\n",
      "epoch : 0 [5945/21279] Train loss: 0.20195,Valid loss: 0.25267, time : 12.010790824890137 lr : 0.8953382542587163\n",
      "epoch : 0 [5946/21279] Train loss: 0.19714,Valid loss: 0.25395, time : 11.611701250076294 lr : 0.8953382542587163\n",
      "epoch : 0 [5947/21279] Train loss: 0.19891,Valid loss: 0.38494, time : 12.133029222488403 lr : 0.8953382542587163\n",
      "epoch : 0 [5948/21279] Train loss: 0.20271,Valid loss: 0.41082, time : 12.037359714508057 lr : 0.8953382542587163\n",
      "epoch : 0 [5949/21279] Train loss: 0.19064,Valid loss: 0.39674, time : 11.854038953781128 lr : 0.8953382542587163\n",
      "epoch : 0 [5950/21279] Train loss: 0.19545,Valid loss: 0.53771, time : 13.771811485290527 lr : 0.8953382542587163\n",
      "epoch : 0 [5951/21279] Train loss: 0.20166,Valid loss: 0.38890, time : 12.002325534820557 lr : 0.8953382542587163\n",
      "epoch : 0 [5952/21279] Train loss: 0.20679,Valid loss: 0.39006, time : 12.10770034790039 lr : 0.8953382542587163\n",
      "epoch : 0 [5953/21279] Train loss: 0.17613,Valid loss: 0.24999, time : 12.178449153900146 lr : 0.8953382542587163\n",
      "epoch : 0 [5954/21279] Train loss: 0.20122,Valid loss: 0.25665, time : 11.656737327575684 lr : 0.8953382542587163\n",
      "epoch : 0 [5955/21279] Train loss: 0.19603,Valid loss: 0.56157, time : 12.336882829666138 lr : 0.8953382542587163\n",
      "epoch : 0 [5956/21279] Train loss: 0.18936,Valid loss: 0.53394, time : 12.672784805297852 lr : 0.8953382542587163\n",
      "epoch : 0 [5957/21279] Train loss: 0.21554,Valid loss: 0.28606, time : 13.105271577835083 lr : 0.8953382542587163\n",
      "epoch : 0 [5958/21279] Train loss: 0.22036,Valid loss: 0.26373, time : 12.87256669998169 lr : 0.8953382542587163\n",
      "epoch : 0 [5959/21279] Train loss: 0.19714,Valid loss: 0.40200, time : 12.725334167480469 lr : 0.8953382542587163\n",
      "epoch : 0 [5960/21279] Train loss: 0.19363,Valid loss: 0.25741, time : 13.23252534866333 lr : 0.8953382542587163\n",
      "epoch : 0 [5961/21279] Train loss: 0.19387,Valid loss: 0.40078, time : 12.77860951423645 lr : 0.8953382542587163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [5962/21279] Train loss: 0.19101,Valid loss: 0.40601, time : 14.787677526473999 lr : 0.8953382542587163\n",
      "epoch : 0 [5963/21279] Train loss: 0.19433,Valid loss: 0.24702, time : 13.20696759223938 lr : 0.8953382542587163\n",
      "epoch : 0 [5964/21279] Train loss: 0.19933,Valid loss: 0.40147, time : 12.317876815795898 lr : 0.8953382542587163\n",
      "epoch : 0 [5965/21279] Train loss: 0.19946,Valid loss: 0.39868, time : 12.730507612228394 lr : 0.8953382542587163\n",
      "epoch : 0 [5966/21279] Train loss: 0.19549,Valid loss: 0.25638, time : 12.53849983215332 lr : 0.8953382542587163\n",
      "epoch : 0 [5967/21279] Train loss: 0.19857,Valid loss: 0.26556, time : 12.189539670944214 lr : 0.8953382542587163\n",
      "epoch : 0 [5968/21279] Train loss: 0.19151,Valid loss: 0.24858, time : 12.256743669509888 lr : 0.8953382542587163\n",
      "epoch : 0 [5969/21279] Train loss: 0.18191,Valid loss: 0.24263, time : 12.298686265945435 lr : 0.8953382542587163\n",
      "epoch : 0 [5970/21279] Train loss: 0.19150,Valid loss: 0.25890, time : 12.255898714065552 lr : 0.8953382542587163\n",
      "epoch : 0 [5971/21279] Train loss: 0.18910,Valid loss: 0.24455, time : 12.76108169555664 lr : 0.8953382542587163\n",
      "epoch : 0 [5972/21279] Train loss: 0.19510,Valid loss: 0.25393, time : 12.328917026519775 lr : 0.8953382542587163\n",
      "epoch : 0 [5973/21279] Train loss: 0.20148,Valid loss: 0.25514, time : 12.408792495727539 lr : 0.8953382542587163\n",
      "epoch : 0 [5974/21279] Train loss: 0.20544,Valid loss: 0.26375, time : 12.425949335098267 lr : 0.8953382542587163\n",
      "epoch : 0 [5975/21279] Train loss: 0.20320,Valid loss: 0.24978, time : 11.75224494934082 lr : 0.8953382542587163\n",
      "epoch : 0 [5976/21279] Train loss: 0.19916,Valid loss: 0.24884, time : 13.618968963623047 lr : 0.8953382542587163\n",
      "epoch : 0 [5977/21279] Train loss: 0.19867,Valid loss: 0.25439, time : 11.46772027015686 lr : 0.8953382542587163\n",
      "epoch : 0 [5978/21279] Train loss: 0.19267,Valid loss: 0.26088, time : 12.120574235916138 lr : 0.8953382542587163\n",
      "epoch : 0 [5979/21279] Train loss: 0.20415,Valid loss: 0.24728, time : 11.787773609161377 lr : 0.8953382542587163\n",
      "epoch : 0 [5980/21279] Train loss: 0.19208,Valid loss: 0.26066, time : 12.666652917861938 lr : 0.8953382542587163\n",
      "epoch : 0 [5981/21279] Train loss: 0.19187,Valid loss: 0.25973, time : 11.943073034286499 lr : 0.8953382542587163\n",
      "epoch : 0 [5982/21279] Train loss: 0.18884,Valid loss: 0.25748, time : 12.80240511894226 lr : 0.8953382542587163\n",
      "epoch : 0 [5983/21279] Train loss: 0.19040,Valid loss: 0.24792, time : 12.040742635726929 lr : 0.8953382542587163\n",
      "epoch : 0 [5984/21279] Train loss: 0.18820,Valid loss: 0.24863, time : 12.238915920257568 lr : 0.8953382542587163\n",
      "epoch : 0 [5985/21279] Train loss: 0.18828,Valid loss: 0.25557, time : 12.419963359832764 lr : 0.8953382542587163\n",
      "epoch : 0 [5986/21279] Train loss: 0.18846,Valid loss: 0.24992, time : 12.477822303771973 lr : 0.8953382542587163\n",
      "epoch : 0 [5987/21279] Train loss: 0.19011,Valid loss: 0.27435, time : 12.220151424407959 lr : 0.8953382542587163\n",
      "epoch : 0 [5988/21279] Train loss: 0.19148,Valid loss: 0.26242, time : 14.502174139022827 lr : 0.8953382542587163\n",
      "epoch : 0 [5989/21279] Train loss: 0.18896,Valid loss: 0.24040, time : 12.419827699661255 lr : 0.8953382542587163\n",
      "epoch : 0 [5990/21279] Train loss: 0.18962,Valid loss: 0.26009, time : 11.916245698928833 lr : 0.8953382542587163\n",
      "epoch : 0 [5991/21279] Train loss: 0.18729,Valid loss: 0.26208, time : 12.11549687385559 lr : 0.8953382542587163\n",
      "epoch : 0 [5992/21279] Train loss: 0.19073,Valid loss: 0.25047, time : 12.283567905426025 lr : 0.8953382542587163\n",
      "epoch : 0 [5993/21279] Train loss: 0.20045,Valid loss: 0.25772, time : 12.419716358184814 lr : 0.8953382542587163\n",
      "epoch : 0 [5994/21279] Train loss: 0.21725,Valid loss: 0.25929, time : 11.994994878768921 lr : 0.8953382542587163\n",
      "epoch : 0 [5995/21279] Train loss: 0.18918,Valid loss: 0.25312, time : 12.855149984359741 lr : 0.8953382542587163\n",
      "epoch : 0 [5996/21279] Train loss: 0.18690,Valid loss: 0.28616, time : 12.854336261749268 lr : 0.8953382542587163\n",
      "epoch : 0 [5997/21279] Train loss: 0.19651,Valid loss: 0.25377, time : 12.866593837738037 lr : 0.8953382542587163\n",
      "epoch : 0 [5998/21279] Train loss: 0.19486,Valid loss: 0.25419, time : 13.148348093032837 lr : 0.8953382542587163\n",
      "epoch : 0 [5999/21279] Train loss: 0.19366,Valid loss: 0.37972, time : 13.065385580062866 lr : 0.8863848717161291\n",
      "epoch : 0 [6000/21279] Train loss: 0.19863,Valid loss: 0.25344, time : 12.675257682800293 lr : 0.8863848717161291\n",
      "epoch : 0 [6001/21279] Train loss: 0.18301,Valid loss: 0.25921, time : 12.74673056602478 lr : 0.8863848717161291\n",
      "epoch : 0 [6002/21279] Train loss: 0.19138,Valid loss: 0.23505, time : 12.012565612792969 lr : 0.8863848717161291\n",
      "epoch : 0 [6003/21279] Train loss: 0.19534,Valid loss: 0.40894, time : 12.221026420593262 lr : 0.8863848717161291\n",
      "epoch : 0 [6004/21279] Train loss: 0.18404,Valid loss: 0.26641, time : 14.089529275894165 lr : 0.8863848717161291\n",
      "epoch : 0 [6005/21279] Train loss: 0.18768,Valid loss: 0.26591, time : 12.416697025299072 lr : 0.8863848717161291\n",
      "epoch : 0 [6006/21279] Train loss: 0.18706,Valid loss: 0.25268, time : 12.7343008518219 lr : 0.8863848717161291\n",
      "epoch : 0 [6007/21279] Train loss: 0.18230,Valid loss: 0.25370, time : 12.467198610305786 lr : 0.8863848717161291\n",
      "epoch : 0 [6008/21279] Train loss: 0.18816,Valid loss: 0.24545, time : 12.86254334449768 lr : 0.8863848717161291\n",
      "epoch : 0 [6009/21279] Train loss: 0.19269,Valid loss: 0.31221, time : 11.840704441070557 lr : 0.8863848717161291\n",
      "epoch : 0 [6010/21279] Train loss: 0.22277,Valid loss: 0.40596, time : 12.433340072631836 lr : 0.8863848717161291\n",
      "epoch : 0 [6011/21279] Train loss: 0.21833,Valid loss: 1.06766, time : 11.864255666732788 lr : 0.8863848717161291\n",
      "epoch : 0 [6012/21279] Train loss: 0.25218,Valid loss: 1.41885, time : 12.74948239326477 lr : 0.8863848717161291\n",
      "epoch : 0 [6013/21279] Train loss: 0.32038,Valid loss: 1.10218, time : 11.852462768554688 lr : 0.8863848717161291\n",
      "epoch : 0 [6014/21279] Train loss: 0.25838,Valid loss: 0.33811, time : 12.777974128723145 lr : 0.8863848717161291\n",
      "epoch : 0 [6015/21279] Train loss: 0.26922,Valid loss: 0.33415, time : 11.710096836090088 lr : 0.8863848717161291\n",
      "epoch : 0 [6016/21279] Train loss: 0.22240,Valid loss: 0.32397, time : 14.99932074546814 lr : 0.8863848717161291\n",
      "epoch : 0 [6017/21279] Train loss: 0.21146,Valid loss: 0.26542, time : 12.046043634414673 lr : 0.8863848717161291\n",
      "epoch : 0 [6018/21279] Train loss: 0.20996,Valid loss: 0.24180, time : 12.188400030136108 lr : 0.8863848717161291\n",
      "epoch : 0 [6019/21279] Train loss: 0.19121,Valid loss: 0.26138, time : 12.564985513687134 lr : 0.8863848717161291\n",
      "epoch : 0 [6020/21279] Train loss: 0.18771,Valid loss: 0.24626, time : 11.649748086929321 lr : 0.8863848717161291\n",
      "epoch : 0 [6021/21279] Train loss: 0.20181,Valid loss: 0.25052, time : 12.053486585617065 lr : 0.8863848717161291\n",
      "epoch : 0 [6022/21279] Train loss: 0.19464,Valid loss: 0.25946, time : 12.086737871170044 lr : 0.8863848717161291\n",
      "epoch : 0 [6023/21279] Train loss: 0.19059,Valid loss: 0.28045, time : 11.816456317901611 lr : 0.8863848717161291\n",
      "epoch : 0 [6024/21279] Train loss: 0.20910,Valid loss: 0.26154, time : 12.136823177337646 lr : 0.8863848717161291\n",
      "epoch : 0 [6025/21279] Train loss: 0.20605,Valid loss: 0.28060, time : 13.074429988861084 lr : 0.8863848717161291\n",
      "epoch : 0 [6026/21279] Train loss: 0.19211,Valid loss: 0.26002, time : 11.767541408538818 lr : 0.8863848717161291\n",
      "epoch : 0 [6027/21279] Train loss: 0.19577,Valid loss: 0.25542, time : 12.514770746231079 lr : 0.8863848717161291\n",
      "epoch : 0 [6028/21279] Train loss: 0.19068,Valid loss: 0.25094, time : 12.813410758972168 lr : 0.8863848717161291\n",
      "epoch : 0 [6029/21279] Train loss: 0.18624,Valid loss: 0.25649, time : 12.965235948562622 lr : 0.8863848717161291\n",
      "epoch : 0 [6030/21279] Train loss: 0.17505,Valid loss: 0.24619, time : 12.868587732315063 lr : 0.8863848717161291\n",
      "epoch : 0 [6031/21279] Train loss: 0.18763,Valid loss: 0.25429, time : 13.218003273010254 lr : 0.8863848717161291\n",
      "epoch : 0 [6032/21279] Train loss: 0.18279,Valid loss: 0.25698, time : 14.272056102752686 lr : 0.8863848717161291\n",
      "epoch : 0 [6033/21279] Train loss: 0.18989,Valid loss: 0.25421, time : 12.718167781829834 lr : 0.8863848717161291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [6034/21279] Train loss: 0.18020,Valid loss: 0.25932, time : 12.759763956069946 lr : 0.8863848717161291\n",
      "epoch : 0 [6035/21279] Train loss: 0.18265,Valid loss: 0.54856, time : 12.852579355239868 lr : 0.8863848717161291\n",
      "epoch : 0 [6036/21279] Train loss: 0.21853,Valid loss: 0.41743, time : 12.51162075996399 lr : 0.8863848717161291\n",
      "epoch : 0 [6037/21279] Train loss: 0.20316,Valid loss: 0.26839, time : 12.961869239807129 lr : 0.8863848717161291\n",
      "epoch : 0 [6038/21279] Train loss: 0.20569,Valid loss: 0.25659, time : 12.830506086349487 lr : 0.8863848717161291\n",
      "epoch : 0 [6039/21279] Train loss: 0.18651,Valid loss: 0.24955, time : 12.02243423461914 lr : 0.8863848717161291\n",
      "epoch : 0 [6040/21279] Train loss: 0.19352,Valid loss: 0.24115, time : 12.268963098526001 lr : 0.8863848717161291\n",
      "epoch : 0 [6041/21279] Train loss: 0.19244,Valid loss: 0.24254, time : 11.791554689407349 lr : 0.8863848717161291\n",
      "epoch : 0 [6042/21279] Train loss: 0.18658,Valid loss: 0.25323, time : 12.103257656097412 lr : 0.8863848717161291\n",
      "epoch : 0 [6043/21279] Train loss: 0.18546,Valid loss: 0.23205, time : 12.301822423934937 lr : 0.8863848717161291\n",
      "epoch : 0 [6044/21279] Train loss: 0.19860,Valid loss: 0.23887, time : 12.48702621459961 lr : 0.8863848717161291\n",
      "epoch : 0 [6045/21279] Train loss: 0.18914,Valid loss: 0.40494, time : 14.189838409423828 lr : 0.8863848717161291\n",
      "epoch : 0 [6046/21279] Train loss: 0.21434,Valid loss: 0.26205, time : 12.4966139793396 lr : 0.8863848717161291\n",
      "epoch : 0 [6047/21279] Train loss: 0.19179,Valid loss: 0.24385, time : 12.142831563949585 lr : 0.8863848717161291\n",
      "epoch : 0 [6048/21279] Train loss: 0.18661,Valid loss: 0.23747, time : 11.595556735992432 lr : 0.8863848717161291\n",
      "epoch : 0 [6049/21279] Train loss: 0.20154,Valid loss: 0.25233, time : 11.637714147567749 lr : 0.8863848717161291\n",
      "epoch : 0 [6050/21279] Train loss: 0.18389,Valid loss: 0.25457, time : 12.211189031600952 lr : 0.8863848717161291\n",
      "epoch : 0 [6051/21279] Train loss: 0.18273,Valid loss: 0.23702, time : 12.140115737915039 lr : 0.8863848717161291\n",
      "epoch : 0 [6052/21279] Train loss: 0.19030,Valid loss: 0.24331, time : 12.55465316772461 lr : 0.8863848717161291\n",
      "epoch : 0 [6053/21279] Train loss: 0.20863,Valid loss: 0.32883, time : 12.886131525039673 lr : 0.8863848717161291\n",
      "epoch : 0 [6054/21279] Train loss: 0.19893,Valid loss: 0.26624, time : 12.670260429382324 lr : 0.8863848717161291\n",
      "epoch : 0 [6055/21279] Train loss: 0.18810,Valid loss: 0.26188, time : 12.296684741973877 lr : 0.8863848717161291\n",
      "epoch : 0 [6056/21279] Train loss: 0.19858,Valid loss: 0.25810, time : 12.017153978347778 lr : 0.8863848717161291\n",
      "epoch : 0 [6057/21279] Train loss: 0.18342,Valid loss: 0.24566, time : 11.864099264144897 lr : 0.8863848717161291\n",
      "epoch : 0 [6058/21279] Train loss: 0.21118,Valid loss: 0.23954, time : 11.61147689819336 lr : 0.8863848717161291\n",
      "epoch : 0 [6059/21279] Train loss: 0.19839,Valid loss: 0.25076, time : 12.007821559906006 lr : 0.8863848717161291\n",
      "epoch : 0 [6060/21279] Train loss: 0.19769,Valid loss: 0.24997, time : 14.205734491348267 lr : 0.8863848717161291\n",
      "epoch : 0 [6061/21279] Train loss: 0.19369,Valid loss: 0.26711, time : 12.030048608779907 lr : 0.8863848717161291\n",
      "epoch : 0 [6062/21279] Train loss: 0.18201,Valid loss: 0.27064, time : 12.460892915725708 lr : 0.8863848717161291\n",
      "epoch : 0 [6063/21279] Train loss: 0.18088,Valid loss: 0.25771, time : 12.057565689086914 lr : 0.8863848717161291\n",
      "epoch : 0 [6064/21279] Train loss: 0.18075,Valid loss: 0.26155, time : 12.839154481887817 lr : 0.8863848717161291\n",
      "epoch : 0 [6065/21279] Train loss: 0.19134,Valid loss: 0.25488, time : 12.791864156723022 lr : 0.8863848717161291\n",
      "epoch : 0 [6066/21279] Train loss: 0.18764,Valid loss: 0.26087, time : 12.324486494064331 lr : 0.8863848717161291\n",
      "epoch : 0 [6067/21279] Train loss: 0.19100,Valid loss: 0.30623, time : 12.073550939559937 lr : 0.8863848717161291\n",
      "epoch : 0 [6068/21279] Train loss: 0.18659,Valid loss: 0.24986, time : 12.42793583869934 lr : 0.8863848717161291\n",
      "epoch : 0 [6069/21279] Train loss: 0.18248,Valid loss: 0.49390, time : 12.47131896018982 lr : 0.8863848717161291\n",
      "epoch : 0 [6070/21279] Train loss: 0.22186,Valid loss: 1.59665, time : 11.76874041557312 lr : 0.8863848717161291\n",
      "epoch : 0 [6071/21279] Train loss: 0.26703,Valid loss: 1.93877, time : 11.985024452209473 lr : 0.8863848717161291\n",
      "epoch : 0 [6072/21279] Train loss: 0.29769,Valid loss: 0.59341, time : 14.56754207611084 lr : 0.8863848717161291\n",
      "epoch : 0 [6073/21279] Train loss: 0.24187,Valid loss: 0.45184, time : 12.640879392623901 lr : 0.8863848717161291\n",
      "epoch : 0 [6074/21279] Train loss: 0.21147,Valid loss: 0.30600, time : 11.979260683059692 lr : 0.8863848717161291\n",
      "epoch : 0 [6075/21279] Train loss: 0.20178,Valid loss: 0.25855, time : 12.446850299835205 lr : 0.8863848717161291\n",
      "epoch : 0 [6076/21279] Train loss: 0.18814,Valid loss: 0.28220, time : 12.534742593765259 lr : 0.8863848717161291\n",
      "epoch : 0 [6077/21279] Train loss: 0.19237,Valid loss: 0.27600, time : 12.85792589187622 lr : 0.8863848717161291\n",
      "epoch : 0 [6078/21279] Train loss: 0.18969,Valid loss: 0.26658, time : 12.94890809059143 lr : 0.8863848717161291\n",
      "epoch : 0 [6079/21279] Train loss: 0.19721,Valid loss: 0.26394, time : 13.003442287445068 lr : 0.8863848717161291\n",
      "epoch : 0 [6080/21279] Train loss: 0.20176,Valid loss: 0.27067, time : 12.29666805267334 lr : 0.8863848717161291\n",
      "epoch : 0 [6081/21279] Train loss: 0.18796,Valid loss: 0.33875, time : 12.46635127067566 lr : 0.8863848717161291\n",
      "epoch : 0 [6082/21279] Train loss: 0.24563,Valid loss: 0.30936, time : 11.91768479347229 lr : 0.8863848717161291\n",
      "epoch : 0 [6083/21279] Train loss: 0.20914,Valid loss: 0.25771, time : 12.346099376678467 lr : 0.8863848717161291\n",
      "epoch : 0 [6084/21279] Train loss: 0.19309,Valid loss: 0.25401, time : 12.36502981185913 lr : 0.8863848717161291\n",
      "epoch : 0 [6085/21279] Train loss: 0.19284,Valid loss: 0.28899, time : 12.747569561004639 lr : 0.8863848717161291\n",
      "epoch : 0 [6086/21279] Train loss: 0.23191,Valid loss: 0.34268, time : 14.809547185897827 lr : 0.8863848717161291\n",
      "epoch : 0 [6087/21279] Train loss: 0.27388,Valid loss: 0.43472, time : 12.879542589187622 lr : 0.8863848717161291\n",
      "epoch : 0 [6088/21279] Train loss: 0.29086,Valid loss: 0.54714, time : 12.228184938430786 lr : 0.8863848717161291\n",
      "epoch : 0 [6089/21279] Train loss: 0.35594,Valid loss: 0.69164, time : 12.634427070617676 lr : 0.8863848717161291\n",
      "epoch : 0 [6090/21279] Train loss: 0.38249,Valid loss: 0.56627, time : 12.266140460968018 lr : 0.8863848717161291\n",
      "epoch : 0 [6091/21279] Train loss: 0.29557,Valid loss: 0.36391, time : 13.278286457061768 lr : 0.8863848717161291\n",
      "epoch : 0 [6092/21279] Train loss: 0.24196,Valid loss: 0.35943, time : 12.84676742553711 lr : 0.8863848717161291\n",
      "epoch : 0 [6093/21279] Train loss: 0.22245,Valid loss: 0.30696, time : 13.07987928390503 lr : 0.8863848717161291\n",
      "epoch : 0 [6094/21279] Train loss: 0.21593,Valid loss: 0.29732, time : 13.025951623916626 lr : 0.8863848717161291\n",
      "epoch : 0 [6095/21279] Train loss: 0.20319,Valid loss: 0.30616, time : 12.318674802780151 lr : 0.8863848717161291\n",
      "epoch : 0 [6096/21279] Train loss: 0.21258,Valid loss: 0.28903, time : 12.504810810089111 lr : 0.8863848717161291\n",
      "epoch : 0 [6097/21279] Train loss: 0.20176,Valid loss: 0.31430, time : 12.61084532737732 lr : 0.8863848717161291\n",
      "epoch : 0 [6098/21279] Train loss: 0.21122,Valid loss: 0.30440, time : 14.103145122528076 lr : 0.8863848717161291\n",
      "epoch : 0 [6099/21279] Train loss: 0.21338,Valid loss: 0.29352, time : 12.700150728225708 lr : 0.8863848717161291\n",
      "epoch : 0 [6100/21279] Train loss: 0.19440,Valid loss: 0.32279, time : 12.215145587921143 lr : 0.8863848717161291\n",
      "epoch : 0 [6101/21279] Train loss: 0.24127,Valid loss: 0.30789, time : 12.294575691223145 lr : 0.8863848717161291\n",
      "epoch : 0 [6102/21279] Train loss: 0.20786,Valid loss: 0.29645, time : 12.236889839172363 lr : 0.8863848717161291\n",
      "epoch : 0 [6103/21279] Train loss: 0.20740,Valid loss: 0.31889, time : 12.03177261352539 lr : 0.8863848717161291\n",
      "epoch : 0 [6104/21279] Train loss: 0.20646,Valid loss: 0.30846, time : 12.63684606552124 lr : 0.8863848717161291\n",
      "epoch : 0 [6105/21279] Train loss: 0.22477,Valid loss: 0.28271, time : 12.631819248199463 lr : 0.8863848717161291\n",
      "epoch : 0 [6106/21279] Train loss: 0.20114,Valid loss: 0.30685, time : 13.032835006713867 lr : 0.8863848717161291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [6107/21279] Train loss: 0.19950,Valid loss: 0.30430, time : 12.23923921585083 lr : 0.8863848717161291\n",
      "epoch : 0 [6108/21279] Train loss: 0.20249,Valid loss: 0.29241, time : 12.592525005340576 lr : 0.8863848717161291\n",
      "epoch : 0 [6109/21279] Train loss: 0.19237,Valid loss: 0.28250, time : 12.494659423828125 lr : 0.8863848717161291\n",
      "epoch : 0 [6110/21279] Train loss: 0.19421,Valid loss: 0.30057, time : 13.240429639816284 lr : 0.8863848717161291\n",
      "epoch : 0 [6111/21279] Train loss: 0.21260,Valid loss: 0.28675, time : 12.545653104782104 lr : 0.8863848717161291\n",
      "epoch : 0 [6112/21279] Train loss: 0.19327,Valid loss: 0.29317, time : 12.99588942527771 lr : 0.8863848717161291\n",
      "epoch : 0 [6113/21279] Train loss: 0.20656,Valid loss: 0.28381, time : 12.006412744522095 lr : 0.8863848717161291\n",
      "epoch : 0 [6114/21279] Train loss: 0.19331,Valid loss: 0.27870, time : 14.705554485321045 lr : 0.8863848717161291\n",
      "epoch : 0 [6115/21279] Train loss: 0.19237,Valid loss: 0.31022, time : 12.361741065979004 lr : 0.8863848717161291\n",
      "epoch : 0 [6116/21279] Train loss: 0.19764,Valid loss: 0.29915, time : 12.034998655319214 lr : 0.8863848717161291\n",
      "epoch : 0 [6117/21279] Train loss: 0.19842,Valid loss: 0.27916, time : 12.176871061325073 lr : 0.8863848717161291\n",
      "epoch : 0 [6118/21279] Train loss: 0.19414,Valid loss: 0.28928, time : 12.204854011535645 lr : 0.8863848717161291\n",
      "epoch : 0 [6119/21279] Train loss: 0.18381,Valid loss: 0.28491, time : 11.417190313339233 lr : 0.8863848717161291\n",
      "epoch : 0 [6120/21279] Train loss: 0.19714,Valid loss: 0.26541, time : 11.893248796463013 lr : 0.8863848717161291\n",
      "epoch : 0 [6121/21279] Train loss: 0.18827,Valid loss: 0.27920, time : 11.870389699935913 lr : 0.8863848717161291\n",
      "epoch : 0 [6122/21279] Train loss: 0.21124,Valid loss: 0.27081, time : 12.067087650299072 lr : 0.8863848717161291\n",
      "epoch : 0 [6123/21279] Train loss: 0.18668,Valid loss: 0.26868, time : 11.389685869216919 lr : 0.8863848717161291\n",
      "epoch : 0 [6124/21279] Train loss: 0.20214,Valid loss: 0.27409, time : 11.942518949508667 lr : 0.8863848717161291\n",
      "epoch : 0 [6125/21279] Train loss: 0.19465,Valid loss: 0.30179, time : 12.087642669677734 lr : 0.8863848717161291\n",
      "epoch : 0 [6126/21279] Train loss: 0.19225,Valid loss: 0.26050, time : 13.575117826461792 lr : 0.8863848717161291\n",
      "epoch : 0 [6127/21279] Train loss: 0.18376,Valid loss: 0.27172, time : 11.914972066879272 lr : 0.8863848717161291\n",
      "epoch : 0 [6128/21279] Train loss: 0.18908,Valid loss: 0.26246, time : 11.503733396530151 lr : 0.8863848717161291\n",
      "epoch : 0 [6129/21279] Train loss: 0.19174,Valid loss: 0.27477, time : 12.29166579246521 lr : 0.8863848717161291\n",
      "epoch : 0 [6130/21279] Train loss: 0.19850,Valid loss: 0.27689, time : 11.77487564086914 lr : 0.8863848717161291\n",
      "epoch : 0 [6131/21279] Train loss: 0.18653,Valid loss: 0.27419, time : 11.764764785766602 lr : 0.8863848717161291\n",
      "epoch : 0 [6132/21279] Train loss: 0.19666,Valid loss: 0.29522, time : 12.133676290512085 lr : 0.8863848717161291\n",
      "epoch : 0 [6133/21279] Train loss: 0.20381,Valid loss: 0.42429, time : 12.249073028564453 lr : 0.8863848717161291\n",
      "epoch : 0 [6134/21279] Train loss: 0.21015,Valid loss: 0.86309, time : 11.687662601470947 lr : 0.8863848717161291\n",
      "epoch : 0 [6135/21279] Train loss: 0.26074,Valid loss: 0.86145, time : 12.157094478607178 lr : 0.8863848717161291\n",
      "epoch : 0 [6136/21279] Train loss: 0.22547,Valid loss: 0.31542, time : 12.419891834259033 lr : 0.8863848717161291\n",
      "epoch : 0 [6137/21279] Train loss: 0.22179,Valid loss: 0.29499, time : 12.558116912841797 lr : 0.8863848717161291\n",
      "epoch : 0 [6138/21279] Train loss: 0.21680,Valid loss: 0.26284, time : 12.507966041564941 lr : 0.8863848717161291\n",
      "epoch : 0 [6139/21279] Train loss: 0.21106,Valid loss: 0.27812, time : 12.850252151489258 lr : 0.8863848717161291\n",
      "epoch : 0 [6140/21279] Train loss: 0.19259,Valid loss: 0.25786, time : 12.533820152282715 lr : 0.8863848717161291\n",
      "epoch : 0 [6141/21279] Train loss: 0.19374,Valid loss: 0.28474, time : 12.92539119720459 lr : 0.8863848717161291\n",
      "epoch : 0 [6142/21279] Train loss: 0.20264,Valid loss: 0.26968, time : 15.425504207611084 lr : 0.8863848717161291\n",
      "epoch : 0 [6143/21279] Train loss: 0.19794,Valid loss: 0.28430, time : 12.735164642333984 lr : 0.8863848717161291\n",
      "epoch : 0 [6144/21279] Train loss: 0.19033,Valid loss: 0.28291, time : 12.05964207649231 lr : 0.8863848717161291\n",
      "epoch : 0 [6145/21279] Train loss: 0.19782,Valid loss: 0.25942, time : 11.85896348953247 lr : 0.8863848717161291\n",
      "epoch : 0 [6146/21279] Train loss: 0.20364,Valid loss: 0.26783, time : 12.553176403045654 lr : 0.8863848717161291\n",
      "epoch : 0 [6147/21279] Train loss: 0.19263,Valid loss: 0.25768, time : 12.865992546081543 lr : 0.8863848717161291\n",
      "epoch : 0 [6148/21279] Train loss: 0.18500,Valid loss: 0.25498, time : 12.144334077835083 lr : 0.8863848717161291\n",
      "epoch : 0 [6149/21279] Train loss: 0.19702,Valid loss: 0.27751, time : 12.354003667831421 lr : 0.8863848717161291\n",
      "epoch : 0 [6150/21279] Train loss: 0.19470,Valid loss: 0.26507, time : 11.813020706176758 lr : 0.8863848717161291\n",
      "epoch : 0 [6151/21279] Train loss: 0.19197,Valid loss: 0.25417, time : 12.225613832473755 lr : 0.8863848717161291\n",
      "epoch : 0 [6152/21279] Train loss: 0.19410,Valid loss: 0.26469, time : 12.15004301071167 lr : 0.8863848717161291\n",
      "epoch : 0 [6153/21279] Train loss: 0.19169,Valid loss: 0.25780, time : 12.907842874526978 lr : 0.8863848717161291\n",
      "epoch : 0 [6154/21279] Train loss: 0.18073,Valid loss: 0.24720, time : 12.099884510040283 lr : 0.8863848717161291\n",
      "epoch : 0 [6155/21279] Train loss: 0.20289,Valid loss: 0.24950, time : 14.360207080841064 lr : 0.8863848717161291\n",
      "epoch : 0 [6156/21279] Train loss: 0.19294,Valid loss: 0.25489, time : 12.056727409362793 lr : 0.8863848717161291\n",
      "epoch : 0 [6157/21279] Train loss: 0.19790,Valid loss: 0.55601, time : 12.256403684616089 lr : 0.8863848717161291\n",
      "epoch : 0 [6158/21279] Train loss: 0.21913,Valid loss: 0.30116, time : 12.60802960395813 lr : 0.8863848717161291\n",
      "epoch : 0 [6159/21279] Train loss: 0.20854,Valid loss: 0.60723, time : 12.509236097335815 lr : 0.8863848717161291\n",
      "epoch : 0 [6160/21279] Train loss: 0.21543,Valid loss: 0.45689, time : 11.925848960876465 lr : 0.8863848717161291\n",
      "epoch : 0 [6161/21279] Train loss: 0.18983,Valid loss: 0.40907, time : 12.117304801940918 lr : 0.8863848717161291\n",
      "epoch : 0 [6162/21279] Train loss: 0.18655,Valid loss: 0.37156, time : 12.414021253585815 lr : 0.8863848717161291\n",
      "epoch : 0 [6163/21279] Train loss: 0.19743,Valid loss: 0.46829, time : 11.928427457809448 lr : 0.8863848717161291\n",
      "epoch : 0 [6164/21279] Train loss: 0.22757,Valid loss: 0.45198, time : 12.302996397018433 lr : 0.8863848717161291\n",
      "epoch : 0 [6165/21279] Train loss: 0.19184,Valid loss: 0.36459, time : 12.09562087059021 lr : 0.8863848717161291\n",
      "epoch : 0 [6166/21279] Train loss: 0.21054,Valid loss: 0.37109, time : 12.350689888000488 lr : 0.8863848717161291\n",
      "epoch : 0 [6167/21279] Train loss: 0.22366,Valid loss: 0.49443, time : 12.40341329574585 lr : 0.8863848717161291\n",
      "epoch : 0 [6168/21279] Train loss: 0.23413,Valid loss: 0.48941, time : 11.823756217956543 lr : 0.8863848717161291\n",
      "epoch : 0 [6169/21279] Train loss: 0.25024,Valid loss: 0.91661, time : 12.81473994255066 lr : 0.8863848717161291\n",
      "epoch : 0 [6170/21279] Train loss: 0.27645,Valid loss: 1.38282, time : 14.622443675994873 lr : 0.8863848717161291\n",
      "epoch : 0 [6171/21279] Train loss: 0.21569,Valid loss: 0.28145, time : 12.820648431777954 lr : 0.8863848717161291\n",
      "epoch : 0 [6172/21279] Train loss: 0.19936,Valid loss: 0.26205, time : 12.425034999847412 lr : 0.8863848717161291\n",
      "epoch : 0 [6173/21279] Train loss: 0.18111,Valid loss: 0.25703, time : 12.5175199508667 lr : 0.8863848717161291\n",
      "epoch : 0 [6174/21279] Train loss: 0.18856,Valid loss: 0.44368, time : 12.209076642990112 lr : 0.8863848717161291\n",
      "epoch : 0 [6175/21279] Train loss: 0.18303,Valid loss: 0.45124, time : 12.418406963348389 lr : 0.8863848717161291\n",
      "epoch : 0 [6176/21279] Train loss: 0.18281,Valid loss: 0.44325, time : 12.756003141403198 lr : 0.8863848717161291\n",
      "epoch : 0 [6177/21279] Train loss: 0.20789,Valid loss: 0.42733, time : 12.561053037643433 lr : 0.8863848717161291\n",
      "epoch : 0 [6178/21279] Train loss: 0.19613,Valid loss: 0.44558, time : 12.553870439529419 lr : 0.8863848717161291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [6179/21279] Train loss: 0.17470,Valid loss: 0.26534, time : 12.637146234512329 lr : 0.8863848717161291\n",
      "epoch : 0 [6180/21279] Train loss: 0.20235,Valid loss: 0.46128, time : 12.657594919204712 lr : 0.8863848717161291\n",
      "epoch : 0 [6181/21279] Train loss: 0.19002,Valid loss: 0.24877, time : 12.825918912887573 lr : 0.8863848717161291\n",
      "epoch : 0 [6182/21279] Train loss: 0.19870,Valid loss: 0.23773, time : 14.763952255249023 lr : 0.8863848717161291\n",
      "epoch : 0 [6183/21279] Train loss: 0.19331,Valid loss: 0.23074, time : 12.682078838348389 lr : 0.8863848717161291\n",
      "epoch : 0 [6184/21279] Train loss: 0.17929,Valid loss: 0.24034, time : 11.847204208374023 lr : 0.8863848717161291\n",
      "epoch : 0 [6185/21279] Train loss: 0.18225,Valid loss: 0.24645, time : 12.433811902999878 lr : 0.8863848717161291\n",
      "epoch : 0 [6186/21279] Train loss: 0.18125,Valid loss: 0.24995, time : 12.593262672424316 lr : 0.8863848717161291\n",
      "epoch : 0 [6187/21279] Train loss: 0.18723,Valid loss: 0.23450, time : 12.803888320922852 lr : 0.8863848717161291\n",
      "epoch : 0 [6188/21279] Train loss: 0.17530,Valid loss: 0.27001, time : 12.51266622543335 lr : 0.8863848717161291\n",
      "epoch : 0 [6189/21279] Train loss: 0.18620,Valid loss: 0.23380, time : 12.428762197494507 lr : 0.8863848717161291\n",
      "epoch : 0 [6190/21279] Train loss: 0.19523,Valid loss: 0.25586, time : 12.4820237159729 lr : 0.8863848717161291\n",
      "epoch : 0 [6191/21279] Train loss: 0.17812,Valid loss: 0.25966, time : 12.707208156585693 lr : 0.8863848717161291\n",
      "epoch : 0 [6192/21279] Train loss: 0.18157,Valid loss: 0.25307, time : 12.583949565887451 lr : 0.8863848717161291\n",
      "epoch : 0 [6193/21279] Train loss: 0.17574,Valid loss: 0.24377, time : 13.151522159576416 lr : 0.8863848717161291\n",
      "epoch : 0 [6194/21279] Train loss: 0.18249,Valid loss: 0.25842, time : 12.7709801197052 lr : 0.8863848717161291\n",
      "epoch : 0 [6195/21279] Train loss: 0.18418,Valid loss: 0.27252, time : 12.930202960968018 lr : 0.8863848717161291\n",
      "epoch : 0 [6196/21279] Train loss: 0.17536,Valid loss: 0.23755, time : 14.719106912612915 lr : 0.8863848717161291\n",
      "epoch : 0 [6197/21279] Train loss: 0.19355,Valid loss: 0.24216, time : 12.646657466888428 lr : 0.8863848717161291\n",
      "epoch : 0 [6198/21279] Train loss: 0.18024,Valid loss: 0.23806, time : 12.78254246711731 lr : 0.8863848717161291\n",
      "epoch : 0 [6199/21279] Train loss: 0.17900,Valid loss: 0.22461, time : 13.09051775932312 lr : 0.8863848717161291\n",
      "epoch : 0 [6200/21279] Train loss: 0.18106,Valid loss: 0.24027, time : 13.122377157211304 lr : 0.8863848717161291\n",
      "epoch : 0 [6201/21279] Train loss: 0.19072,Valid loss: 0.24566, time : 12.841349840164185 lr : 0.8863848717161291\n",
      "epoch : 0 [6202/21279] Train loss: 0.18258,Valid loss: 0.25107, time : 12.986824750900269 lr : 0.8863848717161291\n",
      "epoch : 0 [6203/21279] Train loss: 0.17391,Valid loss: 0.23904, time : 12.371004819869995 lr : 0.8863848717161291\n",
      "epoch : 0 [6204/21279] Train loss: 0.19030,Valid loss: 0.76882, time : 12.735837936401367 lr : 0.8863848717161291\n",
      "epoch : 0 [6205/21279] Train loss: 0.21343,Valid loss: 0.35061, time : 12.205390453338623 lr : 0.8863848717161291\n",
      "epoch : 0 [6206/21279] Train loss: 0.18954,Valid loss: 0.27147, time : 12.459086179733276 lr : 0.8863848717161291\n",
      "epoch : 0 [6207/21279] Train loss: 0.20327,Valid loss: 2.39309, time : 11.954460620880127 lr : 0.8863848717161291\n",
      "epoch : 0 [6208/21279] Train loss: 0.65200,Valid loss: 0.38350, time : 14.400326490402222 lr : 0.8863848717161291\n",
      "epoch : 0 [6209/21279] Train loss: 0.25096,Valid loss: 0.46952, time : 11.902143001556396 lr : 0.8863848717161291\n",
      "epoch : 0 [6210/21279] Train loss: 0.22704,Valid loss: 0.59858, time : 12.118666887283325 lr : 0.8863848717161291\n",
      "epoch : 0 [6211/21279] Train loss: 0.20784,Valid loss: 0.27446, time : 11.946825504302979 lr : 0.8863848717161291\n",
      "epoch : 0 [6212/21279] Train loss: 0.20475,Valid loss: 0.26072, time : 12.466559410095215 lr : 0.8863848717161291\n",
      "epoch : 0 [6213/21279] Train loss: 0.19548,Valid loss: 0.26267, time : 11.93258261680603 lr : 0.8863848717161291\n",
      "epoch : 0 [6214/21279] Train loss: 0.16895,Valid loss: 0.24900, time : 12.454490661621094 lr : 0.8863848717161291\n",
      "epoch : 0 [6215/21279] Train loss: 0.18765,Valid loss: 0.23859, time : 12.196242809295654 lr : 0.8863848717161291\n",
      "epoch : 0 [6216/21279] Train loss: 0.19384,Valid loss: 0.25618, time : 11.867326021194458 lr : 0.8863848717161291\n",
      "epoch : 0 [6217/21279] Train loss: 0.19336,Valid loss: 0.24844, time : 12.224386930465698 lr : 0.8863848717161291\n",
      "epoch : 0 [6218/21279] Train loss: 0.18508,Valid loss: 0.23624, time : 11.911709785461426 lr : 0.8863848717161291\n",
      "epoch : 0 [6219/21279] Train loss: 0.18121,Valid loss: 0.25768, time : 12.053956985473633 lr : 0.8863848717161291\n",
      "epoch : 0 [6220/21279] Train loss: 0.16989,Valid loss: 0.25398, time : 12.088910102844238 lr : 0.8863848717161291\n",
      "epoch : 0 [6221/21279] Train loss: 0.17500,Valid loss: 0.25249, time : 12.098773717880249 lr : 0.8863848717161291\n",
      "epoch : 0 [6222/21279] Train loss: 0.17866,Valid loss: 0.25181, time : 12.008206129074097 lr : 0.8863848717161291\n",
      "epoch : 0 [6223/21279] Train loss: 0.18651,Valid loss: 0.24254, time : 12.46429705619812 lr : 0.8863848717161291\n",
      "epoch : 0 [6224/21279] Train loss: 0.17999,Valid loss: 0.24289, time : 13.450778722763062 lr : 0.8863848717161291\n",
      "epoch : 0 [6225/21279] Train loss: 0.18862,Valid loss: 0.24125, time : 11.785057544708252 lr : 0.8863848717161291\n",
      "epoch : 0 [6226/21279] Train loss: 0.19008,Valid loss: 0.24050, time : 12.023822784423828 lr : 0.8863848717161291\n",
      "epoch : 0 [6227/21279] Train loss: 0.19434,Valid loss: 0.24848, time : 12.357645511627197 lr : 0.8863848717161291\n",
      "epoch : 0 [6228/21279] Train loss: 0.16777,Valid loss: 0.24170, time : 12.366832971572876 lr : 0.8863848717161291\n",
      "epoch : 0 [6229/21279] Train loss: 0.18149,Valid loss: 0.24228, time : 12.570669889450073 lr : 0.8863848717161291\n",
      "epoch : 0 [6230/21279] Train loss: 0.17685,Valid loss: 0.23706, time : 12.958162307739258 lr : 0.8863848717161291\n",
      "epoch : 0 [6231/21279] Train loss: 0.16491,Valid loss: 0.22975, time : 13.162749767303467 lr : 0.8863848717161291\n",
      "epoch : 0 [6232/21279] Train loss: 0.18473,Valid loss: 0.24521, time : 12.941430807113647 lr : 0.8863848717161291\n",
      "epoch : 0 [6233/21279] Train loss: 0.18738,Valid loss: 0.24189, time : 12.906493663787842 lr : 0.8863848717161291\n",
      "epoch : 0 [6234/21279] Train loss: 0.17439,Valid loss: 0.23568, time : 13.042147397994995 lr : 0.8863848717161291\n",
      "epoch : 0 [6235/21279] Train loss: 0.16213,Valid loss: 0.23996, time : 12.705775737762451 lr : 0.8863848717161291\n",
      "epoch : 0 [6236/21279] Train loss: 0.18917,Valid loss: 0.25243, time : 20.635308504104614 lr : 0.8863848717161291\n",
      "epoch : 0 [6237/21279] Train loss: 0.19484,Valid loss: 0.25153, time : 12.02139687538147 lr : 0.8863848717161291\n",
      "epoch : 0 [6238/21279] Train loss: 0.18624,Valid loss: 0.25018, time : 13.241515874862671 lr : 0.8863848717161291\n",
      "epoch : 0 [6239/21279] Train loss: 0.17683,Valid loss: 0.23735, time : 13.458663702011108 lr : 0.8863848717161291\n",
      "epoch : 0 [6240/21279] Train loss: 0.18191,Valid loss: 0.49155, time : 13.1041100025177 lr : 0.8863848717161291\n",
      "epoch : 0 [6241/21279] Train loss: 0.18686,Valid loss: 0.23027, time : 13.211181879043579 lr : 0.8863848717161291\n",
      "epoch : 0 [6242/21279] Train loss: 0.17318,Valid loss: 0.24327, time : 13.133127927780151 lr : 0.8863848717161291\n",
      "epoch : 0 [6243/21279] Train loss: 0.18893,Valid loss: 0.23412, time : 13.084289312362671 lr : 0.8863848717161291\n",
      "epoch : 0 [6244/21279] Train loss: 0.18358,Valid loss: 0.23044, time : 13.004668235778809 lr : 0.8863848717161291\n",
      "epoch : 0 [6245/21279] Train loss: 0.17468,Valid loss: 0.22207, time : 12.329390525817871 lr : 0.8863848717161291\n",
      "epoch : 0 [6246/21279] Train loss: 0.17789,Valid loss: 0.22854, time : 12.380049467086792 lr : 0.8863848717161291\n",
      "epoch : 0 [6247/21279] Train loss: 0.16596,Valid loss: 0.25293, time : 12.257136106491089 lr : 0.8863848717161291\n",
      "epoch : 0 [6248/21279] Train loss: 0.21485,Valid loss: 0.27545, time : 11.973842859268188 lr : 0.8863848717161291\n",
      "epoch : 0 [6249/21279] Train loss: 0.22521,Valid loss: 0.82306, time : 12.629090070724487 lr : 0.8863848717161291\n",
      "epoch : 0 [6250/21279] Train loss: 0.21755,Valid loss: 0.26503, time : 12.078640460968018 lr : 0.8863848717161291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 [6251/21279] Train loss: 0.19983,Valid loss: 0.23777, time : 12.071133375167847 lr : 0.8863848717161291\n",
      "epoch : 0 [6252/21279] Train loss: 0.17838,Valid loss: 0.24696, time : 14.266223907470703 lr : 0.8863848717161291\n",
      "epoch : 0 [6253/21279] Train loss: 0.17976,Valid loss: 0.23451, time : 12.356256008148193 lr : 0.8863848717161291\n",
      "epoch : 0 [6254/21279] Train loss: 0.19147,Valid loss: 0.24594, time : 12.26571536064148 lr : 0.8863848717161291\n",
      "epoch : 0 [6255/21279] Train loss: 0.18011,Valid loss: 0.24755, time : 11.820903301239014 lr : 0.8863848717161291\n",
      "epoch : 0 [6256/21279] Train loss: 0.19618,Valid loss: 0.25778, time : 12.339102268218994 lr : 0.8863848717161291\n",
      "epoch : 0 [6257/21279] Train loss: 0.16436,Valid loss: 0.23133, time : 12.536713123321533 lr : 0.8863848717161291\n",
      "epoch : 0 [6258/21279] Train loss: 0.18741,Valid loss: 0.23271, time : 12.745091438293457 lr : 0.8863848717161291\n",
      "epoch : 0 [6259/21279] Train loss: 0.16688,Valid loss: 0.23915, time : 12.449487447738647 lr : 0.8863848717161291\n",
      "epoch : 0 [6260/21279] Train loss: 0.17773,Valid loss: 0.22677, time : 12.519658327102661 lr : 0.8863848717161291\n",
      "epoch : 0 [6261/21279] Train loss: 0.18152,Valid loss: 0.22981, time : 12.375917196273804 lr : 0.8863848717161291\n",
      "epoch : 0 [6262/21279] Train loss: 0.18033,Valid loss: 0.22903, time : 12.7425057888031 lr : 0.8863848717161291\n",
      "epoch : 0 [6263/21279] Train loss: 0.17258,Valid loss: 0.24736, time : 12.694456100463867 lr : 0.8863848717161291\n",
      "epoch : 0 [6264/21279] Train loss: 0.17316,Valid loss: 0.22200, time : 12.905078172683716 lr : 0.8863848717161291\n",
      "epoch : 0 [6265/21279] Train loss: 0.18009,Valid loss: 0.24087, time : 14.89798378944397 lr : 0.8863848717161291\n",
      "epoch : 0 [6266/21279] Train loss: 0.17303,Valid loss: 0.21554, time : 12.27197003364563 lr : 0.8863848717161291\n",
      "epoch : 0 [6267/21279] Train loss: 0.16406,Valid loss: 0.22749, time : 13.019930124282837 lr : 0.8863848717161291\n",
      "epoch : 0 [6268/21279] Train loss: 0.17956,Valid loss: 0.22891, time : 12.748574495315552 lr : 0.8863848717161291\n",
      "epoch : 0 [6269/21279] Train loss: 0.19138,Valid loss: 0.24243, time : 12.185101985931396 lr : 0.8863848717161291\n",
      "epoch : 0 [6270/21279] Train loss: 0.18158,Valid loss: 0.22187, time : 12.981333494186401 lr : 0.8863848717161291\n",
      "epoch : 0 [6271/21279] Train loss: 0.18167,Valid loss: 0.21384, time : 12.799521684646606 lr : 0.8863848717161291\n",
      "epoch : 0 [6272/21279] Train loss: 0.17952,Valid loss: 0.22506, time : 11.585246801376343 lr : 0.8863848717161291\n",
      "epoch : 0 [6273/21279] Train loss: 0.18998,Valid loss: 0.23361, time : 11.86133337020874 lr : 0.8863848717161291\n",
      "epoch : 0 [6274/21279] Train loss: 0.17164,Valid loss: 0.23196, time : 12.063592433929443 lr : 0.8863848717161291\n",
      "epoch : 0 [6275/21279] Train loss: 0.18969,Valid loss: 0.22597, time : 11.856407403945923 lr : 0.8863848717161291\n",
      "epoch : 0 [6276/21279] Train loss: 0.17578,Valid loss: 0.22016, time : 11.578986883163452 lr : 0.8863848717161291\n",
      "epoch : 0 [6277/21279] Train loss: 0.17896,Valid loss: 0.23317, time : 11.282447814941406 lr : 0.8863848717161291\n",
      "epoch : 0 [6278/21279] Train loss: 0.16689,Valid loss: 0.23391, time : 11.643762350082397 lr : 0.8863848717161291\n",
      "epoch : 0 [6279/21279] Train loss: 0.17570,Valid loss: 0.22235, time : 11.794294357299805 lr : 0.8863848717161291\n",
      "epoch : 0 [6280/21279] Train loss: 0.17251,Valid loss: 0.21707, time : 13.726260900497437 lr : 0.8863848717161291\n",
      "epoch : 0 [6281/21279] Train loss: 0.17120,Valid loss: 0.22855, time : 12.71544623374939 lr : 0.8863848717161291\n",
      "epoch : 0 [6282/21279] Train loss: 0.17050,Valid loss: 0.23109, time : 12.280264377593994 lr : 0.8863848717161291\n",
      "epoch : 0 [6283/21279] Train loss: 0.18635,Valid loss: 0.22495, time : 12.332385778427124 lr : 0.8863848717161291\n",
      "epoch : 0 [6284/21279] Train loss: 0.17097,Valid loss: 0.22408, time : 12.412838459014893 lr : 0.8863848717161291\n",
      "epoch : 0 [6285/21279] Train loss: 0.17738,Valid loss: 0.22600, time : 12.344382286071777 lr : 0.8863848717161291\n",
      "epoch : 0 [6286/21279] Train loss: 0.19172,Valid loss: 0.23231, time : 11.751209020614624 lr : 0.8863848717161291\n",
      "epoch : 0 [6287/21279] Train loss: 0.18530,Valid loss: 0.23423, time : 12.011900424957275 lr : 0.8863848717161291\n",
      "epoch : 0 [6288/21279] Train loss: 0.17653,Valid loss: 0.23198, time : 12.427831888198853 lr : 0.8863848717161291\n",
      "epoch : 0 [6289/21279] Train loss: 0.17651,Valid loss: 0.22979, time : 12.788513898849487 lr : 0.8863848717161291\n",
      "epoch : 0 [6290/21279] Train loss: 0.17865,Valid loss: 0.23473, time : 13.271191835403442 lr : 0.8863848717161291\n",
      "epoch : 0 [6291/21279] Train loss: 0.17637,Valid loss: 0.23282, time : 12.115085363388062 lr : 0.8863848717161291\n",
      "epoch : 0 [6292/21279] Train loss: 0.19192,Valid loss: 0.22116, time : 14.090983629226685 lr : 0.8863848717161291\n",
      "epoch : 0 [6293/21279] Train loss: 0.17113,Valid loss: 0.23373, time : 12.353302240371704 lr : 0.8863848717161291\n",
      "epoch : 0 [6294/21279] Train loss: 0.17783,Valid loss: 0.25469, time : 12.40532398223877 lr : 0.8863848717161291\n",
      "epoch : 0 [6295/21279] Train loss: 0.17271,Valid loss: 0.23065, time : 12.33154582977295 lr : 0.8863848717161291\n",
      "epoch : 0 [6296/21279] Train loss: 0.18012,Valid loss: 0.22031, time : 12.47884225845337 lr : 0.8863848717161291\n",
      "epoch : 0 [6297/21279] Train loss: 0.18603,Valid loss: 0.21039, time : 12.562272787094116 lr : 0.8863848717161291\n",
      "epoch : 0 [6298/21279] Train loss: 0.18022,Valid loss: 0.22277, time : 12.526795864105225 lr : 0.8863848717161291\n",
      "epoch : 0 [6299/21279] Train loss: 0.17129,Valid loss: 0.22061, time : 12.174847841262817 lr : 0.8863848717161291\n",
      "epoch : 0 [6300/21279] Train loss: 0.17336,Valid loss: 0.22941, time : 11.648540496826172 lr : 0.8863848717161291\n",
      "epoch : 0 [6301/21279] Train loss: 0.19339,Valid loss: 0.22434, time : 11.739824533462524 lr : 0.8863848717161291\n",
      "epoch : 0 [6302/21279] Train loss: 0.18337,Valid loss: 0.21842, time : 11.924906969070435 lr : 0.8863848717161291\n",
      "epoch : 0 [6303/21279] Train loss: 0.16672,Valid loss: 0.37450, time : 12.102503299713135 lr : 0.8863848717161291\n",
      "epoch : 0 [6304/21279] Train loss: 0.17382,Valid loss: 0.24776, time : 11.587059259414673 lr : 0.8863848717161291\n",
      "epoch : 0 [6305/21279] Train loss: 0.17160,Valid loss: 0.55462, time : 12.053426504135132 lr : 0.8863848717161291\n",
      "epoch : 0 [6306/21279] Train loss: 0.17709,Valid loss: 0.22615, time : 13.891593933105469 lr : 0.8863848717161291\n",
      "epoch : 0 [6307/21279] Train loss: 0.18673,Valid loss: 0.85076, time : 11.982789039611816 lr : 0.8863848717161291\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "from utils import CTCLabelConverter, CTCLabelConverterForBaiduWarpctc, AttnLabelConverter, Averager\n",
    "from dataset import custom_dataset,AlignCollate\n",
    "from model import Model\n",
    "\n",
    "import easydict\n",
    "global opt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "global opt\n",
    "opt = easydict.EasyDict({\n",
    "    \"exp_name\": \"test_01\",\n",
    "    \"train_data\": \"/data/data/STARN/data_lmdb_release/training\",\n",
    "    \"valid_data\":\"/data/data/STARN/data_lmdb_release/validation\",\n",
    "    \"manualSeed\": 1111,\n",
    "    \"workers\": 8,\n",
    "    \"batch_size\":1024,\n",
    "    \"num_iter\":300000,\n",
    "    \"valInterval\":1,\n",
    "    \"saved_model\":'',\n",
    "    \"FT\":False,\n",
    "    \"adam\":False,\n",
    "    \"lr\":1,\n",
    "    \"beta1\":0.9,\n",
    "    \"rho\":0.95,\n",
    "    \"eps\":1e-8,\n",
    "    \"grad_clip\":5,\n",
    "    \"baiduCTC\":False,\n",
    "    \"select_data\":'ST',\n",
    "    \"batch_ratio\":'1',\n",
    "    \"total_data_usage_ratio\":'1.0',\n",
    "    \"batch_max_length\":25,\n",
    "    \"imgW\":100,\n",
    "    \"imgH\":32,\n",
    "    \"rgb\":False,\n",
    "    \"character\":\"0123456789abcdefghijklmnopqrstuvwxyz\",\n",
    "    \"sensitive\":False,\n",
    "    \"PAD\":False,\n",
    "    \"data_filtering_off\":False,\n",
    "    \"Transformation\":\"TPS\",\n",
    "    \"FeatureExtraction\":\"ResNet\",\n",
    "    \"SequenceModeling\":\"BiLSTM\",\n",
    "    \"Prediction\":'Attn',\n",
    "    \"num_fiducial\":20,\n",
    "    \"input_channel\":1,\n",
    "    \"output_channel\":512,\n",
    "    \"hidden_size\":256    \n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def validation(model, criterion, evaluation_loader, converter, opt):\n",
    "    \"\"\" validation or evaluation \"\"\"\n",
    "    n_correct = 0\n",
    "    norm_ED = 0\n",
    "    length_of_data = 0\n",
    "    infer_time = 0\n",
    "    valid_loss_avg = Averager()\n",
    "\n",
    "    for i, (image_tensors, labels) in enumerate(evaluation_loader):\n",
    "        batch_size = image_tensors.size(0)\n",
    "        length_of_data = length_of_data + batch_size\n",
    "        image = image_tensors.to(device)\n",
    "        # For max length prediction\n",
    "        length_for_pred = torch.IntTensor([opt.batch_max_length] * batch_size).to(device)\n",
    "        text_for_pred = torch.LongTensor(batch_size, opt.batch_max_length + 1).fill_(0).to(device)\n",
    "\n",
    "        text_for_loss, length_for_loss = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
    "\n",
    "        start_time = time.time()\n",
    "        if 'CTC' in opt.Prediction:\n",
    "            preds = model(image, text_for_pred)\n",
    "            forward_time = time.time() - start_time\n",
    "\n",
    "            # Calculate evaluation loss for CTC deocder.\n",
    "            preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
    "            # permute 'preds' to use CTCloss format\n",
    "            if opt.baiduCTC:\n",
    "                cost = criterion(preds.permute(1, 0, 2), text_for_loss, preds_size, length_for_loss) / batch_size\n",
    "            else:\n",
    "                cost = criterion(preds.log_softmax(2).permute(1, 0, 2), text_for_loss, preds_size, length_for_loss)\n",
    "\n",
    "            # Select max probabilty (greedy decoding) then decode index to character\n",
    "            if opt.baiduCTC:\n",
    "                _, preds_index = preds.max(2)\n",
    "                preds_index = preds_index.view(-1)\n",
    "            else:\n",
    "                _, preds_index = preds.max(2)\n",
    "            preds_str = converter.decode(preds_index.data, preds_size.data)\n",
    "        \n",
    "        else:\n",
    "            preds = model(image, text_for_pred, is_train=False)\n",
    "            forward_time = time.time() - start_time\n",
    "\n",
    "            preds = preds[:, :text_for_loss.shape[1] - 1, :]\n",
    "            target = text_for_loss[:, 1:]  # without [GO] Symbol\n",
    "            cost = criterion(preds.contiguous().view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
    "\n",
    "            # select max probabilty (greedy decoding) then decode index to character\n",
    "            _, preds_index = preds.max(2)\n",
    "            preds_str = converter.decode(preds_index, length_for_pred)\n",
    "            labels = converter.decode(text_for_loss[:, 1:], length_for_loss)\n",
    "\n",
    "        infer_time += forward_time\n",
    "        valid_loss_avg.add(cost)\n",
    "\n",
    "        # calculate accuracy & confidence score\n",
    "        preds_prob = F.softmax(preds, dim=2)\n",
    "        preds_max_prob, _ = preds_prob.max(dim=2)\n",
    "        confidence_score_list = []\n",
    "        for gt, pred, pred_max_prob in zip(labels, preds_str, preds_max_prob):\n",
    "            if 'Attn' in opt.Prediction:\n",
    "                gt = gt[:gt.find('[s]')]\n",
    "                pred_EOS = pred.find('[s]')\n",
    "                pred = pred[:pred_EOS]  # prune after \"end of sentence\" token ([s])\n",
    "                pred_max_prob = pred_max_prob[:pred_EOS]\n",
    "\n",
    "\n",
    "            if pred == gt:\n",
    "                n_correct += 1\n",
    "\n",
    "            '''\n",
    "            (old version) ICDAR2017 DOST Normalized Edit Distance https://rrc.cvc.uab.es/?ch=7&com=tasks\n",
    "            \"For each word we calculate the normalized edit distance to the length of the ground truth transcription.\"\n",
    "            if len(gt) == 0:\n",
    "                norm_ED += 1\n",
    "            else:\n",
    "                norm_ED += edit_distance(pred, gt) / len(gt)\n",
    "            '''\n",
    "\n",
    "            # ICDAR2019 Normalized Edit Distance\n",
    "            if len(gt) == 0 or len(pred) == 0:\n",
    "                norm_ED += 0\n",
    "            elif len(gt) > len(pred):\n",
    "                norm_ED += 1 - edit_distance(pred, gt) / len(gt)\n",
    "            else:\n",
    "                norm_ED += 1 - edit_distance(pred, gt) / len(pred)\n",
    "\n",
    "            # calculate confidence score (= multiply of pred_max_prob)\n",
    "            try:\n",
    "                confidence_score = pred_max_prob.cumprod(dim=0)[-1]\n",
    "            except:\n",
    "                confidence_score = 0  # for empty pred case, when prune after \"end of sentence\" token ([s])\n",
    "            confidence_score_list.append(confidence_score)\n",
    "            # print(pred, gt, pred==gt, confidence_score)\n",
    "\n",
    "    accuracy = n_correct / float(length_of_data) * 100\n",
    "    norm_ED = norm_ED / float(length_of_data)  # ICDAR2019 Normalized Edit Distance\n",
    "\n",
    "    return valid_loss_avg.val(), accuracy, norm_ED, preds_str, confidence_score_list, labels, infer_time, length_of_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \"\"\" Seed and GPU setting \"\"\"\n",
    "    # print(\"Random Seed: \", opt.manualSeed)\n",
    "    random.seed(opt.manualSeed)\n",
    "    np.random.seed(opt.manualSeed)\n",
    "    torch.manual_seed(opt.manualSeed)\n",
    "    torch.cuda.manual_seed(opt.manualSeed)\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = True\n",
    "    opt.num_gpu = torch.cuda.device_count()\n",
    "    # print('device count', opt.num_gpu)\n",
    "    if opt.num_gpu > 1:\n",
    "        print('------ Use multi-GPU setting ------')\n",
    "        print('if you stuck too long time with multi-GPU setting, try to set --workers 0')\n",
    "        # check multi-GPU issue https://github.com/clovaai/deep-text-recognition-benchmark/issues/1\n",
    "        opt.workers = opt.workers * opt.num_gpu\n",
    "        opt.batch_size = opt.batch_size * opt.num_gpu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    numclass_path = \"./ch_range.txt\"\n",
    "    f = open(numclass_path, 'r')\n",
    "    ch_temp = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    opt.character = ch_temp\n",
    "\n",
    "    converter = AttnLabelConverter(opt.character)\n",
    "    opt.num_class = len(converter.character)\n",
    "\n",
    "\n",
    "    train_dataset = custom_dataset(\"./dict/nia_refine_concat.txt\",\"./font_full\",\"train\")\n",
    "    valid_dataset = custom_dataset(\"./dict/nia_refine_concat.txt\",\"./font\",\"valid\")\n",
    "\n",
    "    AlignCollate_valid = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=opt.batch_size,\n",
    "            shuffle=True,  # 'True' to check training progress with validation function.\n",
    "            num_workers=int(opt.workers),\n",
    "            collate_fn=AlignCollate_valid, pin_memory=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=opt.batch_size,\n",
    "            shuffle=True,  # 'True' to check training progress with validation function.\n",
    "            num_workers=int(opt.workers),\n",
    "            collate_fn=AlignCollate_valid, pin_memory=True)\n",
    "\n",
    "\n",
    "    if opt.rgb:\n",
    "        opt.input_channel = 3\n",
    "    model = Model(opt)\n",
    "\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'localization_fc2' in name:\n",
    "            print(f'Skip {name} as it is already initialized')\n",
    "            continue\n",
    "        try:\n",
    "            if 'bias' in name:\n",
    "                init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                init.kaiming_normal_(param)\n",
    "        except Exception as e:  # for batchnorm.\n",
    "            if 'weight' in name:\n",
    "                param.data.fill_(1)\n",
    "            continue\n",
    "\n",
    "\n",
    "    model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "\n",
    "    loss_avg = Averager()\n",
    "\n",
    "\n",
    "    filtered_parameters = []\n",
    "\n",
    "    for p in filter(lambda p: p.requires_grad, model.parameters()):\n",
    "        filtered_parameters.append(p)\n",
    "\n",
    "\n",
    "    if opt.adam:\n",
    "#         optimizer = optim.Adam(filtered_parameters, lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "        optimizer = optim.Adam(filtered_parameters, lr=opt.lr)\n",
    "    else:\n",
    "        optimizer = optim.Adadelta(filtered_parameters, lr=opt.lr, rho=opt.rho, eps=opt.eps)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=360, gamma=0.98)\n",
    "    \n",
    "    nb_epochs = 100000\n",
    "\n",
    "    for epoch in range(nb_epochs + 1):\n",
    "        \n",
    "        for batch_idx, samples in enumerate(train_loader):\n",
    "\n",
    "            log = open(f'./log_val.txt', 'a')\n",
    "            log2= open(f'./log_train.txt', 'a')\n",
    "\n",
    "            start_time = time.time()        \n",
    "            model.train()\n",
    "\n",
    "            image_tensors, labels = samples\n",
    "            image = image_tensors.to(device)\n",
    "            text, length = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            preds = model(image, text[:, :-1])  # align with Attention.forward\n",
    "            target = text[:, 1:]  # without [GO] Symbol\n",
    "            cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
    "\n",
    "\n",
    "\n",
    "            model.zero_grad()\n",
    "            cost.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip)  # gradient clipping with 5 (Default)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            loss_avg.add(cost)\n",
    "\n",
    "            for param_group in optimizer.param_groups:\n",
    "                learning_rate_val=param_group['lr']\n",
    "\n",
    "\n",
    "            ## \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                valid_loss, current_accuracy, current_norm_ED, preds, confidence_score, labels, infer_time, length_of_data = validation(\n",
    "                            model, criterion, valid_loader, converter, opt)\n",
    "\n",
    "            end = time.time()\n",
    "            loss_log = f'epoch : {epoch} [{batch_idx}/{len(train_loader)}] Train loss: {loss_avg.val():0.5f},Valid loss: {valid_loss:0.5f}, time : {end-start_time} lr : {learning_rate_val}'        \n",
    "            loss_avg.reset()\n",
    "\n",
    "\n",
    "            print(loss_log)\n",
    "\n",
    "            dashed_line = '-' * 80\n",
    "            head = f'{\"Ground Truth\":25s} | {\"Prediction\":25s} | Confidence Score & T/F'\n",
    "            predicted_result_log = f'{dashed_line}\\n{head}\\n{dashed_line}\\n'\n",
    "            for gt, pred, confidence in zip(labels[:5], preds[:5], confidence_score[:5]):\n",
    "                if 'Attn' in opt.Prediction:\n",
    "                    gt = gt[:gt.find('[s]')]\n",
    "                    pred = pred[:pred.find('[s]')]\n",
    "\n",
    "                predicted_result_log += f'{gt:25s} | {pred:25s} | {confidence:0.4f}\\t{str(pred == gt)}\\n'\n",
    "            predicted_result_log += f'{dashed_line}'\n",
    "    #         print(predicted_result_log)\n",
    "            \n",
    "            log2.write(loss_log + '\\n')\n",
    "            log.write(loss_log + '\\n')\n",
    "            log.write(predicted_result_log + '\\n')\n",
    "            log.close()\n",
    "            log2.close()\n",
    "            \n",
    "#         scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a139ac64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
