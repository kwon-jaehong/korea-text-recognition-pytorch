{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdeacc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Use multi-GPU setting ------\n",
      "if you stuck too long time with multi-GPU setting, try to set --workers 0\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
      "epoch : 0 [0/21279] Train loss: 8.01477,Valid loss: 7.96793, time : 43.7067768573761 lr : 1\n",
      "epoch : 0 [1/21279] Train loss: 7.90198,Valid loss: 7.96471, time : 10.575998544692993 lr : 1\n",
      "epoch : 0 [2/21279] Train loss: 7.76169,Valid loss: 7.91519, time : 10.225582599639893 lr : 1\n",
      "epoch : 0 [3/21279] Train loss: 7.57507,Valid loss: 7.62969, time : 10.508798122406006 lr : 1\n",
      "epoch : 0 [4/21279] Train loss: 7.32233,Valid loss: 7.40063, time : 10.808136940002441 lr : 1\n",
      "epoch : 0 [5/21279] Train loss: 7.04711,Valid loss: 6.98339, time : 10.834587097167969 lr : 1\n",
      "epoch : 0 [6/21279] Train loss: 6.85731,Valid loss: 6.82664, time : 11.082875967025757 lr : 1\n",
      "epoch : 0 [7/21279] Train loss: 6.76499,Valid loss: 6.71882, time : 10.605359315872192 lr : 1\n",
      "epoch : 0 [8/21279] Train loss: 6.68107,Valid loss: 6.63644, time : 10.673686742782593 lr : 1\n",
      "epoch : 0 [9/21279] Train loss: 6.61109,Valid loss: 6.55296, time : 12.468891620635986 lr : 1\n",
      "epoch : 0 [10/21279] Train loss: 6.54230,Valid loss: 6.49550, time : 10.943067073822021 lr : 1\n",
      "epoch : 0 [11/21279] Train loss: 6.50072,Valid loss: 6.37366, time : 10.621774196624756 lr : 1\n",
      "epoch : 0 [12/21279] Train loss: 6.38868,Valid loss: 6.29140, time : 11.034197092056274 lr : 1\n",
      "epoch : 0 [13/21279] Train loss: 6.32784,Valid loss: 6.22216, time : 11.00511622428894 lr : 1\n",
      "epoch : 0 [14/21279] Train loss: 6.24932,Valid loss: 6.15757, time : 11.072881937026978 lr : 1\n",
      "epoch : 0 [15/21279] Train loss: 6.19524,Valid loss: 6.10097, time : 11.21462106704712 lr : 1\n",
      "epoch : 0 [16/21279] Train loss: 6.12983,Valid loss: 6.04277, time : 11.329920291900635 lr : 1\n",
      "epoch : 0 [17/21279] Train loss: 6.09320,Valid loss: 5.99529, time : 11.166548728942871 lr : 1\n",
      "epoch : 0 [18/21279] Train loss: 6.02189,Valid loss: 5.93967, time : 11.254831314086914 lr : 1\n",
      "epoch : 0 [19/21279] Train loss: 5.98026,Valid loss: 5.91070, time : 12.441884994506836 lr : 1\n",
      "epoch : 0 [20/21279] Train loss: 5.93123,Valid loss: 5.86791, time : 11.472780466079712 lr : 1\n",
      "epoch : 0 [21/21279] Train loss: 5.89264,Valid loss: 5.86427, time : 13.49535608291626 lr : 1\n",
      "epoch : 0 [22/21279] Train loss: 5.87508,Valid loss: 5.81655, time : 11.595378398895264 lr : 1\n",
      "epoch : 0 [23/21279] Train loss: 5.85226,Valid loss: 5.80615, time : 11.100006818771362 lr : 1\n",
      "epoch : 0 [24/21279] Train loss: 5.80448,Valid loss: 5.75800, time : 11.208696126937866 lr : 1\n",
      "epoch : 0 [25/21279] Train loss: 5.76399,Valid loss: 5.74477, time : 11.73926568031311 lr : 1\n",
      "epoch : 0 [26/21279] Train loss: 5.73505,Valid loss: 5.71466, time : 11.368431568145752 lr : 1\n",
      "epoch : 0 [27/21279] Train loss: 5.70302,Valid loss: 5.70471, time : 11.21553921699524 lr : 1\n",
      "epoch : 0 [28/21279] Train loss: 5.67665,Valid loss: 5.68300, time : 11.243731498718262 lr : 1\n",
      "epoch : 0 [29/21279] Train loss: 5.64712,Valid loss: 5.67805, time : 12.002270936965942 lr : 1\n",
      "epoch : 0 [30/21279] Train loss: 5.63937,Valid loss: 5.65436, time : 12.179198265075684 lr : 1\n",
      "epoch : 0 [31/21279] Train loss: 5.66039,Valid loss: 5.66006, time : 12.358285188674927 lr : 1\n",
      "epoch : 0 [32/21279] Train loss: 5.62766,Valid loss: 5.63835, time : 11.44223403930664 lr : 1\n",
      "epoch : 0 [33/21279] Train loss: 5.60639,Valid loss: 5.64106, time : 11.341644763946533 lr : 1\n",
      "epoch : 0 [34/21279] Train loss: 5.59536,Valid loss: 5.62597, time : 11.830445766448975 lr : 1\n",
      "epoch : 0 [35/21279] Train loss: 5.58124,Valid loss: 5.62122, time : 12.11751127243042 lr : 1\n",
      "epoch : 0 [36/21279] Train loss: 5.59511,Valid loss: 5.60367, time : 12.057310819625854 lr : 1\n",
      "epoch : 0 [37/21279] Train loss: 5.56984,Valid loss: 5.60524, time : 15.92680549621582 lr : 1\n",
      "epoch : 0 [38/21279] Train loss: 5.54659,Valid loss: 5.59670, time : 11.190258026123047 lr : 1\n",
      "epoch : 0 [39/21279] Train loss: 5.53822,Valid loss: 5.59437, time : 11.37120509147644 lr : 1\n",
      "epoch : 0 [40/21279] Train loss: 5.54992,Valid loss: 5.59158, time : 11.776246786117554 lr : 1\n",
      "epoch : 0 [41/21279] Train loss: 5.53921,Valid loss: 5.57671, time : 11.379251718521118 lr : 1\n",
      "epoch : 0 [42/21279] Train loss: 5.53284,Valid loss: 5.57469, time : 12.05818772315979 lr : 1\n",
      "epoch : 0 [43/21279] Train loss: 5.50284,Valid loss: 5.55969, time : 11.214769124984741 lr : 1\n",
      "epoch : 0 [44/21279] Train loss: 5.52341,Valid loss: 5.55756, time : 11.725409984588623 lr : 1\n",
      "epoch : 0 [45/21279] Train loss: 5.49992,Valid loss: 5.54656, time : 11.702848672866821 lr : 1\n",
      "epoch : 0 [46/21279] Train loss: 5.49887,Valid loss: 5.55118, time : 11.69465684890747 lr : 1\n",
      "epoch : 0 [47/21279] Train loss: 5.46959,Valid loss: 5.53414, time : 12.087941646575928 lr : 1\n",
      "epoch : 0 [48/21279] Train loss: 5.47224,Valid loss: 5.54516, time : 12.799283981323242 lr : 1\n",
      "epoch : 0 [49/21279] Train loss: 5.47691,Valid loss: 5.52906, time : 14.396468877792358 lr : 1\n",
      "epoch : 0 [50/21279] Train loss: 5.49536,Valid loss: 5.54534, time : 11.440520286560059 lr : 1\n",
      "epoch : 0 [51/21279] Train loss: 5.47170,Valid loss: 5.53269, time : 12.200302124023438 lr : 1\n",
      "epoch : 0 [52/21279] Train loss: 5.48120,Valid loss: 5.53277, time : 11.46939492225647 lr : 1\n",
      "epoch : 0 [53/21279] Train loss: 5.47036,Valid loss: 5.51120, time : 11.693096399307251 lr : 1\n",
      "epoch : 0 [54/21279] Train loss: 5.45675,Valid loss: 5.52150, time : 12.032243728637695 lr : 1\n",
      "epoch : 0 [55/21279] Train loss: 5.44418,Valid loss: 5.50443, time : 11.344359159469604 lr : 1\n",
      "epoch : 0 [56/21279] Train loss: 5.43948,Valid loss: 5.54575, time : 11.387184143066406 lr : 1\n",
      "epoch : 0 [57/21279] Train loss: 5.45798,Valid loss: 5.51942, time : 11.642874479293823 lr : 1\n",
      "epoch : 0 [58/21279] Train loss: 5.46100,Valid loss: 5.51649, time : 11.67667007446289 lr : 1\n",
      "epoch : 0 [59/21279] Train loss: 5.44292,Valid loss: 5.49269, time : 12.158174514770508 lr : 1\n",
      "epoch : 0 [60/21279] Train loss: 5.45611,Valid loss: 5.49036, time : 11.846890926361084 lr : 1\n",
      "epoch : 0 [61/21279] Train loss: 5.43589,Valid loss: 5.47833, time : 11.923168420791626 lr : 1\n",
      "epoch : 0 [62/21279] Train loss: 5.41849,Valid loss: 5.48183, time : 12.348390102386475 lr : 1\n",
      "epoch : 0 [63/21279] Train loss: 5.41207,Valid loss: 5.47065, time : 12.240569591522217 lr : 1\n",
      "epoch : 0 [64/21279] Train loss: 5.41238,Valid loss: 5.50059, time : 12.230053663253784 lr : 1\n",
      "epoch : 0 [65/21279] Train loss: 5.42790,Valid loss: 5.48008, time : 13.962921142578125 lr : 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "from utils import CTCLabelConverter, CTCLabelConverterForBaiduWarpctc, AttnLabelConverter, Averager\n",
    "from dataset import custom_dataset,AlignCollate\n",
    "from model import Model\n",
    "\n",
    "import easydict\n",
    "global opt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "global opt\n",
    "opt = easydict.EasyDict({\n",
    "    \"exp_name\": \"test_01\",\n",
    "    \"train_data\": \"/data/data/STARN/data_lmdb_release/training\",\n",
    "    \"valid_data\":\"/data/data/STARN/data_lmdb_release/validation\",\n",
    "    \"manualSeed\": 1111,\n",
    "    \"workers\": 8,\n",
    "    \"batch_size\":1024,\n",
    "    \"num_iter\":300000,\n",
    "    \"valInterval\":1,\n",
    "    \"saved_model\":'',\n",
    "    \"FT\":False,\n",
    "    \"adam\":False,\n",
    "    \"lr\":1,\n",
    "    \"beta1\":0.9,\n",
    "    \"rho\":0.95,\n",
    "    \"eps\":1e-8,\n",
    "    \"grad_clip\":5,\n",
    "    \"baiduCTC\":False,\n",
    "    \"select_data\":'ST',\n",
    "    \"batch_ratio\":'1',\n",
    "    \"total_data_usage_ratio\":'1.0',\n",
    "    \"batch_max_length\":25,\n",
    "    \"imgW\":100,\n",
    "    \"imgH\":32,\n",
    "    \"rgb\":False,\n",
    "    \"character\":\"0123456789abcdefghijklmnopqrstuvwxyz\",\n",
    "    \"sensitive\":False,\n",
    "    \"PAD\":False,\n",
    "    \"data_filtering_off\":False,\n",
    "    \"Transformation\":\"TPS\",\n",
    "    \"FeatureExtraction\":\"ResNet\",\n",
    "    \"SequenceModeling\":\"BiLSTM\",\n",
    "    \"Prediction\":'Attn',\n",
    "    \"num_fiducial\":20,\n",
    "    \"input_channel\":1,\n",
    "    \"output_channel\":512,\n",
    "    \"hidden_size\":256    \n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def validation(model, criterion, evaluation_loader, converter, opt):\n",
    "    \"\"\" validation or evaluation \"\"\"\n",
    "    n_correct = 0\n",
    "    norm_ED = 0\n",
    "    length_of_data = 0\n",
    "    infer_time = 0\n",
    "    valid_loss_avg = Averager()\n",
    "\n",
    "    for i, (image_tensors, labels) in enumerate(evaluation_loader):\n",
    "        batch_size = image_tensors.size(0)\n",
    "        length_of_data = length_of_data + batch_size\n",
    "        image = image_tensors.to(device)\n",
    "        # For max length prediction\n",
    "        length_for_pred = torch.IntTensor([opt.batch_max_length] * batch_size).to(device)\n",
    "        text_for_pred = torch.LongTensor(batch_size, opt.batch_max_length + 1).fill_(0).to(device)\n",
    "\n",
    "        text_for_loss, length_for_loss = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
    "\n",
    "        start_time = time.time()\n",
    "        if 'CTC' in opt.Prediction:\n",
    "            preds = model(image, text_for_pred)\n",
    "            forward_time = time.time() - start_time\n",
    "\n",
    "            # Calculate evaluation loss for CTC deocder.\n",
    "            preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
    "            # permute 'preds' to use CTCloss format\n",
    "            if opt.baiduCTC:\n",
    "                cost = criterion(preds.permute(1, 0, 2), text_for_loss, preds_size, length_for_loss) / batch_size\n",
    "            else:\n",
    "                cost = criterion(preds.log_softmax(2).permute(1, 0, 2), text_for_loss, preds_size, length_for_loss)\n",
    "\n",
    "            # Select max probabilty (greedy decoding) then decode index to character\n",
    "            if opt.baiduCTC:\n",
    "                _, preds_index = preds.max(2)\n",
    "                preds_index = preds_index.view(-1)\n",
    "            else:\n",
    "                _, preds_index = preds.max(2)\n",
    "            preds_str = converter.decode(preds_index.data, preds_size.data)\n",
    "        \n",
    "        else:\n",
    "            preds = model(image, text_for_pred, is_train=False)\n",
    "            forward_time = time.time() - start_time\n",
    "\n",
    "            preds = preds[:, :text_for_loss.shape[1] - 1, :]\n",
    "            target = text_for_loss[:, 1:]  # without [GO] Symbol\n",
    "            cost = criterion(preds.contiguous().view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
    "\n",
    "            # select max probabilty (greedy decoding) then decode index to character\n",
    "            _, preds_index = preds.max(2)\n",
    "            preds_str = converter.decode(preds_index, length_for_pred)\n",
    "            labels = converter.decode(text_for_loss[:, 1:], length_for_loss)\n",
    "\n",
    "        infer_time += forward_time\n",
    "        valid_loss_avg.add(cost)\n",
    "\n",
    "        # calculate accuracy & confidence score\n",
    "        preds_prob = F.softmax(preds, dim=2)\n",
    "        preds_max_prob, _ = preds_prob.max(dim=2)\n",
    "        confidence_score_list = []\n",
    "        for gt, pred, pred_max_prob in zip(labels, preds_str, preds_max_prob):\n",
    "            if 'Attn' in opt.Prediction:\n",
    "                gt = gt[:gt.find('[s]')]\n",
    "                pred_EOS = pred.find('[s]')\n",
    "                pred = pred[:pred_EOS]  # prune after \"end of sentence\" token ([s])\n",
    "                pred_max_prob = pred_max_prob[:pred_EOS]\n",
    "\n",
    "\n",
    "            if pred == gt:\n",
    "                n_correct += 1\n",
    "\n",
    "            '''\n",
    "            (old version) ICDAR2017 DOST Normalized Edit Distance https://rrc.cvc.uab.es/?ch=7&com=tasks\n",
    "            \"For each word we calculate the normalized edit distance to the length of the ground truth transcription.\"\n",
    "            if len(gt) == 0:\n",
    "                norm_ED += 1\n",
    "            else:\n",
    "                norm_ED += edit_distance(pred, gt) / len(gt)\n",
    "            '''\n",
    "\n",
    "            # ICDAR2019 Normalized Edit Distance\n",
    "            if len(gt) == 0 or len(pred) == 0:\n",
    "                norm_ED += 0\n",
    "            elif len(gt) > len(pred):\n",
    "                norm_ED += 1 - edit_distance(pred, gt) / len(gt)\n",
    "            else:\n",
    "                norm_ED += 1 - edit_distance(pred, gt) / len(pred)\n",
    "\n",
    "            # calculate confidence score (= multiply of pred_max_prob)\n",
    "            try:\n",
    "                confidence_score = pred_max_prob.cumprod(dim=0)[-1]\n",
    "            except:\n",
    "                confidence_score = 0  # for empty pred case, when prune after \"end of sentence\" token ([s])\n",
    "            confidence_score_list.append(confidence_score)\n",
    "            # print(pred, gt, pred==gt, confidence_score)\n",
    "\n",
    "    accuracy = n_correct / float(length_of_data) * 100\n",
    "    norm_ED = norm_ED / float(length_of_data)  # ICDAR2019 Normalized Edit Distance\n",
    "\n",
    "    return valid_loss_avg.val(), accuracy, norm_ED, preds_str, confidence_score_list, labels, infer_time, length_of_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \"\"\" Seed and GPU setting \"\"\"\n",
    "    # print(\"Random Seed: \", opt.manualSeed)\n",
    "    random.seed(opt.manualSeed)\n",
    "    np.random.seed(opt.manualSeed)\n",
    "    torch.manual_seed(opt.manualSeed)\n",
    "    torch.cuda.manual_seed(opt.manualSeed)\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = True\n",
    "    opt.num_gpu = torch.cuda.device_count()\n",
    "    # print('device count', opt.num_gpu)\n",
    "    if opt.num_gpu > 1:\n",
    "        print('------ Use multi-GPU setting ------')\n",
    "        print('if you stuck too long time with multi-GPU setting, try to set --workers 0')\n",
    "        # check multi-GPU issue https://github.com/clovaai/deep-text-recognition-benchmark/issues/1\n",
    "        opt.workers = opt.workers * opt.num_gpu\n",
    "        opt.batch_size = opt.batch_size * opt.num_gpu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    numclass_path = \"./ch_range.txt\"\n",
    "    f = open(numclass_path, 'r')\n",
    "    ch_temp = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    opt.character = ch_temp\n",
    "\n",
    "    converter = AttnLabelConverter(opt.character)\n",
    "    opt.num_class = len(converter.character)\n",
    "\n",
    "\n",
    "    train_dataset = custom_dataset(\"./dict/nia_refine_concat.txt\",\"./font_full\",\"train\")\n",
    "    valid_dataset = custom_dataset(\"./dict/nia_refine_concat.txt\",\"./font\",\"valid\")\n",
    "\n",
    "    AlignCollate_valid = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=opt.batch_size,\n",
    "            shuffle=True,  # 'True' to check training progress with validation function.\n",
    "            num_workers=int(opt.workers),\n",
    "            collate_fn=AlignCollate_valid, pin_memory=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=opt.batch_size,\n",
    "            shuffle=True,  # 'True' to check training progress with validation function.\n",
    "            num_workers=int(opt.workers),\n",
    "            collate_fn=AlignCollate_valid, pin_memory=True)\n",
    "\n",
    "\n",
    "    if opt.rgb:\n",
    "        opt.input_channel = 3\n",
    "    model = Model(opt)\n",
    "\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'localization_fc2' in name:\n",
    "            print(f'Skip {name} as it is already initialized')\n",
    "            continue\n",
    "        try:\n",
    "            if 'bias' in name:\n",
    "                init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                init.kaiming_normal_(param)\n",
    "        except Exception as e:  # for batchnorm.\n",
    "            if 'weight' in name:\n",
    "                param.data.fill_(1)\n",
    "            continue\n",
    "\n",
    "\n",
    "    model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "\n",
    "    loss_avg = Averager()\n",
    "\n",
    "\n",
    "    filtered_parameters = []\n",
    "\n",
    "    for p in filter(lambda p: p.requires_grad, model.parameters()):\n",
    "        filtered_parameters.append(p)\n",
    "\n",
    "\n",
    "    if opt.adam:\n",
    "#         optimizer = optim.Adam(filtered_parameters, lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "        optimizer = optim.Adam(filtered_parameters, lr=opt.lr)\n",
    "    else:\n",
    "        optimizer = optim.Adadelta(filtered_parameters, lr=opt.lr, rho=opt.rho, eps=opt.eps)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
    "    \n",
    "    nb_epochs = 100000\n",
    "\n",
    "    for epoch in range(nb_epochs + 1):\n",
    "        \n",
    "        for batch_idx, samples in enumerate(train_loader):\n",
    "\n",
    "            log = open(f'./log_val.txt', 'a')\n",
    "            log2= open(f'./log_train.txt', 'a')\n",
    "\n",
    "            start_time = time.time()        \n",
    "            model.train()\n",
    "\n",
    "            image_tensors, labels = samples\n",
    "            image = image_tensors.to(device)\n",
    "            text, length = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            preds = model(image, text[:, :-1])  # align with Attention.forward\n",
    "            target = text[:, 1:]  # without [GO] Symbol\n",
    "            cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
    "\n",
    "\n",
    "\n",
    "            model.zero_grad()\n",
    "            cost.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip)  # gradient clipping with 5 (Default)\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_avg.add(cost)\n",
    "\n",
    "            for param_group in optimizer.param_groups:\n",
    "                learning_rate_val=param_group['lr']\n",
    "\n",
    "\n",
    "            ## 평가\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                valid_loss, current_accuracy, current_norm_ED, preds, confidence_score, labels, infer_time, length_of_data = validation(\n",
    "                            model, criterion, valid_loader, converter, opt)\n",
    "\n",
    "            end = time.time()\n",
    "            loss_log = f'epoch : {epoch} [{batch_idx}/{len(train_loader)}] Train loss: {loss_avg.val():0.5f},Valid loss: {valid_loss:0.5f}, time : {end-start_time} lr : {learning_rate_val}'        \n",
    "            loss_avg.reset()\n",
    "\n",
    "\n",
    "            print(loss_log)\n",
    "\n",
    "            dashed_line = '-' * 80\n",
    "            head = f'{\"Ground Truth\":25s} | {\"Prediction\":25s} | Confidence Score & T/F'\n",
    "            predicted_result_log = f'{dashed_line}\\n{head}\\n{dashed_line}\\n'\n",
    "            for gt, pred, confidence in zip(labels[:5], preds[:5], confidence_score[:5]):\n",
    "                if 'Attn' in opt.Prediction:\n",
    "                    gt = gt[:gt.find('[s]')]\n",
    "                    pred = pred[:pred.find('[s]')]\n",
    "\n",
    "                predicted_result_log += f'{gt:25s} | {pred:25s} | {confidence:0.4f}\\t{str(pred == gt)}\\n'\n",
    "            predicted_result_log += f'{dashed_line}'\n",
    "    #         print(predicted_result_log)\n",
    "            \n",
    "            log2.write(loss_log + '\\n')\n",
    "            log.write(loss_log + '\\n')\n",
    "            log.write(predicted_result_log + '\\n')\n",
    "            log.close()\n",
    "            log2.close()\n",
    "            \n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eaf713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
